[
  {
    "section_name": "SMPTE Conferences",
    "json_creation_date": "2025-March-05",
    "years": [
      {
        "year": "2023",
        "conferences": [
          {
            "conference_name": "SMPTE 2023 Media Technology Summit",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "Breaking the Fourth Wall through Extended Reality",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jason S. Kao",
                    "Karen Kao"
                  ],
                  "abstract": "Filmmakers pursue a goal of a more absorbing and powerful sensory viewing experience through implementing advanced technologies. With the thriving of extended reality (XR), an XR revolution in the entertainment industry has been initiated by practitioners. This article reviews cinematic realism from aspects of photorealism, the phenomenal S3D cinema, and its unfulfillments for the immersive experience, and elaborates the XR trend by specifying the potential of implementing augmented reality (AR) as a medium for a new level of cinematic realism. AR's feature of presenting virtual imaging in the physical world provides a solid foundation for an extended dimension over the viewing screen. This article introduces the concept of augmented dimension (AD) that implements augmented reality as the out-of-screen visual effects to explore the perceptual realism in cinematic experiences. Compared with stereoscopic 3D films, the three-dimensional perception in AD can be considered as perceptual realism rather than photorealism. This article also illustrates the proposed pipeline to produce AD films and concludes the potential of AD for the future immersive cinema.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Augmented reality",
                      "cinematic realism",
                      "immersion cinema",
                      "augmented dimension"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001994"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Unlocking the Value of Media Libraries With AI and ML",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jason Perr"
                  ],
                  "abstract": "In the dynamic landscape of the media and entertainment industry, the quest for efficiency and optimization is perpetual. As we stand on the cusp of a new era, AI and ML technologies promise to revolutionize the way we handle, process, and monetize media content. The challenges are evident, but so are the solutions, provided we know where to look.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001999"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Cameras and LED walls - A challenging relationship",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Klaus Weber"
                  ],
                  "abstract": "LED walls have become an important part of scene design in many media and entertainment applications, but LED walls are also being used more and more for virtual backgrounds and similar applications. — However, there are several challenges in combination with cameras that often make it difficult to achieve an optimal result. A fundamental problem is that both the LED walls and the image sensors in the cameras use discrete pixel structures, which in certain cases can lead to interference between those two structures, so depending on the application, certain camera positions and image settings must be avoided, which in turn can lead to unwanted limitations in the image composition. There are limited ways to minimize this potential interference with a given LED wall, but on the camera side there are some ways to get the best possible result through optimized optical pre-filtering. However, the extent of the problem depends heavily on the camera technology used. Cameras that have the same resolution for all three colors offer significantly more possibilities to enable the best possible optical pre-filtering for the circumstances. — In addition, new applications, especially in VR and AR, where the LED wall is operated at an increased frame rate, pose completely new challenges for image capture technology. For these challenges, it is of crucial importance that the image sensors in the camera have a global shutter, because this is the only way to expose and read out all image elements simultaneously in a short-time exposure. Additionally, there are possibilities, especially on the camera side, to create a smoother and easier integration of cameras into the production environment. For example, through new functionalities such as the implementation of a delay circuit between the image sensors and signal processing for shifting the exposure moment. — The paper addresses the challenges and potential solutions that arise from pixel structures, as well as the specific challenges and potential solutions that arise from increased refresh rates.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LED wall",
                      "CMOS imagers",
                      "pixel",
                      "OLPF",
                      "alias",
                      "PLS",
                      "VR",
                      "AR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002006"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "The evolution of delivering immersive media over 5G/Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mauricio Aracena",
                    "Bill Redmann",
                    "Du Ho Kang",
                    "Ing. Louay Bassbouss",
                    "Sebastian Schwarz"
                  ],
                  "abstract": "Aspects of the 5G ecosystem, now being deployed in 3GPP releases 17/18/19, include split processing and edge computing resources. These can be enlisted to offload manipulation and rendering of immersive datasets, thereby reducing the burden on the mobile device. Instead, the mobile device receives only the rendered video, for one or both eyes, ready-made for display by the headset. — Key design criteria for 5G connectivity to near-edge compute resources have been established based, in large part, on augmented and mixed reality use cases that rely on network slicing and quality of service (QoS) management, impose limits on bidirectional communication latencies, and establish minimum requirements for the compute resources themselves. Additionally, 5G system is becoming “XR aware” with a specific set of features for XR offloading. These features provide not only the proper network requirements, but also additional intelligence to consider device power and capacity considerations critical to scaling the deployment of XR services. — This paper describes the evolution of XR applications from merely delivering media over 5G to how to best utilize 5G cloud/edge infrastructure to process and distribute advanced immersive experiences and content to lightweight, wireless, head-mounted displays. Critical use cases impose clear network requirements and how those are met in 5G is examined. Lastly, the shape of potential relationships within the stakeholder ecosystem are presented, all with the goal of guiding content providers (developers and service providers) through the paradigm shift from device-centric to network-centric XR services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "5G",
                      "virtual reality",
                      "augmented reality",
                      "mixed reality",
                      "VR",
                      "AR",
                      "MR",
                      "immersive",
                      "XR",
                      "network slice",
                      "edge compute",
                      "edge render",
                      "cloud gaming",
                      "hyperscale cloud provider",
                      "communication service provider"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002007"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Using Knowledge Graphs to Enhance Queries over Heterogeneous Asset Stores",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roger Sacilotto",
                    "Shailendra Mathur",
                    "Rob Gonsalves"
                  ],
                  "abstract": "As media organizations accumulate diverse data from various sources, the need for effective data integration and information retrieval becomes increasingly critical. Graph databases offer a flexible and efficient platform for integration by leveraging graph-based data models and querying mechanisms. Graph databases can seamlessly integrate disparate data sets regardless of their original format or structure. Knowledge can be added to the graph through the application of semantic meaning to the data. Knowledge graphs can be enhanced with results of Machine Learning algorithms that extract additional information from the underlying data. This paper will demonstrate how knowledge graphs offer unique capabilities for understanding patterns over collections of large data sets.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Knowledge Graphs",
                      "Data Integration",
                      "Semantic Understanding",
                      "Machine Learning"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002010"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Long-term Preservation of Cinematographic Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Siegfried Foessel",
                    "Heiko Sparenberg",
                    "Nikolai Belevantsev",
                    "Yi Lou"
                  ],
                  "abstract": "With the cessation of analogue film as distribution medium for cinematographic content, its use as a storage medium was also abandoned. This created new challenges in the long-term preservation of cinema movies - now in its digital form. AMPAS drew attention to this in the two reports “The Digital Dilemma” in 2007 and 2012. — While storage capacities have continued to grow and are no longer the biggest problem, the increasing variety but also the rapid obsolescence of digital formats remains a hot topic. For this reason, a new European standard has been developed to address this issue. This paper presents the requirements, considerations and solutions discussed during the standardization project. It explains the system architecture, formats, and elements of a “preservation package” and the criteria for selecting specific metadata within the new standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Long-term preservation",
                      "metadata",
                      "DCP",
                      "file formats"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001997"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Exploring Workflows for Real-Time HDR-SDR Conversion",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "India Fleuchaus",
                    "Justus Mai",
                    "Lasse Bickelmann",
                    "Romy Walcher",
                    "Justin Janben",
                    "Kevin Felkel",
                    "Jan Frohlich"
                  ],
                  "abstract": "Due to the growing demand for high quality imaging in the movie industry as well as in broadcasting environments, research on high dynamic range (HDR) technologies is enhanced more and more. The incentive for the great interest in HDR content is particularly based on properties such as natural reproducibility of a scene containing the approximate dynamic range of real-world brightness distribution, a broader color spectrum and a more intense spaital depth in the image. Especially in the broadcast-related scope there is still potential to further develop and improve HDR technology. As not every end user has an HDR-compatible device as of now, methods are needed to map high dynamic range content to standard dynamic range (SDR) including transfer function and color gamut. Considering usually demanded real-time HDR-SDR conversion workflows, conventional mappers often produce an unaesthetic and unnatural look due to color hue shifts, flat brightness distribution or unnatural looking skin tones, which causes loss of the creative intent of images especially but not only in context of intense lighting effects. — On that account, the research team has set themselves the goal of analyzing existing mapping algorithms for a real-time broadcast use case in a show context. To properly test and apply the used algorithms on HDR video footage, a new dataset of HDR show content is produced. The insights of this comparison are depicted and explained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "High Dynamic Range",
                      "PQ",
                      "SDR",
                      "Dynamic Range",
                      "Brightness",
                      "Live Broadcast Production",
                      "Television",
                      "Broadcast Engineering",
                      "Film",
                      "Motion Picture",
                      "HDR-SDR Conversion"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001993"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Enhancements to Media Transport in ICVFX using SMPTE 2110",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alejandro Arango",
                    "Simon Therriault",
                    "Andrey Yamashev"
                  ],
                  "abstract": "In this paper, we propose an enhancement to clustered rendering for In-Camera Visual Effects (ICVFX) that leverages the quality, low latency, and timing guarantees in SMPTE 2110, a standard for professional media over managed IP networks. — We show how SMPTE 2110 can be used to multicast multiple camera views of variable or overscanned resolutions, each rendered by dedicated camera render nodes, and received by the collection of render nodes in the cluster that warp and compose it on top of the rendered out-of-camera pixels, resulting in a more efficient, scalable, and higher performing rendering cluster. Since the pixels are now transported between render and composer nodes, we describe techniques to mitigate, and in some cases completely hide, the time required to multicast the pixels over the network, resulting in no added frame latency. — We also demonstrate that the final pixels can then be output via SMPTE 2110 to synchronously drive each section of the LED wall, which results in low latency, simplified and more flexible hardware setup that also unifies the media transport strategy in an ICVFX stage. We show how SMPTE ST 2110 and IEEE-1588 Precision Time Protocol (PTP) with SMPTE ST 2059 enable the ability to synchronize the video output of the multiple render nodes that drive an LED wall, ensuring temporal coherence and spatial alignment of the virtual scene. We explain the clustered media output genlock and framelock algorithm and demonstrate the benefits of our approach with a proof-of-concept implementation and some experimental results. — Find our implementation in the Unreal Engine source code: https://www.unrealengine.com/en-US/ue-on-github",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Virtual Production",
                      "ICVFX",
                      "Visual Effects",
                      "LED Wall",
                      "Multicast",
                      "Inner Frustum",
                      "Framelock",
                      "PTP",
                      "IEEE-1588",
                      "ST 2110",
                      "ST 2059"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001996"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Atheneum: The Blockchain That Manages Theatrical Releases",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Diehl"
                  ],
                  "abstract": "Managing theatrical releases is a complex, crucial business task. Proper management is a crucial factor in success. Unfortunately, this management is currently ad-hoc and non-optimal. — Blockchain is a secure distributed ledger that may offer a collegial, efficient, cost-effective solution. — Atheneum is a permissioned blockchain that manages the titles and releases of all studios. It hands the distribution rights to the distributors. The smartcontracts enforce that release dates and territories comply with the business rules. Atheneum implements a Decentralized Autonomous Organization (DAO) to streamline the enrolment and revocation of entities. — Using open-source Hyperledger Fabric, Atheneum perfectly illustrates how blockchain technology can benefit the media industry outside of cryptocurrencies and non-fungible tokens (NFT).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Blockchain",
                      "DAO",
                      "smartcontract",
                      "theatrical release",
                      "Hyperledger",
                      "Atheneum"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001998"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Real-time Personalized Ranking and Recommendation System for Linear TV: A Dual Dynamic Queue Approach",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ning Xu",
                    "Tao Chen"
                  ],
                  "abstract": "The increasing number of channels on linear TV has amplified the challenge of efficient content discovery for viewers. This paper presents an innovative, real-time personalized ranking and recommendation system designed to address this problem. The objective was to enhance viewer satisfaction and interaction through a personalized, dynamic channel surfing experience. Our approach uses a dual dynamic queue system - the Dynamic History Channel Queue (DHCQ) and the Dynamic Future Channel Queue (DFCQ), each serving a unique purpose in managing the viewer's channel interaction. — Advanced deep learning models reinforce these queues’ dynamism by generating ‘global’ and ‘local’ content embeddings and ‘user’ embeddings. These embeddings are used to provide real-time updates, considering both timestamps and the time-sensitivities of the content and viewer. A ‘look- ahead’ feature was integrated to account for future content on each channel, adding another layer of personalization. — Preliminary user feedback highlighted a strong interest in this new form of personalized channel surfing, with a majority of respondents indicating a preference for our system over traditional channel navigation methods. The results show that our proposed solution could potentially change the way users interact with the ever-growing number of channels on linear TV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Linear TV",
                      "Channel Ranking",
                      "Channel Surfing",
                      "Real-time Personalization",
                      "Dynamic Queues",
                      "User Preferences",
                      "Personalized Content Delivery"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002000"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Hyperconverged Design: Reducing the Environmental Impact of Production Technologies Throughout the Product Lifecycle",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alun Fryer",
                    "Amanda Holtstrom"
                  ],
                  "abstract": "The production industry is experiencing mounting pressure to deliver more content on more platforms which is leading content producers to software and cloud-based solutions, serving on- demand, OTT delivery. However, this growth in content and IP-based delivery methods come at an environmental cost both in terms of energy consumption and the complexity of equipment. The hyperconverged design approach combines production capabilities into a single product and offers engineers and designers immediate ways to reduce a product's environmental impact while simultaneously simplifying its deployment, management, and operation. Throughout the product lifecycle, from design to disposition, hyperconverged products can support the media and entertainment industry in achieving sustainability targets, which protects and conserves the environment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Hyperconverged",
                      "product design",
                      "sustainability",
                      "energy consumption",
                      "mass",
                      "tonne- kilometer"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001995"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Cloud-based Internet Linear Video Delivery System Using Edge Computing on CDN",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daiki Fukudome",
                    "Satoshi Nishimura"
                  ],
                  "abstract": "Internet users are increasingly exposed to linear streaming services. Unlike television (TV) broadcasting, there is no limit to the number of channels that can be delivered via linear streaming services. Considering regions and various viewer preferences, several linear delivery platforms on cloud are being developed to efficiently provide various channels. In such platforms that use HTTP adaptive streaming (HAS), programs are scheduled in a manipulated manifest file. However, when an urgent program is dynamically inserted, the aforementioned approach requires complex implementations on the server and player sides to ensure reliable and rapid program switching, especially in low latency delivery because all the players’ manifest files must be quickly updated. Thus, we propose a cloud-based HAS linear delivery system that utilizes edge computing within the content delivery network (CDN) to facilitate prompt schedule changes. By shifting away from manifest manipulation or baseband switching used in TV broadcasting systems, the proposed approach offers quick adaptations to urgent schedule changes and efficient delivery of addressable linear streaming channels. This study presents an end-to-end system that focuses on the efficient use of cloud resources for encoding, program switching at pre-scheduled times by leveraging the CDN's edge capabilities, and simple low-latency playback. Moreover, the prompt realization of program schedule changes, particularly in scenarios involving dynamic urgent program insertions, and the replacement of certain programs based on viewers’ attributes on CDN edge, are addressed. By utilizing CDN edge computing, the cloud-based system offers dependable program switching to efficiently deliver localized or personalized channels.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Linear streaming",
                      "HTTP adaptive streaming (HAS)",
                      "dynamic adaptive streaming over HTTP (DASH)",
                      "common media application format (CMAF)",
                      "content delivery network (CDN)",
                      "CDN edge computing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002003"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Green Video Compression for Metaverse: Lessons Learned from VP9 and HEVC",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Natalia Molinero Mingorance"
                  ],
                  "abstract": "Unprecedented growth in video consumption applications has been witnessed over the past decade, and new heights are now being reached with the emergence of the metaverse. As the metaverse expands, a substantial increase in the volume of digital data and the computational load on networks, data centers, and user devices is brought along. This continuous processing of information leads to significant energy consumption, resulting in a staggering amount of CO2 emissions annually. To address this challenge, the development of lightweight video compression algorithms that can effectively reduce file sizes and facilitate efficient transmission over the Internet needs to be prioritized. However, the desired level of efficiency cannot be achieved by current standards. In this study, a comprehensive analysis of the most resource-intensive task, Motion Estimation (ME), is conducted in two state-of-the-art compression algorithms used for metaverse videos: VP9 and HEVC. An implementation in Matlab that centers on the ME process of both algorithms has been developed for an exhaustive performance evaluation, allowing for an objective comparison. Furthermore, novel approaches were incorporated into the code to assess sustainability factors. The insights gained from this analysis shed light on key areas that require improvement in future video compression algorithms, paving the way for sustainable and optimized video storage and transmission in the metaverse.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "metaverse",
                      "motion estimation",
                      "sustainability",
                      "VP9"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002002"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Testing 4K HDR-WCG professional video content for subjective quality using a remote testing approach",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anustup Choudhury",
                    "Lukas Krasula",
                    "Scott Daly",
                    "Zhi Li",
                    "Robin Atkins",
                    "Ludovic Malfait"
                  ],
                  "abstract": "Modern content is rapidly shifting from the standard dynamic range (SDR) color volume defined in ITU-R BT.709 towards the high dynamic range and wide color gamut (HDR-WCG) color volume defined in ITU-R BT.2100. For optimizing delivery channels of this content it is crucial to have high performance video quality metrics. However, existing subjective databases used to design and qualify such video quality metrics do not provide adequate test coverage for professional HDR-WCG video content. In this paper we describe a subjective video quality study aimed to be relevant for existing as well as near future HDR-WCG. — Due to the Covid pandemic, the experiment was designed for remote testing, rather than a typical laboratory environment. We carefully analyzed the subjective results and concluded that it is possible to obtain comparable reliability of data in our remote testing environment with a controlled laboratory environment. This opens the door for large-scale video quality testing, enabling continual refinement of video quality metrics, reducing the turn-around time for subjective testing, and eliminating bias in the training data by accessing a much larger and more diverse set of users. — We applied the subjective data set to compare existing image/video quality metrics such as VMAF, HDR-VDP and HDR-VQM. Furthermore, we identified several ways the VMAF metric can be adjusted to improve its accuracy on HDR-WCG content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "Visual Quality metric",
                      "Subjective study",
                      "Contrast Sensitive Function"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002001"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Development of Cloud-Based Media Production Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jae-young Lee",
                    "Soonchoul Kim",
                    "Hye-Ju Oh",
                    "Jae Ho Lee",
                    "In Joon Cho"
                  ],
                  "abstract": "This paper presents development of cloud-based media production systems. For real-time process of high quality live media, the developed system includes the following key technical components: IP (Internet Protocol) media gateway, cloud-based media switcher, device management and control scheme for remote environments, and deep learning method for automated production. The hardware-developed IP media gateway is designed to be interoperable with various media data formats in the industry and efficiently deliver the media data over IP networks. In the developed cloud platform, the cloud-based media switcher is implemented for real-time live media process when multiple camera video sources are delivered through IP networks. The device management and control scheme is introduced adopting a messaging protocol known as MQTT (Message Queuing Telemetry Protocol) in order to support efficient and reliable delivery of control and connection information over remote environments. Finally a deep learning method applied to a media switcher is presented to provide possible automation in media production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media Production",
                      "IP",
                      "Cloud",
                      "Media Gateway",
                      "Wide Area Network",
                      "Deep Learning"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002005"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Using Categorical Observers to Minimize Metameric Failures on Wide Color Gamut Displays",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Catherine Meininger",
                    "Liam Lynch",
                    "Allison Hazebrouck",
                    "Andy Masia",
                    "Tom Lianza"
                  ],
                  "abstract": "It is common industry practice to calibrate displays using measurement data based on the CIE-1931 2° Standard Observer color-matching function (CMF) to represent the human visual system response. Anecdotal observations, with some experimental evidence, have shown that adjusting two displays with different spectral power distributions to the same CIE-1931 tristimulus values (TSVs) produces a calibration that is not a visual match for some, if not all, human observers. In other words, displays adjusted so that they should produce metameric matches do not do so. — Research shows that this is due to deviations in CMFs between observers that also differ from the CIE-1931 2° Standard Observer; and that populations of observers can be clustered into categories, each of which have largely similar CMFs. It may be that selection of an appropriate alternate set of CMFs for any given color grader, cinematographer, color editor, or others making critical color judgments or adjustments across spectrally dissimilar displays may reduce metameric failures and increase productivity throughout a motion-picture workflow. — This paper presents results from a psychophysical study to determine if there is a “best-match” CMF for a real human observer from Asano and Fairchild's 10 categorical observers that reduces metameric failures between 2 displays that have significantly different spectral power distributions. The results are further analyzed to support a discussion about the practical implementation of categorical observer transforms in a motion-picture workflow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Metamerism",
                      "observer metamerism",
                      "color-matching functions",
                      "categorical observers",
                      "color calibration",
                      "color management"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002019"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Avid DNx GX - A High-Quality, Flexible RGB(A) Codec at Commodity Bitrates, Combining SMPTE ST 2019-1 (VC-3) and SMPTE RDD 50 (DNxUncompressed)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Markus Weber"
                  ],
                  "abstract": "When the tunable compression feature from the QuickTime Animation codec was withdrawn, it left behind a gap in its wake which animators have been struggling to fill with alternatives. The natural first choice, commodity video codecs, leads to color deterioration at sharp edges when applied to broadcast graphics, virtual productions/volumes, VFX exchange, augmented graphics, or motion graphics. The root cause can be found in using YCBCR sub-sampling as part of the compression, even if the original imagery was in RGB. These artifacts are usually deemed acceptable if the graphic is directly transmitted. Not, however, if further image processing (warping, blending, compositing) is required. — The artifacts can be avoided by using an RGB-based compression approach. — Largely unknown, the 444 mode (12/10 bit) of SMPTE VC-3 (ST 2019-1), which supports RGB- based compression, is adjustable to target bitrates down to about 20:1 compression. With a minor modification it can also be applied to 8-bit levels for even better quality at the same bitrate. The compressed images show vastly superior visual quality when compared to the same image compressed using YCBCR 4:2:2 at the same target bitrate. — The compressed results can be packed into a DNxPacked bitstream format, which is defined in Part 1 of SMPTE RDD 50. This allows combining the RGB compressed filler with a RLE compressed alpha channel of completely independent bit depth, bypassing the VC-3 limitation requiring the alpha channel to use the same bit depth as the filler.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VC-3",
                      "RDD 50",
                      "RGB compression",
                      "alpha channel",
                      "tunable bitrate"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002020"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Making Film Grain Great Again: Introducing AV1-Compatible Film Grain Modeling for Existing HEVC-Based Video Codecs",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dan Grois",
                    "Alex Giladi",
                    "Thomas Guionnet",
                    "Thomas Burnichon",
                    "Nikolay Tverdokhleb",
                    "Mickael Raulet"
                  ],
                  "abstract": "Recently, film grain applications started to gain a lot of popularity due to an increasing demand for natural visual appearance, in the light of a dramatically increasing amount of artificially generated content. Film grain is spatially random in nature, similarly to noise, while its physical size can vary as well. In addition, film grain is independent in a temporal domain, thereby making it inherently difficult to compress for conventional video encoders. — Therefore, in order to improve a video coding gain it is desirable to remove the film grain prior to encoding, and then to add it back after decoding and prior to display as a post-processing step, thereby leading to significant bitrate savings. This approach was successfully incorporated by Alliance for Open Media (AOM) within its proprietary AV1 coding scheme as a normative process, starting from its 1st version (AV1 v1.0) in 2018. — In this work, the AV1-compatible film grain modeling for the H.265/MPEG-HEVC based video codecs has been carried out to efficiently utilize the existing AV1 film grain post-processing support. This is done by providing the estimated film grain parameters within the ITU-T Recommendation T.35 (ITU-T T.35) Supplemental Enhancement Information (SEI) message. According to the extensive experimental results conducted on popular cinematic content, very significant bitrate savings are achieved for substantially the same subjective video presentation quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "film grain",
                      "video compression",
                      "coding efficiency",
                      "video coding gain",
                      "HEVC",
                      "AOM",
                      "AV1",
                      "H.265",
                      "visual quality",
                      "subjective quality assessment"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002021"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Getting comfortable with CIE charts for color grading",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lakshmanan Gopishankar"
                  ],
                  "abstract": "A common task in color grading in post is to grade to one gamut while constraining to another. Example, grade to ITU-R BT.2020 but constrain to DCI-P3. If colorists can quantitatively determine the excursions of colors from the gamut of interest, they can then either remap the colors or allow them to clip at the gamut boundary. Currently, this work is handled using a combination of legacy tools and monitoring with reference monitors. This can be time consuming and prone to errors. — The CIE chromaticity chart provides a 2D view of chromaticity content of the image. Traditionally, the CIE chart has been a mystery relegated to academic textbooks and used by those with deep knowledge of color science. This paper presents innovations based on deriving useful data from the CIE chart that helps colorists quickly determine how far off colors are from the gamut of interest. — The Gamut Excursion Measurement (GEM) effectively unrolls the CIE chart and presents a quantitative snapshot of the gamut excursions outside a gamut of interest as a 2D linear chart over the spectrum of colors, thus helping to quickly identify regions of interest to focus on. The excursions can then be visualized (using the GEM data) with a multi-level false color heat map. Luminance Qualified CIE is a method of constraining the CIE chart against luminance, allowing users to study colors within specific luminance ranges of interest. Combinations of the above tools provide fast, effective techniques for color grading.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CIE",
                      "color grading",
                      "false color",
                      "gamut boundary",
                      "region of interest",
                      "luminance qualified",
                      "Gamut Excursion Measurement",
                      "GEM"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002024"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Reducing Cinema Projectors Power Consumption using Global Dimming and Image Statistics",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ronan Boitard",
                    "Nusrat Mehajabin",
                    "Anders Ballestad",
                    "Gerwin Damberg"
                  ],
                  "abstract": "Digital cinema projectors illuminate giant screens, offering audiences the best immersive and social experience. Thanks to design improvements and full RGB laser light sources, recently released cinema projectors consume much less power and have a lower cost of ownership than previous generation systems. However, ongoing rise in energy costs still challenges the sustainability of commercial theaters. — To improve the power efficiency of displays, global dimming features are now being implemented in many consumer TVs and projectors. Global dimming of a display's light source not only leads to power savings but also improves the black level in scenes with limited bright features. Depending on the implementation, Global Dimming can either faithfully reproduce any content or trade accuracy for increased power savings. — In this article, we simulate the expected power savings of Global Dimming in cinema under various scenarios. Results show that limited power savings is to be expected when the input content is faithfully reproduced. Enabling the rendering of a limited number of pixels (using a percentile) greatly increases the power savings at the risk of creating visual artifacts. Combining limited rendering with refreshing dimming only at shot intersection seems to be the most promising approach, as it enables significant power savings while maintaining artifact-free rendering. Despite these promising results, implementing such an approach faces several workflow and distribution hurdles that need to be solved. Combining global dimming and lightsteering technology, where light can be used much more efficiently, could lead the way to significant power savings for exhibitors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Power consumption",
                      "Digital Cinema",
                      "Global Dimming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002025"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Advanced Volumetric Video Format for Enhancing Photo-realistic Lighting Reproduction",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yuma Wakahara",
                    "Toshie Misu",
                    "Kensuke Hisatomi"
                  ],
                  "abstract": "This study proposes a volumetric capturing studio, called NHK Meta Studio, that can acquire various material attributes and light-field parameters to enable photo-realistic relighting. Volumetric videos captured from Meta Studio comprise a multidimensional extended point cloud for each frame, and hence, have large amounts of data. Although it is possible to export all parameters into existing formats, the large amounts of data make this approach less optimal. Therefore, we propose a hierarchical volumetric video format that comprises base and enhancement layers. The base layer is designed for compatibility with the existing format and rendering for a simple relighting method. The uncompressed base-layer format is represented in the Stanford triangle format (.ply) and the compressed base layer is used for an extension of the MPEG volumetric video format called visual volumetric video-based coding (V3C). As a conventional file format is adopted, integration with existing 3D applications becomes easy. The enhancement layer includes the other components and the advanced rendering shader program, which enables us to fully utilize our advanced photo-realistic rendering method; however, full real-time rendering is still under development. Prior to full real-time rendering, we developed an efficient rendering system for the base layer. This system was verified for integration with game engines. Even real-time rendering using full information is not accomplished, real-time rendering will make it possible to make wide use of Meta Studio's volumetric data.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "olumetric videos",
                      "rendering",
                      "shading",
                      "virtual video production",
                      "immersive",
                      "point cloud",
                      "free- viewpoint",
                      "XR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002011"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Advanced application of NMOS specifications for resource sharing in IP production systems and studio design",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ikumi Endo",
                    "Akiko Kagawa",
                    "Kazuyuki Arai"
                  ],
                  "abstract": "At NHK, the first IP studio adopting SMPTE ST 2110 standards was set up in the NHK Hiroshima Broadcasting Station in March 2023. In addition, seven IP studios will be set up in NHK's new Tokyo office complex scheduled to be open in 2026, and the plan there is to improve the equipment utilization rate through resource sharing of cameras, video servers, subtitle system, etc. among those studios. We have developed the following three elemental technologies that are needed for resource sharing. — 1. Each studio must receive and control only the resources that can be used for program production. To allocate exclusive NMOS IS-05 control of a media stream, we developed a mechanism to re-register any shared resources registered in the primary Registration & Discovery System (RDS) in the secondary RDS attached to each sub-control room. This makes it possible to reference (IS-04) and control (IS-05) only registered resources from each studio's controller. — 2. In the new IP studios, the resolution of the video stream should be switchable between 2K or 4K according to the program. To dynamically control switch bandwidth, we developed an application that references Session Description Protocol (SDP) to enter each multicast flow and bandwidth into a database and that dynamically rewrites the Non-Blocking Multicast (NBM) table of a Cisco network switch. This enables dynamic bandwidth control in accordance with changes in device resolution (4K/2K) = bit rate. — 3. Longitudinal Time Code (LTC) is important for searching edit points of multiple materials, though it may not be synchronized appropriately in an IP-based system. We developed a mechanism for adding an appropriate amount of delay based on the combination of ancillary data (ST 2110-40), video (ST 2110-20), and audio (ST 2110-30). This enables the timing of video and audio streams to be dynamically adjusted in an IP system in which each path has a different delay.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NMOS",
                      "resource sharing",
                      "multi-vendor system",
                      "access management",
                      "exclusive control",
                      "bandwidth control",
                      "Non-Blocking Multicast",
                      "lip sync"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002004"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Free the voice! Systems, Devices and Methods for Multi-Dimensional Spatial Recording and Playback",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rafael Chinchilla"
                  ],
                  "abstract": "This proposal tries to answer the need to free the movement of the voice of the characters in the surround soundscape, following the action or the creative needs of a movie. — The system makes use of a series of sensors and receivers on location that allows the recording of the real time position of a sound source and its relationship with the camera. During postproduction, this data is applied to the individual tracks to recreate the same spatial relationships in a three- dimensional soundscape. Since the data is recorded separately from the audio, it can be applied to the dubbed versions of the film. — A second problem we face is that all the detailed work the sound engineers do to recreate the acoustics of a given space -the location of a scene- by the means of adding reverb or a particular equalization, is lost in the foreign language versions of the film. — The system is also a method to define a physical space by its acoustic characteristics, information that can be incorporated further down the postproduction process and in the exhibition and streaming phases and taylor it to the unique environment of the final user.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Film sound",
                      "Surround sound",
                      "3D soundscape",
                      "Acoustics",
                      "Multi-dimensional sound",
                      "Spatial data",
                      "Sound mix",
                      "Dubbing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002012"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Improving Context-Aware Encoding by Adaptation to “True Resolution” of the Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yuriy Reznik",
                    "Karl Lillevold",
                    "Abhijith Jagannath",
                    "Nabajeet Barman"
                  ],
                  "abstract": "As well known, when the input video is upscaled, the effectiveness of its transcoding and delivery may suffer. The encoded stream may not look sharp and use more bits than necessary.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video resolution detection",
                      "context-aware encoding",
                      "CAE",
                      "ABR streaming",
                      "DASH",
                      "HLS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002015"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Simplifying Multi-CDN Delivery with HLS / DASH Content Steering",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yuriy Reznik",
                    "Adam Waldron",
                    "Guillem Cabrera"
                  ],
                  "abstract": "Content Steering is a new feature in both HLS and MPEG DASH standards, enabling regulating the use of multiple CDNs for streaming. Its key promise is the simplification of the design of multi-CDN delivery systems. No custom client plugins, DNS redirects, or CMS integrations are needed to deploy multi-CDN systems. It also addresses the problem of seamless in-session switching. In this paper, we will review the principles of operation of the HLS / DASH content steering method and explain how to design practical mass-scalable systems using it. We will also survey the current state of adoption of this standard by HLS/DASH streaming clients and related open-source tools and projects.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HLS",
                      "DASH",
                      "Content Steering",
                      "Multi-CDN streaming",
                      "CDN switching technologies"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002018"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Efficient Media Production and Management with AI Assistants: A Multi-Domain Exploration",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rob Gonsalves",
                    "Katherine Li",
                    "Stephen Wilson",
                    "Nestor Napoles Lopez",
                    "Shailendra Mathur"
                  ],
                  "abstract": "Artificial Intelligence is significantly reshaping media production and asset management, transitioning from a mere tool to a collaborative partner. This research explores the application of AI models across four principal areas of media creation: Media Asset Management, Video Editing, Audio Production, and Music Composition. — By leveraging AI capabilities such as semantic embedding, large language models, and speech-to- text models, this study investigates the profound impact of AI on creative processes, workflow optimization, and ideation stimulation. Through automated mundane task execution, contextual search, recommendation engines, and in-context application help, AI assistants empower creators to focus on higher-order tasks while benefiting from efficient AI-driven assistance. We examine the use of AI models in each domain, highlighting their contributions to content management, semantic media search, video editing with transcripts, sound design, and chord symbol auto-completion. — By highlighting AI's role as a collaborator rather than a replacement, this paper emphasizes the symbiotic relationship between human ingenuity and AI-driven efficiency, underscoring the profound potential for groundbreaking media content creation. In an era where AI is an integral part of the media landscape, this paper addresses the transformative power of AI across diverse creative domains, ushering in a new era of media production and media management.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Artificial Intelligence",
                      "Machine Learning",
                      "Media Production",
                      "Asset Management",
                      "OpenCLIP",
                      "GPT-4",
                      "LLaMa2",
                      "Whisper",
                      "Audio Production",
                      "Music Composition",
                      "Video Editing",
                      "Media Asset Management"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002009"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "The Impact of Background Luminance on the Perception of Chromatic Lightness",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrea Avendano Martinez",
                    "Jake Zueina",
                    "Jaclyn Pytlarz"
                  ],
                  "abstract": "Background luminance drastically affects the color appearance of content. Modern display technologies allow for the reproduction of highly saturated colors, whose perceived lightness tends to look ‘dull’ or muted when superimposed on backgrounds of higher luminance values. These perceptual effects can be predicted by analyzing the relationship between a color's chromatic contribution to perceived lightness and how it changes with background luminance. A two-alternative-forced-choice psychophysical lightness-matching experiment was conducted across different levels of background luminance. The Helmholtz-Kohlrausch (H-K) effect was found to have a significant impact on observers’ expectations when assessing the lightness of a chromatic color under changing background luminance levels. The experimental results show that as background luminance is increased for highly saturated, low luminance colors, current models overestimate perceived lightness changes by more than double. To perceptually maintain the intent of creative content, there is a need for color appearance models to accurately predict chromatic lightness under changes to the background luminance level.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Color appearance",
                      "background",
                      "brightness",
                      "colorfulness",
                      "psychophysical experiment",
                      "image processing",
                      "Helmholtz-Kohlrausch",
                      "lightness"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002008"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Hybrid Images for Personalized Media Streaming Optimization",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Doh-Suk Kim",
                    "Scott Daly",
                    "Ludovic Malfait",
                    "Neel Chaudhari",
                    "Jeffrey Riedmiller"
                  ],
                  "abstract": "Efficiently transmitting media while maintaining or improving the quality of experience (QoE) poses a constant challenge. On the media playback side, there exists a variety of factors affecting the resulting QoE perceived by end users, such as device characteristics, viewing conditions, and individual visual acuity. Understanding the characteristics of playback-side context can provide opportunities for optimizing media delivery tailored to each user. — We present a novel approach to estimating viewers’ visible frequency ranges by creating hybrid images in a quantitatively controlled manner. The proposed approach, which can be applied to adaptive bitrate (ABR) streaming optimization, combines low- and high-frequency components of two different images providing multiscale image perception. The proposed method is designed to adjust the hybrid image size and the cutoff frequencies of lowpass and highpass filters of hybrid image synthesis according to the given frequency range under test. This method can be used to estimate the minimum video resolution for maintaining maximum QoE, in any viewing conditions and devices. — Our experimental results reveal a strong correlation between the minimum resolution obtained from hybrid image perception tasks and the traditional just noticeable difference (JND) of real images of different resolutions when presented side-by-side. These JND tasks exhibit a wider spread both in the measured minimum resolution and elapsed time to complete the tasks, potentially due to the complexity of the cognitive process and the variability caused by contents and subjects. In contrast, the hybrid image technique achieves more stable results with much less effort from subjects.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "QoE (Quality of Experience)",
                      "Hybrid image",
                      "playback-side context",
                      "image resolution",
                      "viewing distance",
                      "streaming optimization",
                      "personalization"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002014"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Creative Intent on the Windward Slopes",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Scott Daly",
                    "Shane Ruggieri",
                    "Dan Darcy",
                    "Evan Gitterman",
                    "Poppy Crum"
                  ],
                  "abstract": "SMPTE was formed in 1916 as narrative performance was ushered onto the technological stage allowing for mass distribution and transmission. While there is no need to list those advantages, there is one weakness with audiovisual media as compared to the traditional stage, which media still has not overcome. This is real-time audience feedback, and the ability to adjust the performance based on differing audience reactions. This paper motivates the use of biosensors in media by highlighting the problem of signal loss due to playback technology. A metadata system is proposed that allows creatives to steer signal modifications as a function of audience emotion and cognition as determined by biosensor analysis This is needed because today's audiovisual ecosystem includes such a wide variety of playback devices that the audience's experience can differ substantially for the same source content. Metadata for narrative and emotional expectation as inserted by creatives during the content production stages combines with the assessment to adapt the rendering. As a result, the system allows for creative intent to be scalable as best as possible across many types of playback systems in a manner analogous to real-time stage presentation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "biosensors",
                      "creative intent",
                      "emotion",
                      "cognition",
                      "image processing",
                      "audio processing",
                      "displays",
                      "sound systems",
                      "real-time signal modification"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002013"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "HDR Production Workflows: A Dynamic Solution That Provides Stable Graphics Management And Compatibility With Static Solutions",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Touze",
                    "Frederic Plissonneau",
                    "Patrick Morvan",
                    "Bill Redmann",
                    "Robin Le Naour",
                    "Laurent Cauvin",
                    "Valerie Allie"
                  ],
                  "abstract": "Live production workflows, particularly those for sports, employ complex pipelines to deliver HD, UHD, SDR, and HDR video streams. Because content originates as HDR or SDR, effective and flexible conversions are required between formats. Graphics insertion is extensively used, presenting scores and analytics. These graphics must remain stable to provide a consistent appearance throughout the conversions. Today, diverse tone mapping and inverse tone mapping technologies are proposed to industry, each with the promise to create premium HDR content while maintaining the quality of SDR versions. Look Up Tables (LUTs) are the chief conversion technique used today, but constrain the capabilities of HDR and/or compromise the SDR look. Further, their static nature exposes content to artifacts emerging from changing conditions during live capture (e.g., sunset, passing clouds, shadows). While dynamic techniques accommodate such changes, a problem emerging is that none of the different LUT solutions nor dynamic solutions are fully interoperable: Each produces content with different properties, requiring different conversions to satisfy the critical requirement of delivering a seamless final content. This paper presents a generic solution, based on metadata, that resolves the compatibility issue. We present an implementation, a dynamic solution, implementing this proposal and providing tools based on dynamic metadata generation that ensures viewers enjoy the highest HDR video quality with no compromise of the SDR stream. By leveraging an image-based adaptation having already-acknowledged benefits of dynamic conversion, this solution introduces a constraint to allow stable graphics management: a specific Static Diffuse White, which ensures compatibility with existing static workflows while offering resolution to their shortcomings and paves the way for industry to transition smoothly from static to dynamic techniques and ensure delivery of premium HDR and SDR content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "SDR",
                      "Tone Mapping",
                      "Inverse Tone Mapping",
                      "Tone expansion",
                      "Tone compression",
                      "TM",
                      "ITM",
                      "graphics management",
                      "HDR live production",
                      "Diffuse White",
                      "3D-LUT"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002016"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "What Electronic Image Noise Signatures Can Tell Us About Image Linearity and Camera Encoding",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ricardo R. Figueroa"
                  ],
                  "abstract": "Electronic image noise is often categorized as an artifact of image capture which typically requires correction. There are several sources of electronic image noise that contribute to the overall total noise in an image. Some of the noise from specific sources, known as systematic noise, can be corrected for in-camera, but noise due to certain sources, like photon noise, persists after capture and increases with exposure. We study this relationship between exposure and noise and discover that this relationship reveals information about the linearity, or non-linearity of the image encoding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Radiometric Calibration",
                      "Opto-Electronic Transfer Function (OETF)",
                      "Camera Response Function (CRF)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002017"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Optimized pixel streaming for ultra-low latency cloud gaming and VR/XR applications.",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Guido Meardi",
                    "Kevin Mockford"
                  ],
                  "abstract": "Until recently, top-notch gaming and XR/VR experiences required costly hardware with powerful GPUs. Today's cloud-based solutions aim to make these experiences more accessible by rendering the experience in the cloud and then “pixel streaming” - i.e., with one video encoding per each user - the point of view, but doing so hinges on delivering high-quality, ultra-low latency video, so compression efficiency is a core component of these applications. — While traditional codecs like H.264 and HEVC are currently used, they have limitations in cloud gaming and VR/XR scenarios. Newer codecs like AV1 and VVC offer better compression but are computationally heavy and produce lower gains vs HEVC in real-time ultra-low-latency applications. Enter MPEG-5 Part 2 LCEVC, a low-complexity enhancement that improves compression up to 30% when used with existing codecs like HEVC, AV1 or VVC, without adding computational burden and with coding tools that maintain their efficiency also in low-latency scenarios. Compatible with existing devices and codecs like HEVC, AV1, and VVC, LCEVC enables scalable, high-quality pixel streaming within the bandwidth limits necessary for widespread deployment. — This paper provides data on LCEVC's performance in conjunction with HEVC, specifically focusing on its application in ultra-low latency streaming for cloud gaming and VR/XR, where quality and responsiveness are key.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "cloud gaming",
                      "VR",
                      "XR",
                      "MPEG-5 LCEVC",
                      "AV1",
                      "VVC",
                      "HEVC",
                      "H.264"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002023"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "The future of video compression - Moving beyond hybrid codecs with machine learning",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Guionnet",
                    "Marwa Tarchouli",
                    "Thomas Burnichon",
                    "Mickael Raulet"
                  ],
                  "abstract": "The consumption of video content on the internet is increasing at a constant pace, along with an increase of video quality. As an answer to the ever-growing demand for high quality video, compression technology improves steadily. About every decade, a new major video compression standard is issued, providing a decrease of bitrate by a factor two. Interestingly, the technology does not change radically between codecs generations. Instead, the same principles are re-used and pushed further. There has been several attempts to depart from this model, but none achieved to be competitive. Recently, the research community has started focusing on deep learning-based strategies. Could it be the new contender to the classical approach? This paper analyzes the benefits and limitations of deep learning-based video compression methods, and investigates practical aspects such as rate control, delay, memory consumption and power consumption. Overlapping patch-based end-to-end video compression strategy is proposed to overcome memory limitations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video Compression",
                      "Video codec",
                      "MPEG-2",
                      "H.264",
                      "AVC",
                      "HEVC",
                      "VVC",
                      "artificial intelligence",
                      "machine learning",
                      "deep learning",
                      "end-to-end video encoding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002026"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Enhancing Content Creation Workflows through Automatic Speech Recognition Techniques",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Randy Fayan",
                    "Zahra Montajabi",
                    "Rob Gonsalves"
                  ],
                  "abstract": "This research provides a comprehensive review of prevailing Automatic Speech Recognition (ASR) methods and their profound impact on media production. Central to this exploration is the pivotal role of the transformer model, showcasing its unique self-attention mechanism ideal for tasks demanding comprehension of temporal relationships. We conduct an in- depth comparison, evaluating leading ASR models like Multilingual Machine Speech (MMS) from Meta, Whisper from OpenAI, and Google's Universal Speech Model (USM). Their performance is gauged against commercial services from tech giants such as Microsoft Azure, Amazon Web Services, and Google Cloud Platform. The paper covers aspects of ASR systems like voice activity detection, language identification, multilanguage support and the metrics used to characterize the accuracy of the systems. The research also identifies important challenges, like the dearth of data for some languages and the intricacies associated with linguistic nuances. Further, we discuss the role of ASR in media production, ranging from generating time-based captions to revolutionizing editing methodologies. Through a detailed breakdown of the ASR process, from audio preprocessing to postprocessing, this study endeavors to merge academic insights with practical applications, empowering media producers to leverage the immense capabilities of contemporary ASR technologies.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Artificial Intelligence",
                      "Machine Learning",
                      "Automatic Speech Recognition"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002027"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "New Storage Techniques and Technologies to Accelerate Camera to Cloud Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kristy DeMarco"
                  ],
                  "abstract": "Today's media and entertainment content creation workflows present unique data logistics challenges for data management teams. Between barriers to data mobility, challenges to data security, accelerated project timelines, and the industry-wide push to embrace digitally native workflows—a new kind of data storage solution is long overdue. — To overcome these issues, production teams, digital imaging technicians (DITs) and IT Production groups need their data in the right place, at the right time, and with the right accessibility, removing roadblocks in data logistics workflows. — Today's most competitive solutions to data logistics challenges enable customers to pay for high capacity, high performance, highly reliable storage solutions that meet data challenges head on, enabling users to store data anywhere—while only paying for the hardware each specific project needs—and physically transport that data securely to their post-production landing destination of choice for multi-cloud workflows and active archive. From project management and logistics support to highly reliable, S3 cloud storage with a flat-fee cloud import service, this technical paper will explore how partnering with a storage solution provider and embracing a subscription-based, as-a- service model for data management can help data managers accelerate camera to cloud workflows, resulting in cost savings and streamlined content collaboration. — Preliminary research and application results include: — • A short-term data-transfer-as-a-solution (DTaaS) subscription may be only 20% the cost of a storage area network (SAN) expansion — • Transfer content in days, not weeks, saving up to 12-15 hours per week of overtime costs — • S3 cloud storage with predictable cost and no additional fees — In an industry as fast paced as M&E, data storage capacity, security, and mobility should be the least of studios and production companies’ concerns. With DTaaS, IT professionals can trust their valuable content will be available when and where it's needed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Seagate Technology",
                      "Seagate",
                      "Lyve Systems",
                      "Lyve Mobile",
                      "Lyve Cloud",
                      "Cloud Import",
                      "Data Transfer as a Service",
                      "DTaaS",
                      "Camera-to-Cloud",
                      "Data Management",
                      "On Set",
                      "On Prem",
                      "Ingest",
                      "Consolidation",
                      "Transport",
                      "Pre-production",
                      "Post-production",
                      "Workflow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002022"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Ambient Light Compensation Through Adaptive Visual Modeling",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jaclyn Pytlarz"
                  ],
                  "abstract": "Ambient light can significantly degrade picture quality by reducing visibility of details and contrast. In many cases, it is difficult to control or eliminate ambient light, making it essential to compensate for its effect. This is especially true in the context of media and entertainment, where viewers often consume content in different lighting conditions and environments. Traditional image processing techniques, such as adjusting the backlight, brightness/contrast, or more professionally using a PLUGE signal, do not sufficiently model the human visual system. The result is that detail is lost under changes in ambient light. This is especially problematic for very dark scenes, which has become apparent with cinematic high dynamic range content where numerous consumer complaints have graced headline news. — This paper proposes a method of ambient light compensation by adaptively modeling the contrast sensitivity functions of the human visual system. By estimating global eye adaptation to both the content and the surround environment, the contrast sensitivity models may be used to maintain perceptual detail and contrast under varying ambient illumination. We build upon existing models of human vision and show how we can use cone sensitivity to maintain global contrast. Since displays have limited dynamic range, we show how this can be adaptive to both the content and environment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ambient",
                      "light",
                      "contrast",
                      "perception",
                      "media"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002028"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Profiling the ST 2110 Network Traffic for Load Testing with Open-Source Tools",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ievgen Kostiukevych",
                    "Thomas Kernen",
                    "Willem Vermost",
                    "Pavlo Kondratenko"
                  ],
                  "abstract": "As the broadcast industry transitions towards more high-performance IP-based and software workflows, more and more demands are placed on the networks and switching platforms to deliver consistent and predictable performance. Adopting the ST 2110 standard adds another layer of complexity due to its specific timing, synchronization, and bandwidth requirements. Moreover, the typical traffic profile of an ST 2110 system is, in fact, very different from that of the traditional IMIX",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "broadcasting",
                      "high-performance",
                      "IP-based workflows",
                      "software workflows",
                      "networks",
                      "switching platforms",
                      "consistent",
                      "predictable",
                      "performance",
                      "ST 2110 standard",
                      "timing",
                      "synchronization",
                      "bandwidth requirements",
                      "traffic profile",
                      "IMIX",
                      "load test",
                      "repeatable",
                      "standardized",
                      "media stream",
                      "operational",
                      "ST 2110 systems",
                      "statistical model",
                      "media use cases",
                      "open-source tools",
                      "load testing",
                      "media companies",
                      "broadcasters",
                      "integrators",
                      "high-traffic scenarios",
                      "system limitations",
                      "scalability",
                      "cost-effective",
                      "efficient",
                      "network designs"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002030"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Ultra-low Latency Video Delivery using WebRTC Data Channels",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Olie Baumann"
                  ],
                  "abstract": "Delivery of video with camera-to-screen latencies of less than two seconds, so called ultra-low latency, is the latest battleground for live streaming providers and vendors. Historically, broadcast latencies have been between five and ten seconds, significantly lower than those which can be achieved using the standardised streaming protocols based on HTTP. The frustration of hearing about a change in score, through social media for example, before seeing it on a streaming service prompted the development of the low latency variants of HTTP based protocols. These can bring the camera-to-screen latency down to between six and eight seconds, easily competing with, if not surpassing, standard broadcast. — Providers’ need for new monetization strategies and increased consumer engagement drives the need to reduce this further. Existing technologies’ inherent limitations in this respect demand a new delivery mechanism. The development of WebRTC Media Streams focuses on video conferencing where round-trip latencies in the 100s of milliseconds are key. However, video conferencing has little need for the high picture quality, content protection, alternative audio, and delivery to millions of users necessary for premium streaming service providers. — This paper discusses the limitations and advantages of using HTTP and WebRTC for media delivery and presents a novel approach to delivering media to clients using WebRTC Data Channels. By using a UDP-based protocol, WebRTC overcomes the congestion and head-of-line blocking issues associated with TCP, allowing the delivery of media with latencies below two seconds. The use of Data Channels has three main advantages over Media Channels. Firstly, it enables video content to be encrypted using standard Digital Rights Management methods. Secondly, it allows the use of broadcast quality encoders which make use of all codec tools rather than the restricted toolset dictated by WebRTC encoders. Thirdly, the use of Data Channels removes the need for a per-client encode of the content. Instead, the pre-encoded and encrypted content is simply replicated to all clients at the edge of the network. This, in turn, means that the solution scales efficiently to the ever-increasing streaming audience.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Live streaming",
                      "WebRTC",
                      "ultra-low latency video"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002032"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Real-time Streaming Reliability and Performance Optimization Using Content Steering",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniel Silhavy",
                    "Stefan Pham",
                    "Alex Giladi",
                    "Alex Balk",
                    "Ali C. Begen",
                    "Will Law"
                  ],
                  "abstract": "Media streaming over the Internet is dominated by HTTP adaptive streaming solutions such as DASH and HLS. These solutions typically host the required manifest files and media segments on multiple content delivery networks (CDNs). To avoid outages and performance problems and for scalability reasons, selecting the optimal CDN is an essential step in the media streaming workflow. Content steering provides a deterministic capability for a content distributor to switch a player's CDN source, both at startup and in the middle of a session, through a remote out-of-band steering service. This paper focuses on the theoretical and practical aspects of content steering for DASH. We highlight the important features of the DASH-IF Content Steering specification and demonstrate our implementation in an open-source media player (dash.js). Moreover, we illustrate how streaming metrics based on the CTA-5004 (Common Media Client Data, CMCD) specification and information about the Internet service provider can drive the selection mechanism on the steering server. Our results show that content steering enables a seamless transition between different CDNs during a running streaming session and has the potential to significantly improve the quality of experience for the end-user.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Content Steering",
                      "Content Delivery Network(CDN)",
                      "DASH",
                      "HLS",
                      "Adaptive Bitrate Streaming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002031"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "How to Effectively Enhance PTP Redundancy Using Dual Ports",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202023%20Media%20Technology%20Summit/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nikolaus Kero",
                    "Thomas Kernen"
                  ],
                  "abstract": "In the recent past, media transport over IP networks has become a viable option for the broadcasting industry. The SMPTE ST-2110 family of standards has proven to be a key factor in guaranteeing the required level of performance as well as full interoperability between different vendors. A small but nevertheless crucial part of the All-IP-Studio is an accurate and reliable common notion of time throughout the whole network. The broadcasting industry chose the IEEE 1588 Precision Time Protocol (PTP) for time transfer because it is a well-established method and is used in many application domains. PTP offers a certain level of fault tolerance, coping with the loss of the reference (PTP Grandmaster) autonomously by electing an auxiliary device to assume this role. Mission-critical applications may require a higher level of resilience to detect and/or counteract more complex error conditions such as intermittent or permanent loss of time transfer as well as deterioration of its quality - both will remain undetected by PTP. Rather than keeping all auxiliary PTP Grandmasters in hot-standby mode, we propose to deploy more than one active time reference. This allows all PTP end devices (Followers) to select the best time source using extended selection criteria and thus cope with almost every error condition without transient or permanent deterioration of the synchronization accuracy. — We will describe in detail how to implement this extension without violating or extending the original PTP protocol, which is a mandatory requirement for any improvement of PTP time transfer. Within a multi-vendor testbed, we will demonstrate the performance and advantages of this approach by inducing the most common transient and permanent error conditions within a typical PTP network. The accuracy of the proposed solution will be evaluated by measuring the offset of the PTP hardware clocks of all Followers with respect to the PTP Grandmaster. The results will be compared with the performance of a commercial PTP implementation being subjected to the same error conditions. The paper will conclude by briefly describing how to implement this technology and commenting on the implementation overhead as well as the expected increase in resource usage.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2023-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "ST2110",
                      "ST2059-2",
                      "Redundant Clock Synchronization",
                      "PTP",
                      "IEEE1588"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M002029"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2022",
        "conferences": [
          {
            "conference_name": "SMPTE 2022 Media Technology Summit",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "A Proposal for a Standard to Improve Soundtrack Dynamic Range and Dialog Clarity for Better Enjoyment of Digital Cinema",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Buck Moore"
                  ],
                  "abstract": "Movie soundtracks that are mixed on a digital workstation with dialog levels at -35LKFS with peaks at -1dBFS, often translate to dynamic fluctuations of up to 50dBSPL, which, while mimicking ‘reality’, often annoys many audience members. As Netflix states on their Sound Mix Specifications page: “…content which is not excessively dynamic provides a better experience for our customers.” (1) Oscar winning sound designer Randy Thom has even stated: “The proliferation of digital movie houses with high fidelity amplifiers and speakers has provided Directors with a powerful set of instruments which they can use wisely or foolishly.” (2) — As stated on canadianaudiologist.ca: “Unlike previous analog sound, current digital sound is said to not distort at loud volumes and can be increased to extreme levels without static, fuzziness, or distortion. In other words, making sound louder with digital is less likely to reduce sound quality. As a result, movie producers, studios, and directors are generating soundtracks at very high sound levels - levels that can be annoying, and could potentially be harmful to hearing.” (3) — A well designed soundtrack with clear dialog and acceptable dynamic range should begin during the re-recording mix and print master stage to mitigate audience ‘annoyance factor’. This paper explores a simple mixing strategy which can greatly improve the listening experience for cinema audiences.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital cinema soundtrack",
                      "DCP",
                      "LUFS",
                      "LKFS",
                      "dBFS",
                      "B-chain",
                      "Randy Thom",
                      "LFE",
                      "A-weighted",
                      "C-weighted",
                      "X curve",
                      "Annoyance Level Acceptance",
                      "Loudness"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001954"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Workflow as a Service Delivered by the Dynamic Media Services Architecture",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brad Gilmer",
                    "Grant Hammond"
                  ],
                  "abstract": "Workflow as a Service (WaaS) is a term representing a platform that serves users wishing to deploy their workflows on-demand onto cloud-managed, hybrid, or on-premises services. Whilst the idea of WaaS has been around for many years (and perhaps has its origins in the Ptolemyi and Keplerii projects), it is only now, as a consequence of broadcast facilities being constructed based on IT technologies, that the WaaS paradigm is becoming applicable and relevant to broadcast production workflows. The Dynamic Media Services Architecture (DMS Architecture) described in this paper lays out an architectural approach that has the potential to deliver Workflow as a Service for the media industry. Truly dynamic facilities require the near-constant creation, consumption and dissolution of workflows; workflows that are created by taking advantage of capabilities provided from a pool of shared resources. This article describes an architecture capable of delivering this vision and breaks down the functionality in the architecture into major layers. The DMS Architecture provides a way forward, identifying key concepts, components and layers required to deliver some of the many promises of IT technology to our industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Workflow-as-a-Service",
                      "Dynamic Media Services Architecture",
                      "Layered Media Architecture",
                      "ST 2110 Architecture",
                      "NMOS Architecture",
                      "CI/CD media production",
                      "IaC media production",
                      "software defined media production",
                      "infrastructure as code media production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001965"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Uncompressed Video in the Public Cloud: Are We There Yet?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mike Coleman",
                    "Jialu Wang"
                  ],
                  "abstract": "Broadcasters are beginning to use the public cloud for live production, but unlike groundbased production most of the media processing in the cloud operates on compressed media. One public cloud offers a solution for uncompressed transfer but that solution currently has some limitations that prevent widespread use between customers. We have had some success transporting uncompressed video on several clouds using a multi-flow UDP transport, which is described in this report. We also discuss the expected architecture of cloud services that process video, and how they differ from ground based IP production, and some of the areas where standardization will be needed. There are many use cases for compressed media in the cloud, and many of them will remain for a long time. For the near future, due to business, technical and standardization issues, we see uncompressed video transport relegated to an internal implementation detail of services that will continue to use standardized compressed formats for ingress and egress.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "cloud",
                      "live production",
                      "cloud-native",
                      "video networking",
                      "network testing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001967"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Low-Complexity Quality Measurement for Real-Time Video Compression",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jan De Cock",
                    "Axel De Decker",
                    "Sangar Sivashanmugam"
                  ],
                  "abstract": "A wide variety of video quality (VQ) metrics have been introduced over the past decades. VQ metrics are used in a range of applications, including video quality monitoring, encoder optimization, bitrate selection, and adaptive bitrate ladder configuration. While quality metrics have been developed that correlate well with human visual perception, they typically require high computational complexity. Other popular metrics are less complex, but are not accurate enough to base encoder decisions on. — In this paper, we discuss relevant quality metrics and their computational complexity. We address the difficulties around real-time VQ measurement, and determine which metrics can be used inside real-time encoders, to not only measure, but to actively control video quality. We include recent Machine Learning (ML) driven research, with a focus on the complexity introduced by ML techniques for video quality assessment. While these techniques provide benefits to improve VQ measurement and monitoring applications, we illustrate the fine line between accuracy of ML networks and the number of operations performed in these networks and their associated cost.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video quality",
                      "quality metrics",
                      "real-time",
                      "computational complexity"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001958"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "JPEG XS Standard (ISO/IEC 21122) for Lightweight, Low-Latency Image Coding",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Siegfried Foessel",
                    "Thomas Richter"
                  ],
                  "abstract": "At its 94th meeting, ISO/IEC SC29WG1 (aka. JPEG committee) decided to create a third edition of the JPEG XS standard (ISO/IEC 21122) for lightweight, low-latency image coding. While existing coding tools already support the compression of natural content and CFA RAW Bayer pattern data well, this third edition will extend the previous editions with coding tools that improve its performance on compression of screen content and static background sequences. — First experiments demonstrate that the proposed coding tools can improve the average PSNR performance of JPEG XS on such sequences more than 10dB, and approximately 3dB on computer generated content. In this work, authors will present the proposed coding tools and will evaluate their performance objectively by PSNR.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video Coding",
                      "low-latency coding",
                      "gradual refresh",
                      "JPEG XS",
                      "inter-prediction"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001955"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Media and Entertainment Sustainability on the Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Edwards",
                    "Jason OMalley"
                  ],
                  "abstract": "Media and Entertainment (M&E) companies are becoming increasingly committed to building a sustainable business for their employees, customers, and communities. At the same time, M&E companies are seeking to enhance and re-invent their business using cloud computing (the on-demand delivery of compute power, database, storage, applications, and other IT resources via the Internet with pay-as-you-go pricing). Fortunately, the goals of improving sustainability and cloud adoption can be synergistic, as enhanced business efficiency via cloud can also drive sustainability. Cloud providers, through scale and focus on innovation, can achieve higher resource utilization and energy efficiency than is possible for typical on-premises or collocated data centers. This paper will examine why M&E companies are seeking sustainability, terminology used in sustainability, published sustainability goals of M&E companies, and how M&E companies can achieve enhanced sustainability on the cloud.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Sustainability",
                      "cloud",
                      "carbon",
                      "net zero",
                      "remote production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001962"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Case Study: Enabling Open Caching for Last-Mile Delivery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sanjay Mishra",
                    "ErinRose Widner"
                  ],
                  "abstract": "Subscriptions for video-on-demand services (SVOD) have now surpassed pay-TV subscriptions. Due to this new viewing trend, combined with the expectation of having a quality experience that is the same if not better than broadcast, the end-to-end infrastructure to support video delivery (particularly for SVOD) has evolved. To render an Internet-video streaming experience that is equivalent (or better) to broadcast-TV, a video delivery ecosystem is required that does not impose a latency penalty to the viewer along with providing a last-mile that is capable of delivering video stream quality on par with standard video or a High Definition video including ultra-high definition (4K and 8K).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K",
                      "8K",
                      "Bit-rates",
                      "bandwidth",
                      "buffering",
                      "CAGR",
                      "CP",
                      "Cable",
                      "Caches",
                      "CDN",
                      "DOCSIS",
                      "IETF",
                      "ISP",
                      "Jitter",
                      "latency",
                      "OCN",
                      "POP",
                      "SVOD",
                      "SD",
                      "UHD"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001959"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Video Compression Using Convolutional Neural Networks of Video with Chroma Subsampling",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Vahid Khorasani Ghassab",
                    "Rob Gonsalves",
                    "Shailendra Mathur",
                    "Nizar Bouguila"
                  ],
                  "abstract": "In the context of Convolutional Neural Networks based video compression, motivated by the lower acuity of the human visual system for color differences as compared with luma, we investigate a video compression framework using autoencoder networks that encode and decode videos by using less chroma information than luma information. For this purpose, instead of converting Y'CbCr 4:2:2/4:2:0 videos to and from RGB 4:4:4 as per the current state-of-the-art, we have kept the video in Y'CbCr 4:2:2/4:2:0 and merged the luma and chroma channels after the luma is downsampled to match the chroma size. We have performed an inverse function for the decoder. The performance of our models against the 4:4:4 baseline is evaluated by using CPSNR, MS-SSIM, and VMAF metrics. Our experiments reveal that, as compared to video compression involving conversion to and from RGB 4:4:4, the proposed method increases the video quality by about 5% for Y'CbCr 4:2:2 and 6% for Y'CbCr 4:2:0 while reducing the amount of computation by nearly 37% for Y'CbCr 4:2:2 and 40% for Y'CbCr 4:2:0. These results point us to optimization for 4:2:2 and 4:2:0 video of the current state-of-the-art autoencoder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video Compression",
                      "Neural Networks",
                      "Machine Learning",
                      "CNN",
                      "Chroma Subsampling"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001957"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Streamlining WebRTC and DASH for Near-Real-Time Media Delivery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Louay Bassbouss",
                    "Ali C. Begen",
                    "Daniel Silhavy",
                    "Omar Sherif Gamal Attia",
                    "Julia Kenyon",
                    "Ofer Shem Tov",
                    "Jonas Birme"
                  ],
                  "abstract": "WebRTC is a set of W3C and IETF standards that allows real-time media delivery to users, with an end-to-end latency of under half a second. Support for WebRTC is built into all modern browsers across desktop and mobile devices, allowing for video, audio, and data streaming. The original focus of WebRTC has been videoconferencing. However, it is increasingly being used today for real-time streaming of premium content because of its ultra-low latency features. These features enable new user experiences involving user interactivity that are not easy to deliver or even possible with the traditional broadcast or streaming delivery protocols. Due to this increasing usage for premium content, the integration of WebRTC with the de facto adaptive streaming protocols such as Dynamic Adaptive Streaming over HTTP (DASH) is desirable. — This paper describes some use cases that could benefit from an integrated approach to streaming with DASH and WebRTC. These include the insertion of pre-recorded advertising into real-time streams such as sporting events, cloud gaming events, or concerts; co-watching synchronized streams with audio/video/text chat; and interactive broadcast content consisting of both live and on-demand elements. Interactivity can range from simple text-based feedback to the audience's video participation with event commentators. This paper describes the key performance indicators (KPIs) relevant to each use case. These include various measures of latency, delay, and synchronization as well as quality and adaptability to changing network conditions. Example workflows between DASH and WebRTC clients are provided and discussed, as are proposed architectures for both servers and clients.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "WebRTC",
                      "DASH",
                      "real-time streaming",
                      "adaptive bitrate streaming",
                      "sub-second latency",
                      "interactive content",
                      "premium content streaming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001961"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "The Future of Documentation: Unified System Design",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lukas Odhner"
                  ],
                  "abstract": "Broadcast engineering documentation has been around a long time. Originally, drawings - drafted by hand - served the function of capturing the intended state of a system or design. Software started playing a role in the design process in the late ′70s/early ′80s and AutoCAD has since been the tool of choice for broadcast documentation through the transition from analog to digital (SMPTE 259M), as well as the transition to HD (SMPTE 292M). However, the shift to IP video has been more challenging to document than any standard that proceeded it. MPEG-TS, ST 2022-6, and ST 2110 are fundamentally different from SDI standards that directly correlate signal and cable. For IP-native standards, when it comes to the “relationship status” between the physical and the logical, it's complicated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Documentation",
                      "AutoCAD",
                      "Drawings",
                      "IPAM",
                      "DCIM",
                      "Network Automation",
                      "Design Tools",
                      "Logical",
                      "Physical",
                      "Linked",
                      "ST-2110",
                      "Infrastructure",
                      "Ndox",
                      "Netbox",
                      "Database",
                      "Open Source"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001964"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Media Gateways in Hybrid Wired and Wireless Media Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Brightwell",
                    "Pedro Ferreira",
                    "Thorsten Lohmar",
                    "Paola Sunna"
                  ],
                  "abstract": "Professional media production will in the future require more flexibility over where and how its operations are provided, so “effective use” includes operation where there are multiple networks, which could include 5G, wired, cloud-based and home networks. The broadcast industry's adoption of live networked media systems is still relatively immature, and there is not yet a consistent and complete approach to describing architectures and the interfaces required for interoperability. In this paper, the AMWA Network Media Systems Template has been used to build a set of media orchestration and control functions for a professional media production using both 5G and wired (ST 2110 based) media network. In particular, the scenario under consideration comes from the EU Horizon IC-41 Project called 5G-RECORDS (https://www.5g-records.eu/) and is about a multi-camera 5G-enabled broadcast studio. The MOCG (Media Operational Control Gateway) is the component that the partners are developing to control the setup of media resources; it sits on top of the 5G network, to automate and simplify the operational control of broadcast equipment deployed in various locations. In production, this is done through AMWA NMOS APIs. In the 5G network, the use of these APIs needs to be adapted through the introduction of several middleware components decoupling the remote operations from the studio and replicating/emulating NMOS control functions within a 5G environment. This paper gives a detailed description of the wireless studio use-case, the MOCG and the Media Gateway responsible for anchoring the media components within the 5G network and the production studio.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "5G",
                      "AMWA",
                      "NMOS",
                      "ST 2110",
                      "multi-camera",
                      "control",
                      "media components",
                      "media gateway",
                      "Horizon IC-41",
                      "orchestration",
                      "media production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001981"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "CMG 8K UHD IP Signal Routing and Transmission at the 2022 Beijing Winter Olympics",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mei Jianping",
                    "Ge Tao",
                    "Zhao Guihua",
                    "Xue Zhixing",
                    "Lin Fei",
                    "Bao Fang"
                  ],
                  "abstract": "The China Media Group (CMG) finished building its 8K UHD TV-relevant production and broadcasting system in early 2022 by innovating the application of 8K UHD TV production, transmission, playout, and presentation. On January 24, CCTV-8K, the CMG's 8K ultra-high definition channel and the 8K UHD “Hundred Cities Thousand Screens” public large-screen project, both launced simultaneously. — The CMG has improved its ability to transport 8K UHD signals by developing an IP UHD routing master control system using COTS routers as the primary switching equipment. The contribution of 8K UHD signals for CMG during the Beijing 2022 Olympic Winter Games was successfully accomplished by this system. The practices and technologies used in the contribution of 8K UHD IP signals are introduced in this paper.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "2022 Beijing Winter Olympics",
                      "8K UHD",
                      "St 2110",
                      "St 2059",
                      "SDN",
                      "PTP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001982"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Possible Solutions for the Vendor Lock-in Control Protocol in IP-based Production Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hirohiko Kuramata",
                    "Mitsuo Okano",
                    "Hikaru Obata"
                  ],
                  "abstract": "International standards for video and audio transmission, such as the SMPTE ST 2110, have become widespread in Internet Protocol (IP)-based production systems. However, device control still depends on the manufacturer's original protocols, resulting in the vendor lock-in problem. Herein, we have attempted to solve this problem. We prototyped a control device for an audio input/output (I/O) unit. Generally, the parameters of an audio I/O unit, such as the preamplifier gain and phantom power, are controlled using the audio mixing console with the manufacturer's original protocol. Therefore, if various audio I/O units from different manufacturers are available at the venues, controlling them is difficult in a control room. Using the vendor-free and open-source protocol, “Ember+” enables us to build a flexible system without the constraints presented by the manufacturer's original protocols. Additionally, we investigated the control of the connection of audio devices and audio channel mapping according to the specifications of AMWA NMOS IS-04, 05, and 08. Although IS-08 is stable with the potential to become widespread, it has not been adopted in many products. We implemented an application software to control the connection of audio devices and evaluated the efficiency of NMOS, especially IS-08. We confirmed that the application could effectively control the channel mapping like an audio router and could be adopted for any control system. Thus, our prototype and investigation present practical solutions using Ember+ and NMOS IS-08 to control devices on a multi-vendor IP production system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IP-based Production",
                      "Device Control",
                      "Open-source Protocol"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001983"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Can ST 2059-2 Benefit from PTP Version 2.1?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nikolaus Kero",
                    "Thomas Kernen"
                  ],
                  "abstract": "With the publication of version 2.0 of the IEEE1588 Standard for accurate time transfer over packet networks in 2008, the Precision Time Protocol (PTP) quickly became the only viable clock synchronization technology for all application domains relying on Ethernet as a transport medium. PTP was deliberately defined in highly generic terms allowing it to be tailored to applicationspecific requirements via PTP profiles. The SMPTE ST 2059-2 standard is the PTP profile for the broadcasting industry and a crucial element for any All-IP Studio deployment. In 2019 the IEEE published a new version of the IEEE1588 standard (PTP v2.1), where PTP was enhanced with several interesting optional features aimed primarily at improving the overall reliability of PTP, especially for larger deployments. — In this paper, we will explain all major new features of PTP v2.1 and investigate to what extent broadcasting applications may benefit from adopting them as part of a new version of the ST 2059-2 PTP profile. Specific focus will be put on possible implications with respect to implementation efforts and operating requirements. We will analyze whether the overall reliability of PTP can be improved by adding new features such as PTP security or extended monitoring. The high accuracy extensions to PTP v2.1 will be described together with a rough effort estimate required to develop and deploy products supporting sub-nanosecond accuracy. — The paper will conclude with a list of recommendations summarizing the benefits of these new features for deploying broadcasting networks at scale.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "PTP",
                      "ST 2059-2",
                      "Timing",
                      "All-IP Studio",
                      "Redundancy",
                      "IEEE1588"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001969"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Practicalities and Analysis of Using PTP over 5G Systems with Dedicated Time Synchronization Support for Media Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ievgen Kostiukevych",
                    "Mohamed Nabil Ibrahim",
                    "Pavlo Kondratenko",
                    "Thomas Kernen",
                    "Thorsten Lohmar"
                  ],
                  "abstract": "The 5G system is becoming more and more a multi-purpose wireless network. Several industry verticals have started using 5G networking technology for their purposes. 3GPP has defined a set of dedicated features relevant to one or more industry verticals. These new features make 5G more suitable for different media production scenarios, such as remote production or mobile studio scenarios, extending the local OB Van facilities and replacing the traditional RF cameras. 5G systems support bi-directional communication by nature, using Time Division Duplex (TDD) or Frequency Division Duplex (FDD). This would allow replacing multiple existing RF transmitters and receivers with a single RF solution. Further, the 5G radio network simultaneously shares the available spectrum with many devices by scheduling small radio resource units. However, some of these 5G systems concepts can become tricky to use for high-performance media over IP due to inherited jitter (due to scheduling and TDD), throughput variations, and path asymmetries (due to capacity allocation for uplink and downlink). The time synchronization between media sources can be challenging in 5G environments due to varying latencies of the radio transmissions. The paper explores the possibility of using IEEE 1588, Precision Time Protocol over a 5G system for media production applications. With 3GPP TS 23.501 Release 16, the 5G System specifications started to include dedicated time synchronization support. 3GPP Release 16 added specific time synchronization support for Time-Sensitive Networks (TSN), i.e., acting as a Time-aware system. With 3GPP Release 17, the support for IEEE 1588 is extended with several additional features. It becomes possible to use PTP according to the SMPTE ST 2059-2 PTP Profile reliably over 5G for media device synchronization. The paper describes lab sessions performed by the 5G RECORDS consortium members, testing the performance of PTP over 5G with and without the dedicated time synchronization support. A trial with a real camera supporting SMPTE ST 2110-22 with JPEG XS was conducted to experiment with synchronization and packet pacing precision. The paper also describes the testing setup based on the open-sourced software used by the team and the methodology developed. The paper concludes on the performance and synchronization quality when using PTP over various 5G systems and analyzes the results from the lab trials.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001966"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Upgrading Performance of Your Streaming Services Using Server Hints",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ali C. Begen",
                    "Yasser Syed",
                    "Alex Giladi"
                  ],
                  "abstract": "A smooth playback behavior is critical for any OTT service. Viewers naturally like not to experience rebuffering events, but less frequent and shorter ones are preferred when they cannot be avoided. However, ensuring smoother playback becomes more challenging as more demanding services such as low-latency live and 4K streaming become more widely available. — It has been shown many times that adaptive streaming clients compete with each other for the available bandwidth and server capacity. The server's priority in responding to the individual requests sent by these clients should be based on clients' time-varying playback buffer conditions. Previously, we presented that the server could wisely allocate its output capacity among the incoming requests and largely mitigate the rebufferings suffered by the clients, provided that the clients informed the server about their buffer statuses using the Common Media Client Data (CMCD) standard. In a more recent study, we developed an alternative solution to the same problem using the Common Media Server Data (CMSD) standard, which is still a work-in-progress in the CTA. In this solution, the server's response to a request that indicated a sufficient buffer level was delayed until the requests that indicated an insufficient buffer level were handled. The server attached a new CMSD parameter to the eventual response disclosing how long the delay was. This parameter avoided misinterpretation and the subsequent incorrect decision by the client's rate-adaptation logic. Our experiments (for which we offer the source code) showed that the proposed CMSD parameter eliminated unnecessary rate-shifting to lower bitrates while reducing the rebuffering rate as well as the rebuffering duration. — This paper summarizes these findings and illustrates other envisioned use cases for the CMSD standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Adaptive streaming",
                      "OTT",
                      "CDN",
                      "DASH",
                      "HLS",
                      "CMSD",
                      "CMCD",
                      "SAND",
                      "server/network assistance"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001960"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "ML-Based Indexing of Media Libraries for Insights and Search",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rob Gonsalves",
                    "Zahra Montajabi",
                    "Shailendra Mathur",
                    "Nizar Bouguila"
                  ],
                  "abstract": "Recent advances in Machine Learning (ML) have produced a new form of semantic indexing that lets users enhance searches, as well as gain new insights into their media libraries. Unlike typical search systems that use extracted metadata, semantic indexing allows users to find relevant material without the need to tag the media with selections from a predefined taxonomy. With semantic search, users can simply enter unstructured text, and the system will find the best matching media clips. The paper extends the use of the same technology to gather analytics on the data which can then be further correlated to generate various insights. — This new form of media indexing can be performed with the CLIP model from OpenAI. The model encodes images and text into embeddings that can be searched to find the closest semantic similarity, enhanced with learned cultural knowledge. This type of indexing can be made practical using a database like Elasticsearch. The system has the benefit of finding media based on keywords, synonyms, and summaries. The same system can also be used for analytics and insights, such as clustering, shot detection, and creating a 2-dimensional map to display correlations. — The paper also presents extensions to the semantic search systems. Based on a study of multiple existing models, these extensions provide new capabilities - to handle many media types, using additional languages, search for spoken phrases in audio files, finding both verbatim and semantically similar phrases, extracting semantic information that leverages multiple video frames, and searching for ambient sounds.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Artificial Intelligence",
                      "Machine Learning",
                      "Media Search",
                      "Semantic Search",
                      "OpenAI CLIP",
                      "multi-lingual CLIP",
                      "wav2vec2",
                      "CLIP4Clip",
                      "Wav2CLIP",
                      "Microsoft CLAP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001973"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Towards Efficient Multi-Codec Streaming",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yuriy Reznik",
                    "Karl Lillevold",
                    "Abhijith Jagannath",
                    "Nabajeet Barman"
                  ],
                  "abstract": "One of the biggest challenges in modern-era streaming is the fragmentation of codec support across receiving devices. For example, modern Apple devices can decode and seamlessly switch between H.264/AVC and HEVC streams. Most new TVs and set-top boxes can also decode HEVC, but they cannot switch between HEVC and H.264/AVC streams. And while most older devices/streaming clients can only receive and decode H.264/AVC streams. With the arrival of next-generation codecs - such as AV1 and VVC, the fragmentation of codec support across devices becomes even more complex. This situation brings a question - how can we serve such a population of devices most efficiently by using codecs delivering the best performance in all cases yet producing the minimum possible number of streams and such that the overall cost of media delivery is minimal? In this paper, we explain how this problem can be formalized and solved at the stage of dynamic generation of encoding profiles for ABR streaming. The proposed solution is a generalization of the context-aware encoding (CAE) class-of techniques, considering multiple sets of renditions generated using each codec and codec usage distributions by the population of the receiving devices. We also discuss several streaming system-level tools needed to make the proposed solution practically deployable.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Adaptive bitrate streaming",
                      "DASH",
                      "HLS",
                      "H.264/AVC",
                      "HEVC",
                      "multi-codec streaming",
                      "per-title encoding",
                      "context-aware encoding",
                      "CAE"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001963"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "PTP Driven Frame Sync for Multi-GPU Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Kernen",
                    "Thomas True",
                    "Ian Williams"
                  ],
                  "abstract": "GPU-based video processing applications that composite rendered graphics with live video require synchronization of the GPU processing to the video essence stream timebase to prevent visual artifacts caused by temporal misalignment. One such application is in-camera visual effects (ICVFX) in virtual production, the technique of capturing GPU-rendered visual effects composited with live action in-camera within an LED volume. As the media industry continues to move from an SDI to a ST 2110 infrastructure, virtual production environments for ICVFX utilize ST 2059-2 PTP locked Network Interface Controllers (NICs) or Data Processing Units (DPUs) for accurate packet pacing of the media essence streams according to the ST 2110-21 specifications. — GPU processing of video frames is typically performed at the display refresh frequency with updates aligned to frame boundaries. This paper describes a solution for synchronizing GPU display updates with a ST 2059-2 PTP locked NIC, where the PTP Hardware Clock (PHC) is disciplined by the PTP stack running on the NIC/DPU. The NIC generates a Transistor-Transistor-Logic (TTL) signal at the required frequency which is then used to align the GPU's display engine frame boundaries with those of the PTP synchronized ST 2110-20 video essence streams to within nanosecond accuracy. Application Programming Interfaces (APIs) allow GPU-based video processing applications to align the generation and processing of frames across multiple GPUs, as well as perfectly synchronizing updates across all displays. — The ability to leverage the ST 2059-2 PTP profile used to synchronize the ST 2110 essence streams to additionally synchronize displays attached to GPUs, significantly simplifies the overall infrastructure deployment and management relative to traditional means of synchronizing displays using a Sync Pulse Generator (SPG) over coax infrastructure.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "PTP",
                      "GPU",
                      "DPU",
                      "NIC",
                      "2110",
                      "Synchronization",
                      "Timing",
                      "Virtual Production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001972"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Amplifying Human Content Expertise with Real-World Machine-Learning Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Plamen Minev"
                  ],
                  "abstract": "Human-led content classification and enrichment have long been the most impactful yet most expensive form of content workflow operations. Large content library owners often find that they have irreplaceable content expertise concentrated in only a few contributors. They become one of the critical gating factors in effective library content utilization. — Recent advancements and productization of innovative AI technology empowers accumulated human expertise and liberate teams from tedious manual activities, enabling much higher productivity and creativity. By applying the latest AI Computer Vision, Natural Language Processing, Machine Learning, and Video Analytics, a content library can be quickly transformed from a pile of ingested media and tape files to rich content that is fully annotated, searchable, and enhanced for efficient user consumption. — Augmenting the content processing workflows in commonly used tools such as a Media Asset Management system with AI functionality brings an immediate benefit to the end user and abstracts the AI technology complexity. — This paper provides an overview of the AI capabilities applicable to the Media and Entertainment industry. It outlines challenges introduced by the new technology capabilities and best practices to overcome them. — In this paper, we take the user through the approach, steps, and processes of taking a timeconsuming, novel content application task usually performed by a human expert, adapt that task to an AI challenge, build and deploy the necessary ML model, then apply it to content as a part of ongoing content operations using familiar asset management systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Content discovery",
                      "annotation",
                      "AI",
                      "ML",
                      "MAM",
                      "DAM",
                      "media management",
                      "automation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001968"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "ST2110 & ST2022-6 SDN Orchestration Across a Hybrid Cisco and Arista Media Network: based on a Future-Proof Industry-Standard Digital Transformation Architecture and Agile Operational Concepts",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Gunkel",
                    "Ben Vandenberghe"
                  ],
                  "abstract": "With the media industry moving from SDI to IP, software-defined networking (SDN) has become essential to manage routing of uncompressed and compressed signals across switch fabrics and media networks. With a variety of standards, best practices, and specifications, naturally different solutions are available, from bespoke and vendor-specific SDN controllers to open-source ICT-centric tools. As every customer also uses different infrastructure and has different needs, there is no one-size-fits-all SDN orchestration solution. — This paper discusses a case study of an Italian telecommunications and broadcast company moving from SDI to IP to manage uncompressed ST2110, ST2022-6, and compressed transport streams across a converged, capacity-constrained network based on Arista and Cisco switch fabrics. This requires an SDN solution to manage and monitor a multi-format, multi-vendor, and multi-site environment. The focus is on orchestrating resources, network capacity, and technical and operational workflows dynamically while hiding the underlying complexity from operators. — This deployment also marked the start of a company-wide digital transformation to continuously evolve business models and support new technologies and workflows required in the future. As such, this media-specific project was maximally aligned with general industry-standard Digital Transformation architectures and objectives and is intended to adhere to the standard ICT principles for Agile data-driven operations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001956"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Final Sample: Mitigating Acoustical Reflection & Unwanted Noise, Guarding On-Set Virtual Production Dialog",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Rigney"
                  ],
                  "abstract": "While capturing in-camera visual effects (ICVFX) or ‘final pixel’ remains a primary goal of On-Set Virtual Production (OSVP), recording usable performance dialog that carries over to final sound mix or ‘final sample’ is its casualty. Production sound mixer/recordists, inexperienced and illsupported in this newly constructed, sonically hostile environment are left to trial and error. Compared with traditional production sound stages, the acoustical environment created within an LED volumetric stage is highly reflective and sensitive to unwanted noise. Automated Dialog Replacement (ADR) is a solution of last resort. ADR comes at great budgetary, logistics, and creative costs. Achieving zero-ADR (ZADR) is as creatively and economically valuable as is the goal of ‘final pixel.’ — This preliminary study demonstrated that today, with education, a sound mitigation specialist, specific mitigation equipment, and cooperative/collaborative inter-departmental communication, mitigation of reverberation and unwanted noise on a volumetric stage can be managed such that post-production sound editors can effectively process (‘clean’) the recorded tracks to serve in the final sound mix, significantly minimizing ADR usage. Early and consistent collaborative inclusion of sound mitigation professionals, future technologies, and interdepartmental training development and implementation will further reduce reverberation and noise, providing better results more quickly.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Final Sample",
                      "Sound Mitigation Specialist",
                      "Production Sound Mixer/Recordist",
                      "On-set Virtual Production (OSVP)",
                      "Volume or Volumetric Stage",
                      "In-Camera Visual Effects (ICVFX)",
                      "Final Pixel",
                      "Reverberation",
                      "RT60",
                      "Speech Transmission Index (STI)",
                      "Acoustical Camera",
                      "Parabolic Microphone",
                      "Array Microphone",
                      "Acoustical Array",
                      "Noise Cancelation",
                      "Artificial Intelligence",
                      "Automated Dialog Replacement (ADR)",
                      "Zero Automated Dialog Replacement (ZADR)",
                      "Zero Reflection (ZR) Screen",
                      "Echo Shader (ES)",
                      "Image-based Lighting",
                      "Conical Frustum",
                      "Keyboard",
                      "Video & Mouse (KVM)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001975"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "HDR Production - Tone Mapping Techniques and Round-Trip Conversion Performance for Mastering with SDR and HDR Sources",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Touze",
                    "Frederic Plissonneau",
                    "Bill Redmann",
                    "Robin Le Naour",
                    "Patrick Lopez",
                    "Patrick Morvan",
                    "Laurent Cauvin",
                    "Nick Mitchell",
                    "Alan Stein"
                  ],
                  "abstract": "Where content producers had to make drastic choices when allocating the limited contrast and colors in SDR, HDR offers them the possibility to show more - meaning telling stories with greater freedom and flexibility. — However, while future-proof, HDR content presents a challenge of its own: The wide variation in capabilities among HDR displays conflicts with the desire to have any HDR or SDR production play optimally on any display, HDR or SDR, regardless. — The general solution to this issue is tone mapping, either tone compression, which maps from HDR to a lower-luminance HDR or SDR, or tone expansion, which maps from SDR or HDR to a higher-luminance HDR. — Though the trend is to produce the highest quality content in HDR, legacy content is ever-present, and lots of new content is still produced in SDR. Mixing feeds in production requires tone expansion for SDR content to match the HDR. Distribution paths can then require tone compression back to SDR without degradation. In this context, a perfect SDR - HDR - SDR round-trip conversion is required to preserve artistic intent for all content. Further, in a live context, such tools need to be automatic and low latency. — This paper discusses various tone mapping techniques, including static solutions such as look-up tables and dynamic solutions based on metadata. The relative advantages are considered and performance of each is analyzed. Particular attention is paid to the round-trip performance, which is important to content producers mastering both SDR and HDR sources yet wanting to exploit the full range of storytelling capabilities an HDR stream can offer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "SDR",
                      "Tone Mapping",
                      "Inverse Tone Mapping",
                      "Tone expansion",
                      "Tone compression",
                      "TM",
                      "ITM",
                      "round trip",
                      "HDR live production",
                      "Diffuse White",
                      "3D-LUT"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001974"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Measurement of Luminance Reproduction Accuracy of Displays for Complex Imagery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Wanat",
                    "Alexander Carpenter",
                    "Michael D. Smith",
                    "Sally Hattori"
                  ],
                  "abstract": "Modern displays utilize complex light emission systems to allow for high dynamic range and wide color gamut image reproduction. This results in luminance and contrast distribution across the screen that is not only highly dependent on the image content but also difficult to accurately measure and predict. The perceptual effects of these shortcomings are partially masked in consumer displays by the spatio-temporal limitations of the human visual system. However, in the case of colorcritical applications such as color grading using professional displays, inaccurate reproduction of image luminance and contrast can drive creative choices that would not have been made otherwise. In this paper, we describe a measurement procedure and analysis aimed at subjectively and objectively determining the ability of a display to accurately reproduce image luminance. The procedure uses a high-resolution imaging light-measuring device to capture per-pixel luminance on a screen and compare it against the luminance distribution of the source image. The procedure includes steps for registering the image measured by the light-measuring device to the reference image, compensating for lens distortions and simulating the modulation transfer function of the lens. — The paper also contains example results collected for two displays along with an analysis of their performance. The test content used in the measurement contains a combination of synthetic imagery and camera-captured, color graded content. We have developed the procedure for color-critical applications to evaluate the performance of displays and determine luminance reproduction accuracy across complex scenes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "display measurement",
                      "luminance reproduction",
                      "spatial luminance",
                      "metrology",
                      "calibration",
                      "display accuracy"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001976"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Using ML to Find the Semantic Region of Interest",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Zahra Montajabi",
                    "Rob Gonsalves",
                    "Nizar Bouguila"
                  ],
                  "abstract": "One of the most challenging problems in computer vision and image processing is the detection of the semantic regions of interest (SRoI). In this paper, we propose a method using OpenAI's CLIP model to find SRoI by performing semantic search for objects in the image which are detected by an object detection model called Generic RoI Extractor (GRoIE). Finding the semantic regions of interest can be used in different image processing tasks such as image and video compression, enhancement, and reformatting. By knowing the semantic region of interest within images, we can improve the visual quality of images by compressing the more important parts with higher quality and the less important parts, such as the background, with a lower quality. This operation can be achieved without changing the overall compression ratio and the Peak Signal-to-noise Ratio (PSNR) quality metric. Finding the SRoI can make the processes of image enhancement and color correction more accurate by focusing only on the important parts. Moreover, for the image reformatting process, the important parts of the image may be lost. But by using the SRoI, we can reformat the image in a better way by keeping the most important regions in the frame.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Artificial Intelligence",
                      "Machine Learning",
                      "Semantic Search",
                      "OpenAI CLIP",
                      "Object Detection",
                      "Image Compression",
                      "Image Reformatting",
                      "Image Enhancement",
                      "Region of Interest",
                      "Semantic Region of Interest"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001971"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "New Era of ST 2110 Compliance Testing with PICS and RP 2110-25",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pavlo Kondratenko",
                    "Ievgen Kostiukevych",
                    "Willem Vermost",
                    "Leigh Whitcomb"
                  ],
                  "abstract": "As the overall adoption of SMPTE ST 2110 and AMWA NMOS specifications grows. To serve the industry with a better understanding of these standards and specifications, the Joint Taskforce on Networked Media (JT-NM) introduced the JT-NM Tested program. While having run the tested program a few times, some issues were discovered. Issues that resulted in feedback on the documents. As well as other questions that were raised. How to improve and how to scale events like this. To assist with this, SMPTE is creating Protocol Implementation Conformance Statements (PICS) for the ST 2110 standard suite, RP 2110-25 (Professional Media Over Managed IP Networks: Measurement Practices), and the Joint Taskforce on Networked Media (JT-NM) has the JT-NM Tested program. The paper will outline the work and the achieved results in the form of PICS documents for the SMPTE ST 2110 standard suite and the RP 2110-25 document to provide for better testing and measurement of SMPTE ST 2110 implementations. We will be discussing the ways to ensure compliance and interoperability of implementations, including the experience gained during several JT-NM Tested events. We will explain how these interop events are operated, the value they bring, and how the PICS will enhance future such events. Another important aspect is monitoring and measuring the implementations' operation parameters, such as packet pacing. A specific problem discussed is the uniformity and consistency of such measurements among the different SMPTE ST 2110 equipment vendors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "EBU",
                      "JT-NM",
                      "PICS",
                      "SMPTE",
                      "interoperability"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001970"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Travails with My Camera: Investigations with Prototype Workflows and Specialist Cameras for Wider Target Platform Coverage, Reduced Complexity, and Universal Distribution",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Simon Thompson"
                  ],
                  "abstract": "In recent years, broadcast research has extensively studied creating robust workflows that can produce images for a small variety of target devices. Despite many different broadcasters undertaking such work, the resulting workflows are remarkably similar. Now we can begin to look at how these workflows can be extended to deliver to a wider number of platforms and devices, such as social media sites and mobile phones, and how novel techniques can be utilized to improve our product. — With plenty of time during various COVID-19 lockdowns and by gaining access to retired colleagues' cupboards of prototype cameras and radical ideas, the author decided to investigate the non-obvious things these cameras could do, how (or if) they can be integrated in to current workflows and, crucially, what's missing? — By using novel cameras, can we dramatically reduce our power usage at events? — By using novel cameras and new metadata in productions, can we create a single format that can work for TV and AR and can we easily create multiple output formats for a wider range of consumer electronic devices? Is there an easier way to integrate true next-generation audio within current UHD production workflows using signaling that already exists? — With a summer of testing - what can we learn?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "European Championships",
                      "EBU",
                      "HFR",
                      "High frame rate",
                      "MGA",
                      "Metadata guided audio",
                      "Plenoptic"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001988"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Unreal Savings: Budget Previs/Techvis for Student Films",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank Deese"
                  ],
                  "abstract": "Previs and Techvis are expressions still largely associated with big-budget motion pictures and tentpole streaming series. For filmmakers still in school or working with limited resources, the terms are more aspirational than practical to their present production endeavors. Yet some budding film directors, producers, and cinematographers on opposite sides of the globe have already recreated filming locations within video game engines to technically and accurately plan lighting, camera placement and movement, as well as the arrangement of actors on set before filming even begins. This process has saved them valuable hours on shooting days, while using only the most rudimentary Previs video and storyboard stills along with Techvis data. — This presentation will examine how two young filmmakers took detailed measurements and photographs of their production locations - one of them in southern China - inputted all the location data into Epic Games's Unreal Engine, populated their virtual sets with assets to recreate furniture and other basic elements of production design, then used the virtual sets in Unreal as if they were actually setting up for production on location. All this detailed planning was done in the comfort of their own homes and saved thousands of dollars in production hours on actual shooting days. — This Techvis and rudimentary Previs process is something that all film students and low-budget film producers could employ at very little cost. The steps of the process are easily replicable and should become basic to film school instruction. Being well practiced in using game engine applications will also be a valuable lead-in for more complex work in professional Previs, Techvis, and Virtual Production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Game Engine",
                      "Unreal Engine",
                      "Unity",
                      "Previs",
                      "Techvis",
                      "Low-Budget",
                      "Student Film",
                      "Location Planning",
                      "Virtual Production",
                      "Storyboard"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001989"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Modelling the Value of JITEX: Just-In-Time Transcoding at the Edge",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gwendal Simon",
                    "Fatemeh Nasiri",
                    "Jan De Cock"
                  ],
                  "abstract": "In today's CDNs, edge servers are more than just reverse proxies. Computing resources can be reserved at the edge at a lower cost thanks to adoption of virtualized technologies and the availability of datacenters deep in 5G networks. CDN administrators can then evaluate whether to run processing-intensive tasks on or near the edge servers. Through edge processing, traditional CDN management limitations can be fixed by using computing resources. Adaptive Bitrate (ABR) Over-The-Top (OTT) streaming pose a new challenge for CDN management due the plurality of assets versions. Precisely, the CDN is required to offer dozens of videos per asset in order to accommodate a broad range of client capabilities, which reduces cache performance and increases backhaul costs. A solution to this problem is to receive a pivot video and transcode it on-the-fly into different formats by the edge processing solution. In this paper, we model the impact of this solution known as just-in-time-transcoding at the edge (JITEX). To do so, an exhaustive system model is designed allowing to define diverse sets of settings, mimicking real-world streaming scenarios. The results indicates that, the use of JITEX seems to be less cost-efficient when exchanged with cache memory budget. However, when exchanged with ingress traffic budget, specially when the down-link is naturally limited, the use of JITEX appears to be more promising.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CDN",
                      "Just-in-time transcoding",
                      "Edge processing",
                      "Cache management."
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001990"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "The Proliferation of NDI in Live Production and Broadcast Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John E. Ferder"
                  ],
                  "abstract": "NDI was initially promoted as an entree to media production over IP as a low-cost alternative for smaller producers such as municipal governments, houses of worship, and the like. The COVID-19 pandemic has seen a sharp rise in the implementation of NDI, and the NDI Consortium continues to develop new versions of the industry standard such as NDI|HX, and NDI5. A suite of tools and applications has been continuously developed and revised as well. More major manufacturers are adding NDI support into their products as its use has expanded into broadcast and live production workflows. This paper examines these developments, and advocates for SMPTE standardization in concert and close partnership with the NDI consortium.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NDI",
                      "NDI|HX",
                      "NDI5",
                      "broadcast",
                      "live production",
                      "NDI Tools",
                      "standard"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001991"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Solving the Challenge of Volumetric Video Production and Streaming: An End-to-end Perspective of Technologies and Device Ecosystem Capabilities and Performance",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mauricio Aracena",
                    "Mick ODoherty",
                    "Oliver Schreer",
                    "Sebastian Schwarz"
                  ],
                  "abstract": "Volumetric models and assets are great elements for content creators to use in the development of appealing immersive experiences. We can think about live sport events with the entire scene captured as volumetric elements and streamed to the mobile devices of thousands of consumers. However, distribution to consumers of high-quality immersive experiences using volumetric assets has been challenged by a number of factors including visual fidelity, bandwidth, latency, and device processing power. Content creators have been constrained from expressing the full potential intended for their original experience. In this paper you will learn about methods to stream volumetric video assets from an end-to-end perspective including an overview of production systems and suitable volumetric compression profiles (using point cloud compression) that can be used to render on any display for a wider reach: VR headsets, AR glasses, and flat screens. An ecosystem overview with device capabilities and performance is presented, and further included an analysis of content and end-user security functionality. Finally, this paper explores the evolution and opportunities of volumetric video streaming using 5G Cloud/Edge infrastructure to process and distribute volumetric content to any device, minimizing device processor power consumption, minimizing overall delay, and providing the best possible user experience.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001980"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Content Personalization; a Future Vision",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Footen",
                    "Jason Williamson",
                    "Blake White",
                    "Jesse Pitt",
                    "Garrett Coley"
                  ],
                  "abstract": "Content personalization has the potential to generate compelling versions of documentaries, dramas, sports recaps, news summaries, movies, and advertisements that dynamically match each viewer's interests - the extreme relevance increasing audience engagement. Additionally, rich viewer-controlled personal preference data in turn increases the value of subscription and advertising revenue streams. — However, there is a growing and competing tension between content distributors' desire to serve precise and meaningful recommendations for viewers and viewers' willingness to allow access to their personal data, especially to unknown or untrusted organizations. The emerging need for content providers is to have a more comprehensive understanding of audience preferences and for viewers the ability to carry their preferences across all content providers. To address these needs, a secure privacy-assured mechanism to support rapid transparent use of data would address these competing tensions. — Today, neither a technical solution nor protocol standard exist to support this vision. The purpose of this paper is to explore the potential of a data rich, viewer controlled content personalization ecosystem.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "audience segmentation",
                      "cloud",
                      "content stitching",
                      "content provider agents",
                      "content recommendation",
                      "content relevance",
                      "content staging",
                      "content targeting",
                      "compelling content",
                      "data ownership",
                      "edge services",
                      "relevant advertising",
                      "personal profile",
                      "personalized production",
                      "personalized programming",
                      "viewer agents",
                      "viewer control",
                      "viewer preference identification"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001978"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Program-Production System Consisting of Multiple NMOS-Compliant Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomofumi Koyama",
                    "Takuya Kurakake",
                    "Toshiki Sato",
                    "Ryosuke Uchida",
                    "Masayuki Sugawara"
                  ],
                  "abstract": "With the development of standards such as SMPTE ST 2110 suite for transmitting signals and AMWA NMOS (Advanced Media Workflow Association Networked Media Open Specifications) for controlling systems, there is a move toward replacing broadcasters' infrastructure with Internet Protocol (IP)-based program-production systems. This movement often starts with smaller components such as outside broadcasting vans and a few studios. Since the advantage of an IP network is connectivity, it is preferable for each of these independently introduced components to be connected and operated as one large program production system that can be shared among many program productions. — An NMOS-compliant program-production system has a registration and discovery system (RDS) with information on all equipment in the production system. The challenge is how to configure and operate RDSs when connecting multiple NMOS-compliant systems. To share resources in the system among multiple program productions, it is also imperative that the equipment in operation be protected from accidental operations. To achieve this, a function to manage the operational schedule of each piece of equipment and a mechanism to issue authorizations on the basis of the schedules are needed. The NMOS IS-10 specification defines an authorization method, but there has been no study on issuing authorization on the basis of a schedule managed by a resource administrator. — In this presentation, we propose a method for managing multiple RDSs and issuing authorizations on the basis of operational schedules to construct a large program-production system consisting of multiple NMOS-compliant systems. The equipment already in place can be used with the proposed method because the application programming interfaces for registration and authorization are the same as those of a standard NMOS-compliant system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NMOS",
                      "access management",
                      "remote production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001979"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Understanding Color Memory: A Study of Skin Tone Perception in Hue, Intensity, and Chroma",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jake Zuena",
                    "Jaclyn Pytlarz"
                  ],
                  "abstract": "Perceptually, one of the strongest memory colors is skin tone. Get it wrong and it's hard to miss. Image adjustments are commonly applied for preference-based image enhancement, and they are applied across a variety of color spaces, so it's important to understand the effects these procedures have on skin tone appearance. In this paper, we present results of a psychovisual experiment that explores the perception of skin tone under changes in hue, chroma, and intensity. Through coupling the effects each axis has on perception of different skin tones, viewer expectations of color appearance can be evaluated. The experimental results convey a low tolerance for changes in hue when altering intensity and chroma and a high tolerance for changes in intensity across all adjustments. When altering intensity, the results present changes in chroma that follow the shape of the ITP gamut hull. There was some variability between skin tones. This speaks to how individual skin tone classification may be helpful to preserve colorimetric appearance following adjustment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Skin tone",
                      "hue",
                      "chroma",
                      "intensity",
                      "psychovisual experiment",
                      "image processing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001977"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "An Edge Processing Platform for Media Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas True",
                    "Gareth Sylvester-Bradley"
                  ],
                  "abstract": "A hybrid, multicloud approach is needed to address the goals of broadcasters to commission and evolve scalable software-based broadcast systems composed of elements from diverse vendors, on Commercial Off-The-Shelf (COTS) hardware, avoiding lock-in at the facility and in the cloud. These software elements need to support common control, integration with enterprise management systems and a sufficient level of automation. — To that end, broadcast vendors' software needs to run everywhere; use standards and open specifications for control and transport interoperability; support fine-grained resource allocation; and leverage IT best practice, e.g., for monitoring, security, and orchestration. We propose an open-source container orchestration platform, virtualized infrastructure layers, and common software APIs for control interoperability, allowing the vendor to focus where their value and revenue is - the application and UX. — As a case study, we construct a scalable edge platform for transcoding, AI inference and other video and audio processing, that can reduce the cost, latency, and power footprint of cloud-based media production. — Multi-architecture, containerized, applications are deployed and managed with Kubernetes. This provides fine-grained allocation of hardware resources, including Graphics Processing Units (GPUs) and ST 2110-capable network interface controllers (NICs). Service discovery and connection management are achieved using the Networked Media Open Specifications (NMOS). The example video and audio processing pipelines are based on the GStreamer open-source multimedia framework, leveraging the high-performance capabilities of GPU and NIC. Prospective services include transcoding, video and/or audio clean-up, super resolution, automatic closed captioning, content moderation, object identification and compositing of chat or data feeds.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Software-based broadcast",
                      "Hybrid",
                      "Multicloud",
                      "Edge",
                      "Virtualization",
                      "Containers",
                      "Kubernetes",
                      "GPU",
                      "NIC",
                      "DPU",
                      "ST 2110",
                      "AMWA NMOS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001984"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Why Holographic 3D Light field Displays are Impossible, and How to Build One Anyway",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Borer"
                  ],
                  "abstract": "Recent years have seen an immense improvement in video quality culminating in today's ultra high definition with high dynamic range and wide color gamut. Viewers can no longer benefit from increases in resolution in flat, 2D, images; they simply can't see any more detail. Yet both consumers and producers are looking for improved displays, including 3D displays. There have been repeated attempts to introduce stereoscopic 3D over many decades. These have either failed completely or lack conspicuous success. Yet people still seem fascinated by true 3D displays, such as laser generated holograms. If high quality true 3D displays were physically and commercially viable it would be a transformative technology set to replace the billions of 2D displays currently in use. The consequences for the industry, both hardware and content production, would be enormous. — This paper seeks to address the potential for light field displays to become the next, and ultimate, display technology. In so doing it discusses the underlying principles of light field displays and it contrasts them to stereoscopic 3D with its many limitations. — Producing high quality light field displays is a very significant challenge. A huge amount of information must be conveyed to viewers so that they can see high resolution images at different depths and from different perspectives. Light field displays are based on underlying 2D displays. Foremost amongst the technical challenges is the huge number of pixels required. Whilst early commercial light field displays are already available1, they have limited spatial resolution and a very limited depth of field. The experience of viewing is something like viewing a puppet theatre. Unfortunately, their conventional, century old, approach doesn't scale to large depths of field. — This paper describes how a light field display's depth of field depends on the characteristics of the display. Based on conventional 2D sampling theory, it gives the absolute resolution of the display (that is the smallest object in, say mm, that can be resolved). But viewers actually perceive angular resolution, so the analysis is adjusted accordingly. The analysis reveals the enormous number of pixels required for a large depth of field and, consequently, why existing approaches are untenable. — By analyzing the image formation process from the viewer's perspective, the paper shows that many fewer pixels are required to achieve a large depth of field. Even so, more resolution is required. It is shown how this can be provided by rendering images over multiple frames, benefiting from the higher frame rates now becoming available. — The analyses are complemented by an example, based on a 7 year old display resolution, to demonstrate the viability of this approach. Considering current commercial, and near future, displays, the approach scales to larger, higher resolution displays. Light field displays were not viable a few years ago. But improvements in display technology, and a better understanding of appropriate image rendering, presented here, mean they have become practical and will increasingly be so in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Light Field Display",
                      "Holographic Display",
                      "Integral Image",
                      "3D Video",
                      "Stereoscopic 3D",
                      "Depth of Field"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001987"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "How Do We Make Media in the Cloud as Easy as on Prem?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Lennon"
                  ],
                  "abstract": "The shift of virtually every aspect of media to the cloud is in progress. Many extoll the wide-ranging benefits of this move, from increased agility, efficiency, freeing up physical space, switching from CapEx to OpEx, de-focusing staff on data center management, and the list goes on. While there are certainly potential benefits of such a move, they often come at a cost. Remember the old term “plug and play”? In the good old days of connecting physical equipment, as long as you had the right boxes, cables and connectors, you often could just plug equipment together, and be up and running in no time. Unfortunately, it's not quite so simple when trying to connect media products in the cloud. — In general, the world of software is far more flexible than the world of hardware, and this is where the real “gotchas” are. The places where integration in the cloud can be tripped up are seemingly endless. But does it really need to be so complex? Why can't we just connect up products from multiple vendors, across platforms, and have them “just work”? Who's working on making this a reality? The good news is that there are standardized solutions to these issues emerging. We'll dive into what they are, and how they realize the promise of making connecting media products in the cloud as easy as doing it on prem.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud",
                      "standards",
                      "interoperability",
                      "plug and play",
                      "SMPTE",
                      "OSA",
                      "CGGC",
                      "on-prem"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001985"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Image Based Lighting - Current Capabilities and Limitations",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marcus Bengtsson",
                    "Timothy S. Kang"
                  ],
                  "abstract": "The widespread adoption of Virtual Production workflows in general and ICVFX (In- Camera Visual Effects) with LED video screens in particular undoubtedly represents some of the biggest technological advancements in film and television production in recent years. With modern color management workflows and frameworks, we can gain full colorimetric control over our entire video/real-time pipeline. However, Virtual Production is not based on LED video screens alone. Image-based lighting (IBL), a computer graphics lighting method well understood in visual effects production, has now evolved into principal photography lighting workflow where the LED video screens are augmented with traditional lighting fixtures, and the video content used to drive the LED video screens also drives the lighting fixtures. While today's lighting fixtures can produce accurate, beautiful, high quality light for magnificent skin tone reproduction, these protocols must evolve to sufficiently communicate all necessarily color and other device parameters to do so. In this paper, we will review and evaluate existing control protocols and data exchange formats and propose a unified, device independent control and metadata infrastructure for both video and lighting systems that will generate a predictable outcome regardless of manufacturer, device type, color space, media source, and control system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Virtual Production",
                      "Image Based Lighting",
                      "In-Camera Visual Effects",
                      "Color Management",
                      "Lighting",
                      "LED",
                      "Video"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001992"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Secure Collaboration in a Low-Trust Environment: Immutable Chain of Custody",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202022%20Media%20Technology%20Summit/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marc Zorn",
                    "Drew Orsinger",
                    "Charles Porter"
                  ],
                  "abstract": "Protecting against spoilers and theft of intellectual property isn't just the job of Security. For file-based workflows, the normal assumption (by outsiders) is that digital assets are just data, and handling is like traditional corporate IT, and Security mostly guarding infrastructure. The biggest challenge has been trying to regulate changes in every environment. Clearly, that effort is not sustainable or perhaps even achievable. Collaboration happens now in real-time, often with players in unknown locations. In the “content creation” world, it's about establishing tailored collaboration, and protecting the conditions of access. — What if data could protect itself, regardless of storage environment? Why can't we create and protect content using a zero-trust model? This paper reviews how the industry can create a content package of value with encryption and access security, transfer package to a collaboration space, track every access and contribution externally, maintain accountability through wide publication of activity and then transfer enhanced value back to content owner. — Learn how this low-trust model can free us from perpetual facility audits.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2022-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Immutable",
                      "Immutability",
                      "Forensics",
                      "Telemetry",
                      "Compliance",
                      "Accountability",
                      "Ledger",
                      "Tractiv",
                      "Traxion",
                      "Encryption",
                      "Permissioning",
                      "Data Usage",
                      "Data Control",
                      "Data Security",
                      "Data Transaction",
                      "Data Event",
                      "Data Integrity",
                      "Data Tracking",
                      "Data Tracing",
                      "Data Distribution",
                      "Security",
                      "Custody",
                      "Blockchain",
                      "Entitlement",
                      "Cloud",
                      "Cloud-Based",
                      "Zero-Trust",
                      "Tracking",
                      "Tracing",
                      "Audit",
                      "Facility Audit",
                      "Content Creation",
                      "Infrastructure",
                      "Collaboration",
                      "Validation",
                      "Chain of Custody",
                      "API",
                      "NIST",
                      "IP",
                      "Intellectual Property",
                      "Proprietary",
                      "Workflow",
                      "Provision",
                      "Control",
                      "Hashing",
                      "Trust",
                      "Event",
                      "Transaction",
                      "Access",
                      "Protect"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001986"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2021",
        "conferences": [
          {
            "conference_name": "SMPTE 2021 Annual Technical Conference",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/",
            "articles": [
              {
                "article_local_id": "11",
                "article_title": "Live Production System to Handle Video Signals with Various Aspect Ratios",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yoshitaka Ikeda",
                    "Tomohiro Nakamura",
                    "Kosuke Nomura",
                    "Kenichiro Masaoka",
                    "Yuichi Kusakabe",
                    "Satoshi Oode",
                    "Takayuki Yamashita"
                  ],
                  "abstract": "To provide an aspect-free television (TV) service that allows viewers to watch more attractive TV programs using various aspect ratios selected based on the creator's intent, we investigate the system requirements and specific transmission methods for live production in broadcast stations. We propose the use of a 16:9 active video area in conventional video signals such as HD/UHD-1 as containers, and determine the range that the user-specified aspect ratio video occupies in the container using identifier ancillary data. This method is highly compatible with existing systems and conventional workflows. Scalability using multiple containers is considered in this study.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "aspect ratio",
                      "live production",
                      "compatibility",
                      "scalability",
                      "container",
                      "identifier"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001941"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Proxy Workflows for a Secure Remote Production Future",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen Tallamy"
                  ],
                  "abstract": "Using lower resolution proxy files for video production has been an option for a number of years, however advancements in technology, remote working demands, and a drive towards remote production and usage of cloud technologies has opened up a range of new possibilities. — Modern proxy workflows depend on a set of underlying technologies to provide a seamless, secure, and productive user experience. The paper will identify enablers for remote production and provide concrete examples to illustrate how media professionals: — • Overcome challenges of collaborating with high resolution footage — • Control access to valuable original footage — • Create unique renditions to simplify workflows and increase traceability",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001931"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "ATSC 3.0 as a Use Case for Public Safety Communications",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Red Grasso",
                    "Fred Engel"
                  ],
                  "abstract": "Fire and EMS services across the United States still rely on paging technology to communicate emergency incident information. The infrastructure for these paging systems is typically owned, operated, and maintained by the local government or agency to ensure coverage includes as close to 100% of the jurisdiction as possible. This paper proposes the use of datacasting technology to serve the paging needs of public safety and uses North Carolina as a test case. This concept could lead to cost-sharing, greater collaboration across jurisdictions, and reduced response times for mutual aid requests. The public deserve the best possible response from the public safety sector and therefore, public safety deserves the best technology available in order to achieve their mission.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Public Safety",
                      "Paging",
                      "Datacasting",
                      "Public Safety Answering Point (PSAP)",
                      "ATSC 3.0",
                      "Digital Television",
                      "NextGen TV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001934"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Multicam Live Production in a Virtual Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom De Wispelaere",
                    "Dries Tastenhoye",
                    "Vincent Van Werde",
                    "Gregg Young",
                    "Willem Vermost"
                  ],
                  "abstract": "Hardly any movie is made without the use of visual effects (VFX). The power of today's graphical processors allows a lot of the effects to be rendered in real-time, which opens the possibility of recording in-camera VFX. This technique has been used in the making of several recent movies. The TV show “The Mandalorian” uses a large active LED wall to project its 3D scenery. This way, the actors, director, and camera operators see the sets in real-time, instead of a greenscreen. Bringing this innovation to the television studio offers several challenges to overcome. The use of a multi-cam setup and synchronous switching of what is displayed on the LED wall or a consistent depth of field to name just two. We have overcome these obstacles with the Ketnet live show “Gouden K's”. Besides the big productions, we believe this technique might be even more beneficial in small productions using a limited technical crew. With a second project “PeetieClub”, VRT wanted to explore the possibilities and limitations of Virtual Studio Production using Game Engine Technology. The software-based solution we've deployed (running on common PC hardware) allows for lots of flexibility, creativity, and high-quality content in real-time. Using Unreal Engine and PTZ cameras, we've built a complete interactive 4-input Virtual Production switcher engine using one main workstation. Both projects will be described including lessons learned from an operational point of view.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "extended reality (XR)",
                      "live",
                      "multicam",
                      "game engine",
                      "LED wall",
                      "character animator",
                      "on-set virtual production."
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001932"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Toward Generalized Psychovisual Preprocessing for Video Encoding",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Aaron Chadha",
                    "Mohammad Ashraful Anam",
                    "Matthias Treder",
                    "Ilya Fadeev",
                    "Yiannis Andreopoulos"
                  ],
                  "abstract": "Deep perceptual preprocessing has recently emerged as a new way to enable further bitrate savings across several generations of video encoders without breaking standards or requiring any changes in client devices. In this paper, we lay the foundations toward a generalized psychovisual preprocessing framework for video encoding and describe one of its promising instantiations that is practically deployable for video-on-demand, live, gaming and user-generated content. Results using state-of-the-art AVC, HEVC and VVC encoders show that average bitrate (BD-rate) gains of 11% to 17% are obtained over three state-of-the-art reference-based quality metrics (Netflix VMAF, SSIM and Apple AVQT), as well as the recently-proposed non-reference ITU-T p.1204 metric. The proposed framework on CPU is shown to be twice faster than x264 medium-preset encoding. On GPU hardware, our approach achieves 714fps for 1080p video (below 2ms/frame), thereby enabling its use in very-low latency live video or game streaming applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Perceptual optimization",
                      "deep neural networks",
                      "video delivery"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001933"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "360 8K Viewport-Independent VR",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thierry Fautier",
                    "Patrick Gendron",
                    "Xavier Ducloux",
                    "Vincent Lepec",
                    "Pascal Perrot"
                  ],
                  "abstract": "360 VR has been deployed in the past few years using different techniques. Viewport-independent technology is used on 4K content for delivery to 4K-capable head-mounted displays (HMDs) and smartphone devices, resulting in a disappointing experience. The alternative is using viewport-dependent technology with 8K content on 4K-capable HMDs and smartphones devices, which enables a good experience, but with complexities and limitations in terms of the integration into existing OTT workflows. The 8K viewport-independent technology presented uses off-the-shelf encoding techniques to compress 8K 360 VR content as a single file and to distribute it in CMAF low-latency DASH mode to 8K-capable devices such as the Oculus Quest 2 or Galaxy S20. This paper will present an end-to-end 8K VR workflow, which is entirely cloud based and capable of delivering high-quality 8K VR DRM-protected content compared with 4K content on different devices. The paper will present the initial results of the trial performed by the VR Study Group of the Streaming Video Alliance (SVA) in collaboration with the VR Industry Forum, where 8K VR content was encoded and streamed on different very-high-speed (fiber and DOCSIS) networks.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001936"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Infrastructure as Code at CBC/Radio-Canada's Media-over-IP Data Center",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sunday Nyamweno",
                    "Patrick Morin",
                    "Carl Buchmann",
                    "Alexandre Dugas",
                    "Felix Poulin"
                  ],
                  "abstract": "Network infrastructure provisioning is a critical subset of the Automated Deployment of CBC/Radio-Canada's Media-Over-IP Data Center. As the On-Air date approached, it became clear that in order to respond to the fast-changing production needs, traditional network provisioning methods were inadequate. As we began to explore various automation solutions, we realized that a new NetDevOps culture needed to be cultivated within our organization. — This paper will present the architecture and implementation of CBC's network automated deployment workflow in collaboration with Arista. We believe these tools and methods will be applicable as a way forward to many Media-over-IP projects at all scales.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media-over-IP",
                      "automation",
                      "configuration",
                      "NetDevOps",
                      "SMPTE ST 2110",
                      "network"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001937"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "5G Media Streaming and 5G Broadcast for Delivery of DASH/HLS Services",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christophe Burdinat",
                    "Thomas Stockhammer",
                    "Mickael Raulet",
                    "Thibaud Biatek"
                  ],
                  "abstract": "Beyond the spectral efficiency and throughput improvement for Enhanced Mobile Broadband (eMBB), 5G brings many new features targeting vertical applications. To leverage new 5G features and capabilities for media distribution, 5G offers the 5G Media Streaming Architecture (5GMSA). It supports a full set of collaboration scenarios between third party content providers and mobile network operators with various degrees of integration adapted to the OTT ecosystem. While the first version of 5GMSA focuses on media delivery over unicast, Multicast/Broadcast in 5G is one of the key new features currently specified by 3GPP and expected for Release 17. Integration of 5G Multicast/Broadcast capabilities within 5GMSA is essential to scale up the network capacity for linear contents. With the publication of DVB-I in 2020, DVB allows for the delivery of linear television services to internet connected devices over broadband and broadcast networks. As an access independent service layer, DVB-I becomes a strong candidate for providing a converging service layer for 5G. This paper will explore the growing capabilities offered by the 5G Media Streaming Architecture; how it the multicast/broadcast capabilities will be integrated; and how it will enable the delivery of DVB-I services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "5G Media Streaming",
                      "LTE-based 5G Broadcast",
                      "5G Multicast/Broadcast Services",
                      "DVB-I",
                      "DVB-MABR",
                      "DASH",
                      "HLS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001938"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Standards & Specifications for Carriage of JPEG XS in RTP for IP Networks",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Edwards"
                  ],
                  "abstract": "JPEG XS is a low-latency, low-complexity wavelet codec that is promising for IP transport of professional media both on-premises and on the cloud. A combination of standards and specifications, including SMPTE ST 2110-22, ISO/IEC 21122-3, IETF RFC 9134, and VSF TR-08 define the transport of JPEG XS in RTP over IP. This paper describes the essential details of that transport.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "JPEG XS",
                      "IP",
                      "RTP",
                      "TR-08",
                      "RFC 9134",
                      "ST 2110",
                      "ISO/IEC 21122",
                      "cloud"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001950"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Software Defined Ultra-low Latency Video-Over-IP System with Compression",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Siegfried Foessel",
                    "Thomas Richter"
                  ],
                  "abstract": "Traditional Video-over-IP implementations in software either result in higher latency due to the processing time required for compression, or in high bandwidth required when transmitted as an uncompressed stream. With UHD-1 and UHD-2 video, this is even more of a challenge, as the uncompressed stream requires high-performance Ethernet networks or dedicated hardware implementing the compression. In some cases however, a software implementation and standard COTS equipment are beneficial to allow higher flexibility. With JPEG XS, a mezzanine compression codec was developed that can also be implemented as an ultra-low latency system in software. However, special attention must be paid how the data for processing is distributed across multiple threads, how large the number of threads is, in order to achieve optimal latency. Using a case study for UHD-1 Video-over-IP, this paper explains how such a system can be implemented with COTS components, which software architecture is necessary and how far the latency can be reduced.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video over IP",
                      "Compression",
                      "Ultra-low latency",
                      "Software defined codec",
                      "JPEG-XS",
                      "SMPTE ST 2110",
                      "10GbE"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001942"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "8K Camera System with Multi-plane Phase-detection Autofocus",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kodai Kikuchi",
                    "Ryohei Funatsu",
                    "Tomohiro Nakamura",
                    "Toshio Yasue",
                    "Kohei Tomioka",
                    "Takayuki Yamashita"
                  ],
                  "abstract": "We propose a phase detection autofocus (PDAF) method for three-chip 8K UHDTV2 240-fps cameras that detects the in-focus position of a lens by using disparity information between pixels with different apertures across multiple sensors. This multi-plane PDAF method executes pupil division in the same incident position while using simple metal-shielded pixel technology, which can achieve accurate AF and enable low-cost implementation. The proposed method implemented in an 8K three-chip camera incorporating 8K sensors with half-shielded phase-detection pixels into the blue and red channels demonstrated robust disparity calculation compared with the conventional single-chip metal-shielded-based PDAF method.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Phase detection autofocus",
                      "metal-shielded sensor",
                      "three-chip color imaging",
                      "8K UHDTV2",
                      "high-speed shooting"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001939"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Performance of Low-Latency DASH/CMAF and Low-Latency HLS Streaming Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yuriy Reznik",
                    "Thiago Teixeira",
                    "Bo Zhang"
                  ],
                  "abstract": "Reducing end-to-end streaming latency is critical to HTTP-based live video streaming. There are currently two technologies in this domain: Low-Latency HLS (LL-HLS) and Low-Latency DASH (LL-DASH). The latter is sometimes also referred to as Low-Latency CMAF (LL-CM.AF), but effectively it is the same architecture. Several existing implementations of streaming players, as well as encoding and packaging tools, support both technologies. Well-known examples include Apple's AVplayer, Shaka player, HLS.js, DASH.js, FFmpeg, etc. In this paper, we conduct a performance analysis of such streaming systems. We perform a series of live streaming experiments, repeated using identical video content, encoders, encoding profiles, and network conditions, emulated by using traces of real-world networks. We capture several performance metrics, such as average stream bitrate, the amounts of downloaded media data, streaming latency, buffering, frequency of stream switching, etc. Subsequently, we analyze the captured data and describe the observed differences in the performance of LL-HLS and LL-DASH-based systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001943"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Biometric Signals Reveal How Audiences Engage with Stories",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Clayton Mosher",
                    "Brian Wellner"
                  ],
                  "abstract": "Consumer wearable Bluetooth enabled biometric devices are becoming more reliable for collecting physiological data. They are also becoming more accessible to the average consumer. Building a technology platform with the right devices, components, and algorithms can enable content creators to gather consumer insights on how viewers are engaging with their content. Additionally, content can be created with the intention of allowing viewers to interact and control storylines by utilizing their physiological responses. This paper outlines the framework by which this type of data can be collected, what types of stimuli can be applied to insight gathering and content creation, and how this data can be processed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Biometrics",
                      "Galvanic Skin Response",
                      "Heart Rate Variability",
                      "Facial Action Coding System",
                      "Gaze Tracking",
                      "Advanced Narratives",
                      "Signal Processing",
                      "Algorithms",
                      "Artificial Intelligence"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001945"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "New Generation 2/3“, 9.5 Mpix CMOS Imager Combines Charge-domain Global Shutter Operation with Exceptional High-speed Capability",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Klaus Weber",
                    "Jeroen Rotte"
                  ],
                  "abstract": "Previously, when developing 2/3” imagers with native 4K resolution, it was necessary to decide whether they would support global shutter operation or high-speed operation, as both requirements could not be realized in a single imager. Furthermore, the sensitivity and dynamic range of even the best native 4K imagers did not reach the level that typical 2/3” HD imagers with their larger pixels have been offering for several years. — Now, for the first time, a 2/3” CMOS imager based on a 65nm process offers 9.5 million pixels as required for UHDTV-1 resolution, with charge-domain global shutter operation and an output data rate of up to 114 Gb/s, enabling super slow-motion operation at full resolution. — This paper details the solutions and technologies used in this new generation of imagers and the resulting improved image parameters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CMOS Imager",
                      "Global shutter",
                      "UHDTV-1",
                      "HDR",
                      "CIS",
                      "2/3-inch",
                      "high speed"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001946"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Digital Print Stock Design: A Framework for the Post-Film Era",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Cullen Kelly"
                  ],
                  "abstract": "For most of cinema history, the defining factor in the post-production “look” of captured imagery was the print stock. In addition to serving the technical function of transforming scene-referred imagery for display, print stocks were engineered by color scientists to impart preferential color characteristics, and selected by filmmakers based on these qualities. — As the physical medium of the print stock has been retired from contemporary image mastering workflows, so too has the guiding principle of a global creative transform. This is neither necessary nor beneficial; in fact, modern colorists are more in need of this concept than ever. — With the expanding color gamut and dynamic range capabilities of cameras and displays, unifying the imagery of a given piece of content has become increasingly challenging. This has led to the development of systems which address the $\underline{technical}$ aspects of the challenge, most notably ACES. Such initiatives and their broad adoption demonstrate an industry-wide recognition that world-class color grading demands world-class engineering. — Yet in spite of this recognition, there exists no initiative aimed at supporting the $\underline{creative}$ aspects of unifying motion imagery at the macro level. As a result, colorists are left to either re-purpose traditional color correction tools, or to step into the role of image scientist to develop their own. — This paper outlines a proposed framework for the design of digital print stocks, composed of a set of manipulations whose parameters can be intuitively modified by artists, resulting in a global look which can be deployed within any imaging pipeline.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "color grading",
                      "look development",
                      "film print",
                      "digital cinema",
                      "HDR",
                      "color management",
                      "ACES"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001947"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Exploring Realtime Conversational Virtual Characters",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ha Nguyen",
                    "Aansh Malik",
                    "Michael Zink"
                  ],
                  "abstract": "Advancements in Artificial Intelligence (AI) such as Speech-To-Text, Language Understanding Models, Language Generation Models, and Text-To-Speech enable various types of applications, one of which is real-time conversational Virtual Characters. Building an end-to-end framework with the right AI technology components enables relatable and multi-dimensional Virtual Characters, who can naturally converse in creatively controlled domains, while consistently maintaining their state and personality in pre-determined narratives. In this work, we designed such a conversational framework with interchangeable, and loosely coupled components to support granular creative details in character performance, efficiency in mass creation of Virtual Characters, and flexibility to embrace future improvements of each component in the fields. We then evaluated the robustness and modularity of the framework by creating Melodie, a Virtual Character who is fond of music, and is a fan and promoter of the Eurovision Song Contest. With Melodie, we went through the full cycle from processing a speaker's audio signals, to generating a proper response using a Natural Language Generation model, to synthesizing the response in a character's Voice Font, to finally synchronizing the synthesized response with corresponding body and facial movements to produce a coherent and believable character performance. Testing and analyzing the implementation of Melodie brought forth areas of improvement and ethical considerations that are, and continue to be, essential to the design of our future applications involving Virtual Characters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Virtual Characters",
                      "Virtual Beings",
                      "Conversational AI",
                      "Conversational Characters",
                      "Artificial Intelligence"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001944"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Tighter NIC/GPU Integration Yields Next Level Media Processing Performance",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Kernen",
                    "Thomas True"
                  ],
                  "abstract": "As the media industry further consolidates building services based on Commercial-Off-The-Shelf (COTS) hardware, the requirement for increasing performance continues to accelerate. The processing of video resolutions up to Ultra HD (UHD) and 8K, higher frame rates, increased bit depth, and High Dynamic Range (HDR) imagery, requires tighter integration and optimization between the Network Interface Controller (NIC) and the Graphical Processing Unit (GPU). Combined with simultaneous input and output of multiple streams, this creates the potential for performance bottlenecks that must be unlocked. — This paper describes how COTS hardware platforms running GPUs alongside ST 2059-2 PTP locked NICs which are accurately pacing packets according to ST 2110-21 requirements may further increase their performance throughput by reducing CPU driven data copy overhead. And in doing so, reduce processing latency and jitter, and more effectively use GPU resources while freeing up CPU resources.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "GPU",
                      "NIC",
                      "DPU",
                      "PTP",
                      "2110",
                      "Timing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001948"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "The Problem with Timecode",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Loughlin",
                    "Derek Schweickart"
                  ],
                  "abstract": "Timecode as it exists today is arbitrary and imprecise, and conflates its role of identifying an individual media element and functioning as a time clock. As we move more and more into file based, cloud first workflows, we need a new time labeling standard that empowers and achieves the same level of complexity that advancements in our video and audio pipelines do. — To address this, we evaluate a number of glaring problems with timecode to understand what problems need solving, and what is required in a new standard. — A new standard needs to be extensible and designed to work inside of a file instead of a video signal. A new standard also needs to address all samples — video frames, audio samples, and data samples — while also avoiding the limitations of a 24-hour clock. Additionally, it should allow for layers in order to track manipulation through a pipeline. A frame or sample should be able to be identified from a delivered file back to its original source. — The creation of a precise time labeling system that allows us not only to provide and accurate sense of when a sample was created, but also by whom and what it is, is required to empower the next generation of digital workflow and creative tools.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Timecode",
                      "Digital Cinema",
                      "Cloud",
                      "Post Production",
                      "Production",
                      "UTC",
                      "time label"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001940"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Calibrating LED Fixtures and Video Walls to the Camera's Chroma Signal",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brad Dickson"
                  ],
                  "abstract": "This presentation is directed to productions using LED Lighting including productions using LED fixtures who want to calibrate their lights to the needs of the camera. Gaffers, Lighting Directors, LED fixture manufactures, virtual productions, video engineers and technical directors. — Viewers will take away the following — • Differences between LED lighting and other light sources — • Deficiencies in the current lighting metrics used to measure light as they are inadequate to show on camera results of a LED light source — • How the use of the cameras chroma signal as a guideline to calibrate LEDs lighting camera to improve the on-camera colour reproduction and create harmony between led sources colour reproduction on camera. — The presentation deals with Novel Technological Approaches and Case Studies for industry proposal changes",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001935"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Hue-Preserving Color Transforms for LED Wall Virtual Production Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/23/",
                "article_tags": [
                  "Original Research",
                  "Open access"
                ],
                "metadata": {
                  "authors": [
                    "Michael D. Smith",
                    "Michael Zink"
                  ],
                  "abstract": "Virtual Production using LED wall display technology is gaining popularity in the entertainment industry to produce motion pictures, episodic television, live broadcast and esports content. This new paradigm typically uses one or more large LED displays that contains millions of individual Light Emitting Diodes (LED) that are used to display a virtual background and/or foreground objects from a virtual scene that is simultaneously captured by the digital photographic camera on set, resulting in so-called “in-camera visual effects”. In a virtual production workflow, digital cameras capture the actors and objects on the set in the foreground while simultaneously capturing the image shown on the LED wall behind the actors. Realtime video game rendering engines update the image shown on the LED wall image to compensate for changes in camera location, camera pose and focal length. Modern digital camera workflows typically include color transforms that were not designed to accurately render the large areas of saturated colors that are possible when capturing the image shown on an LED wall. Some examples of a hue shift that can occur in typical workflows are blue to cyan, red to pink, red to orange and green to yellow. — We found these hue shifts can occur dynamically while racking focus to and from the LED wall, and also statically when the LED wall is kept out of focus, which is a common technique that is used to minimize moiré artifacts. This paper explores a simple modification of these common color transforms to preserve the hue of the scene while also creating a similar Look of the existing color transforms.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LED Wall",
                      "Virtual Production",
                      "Color Transform",
                      "Lookup Table",
                      "LUT",
                      "hue shift",
                      "hue-preserving",
                      "rendering"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001953"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Understanding Banding - Perceptual Modelling and Machine Learning Approaches for Banding Detection",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hojatollah Yeganeh",
                    "Kai Zeng",
                    "Zhou Wang"
                  ],
                  "abstract": "Banding is an annoying visual artifact that frequently appears at various stages along the chain of video acquisition, production, distribution and display. With the thriving popularity of ultra-high definition, high dynamic range, wide color gamut content, and the increasing user expectations that follow, the banding effect has been attracting a growing deal of attention for its strong negative impact on viewer experience in visual content that could otherwise have nearly perfect quality. Here we present two different types of frameworks to detect the banding artifact. The first is knowledge-driven and is built upon computational models that account for the characteristics of the human visual system, the content acquisition, production, distribution and display processes, and the interplay between them. The second is data-driven, and is based on machine learning methods, by training deep neural networks with large-scale datasets.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Banding impairment",
                      "contouring impairment",
                      "perceived video quality",
                      "human visual system"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001952"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Model-based Predictive Control for Continuous Success Planning in Movie Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Suman Kalyan",
                    "Angshuman Patra",
                    "Sujay Kumar",
                    "Abraham Addanki",
                    "Shashank Sahoo"
                  ],
                  "abstract": "The movie industry across the globe is a multi-billion-dollar business for stakeholders. Perhaps the single most financially dominating recipe among all flavors of media entertainments available to the audience. A plethora of carefully coordinated onerous efforts encompassing acting, direction, scriptwriting, casting, editing, and production goes into making and releasing a movie. Financiers and producers reel through several financial losses if the movie does not perform well at the box office. Given the complicated composition of time, money, imagination, creativity, and risk, it becomes imperative to have some measurable, quantifiable, and controllable parameters to predict movie performance on box-office during various stages of making through leveraging insights from plot-summaries, trailers, posters, teasers, social-buzz, cast/crew-selection etc. — Can specialized Artificial Intelligence techniques help from historical data across these modalities to best predict the success of a movie and be the foundation for creating a sustainable architecture for Model-based predictive control? This paper proposes a Model-based predictive control to create a closed-loop feedback system that will enable superior production planning. Model-based predictive control has seen success in the Industrial automation domain and has been historically used for establishing feedback control loops for industrial automation processes. The paper also presents experimental results on the foundation needed for a model-based predictive control: A hybrid, yet comprehensive RNN/ LSTM/CNN-based neural network architecture that can predict the success of the content much earlier to optimize production cost. It leads to a useful foundation that enables content creators to manage especially the pre-production part of the journey much better by making the right decisions that enhance the probability of success.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CNN",
                      "LSTM",
                      "RNN",
                      "Movies",
                      "Posters",
                      "Videos",
                      "Genres",
                      "Explainability",
                      "SHAP",
                      "Grad-CAM",
                      "Multimodal architecture",
                      "Model-based predictive control"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001949"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Dynamic Seamless Resource Allocation for Live Video Compression on a Kubernetes Cluster",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202021%20Annual%20Technical%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Abdelmajid Moussaoui",
                    "Mickael Raulet",
                    "Thomas Guionnet"
                  ],
                  "abstract": "A solution is proposed on top of Kubernetes to dynamically allocate services resources without service interruption. It serves as the basis for optimizing a live video compression service. It is demonstrated that dynamic resource allocation can benefit to a video compression application, either by reducing the resource consumption, hence costs, or by enhancing delivered video quality. By combining the proposed solution with an elastic encoder and machine learning for content complexity estimation, a content and application aware dynamic resource orchestrator for real-time video compression is designed. Preliminary experimental results using ATEME Titan Live Microservices [8] encoders demonstrate substantial bitrate reductions on even the most demanding channel.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2021-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video compression",
                      "machine learning",
                      "AI",
                      "Cloud",
                      "Kubernetes",
                      "Video Coding",
                      "HEVC",
                      "Video quality",
                      "Content Adaptive"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001951"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2020",
        "conferences": [
          {
            "conference_name": "SMPTE 2020 Annual Technical Conference and Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "UHD (2160 / HDR) and HD (1080 / BT.709) Simultaneous Workflows at the CBC",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre Hugues Routhier"
                  ],
                  "abstract": "As video content evolves from traditional television into more complex and varied forms of media, more and more of our content creators capture in higher resolution, frame rate and dynamic range than traditional HD to give themselves creative latitude in post-production. — Generating UHD content comes with its lot of challenges for a traditional HD infrastructure. For example, which version(s) should be archived: The source, ungraded asset, the HD version, the social media version(s) like square and vertical, or a combination of those? If content is shot in UHD, for example, and then cropped in post, should the final, cropped HD product be the one we archive, or the UHD original? If we archive the original, how do we store information about the cropping parameters? If color and dynamic range are wider in the source than the final render (e.g. SLog3/SGamut3), which 3D Look-up Table is the right one to use? Should that 3D LUT also be archived with the source asset? How do we link a specific asset to a specific 3D LUT for posterity? — Public broadcasters have legal obligations with regards to content preservation, but those do not necessarily specify the format(s) for archival, so we need to balance obligations, cost and future value of assets in the process of designing such workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHD",
                      "4K",
                      "HDR",
                      "SLog3",
                      "3D LUT",
                      "Broadcasting",
                      "Post-production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001901"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "How to ensure a good depth perception on a light field display",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Doyen Didier",
                    "Allie Valerie",
                    "Schubert Arno"
                  ],
                  "abstract": "Information captured by the eye allows the human brain to extract depth cues from the scene, to analyze them and to understand a complex 3D scene. In real life all these depth cues are naturally present at the same time and consistent. Rendering them on a display for several viewers is not straightforward. Today no technology can fully achieve this requirement. Per definition, light field content is a collection of light rays that are corresponding to different viewpoints of the same scene. A light field display should be able to render these different viewpoints to a single viewer or to multiple viewers. The quality of a light field display will be measured by its ability to correctly render these different views and the expected depth cues. — In the paper we will define the technical requirements for a light field display to provide effective depth cues such as the binocular disparity, the motion parallax and the accommodation at a pixel resolution expected by the eye. These requirements will be evaluated with respect to existing technologies (e.g. integral imaging displays) or expected future ones (e.g. microLED displays). Simulation of light field displays will be proposed for different display sizes (smartphone, desktop or TV), resolution per view and pixel pitch. These simulations illustrate the main impact of the pixel pitch to reach the light field display goal in terms of depth cue requirements. — The last part of the paper will focus on the data generation issues. How to generate the necessary amount of views at the display side and what are the adapted data formats for such a purpose? The paper will be associated with supplementary videos that will illustrate the view generation topic using a dedicated data format that is optimized for current GPU processors. Video capture of early stage light field displays will also be provided.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001912"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "V-PCC: performance evaluation of the first MPEG Point Cloud Codec",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Celine Guede",
                    "Pierre Andrivon",
                    "Jean-Eudes Marvie",
                    "Julien Ricard",
                    "Bill Redmann",
                    "Jean-Claude Chevet"
                  ],
                  "abstract": "Representation of 3D scenes is increasingly important in several industries by usingVirtual and Augmented Reality technologies. The point cloud format is well suited for such representations. Indeed, point clouds can be created with a simple capture process and modest processing, enabling a real-time, end-to-end point cloud distribution chain. However, point cloud compression is required to obtain data rates and files sizes that could be economically viable for industry. Standardization is required to ensure interoperability. In 2020, the International Organization for Standardization (ISO) Moving Picture Experts Group (MPEG) will publish a standard for its first point cloud codec, MPEG-I Part 5: Visual Volumetric Video-based Coding (V3C) and Video-based Point Cloud Compression (V-PCC). This standard enables a world of new services and applications, including cultural heritage, telepresence, and new forms of entertainment. — In this paper we review the principal use cases targeted by the V-PCC standard, we present the architecture of the V-PCC codec and describe its main tools, by giving insight on complexity at the encoder and decoder level and explaining profiles and conformance points in V-PCC. We then present the methodology established, as a collaboration between industry and academics, for the evaluation of the V-PCC codec performance and the methodology's origins. This methodology was applied to the MPEG point cloud compression test model software (named TMC2) to consistently evaluate technologies proposed during the standardization process. Finally, we compare the performance of the main V-PCC tools available for lossy and lossless compression. Finally the conclusion provides elements in favor of a near-term deployment of V-PCC in the media industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "point cloud compression",
                      "immersive video coding",
                      "performance evaluation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001913"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Deep Learning Approach to Predicting the Success of Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Suman Kalyan",
                    "Ashwyn Tirkey",
                    "Angshuman Patra",
                    "Sujay Kumar",
                    "Pranav Singh",
                    "Abraham Addanki"
                  ],
                  "abstract": "Movie Industry across the globe is a multi-billion dollar in revenue. There are several factors and somewhat complicated, which makes a movie a box-office success. The financial cost of making a movie [1] can range from modest cost to mammoth several 100 million dollars in spending. The audience rules in terms of liking/disliking of a movie. Financiers and producers reel through several financial losses if the movie does not do well in the box-office. Can Artificial Intelligence techniques help from historical data, be it movies, audience reviews/sentiments, cast/crews to predict the success of a movie? Our paper explores the proposal for a hybrid RNN/LSTM/CNN based neural network architecture that can predict the success of the content. It leads to a useful foundation that enables content creators to manage the pre-production part of the journey better by making the right decisions that enhance the probability of success. The foundation of our proposal can help the pre-production state with a certain degree of predictability to the success of the content, explainability causing the success, and the next best action.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CNN",
                      "LSTM",
                      "RNN",
                      "Movies",
                      "Posters",
                      "Videos",
                      "Genres",
                      "Explainability"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001914"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "“AI News Anchor” with Deep Learning-based Speech Synthesis",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kiyoshi Kurihara",
                    "Nobumasa Seiyama",
                    "Tadashi Kumano",
                    "Takashi Fukaya",
                    "Kazunari Saito",
                    "Satoshi Suzuki"
                  ],
                  "abstract": "Deep learning-based text-to-speech (DL-TTS) is used in various situations and the sound quality is close to that of humans. We previously developed a news-specific DL-TTS system and implemented it to our AI news anchor for live broadcast programs and automatic news-speech distribution services. — We also developed our DL-TTS system for controlling speaking style and speech speed, pitch, intonation, and volume to facilitate the creation of various programs. More specifically, this method enables the changing of specific speaking styles, such as news style that mimics the style of news reporters, and conversation style. The purpose of creating this system was to eliminate discomfort due to differences in speech and speaking styles. Controlling the speaking-style is important in news speech because a mismatched speaking style does not appropriately convey news articles. For this study, we conducted an evaluation experiment on the conveying of simple news articles for language learners regarding speaking-style control and found appropriate speaking styles for automatically generated news speech. We conducted another evaluation experiment on whether synthetic speech generated from our system for “easy news” for Japanese language learners is useful for helping people understand the news in Japanese. We also discuss practical applications of our system. — Our news-specific deep neural network based-TTS system was found to effectively provide new services to broadcast stations. In the future, we will consider various use cases of flexible production by using a cloud system. The coronavirus pandemic has forced broadcasters to adopt new working styles. Thus, we will explore a new production system, such as a cloud-based system, for newsspeech automation for this new normal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Deep learning-based TTS",
                      "AI news anchor",
                      "Automatic generated news speech"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001915"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "A 2/3″ 9.5 Mpixel CMOS Imager with High Frame Rate and HDR Capabilities",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Klaus Weber",
                    "Jeroen Rotte"
                  ],
                  "abstract": "Requirements for live sports production in 4K UHD resolution and high dynamic range (HDR) have multiple challenges for the imaging technology. First and foremost, the high pixel count on any given 2/3″ imager size reduces the pixel size to a critical level, while allowing for enough sensitivity and dynamic range required for many different shooting conditions. In addition, stretching the requirements even further, we have high-speed cameras fully integrated into the production workflow supporting native 4K UHD resolution as well as support for the different HDR formats used in live production. — An increase in frame rate increases the bandwidth requirements with the same factor and going from single speed to 3X or 6X speed requires clock rates exceeding the capabilities of the typical 2/3″ imagers used today. The imager presented in this paper demonstrates an architecture that supports high spatial and high temporal resolution and a high output data rate. The sensor is manufactured in a 110/180 nm CMOS process and supports a pixel rate of 3.6 Gpix/s, which translates to an output data rate of 58 Gb/s. The imager uses 4T-4shared pixels in combination with kTC-noise suppression by Digital Double Sampling (DDS) and one 16-bit ADC for each column of the shared pixels. This translates to 2112 ADC outputs which has to be multiplexed and serialized to 16 parallel outputs in 32 LVDS lanes at 1.8 Gb/s for which sixteen 132:1 multiplexers are needed. — To meet the lag performance for demanding live broadcast applications, typically a transfer time of <1 μs is needed. For high frame rate at full resolution, the available time for column settling and A/D conversion makes it impossible to meet this requirement without addressing multiple rows at the same time. To fulfill the transfer time requirements, an innovative row addressing scheme has been developed to toggle between the different rows. — This paper will explain the architecture and readout schemes used to realize a 2/3″ 9.5Mpixel CMOS imager with 3.6 Gpix/s enabling high frame-rate operation in native 4K UHD resolution and full HDR support.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K UHD",
                      "HDR",
                      "CMOS",
                      "Imagers",
                      "Pixel",
                      "SSM",
                      "super-slow-motion"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001905"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "New Technologies that Further Empower Digital Cinematography",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yosuke Kamada",
                    "Yotaro Sanjo",
                    "Nathaniel McFarlin",
                    "Laurence Thorpe"
                  ],
                  "abstract": "The backdrop to this paper is the rapid pace at which digital cinematography has advanced. Propelled at the dawn of the new century by the multiple technological fronts of HDTV motion imaging it soon separately set off on its own digital pursuit of the imaging attributes of Super 35mm motion picture film systems. The Digital Cinema Initiative (DCI) expeditiously developed specifications for the total system based upon 2K and 4K digital production formats. By 2010 there were numerous Super 35mm 4K digital cinematography systems emerging across the world. In 2017 the first full-frame cinematography camera emerged. Others quickly followed. Related acquisition ecosystems encompass lenses, cameras, recording, and on-set reference displays. New generation zoom and prime lenses emerged tailored to the expanding requirements of both movie and television production. Camera image sensors advanced on multiple technological fronts. Digital recording and associated storage media technologies moved especially fast over the past ten years. The emergence of HDR and WCG affected all of these system components, and most especially, the on-set reference display. This paper will report on some recent technological advances in each of these areas of the digital cinematography ecosystem.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Zoom Ratio",
                      "Aspheric lenses",
                      "Optomechanical",
                      "Ergonomic",
                      "Photodiode",
                      "Column amplification",
                      "Sensitometric",
                      "Multi-base ISO",
                      "Dual Gain Output (DGO)",
                      "High Dynamic Range (HDR)",
                      "Wide Color Gamut (WCG)",
                      "Diffraction",
                      "Digital Image Stabilization (DIS)."
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001907"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "The Color Compass: A Color Navigation System in a Dynamic Deliverable World",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rory Gordon"
                  ],
                  "abstract": "Color order systems were developed to aid in the quantification of color. Classic color systems such as Munsell and Ostwald relied upon a three dimensional model of color to visually conceptualize the color order, in the shape of a cylindrical atlas and a double cone, respectively. These systems can aid in designating absolute values and identifying manufacturing standards by numerical specifications. — However, the addition of multiple color targets, including wide-color-gamut (WCG) and high dynamic range (HDR), to motion picture deliverables now means that multiple versions of the same file will be delivered. A cohesion between assets is required, whether or not that is done with metadata in the case of Dolby Vision files, or with completely separate image sequences as may be the case with some providers. Using a numerical color order system does not help QC professionals, color pipeline engineers, or production creatives determine whether these multiple versions are in line with original creative intent. The paper proposes a visual color navigation system, which provides new vocabulary in order that shifts in color, lightness, and chrominance values be identified, related to original creative intent, and shared between creatives and engineers alike in motion picture applications. — The system revolves around a hue disc with four cardinal directions, indicating two axes of warmth to coolness (North-South and East-West). This color compass can be used as a navigational tool within any color encoding scheme or color space in use for a project. For example, the system can be used to discuss the g and j axes in OSA-UCS, the a* and b* axes in CIELAB, or the tritan and protan axes in ICtCp. The system also equates lightness to altitude values, so a user can describe “higher” or “lower” values as one might describe the altitude of terrain. Lastly, chrominance will be described as expanded or contracted, in relation to the original value. — The paper will include illustration of the system at work in different color spaces, in addition to using practical examples from the author's experience with over one hundred episodes of HDR content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "SDR",
                      "color management",
                      "color order system"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001903"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "UHD Production Codecs - the agony of choice",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dagmar Driesnack",
                    "Frans de Jong",
                    "Simon Thompson"
                  ],
                  "abstract": "Video production equipment uses different codecs and settings to balance competing requirements, such as trading off between bitrate and quality. The introduction of UHDTV and HDR adds to the number of codec implementations, making codec choices harder. To help their Members evaluate the visual quality of new video production codecs, the EBU and the IRT have organized expert viewings of the latest production codecs. Based on the plans revealed at IBC 2019, more than 200 possible codec configurations were identified. After a voting round by broadcasters, more than 40 of these configurations were selected for actual testing. The focus was on real-world products, not laboratory prototypes. Seven generations were encoded for each configuration. The PSNR of all sequences was calculated. Subsequently the 1st, 4th and 7th generation of each sequence was scored by expert viewers. The results indicate that overall, the tested codec configurations perform well up to the 7th generation. For some of the algorithms a small quality degradation was seen in noise behavior and spatial resolution but no difference in dynamic range was noticeable. There is a small discernible difference of the performance for the different transfer functions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Production Codecs",
                      "2160p",
                      "1080p",
                      "HDR",
                      "SDR",
                      "ITU-R BT.2100",
                      "ITU-R BT.2020",
                      "ITU-R BT.709",
                      "HLG",
                      "PQ"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001902"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "JPEG-XS Codec Adapted to 8K and ST 2110",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kota Itakura",
                    "Masayuki Miyazaki",
                    "Siegfried Fobel",
                    "Michael Van Dorpe"
                  ],
                  "abstract": "We developed a JPEG-XS codec-based video transmission system corresponding to 8K UHDTV (Fig. 1). JPEG XS has attracted attention as a mezzanine compression technology for IP interfaces such as SMPTE ST 2110-22. JPEG-XS is known for its high compression efficiency, picture quality, and very low latency, but there have not been any products adapted to 8K formats to date. — In contrast, migration of interfaces from SDI to IP in program production facilities such as TV studios or OB vans is accelerating. It is important to define a network design starting with its bitrate per stream, especially in large-scale production systems, because the quantity of network switches and bandwidth in a backbone network design greatly affects development costs, system complexity, and feasibility. — We developed an 8K JPEG-XS software-based codec prototype using only a CPU and not GPU, with which we were able to confirm 8K/60p video quality in real time at various compression ratios. For higher flexibility, the decoder can decode an 8K resolution image by using the full bit stream, or a 4K resolution image by decoding only parts of the bit stream. In terms of efficient system design, we gave it a scalable decoding function, which can also achieve 4K-resolution video, by partially using an 8K code stream. — In this paper, we will introduce the results of the quality evaluations and propose an appropriate bitrate for the 8K JPEG-XS case. Furthermore, we will refer to an example of network design, where it is used in a large-scale, multi-resolution production system for which we are doing such evaluations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "8K UHDTV",
                      "JPEG-XS",
                      "SMPTE ST 2110",
                      "10GbE"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001904"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "High Density Encoding for ARRIRAW Image files",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Gaffney",
                    "Harry Mallon"
                  ],
                  "abstract": "Codex High Density Encoding (HDE) is an encoding and decoding schema for large format ARRIRAW workflows to control the ever-increasing data footprint of RAW data. Studios are demanding 4K and RAW image data to archive and future-proof the negative. High Frame Rate (HFR) and High Dynamic Range (HDR) add to this large format data footprint, leading to significant cost increases as well as storage and transmission challenges. Uncompressed RAW data costs more to transport and store than compressed ProRes files. An uncompressed ARRIRAW image can be reduced with HDE to a file size not much larger than a corresponding ProRes 4444 XQ file. Except with Codex HDE, you can access the original pixel values that were encoded. Codex HDE can be used to compress raw Bayer pattern data (e.g. from a digital image sensor) in such a way that decoded data is identical to the raw data. The encoded files are typically 50-60% of their original size. A wide variety of third-party commercial applications can be used to decode files containing HDE bitstreams for data management, transcoding, color grading, visual effects and archiving. The presentation will describe the structure of data encoded with Codex HDE, along with algorithms for decoding the stored data. It is the intent of the presentation to describe the structure and encoding of all fields in the HDE bitstream, detailing how 3rd party vendors and their applications can decode HDE bitstreams and correctly identify its structure. Recent details on SMPTE RDD51 on HDE will be presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CODEX",
                      "ARRI",
                      "ARRIRAW",
                      "RAW",
                      "HDE",
                      "High Density Encoding",
                      "ZigZag Encoding",
                      "RDD 30:2014",
                      "RDD 51:2020"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001908"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Live VR end-to-end workflows: real-life deployments and advances in VR and network technology",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mauricio Aracena",
                    "Thierry Fautier",
                    "Ozgur Oyman"
                  ],
                  "abstract": "Live VR sports events are gaining traction among viewers since immersive services add a closer experience than watching on a TV providing even better point of views than being at the event. The content acquisition of the Live VR feed is captured using additional cameras dedicated for this purpose (in addition to the traditional cameras). In the venue, there might be several locations where the VR content is captured. The director may choose which Live VR feeds are distributed to home delivery, either by producing one single VR feed, or by giving the choice to the end user to select which one to watch, or a by offering a combination of a produced feed and individual cameras. — In this paper, we describe and analyze the live VR workflows from an end-to-end perspective such as production, contribution, distribution and consumption aspects and describe how this can be complementary to the traditional broadcast services with a 4K like experience. We also describe how the recent advances in VR technology can improve VR experience in an optimal bandwidth using view port dependent technologies (for instance using MPEG OMAF format) and how VR production techniques (such as volumetric) provide advance tools for capturing footage from many angles for producing live free-point of view consumption and volumetric replays. This paper also presents Live VR service deployments using those technologies and it will describe the technical challenges from an end-to-end perspective on how to achieve high quality (VR360 8K equivalent) considering aspects such as bit rate, latency, CDN configurations and device capabilities. Finally, we also address how any high speed broadband infrastructure like 5G, Fiber of DOCSIS 3.1 infrastructure and new 5G devices with their built in 8K capabilities can simplify the Live workflow, and how it can accelerate the 8K VR deployments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "live VR",
                      "VR360",
                      "Volumetric",
                      "VR workflows",
                      "8K",
                      "5G",
                      "Omidirectional Media Format (OMAF)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001910"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "A Benchmark of Objective Quality Metrics for HLG-Based HDR/WCG Image Coding",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yasuko Sugito",
                    "Trevor Canham",
                    "Javier Vazquez-Corral",
                    "Marcelo Bertalmio"
                  ],
                  "abstract": "In this work, we study the suitability of high dynamic range, wide color gamut (HDR/WCG) objective quality metrics to assess the perceived deterioration of compressed images encoded using the Hybrid Log-Gamma (HLG) method, which is the standard for HDR television. — Several image quality metrics have been developed to deal specifically with HDR content, although in previous work we showed that the best results (i.e., better matches to the opinion of human expert observers) are obtained by an HDR metric that consists simply in applying a given standard dynamic range metric, called visual information fidelity (VIF), directly to HLG-encoded images. — However, all these HDR metrics ignore the chroma components for their calculations, i.e., they just consider the luminance channel. For this reason, in the current work, we conduct subjective evaluation experiments in a professional setting using compressed HDR/WCG images encoded with HLG and analyze the ability of the best HDR metric to detect perceivable distortions in the chroma components, as well as the suitability of popular color metrics (including ΔITPR, which supports parameters for HLG) to correlate with the opinion scores. Our first contribution is to show that there is a need to consider the chroma components in HDR metrics, as there are color distortions that subjects perceive but that the best HDR metric fails to detect. Our second contribution is the surprising result that VIF, which utilizes only the luminance channel, correlates much better with the subjective evaluation scores than the metrics that do consider the color components.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High dynamic range (HDR)",
                      "wide color gamut (WCG)",
                      "Hybrid Log-Gamma (HLG)",
                      "image compression",
                      "objective quality metric"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001925"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Twenty years of Frame Interpolation for Retiming in the Movies",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anil Kokaram",
                    "Davinder Singh",
                    "Simon Robinson"
                  ],
                  "abstract": "Frame interpolation is the process of synthesising a new frame in-between existing frames in an image sequence. It has emerged as a key algorithmic module in motion picture effects since its use at a large scale in the making of the movie “The Matrix”. This paper presents a review and a new unified view of the classical algorithms used to create inbetween frames, representing most of the last 20 years of their evolution. This is used to benchmark the recent Deep Learning algorithms against two of the best industrial retimers available. A significantly expanded dataset of 140,000 frames is used for testing. In the context of high resolution material we find that techniques relying principally on DNNs do not clearly outperform the classical ideas. It is only with the emergence of hybrid approaches since 2019 that we see DNNs adding significantly to the performance in this space. Despite the hype surrounding DNNs, we find that there is still something left to do.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Frame interpolation",
                      "Retiming",
                      "Inbetweening",
                      "Motion Estimation",
                      "Optical Flow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001927"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Monitoring and Analysis of SMPTE ST 2059-2 PTP Networks & Media Devices",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Kernen",
                    "Nikolaus Kero"
                  ],
                  "abstract": "As All-IP studios leveraging the SMPTE ST 2110 document suite gain traction, one of the fundamental pillars upon which such systems rely is an accurate and reliable time transfer protocol. SMPTE ST 2059 standardized such a model based on the IEEE 1588 Precision Time Protocol. — Every element, it being network or media devices, impacts the overall time transfer accuracy. This impacts the timing of the ST 2110 media streams that are generated or received by the media nodes. Whilst PTP does provide fault tolerance capabilities, performance degradation of time transfer is not always well understood. This can significantly impact operations in live networks, it being due to a sudden event or a degradation over time. Therefore, an overarching view of the end to end timing system including backup, standby and network devices is required. — Monitoring of such capabilities should be common to all devices, whenever possible, including different means to verify in-band and out-of-band measurements as to how devices are performing, with respect to time transfer. Combined with historical archiving of the monitored data, this provides the framework for tracking and correlating possible events. This paper describes the different monitoring capabilities, their advantages and weaknesses and the value they provide to the monitored datasets. It further focuses on the means to uniformize the process across all monitored devices to ensure consistency in the collected data. Finally, we discuss the ongoing efforts in SMPTE and other standardization bodies around PTP monitoring, the common trends, expected outcome and how these will contribute to streamlining time transfer monitoring, supervision and analysis.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "ST2059-2 Time Transfer",
                      "PTP",
                      "Synchronization",
                      "Monitoring"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001917"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Automated Deployment of CBC/Radio-Canada's Media-over-IP Data Center",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alexandre Dugas",
                    "Felix Poulin",
                    "Francois Legrand"
                  ],
                  "abstract": "CBC/Radio-Canada is putting the finishing touches to its new IP-based production center in Montréal. During the design and early deployment of this major facility, it became clear that we would need to automate and manage the staging and configuration of the thousands of media devices in a fashion similar to an IT data center. — In fact, these new devices require thousands of parameters to be configured, and there are more frequent updates than for conventional devices. Moreover, once the system is put in production, business continuity imposes careful management of system changes in order to minimize the risk of technical regressions and human errors. — The good news is that the IT industry has solved that problem in order to operate huge data centers that require high availability. Continuous Integration and Continuous Deployment (CI/CD) practices have proven track records for operating data centers throughout their lifecycle, from configuration and provisioning, updates and changes, to sanity checks and monitoring. Tools such as DHCP, DNS, IPAM and configuration management tools are mature and widely used. — This paper will present the architecture and implementation of CBC's automated deployment workflow. We will cover requirements on endpoint devices and the technical and human-factor challenges we encountered during our journey putting in place the novel approach for the media facility. We believe these tools and methods will be applicable as a way forward to many media-over-IP projects at all scales.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "media-over-IP",
                      "automation",
                      "deployment",
                      "configuration",
                      "DevOps",
                      "SMPTE ST 2110"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001918"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "NMOS - The Interoperable Control System for an IP world",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jed Deame",
                    "Spencer Deame"
                  ],
                  "abstract": "What is NMOS? A semiconductor technology? Yes, but in the context of broadcast, it is something very different - a set of specifications that enable practical deployments of AV over IP. Why is it important? If you plan to transition to IP, even partially, the information in this paper will demystify the control plane and enable you to appreciate how to orchestrate a media over IP network. — SMPTE ST 2110 has emerged as a key technology enabling flexible and scalable AV over IP infrastructures to be deployed. Until recently, there was an absence of a common control system. Spearheaded by the Advanced Media Workflow Association (AMWA), the Networked Media Open Specification (NMOS) previously defined IS-04 (Registration & Discovery) and IS-05 (Connection Management), which was a great start to getting a standardized control system in place and met the needs of many users. — In order to meet the needs of all users, additional functionality was added to address some of the growing pains associated with transitioning to switched packet media transport. With the goal of going beyond the capabilities and security provided in SDI systems, the NMOS specifications dramatically improve the user experience. — The latest advancements in NMOS, including IS-07 (Event & Tally), IS-08 (Audio Channel Mapping), IS-09 (System Parameters), and some Best Current Practices (BCPs) take NMOS to a new level, surpassing the level of control provided in SDI while also adding a layer of security that has been sorely needed in control systems for quite some time. — NMOS also addresses the needs of the system integrator and studio builder, enabling automatic discovery of important services required to configure endpoints automatically on startup. — This paper will dive into the details about what NMOS is, how it works, and then look at a case study of how NMOS was extended to handle a new application - secure control rooms.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NMOS",
                      "AMWA",
                      "SMPTE ST 2110",
                      "IS-04",
                      "IS-05",
                      "IP",
                      "Security"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001920"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Virtual Tour of Flanders",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Willem Vermost"
                  ],
                  "abstract": "The Tour of Flanders, a classic outdoor cycling event that opens the cycling season, was cancelled due to the COVID-19 pandemic. However, a suitable replacement was created in its place, intended to offer people some solace during this lockdown period during which most recreational activities were suspended. This paper explains how the team managed to create an exciting mixed-reality racing event within a short period of time, given the limits of all social distance rules. It provides insight into how the real riders did race through a virtual landscape and how the viewers got to see this at home. This cloud-based production was performed exclusively with standard office IT equipment and well-known internet technologies. From idea to execution, the clock was ticking: the entire project was to be completed within a matter of days.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Tour of Flanders",
                      "sports",
                      "esports",
                      "cloud-based production",
                      "mixed reality (MR)",
                      "live",
                      "MoIP",
                      "Media-over-IP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001911"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Performance Comparison of Emerging EVC and VVC Video Coding Standards with HEVC and AV1",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dan Grois",
                    "Alex Giladi",
                    "Kiho Choi",
                    "Min Woo Park",
                    "Yinji Piao",
                    "Minsoo Park",
                    "Kwang Pyo Choi"
                  ],
                  "abstract": "The recent dramatic increase in video content consumption requires efficient video coding standards, and this is especially true for UltraHD resolutions, such as 4K and 8K (i.e. 3840×2160 or 7680×4320 resolutions in terms of luma samples, respectively). The well-known HEVC (H.265/MPEG-H) video coding standard was approved in 2013, but despite providing approximately 50% coding gain compared to its predecessor AVC (H.264/MPEG-4), the HEVC adoption is still relatively slow. In addition, larger bit-rate savings than those provided by HEVC are currently desired. In turn, the work on the Versatile Video Coding (VVC) and Essential Video Coding (EVC) standards started in 2018, and after intensive development efforts that continued about two and a half years, these two emerging video coding standards have been recently finalized. VVC (H.266/MPEG-I) is developed jointly by the MPEG and ITU-T VCEG organizations, while EVC (MPEG-5) is an MPEG-only effort. In this paper, we compare the coding performance of EVC and VVC, in terms of both coding gains and computational complexity, to their predecessor - the HEVC video coding standard. In addition, given the growing popularity of the AV1 video codec, which was recently developed by the Alliance for Open Media (AOM), we also include AV1 as an alternative baseline and provide corresponding comparison results. — According to the experimental results, which have been carried out in a Constant Bit-Rate (CBR) mode, the EVC provides about 30% bit-rate savings compared to HEVC for encoding 4K/2160p entertainment content (such as VoD) in terms of BD-BR PSNRYUV, while introducing an encoding computational complexity increase of ~5 times. On the other hand, the VVC provides larger bit-rate savings of about 40% at a price of a significant encoding computational complexity increase of more than 9 times. On the other hand, when performance of the HEVC CBR encoding (i.e. with the rate-control disabled) is compared to performance of the AV1 VBR encoding (i.e. with the rate-control is enabled), it was found that AV1 provides bit-rate savings of about 20% compared to HEVC for encoding 4K/2160p video sequences, as a trade-off of the encoding computational complexity increase by a factor of ~4. — The authors find out both EVC and VVC to be very promising successors of HEVC in terms of coding gains and computational complexity, and the jury is still out on the speed of their adoption.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "video compression",
                      "coding efficiency",
                      "codec comparison",
                      "video coding gain",
                      "VVC",
                      "EVC",
                      "HEVC",
                      "AVC",
                      "AV1",
                      "MPEG",
                      "H.266",
                      "H.265",
                      "H.264",
                      "computational complexity"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001916"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Achieving Cinematic Motion with High Dynamic Range",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jaclyn Pytlarz",
                    "Anustup Choudhury",
                    "Robin Atkins"
                  ],
                  "abstract": "This paper will explore how the appearance of cinematic motion (the characteristic balance of smoothness and realism of motion commonly used in cinema) is affected by high dynamic range (HDR) presentation. We will report on a psychovisual experiment that investigated how observers rated the smoothness of motion between scenes of different motion types (pans, action, slow movement), frame rates, and luminance levels. We found that in order to match the level of cinematic motion in todays' non-HDR presentation, the frame rate may need to either remain at 24 frames per second (fps) or be increased to 30fps, depending on the type of motion and the luminance level of the scene. We conclude that by selecting the appropriate frame rate depending on the motion type in each scene, content creators will be able to achieve the desired cinematic motion without compromising their use of the HDR color palette.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Motion",
                      "Cinema",
                      "High Frame Rate",
                      "High Dynamic Range",
                      "Perception"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001909"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "A Color-Volume Mapping System for Perception-Accurate Reproduction of HDR Imagery in SDR production workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pascal Kutschbach"
                  ],
                  "abstract": "The usage of wide color-volumes within cameras during image acquisition is common nowadays. However, these color-volumes are mostly manufacturer-specific and often get minimized into a standardized color-system, such as ITU-R BT.709. The outstanding color-capture-characteristics of prevailing image sensors therefore do not get used enough yet. Most image reproduction devices won't be able to display HDR/WCG content accurately in the near future. This justifies the current development of products that convert HDR/WCG-imagery to SDR/SCG-imagery with the aim of keeping the original look. The often overlooked aspect of color-volume transformations as a conversion process is of particular importance. Patented or trademarked colors (eg. Coca-Cola Red) should cause the same visual impression on all reproduction devices. Visual artefacts, such as hueshifts, banding or constant color regions instead of differentiated colors, caused by clipped or incorrect converted colors could violate this rule. Tonemapping is usually performed to transform HDR to SDR content. The difference in brightness between HDR and SDR is most visible. Rarely an accurate color-volume transformation is performed. A novel HDR/WCG-SDR/SCG-transformation-algorithm is presented in this paper. It can be used on images after tonemapping, or as a static conversion method between HDR/WCG and SDR/SCG. The aim of the algorithm is to convert colors from a large source color-volume into a smaller target color-volume so that converted colors stay distinguishable and no clipping is necessary. Patent pending EP20188496.2.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "HDR",
                      "Wide Color Gamut",
                      "WCG",
                      "Standard Color Gamut",
                      "SCG",
                      "Color Mapping",
                      "Gamut Mapping",
                      "Gamut Compression",
                      "Color-space Conversion",
                      "HDR-SDR-Conversion"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001921"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "High Throughput JPEG 2000 for Broadcast and IP-based Applications",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Edwards",
                    "Michael D. Smith"
                  ],
                  "abstract": "High Throughput JPEG 2000 (HTJ2K) is a royalty-free image compression standard published in 2019 that enhances JPEG 2000 by replacing its slow block coder with a fast block coder. The resulting speedup (e.g. > 30x for lossless coding) accelerates the encoding and decoding of images which can have a great impact for users. A less obvious benefit of the speedup is the enablement of low latency applications that were previously not possible with the original JPEG 2000 standard. Examples of these new potential applications are live, high-quality, low-latency broadcast video contribution, remote production, and IP-based production on-premise and on public cloud. — This paper examines various HTJ2K encoding parameters and their impact on quality, bitrate, latency, and multi-generation encode/decode cycle performance in the context of requirements of broadcast and IP-based applications. Configurations include a number of different wavelet filters, code-block sizes and wavelet decomposition structures that are available with HTJ2K. The performance of low-latency HTJ2K is also compared to other low-latency wavelet codecs like VC-2, JPEG XS and JPEG 2000 Part-1. The JPEG 2000 Part-1 comparisons use the full frame Broadcast Profile as well as the Ultra-Low Latency (ULL) configuration as per VSF TR-01:2018. A trade-off between latency and compression quality is shown.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "JPEG 2000",
                      "JPEG XS",
                      "VC-2",
                      "low latency",
                      "contribution",
                      "IP production",
                      "High-Throughput JPEG 2000",
                      "HTJ2K"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001906"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Physiologically Personalized Color Management for Motion Picture Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Trevor D. Canham",
                    "David L. Long",
                    "Mark D. Fairchild",
                    "Marcelo Bertalmio"
                  ],
                  "abstract": "One of the essential mechanisms employed by the human visual system when interpreting the natural world is that of trichromatic integration of physical scene spectra by cone photoreceptors. By extension of this, different scene spectra can result in the same color sensation in an observer, a phenomenon known as metamerism. This allows imaging systems to produce realistic reproductions of scene content by the same three channel mechanism. To predict these matches, color matching functions (CMFs) are used which aim to describe the average spectral integration behavior of observers. However, the use of a single average observer CMF has been shown to result in impactful color rendering errors, as there exists significant variation in the spectral absorption characteristics of the eye within populations of color-normal observers. When this is crossed with the growing disparity between the spectral characteristics of emerging display technology it becomes evident that this interobserver variability should be accounted for. — Asano and Fairchild present a physiologically based individual observer model, as well as a method for separating a population of observers into a limited number of categorical CMFs. Building on this work, we present a computationally simple metameric match simulation pipeline which uses these categorical functions. With this pipeline, we perform a simulation with real display spectra and natural images to observe the variability which could occur among a population as a result of observer metamerism in a motion picture viewing scenario. The results provide further evidence that interobserver metameric variability is a relevant problem in the context of natural images. Finally, we outline how this pipeline can be incorporated into one's color management strategy.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Observer metamerism",
                      "color management",
                      "personalization"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001923"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Next Generation OTT Distribution Architecture Supporting Multicast-Assisted ABR (mABR) and HTTP/3 over QUIC",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Aleksander Nowak",
                    "Jonas Hansen",
                    "Allan Hammershoj",
                    "Cedomir Stefanovic"
                  ],
                  "abstract": "The potential audience for streaming media services is massive, but satisfying that kind of demand poses a huge technical challenge. Even if existing Content Delivery Networks were capable of distributing such loads, the costs at that scale would remain beyond the monetary capabilities of any broadcaster. By reducing transmission costs associated with content delivery at scale, broadcasters would pay less to the CDNs, making the content cheaper to the end user. — In traditional broadcasting technologies, a majority of commercially available content distribution architectures are based on a paradigm rooted in linear broadcast services, having a very simple unified service composition focusing and delivery interpretable on compatible TV sets with builtin tuners. Whilst this helped transform the industry by facilitating the transition from analogue to digital broadcast content distribution, it now leaves content providers and broadcast network operators wondering how they can remain relevant in the age of Web and Internet streaming. — This article will take its point of departure in evolved content distribution systems and the resulting system architectures for a next generation broadcast OTT live and on-demand streaming. It will focus on a solution for efficient and secure transport of well-known low latency streaming protocols by employing QUIC as a primary transport protocol for the industry leading IP Multicast architectures supporting multicast-assisted adaptive bitrate (mABR) streaming, enabled by novel HTTP/3 Server Push techniques. At scale, the solution could significantly reduce the amount of open streaming sessions, improving the scalability of existing audio-video streaming architectures, and reducing the wastage of scarce bandwidth. Placing physical gateway boxes within users' home network that fully support QUIC and Multicast content reception can reduce the prevalent lack of user agent support for reception of Multicast QUIC content. The report includes state-of-the-art research behind elements of Multicast QUIC featuring Multicast Gateway authorization using OAuth 2.0 with Proof Key for Code Exchange (PKCE) flow, followed by its design, requirements specification and proof-of-concept implementation written in Golang. — This new model with the core transport protocol based on QUIC will be the foundation for unified content distribution architectures, spanning Internet streaming, IPTV, 5G, and the latest ATSC and DVB physical layers allowing for an efficient, IP-based delivery of linear content to thin clients.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "mABR",
                      "IETF QUIC",
                      "IP Multicast",
                      "low latency streaming",
                      "HTTP/3",
                      "TLS 1.3",
                      "OAuth 2.0",
                      "PKCE",
                      "ATSC3.0",
                      "DVB-GSE",
                      "OTT-B",
                      "ROUTE",
                      "Golang",
                      "5G",
                      "IPTV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001928"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Immersive Audio: Future-Proof Workflows For The Real World",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian A. Vessa"
                  ],
                  "abstract": "Mastering and distributing immersive audio is currently done using proprietary workflows, limiting its interoperability and ultimate acceptance. To move forward with the SMPTE ST 2098-2 Immersive Audio Bitstream (IAB) in an eloquent manner, it is important that the workflows be as efficient and interoperable as possible while creating future-proofed content. It is also critical that the equipment we expect to process and play IAB is ready for the task when content is delivered. We are at the crucial stage of beginning the rollout of IAB, and the workflows that are adopted now will shape how the industry moves forward. — The key is to plan, budget and create for the big picture: long term delivery of both feature and television content to multiple distribution channels rather than the immediate, short term window. Future-proofing is the key to building a valuable and versatile library. Shooting and finishing in 4K/HDR, designing and mixing in immersive audio and putting these into IMF are key to the longevity and sell-ability of the library. — Designing and mixing for immersive audio from the beginning rather than adding it later makes for a better product and is more efficient. This allows the content to be delivered to any market and saves money in the long run. Interoperability is the key to efficient distribution and it must be nurtured and finessed to realize its full potential. Content creators and distributors must make the business case and push manufacturers for the adoption and full implementation of standards. Automation is the key to efficient distribution; interoperability is the key to automation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Immersive audio",
                      "audio",
                      "mixing",
                      "workflow",
                      "future-proof",
                      "DCP",
                      "IMF",
                      "automation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001929"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "A Model for Very Wide Gamut HDR Displays that Accounts for the H-K Effect",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dale Stolitzka",
                    "Jong-Ho Chong",
                    "ChangHee Lee",
                    "Jinoh Kwag"
                  ],
                  "abstract": "We have developed a test method and computational model for predicting the brightness achieved by HDR (high dynamic range) televisions and computer monitors, in particular those with materials that feature primary colors having high spectral purity. The technological integration of quantum dot materials and emissive pixel lighting is expanding the color gamut level to attain a degree of performance unmatched in today's consumer and professional displays. These displays exhibit highly significant improvements in saturation and brightness due in part to the H-K (Helmholtz-Kohlrausch) effect, where people perceive some colors—notably reds and blues—as far brighter than its reference white. — We achieved a suitable methodology by blending the iCAM06 computational model2 originally designed for HDR image evaluation with an improved treatment of vivid colors. Our data collection relied on a one-of-a-kind, yet commercially available 2D spectroradiometer that captures up to 1.4 million samples of spectral data samples across any image, an achievement impossible to attain manually. Our approach coupled nicely with the filter image-processing steps in iCAM06. Finally, we extracted image brightness for white, red and blue for determining the SEMI Perceptual Contrast Length3 (PCL) to assess the predicted improvement level of our model, then matched those results to subjective experiments. As a result, we have a methodology that can be used by display makers to measure and predict brightness as a function of color saturation in order to optimize luminance—notably for reducing power—in displays with spectrally pure primaries.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CIECAM02",
                      "HDR",
                      "High dynamic range",
                      "Helmholtz-Kohlrausch effect",
                      "iCAM06",
                      "Perceptual Contrast Length"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001922"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "The Challenges of Adapting News Production to the New Reality",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raul Alba"
                  ],
                  "abstract": "The world has changed. Technologies have evolved. People don't consume news content as they used to. — The way many media companies are organized is not suitable for the needs that today's fast-paced news consumption habits impose. Media organizations tried to address this problem by creating a separate digital media department, but with the rise in relevance of social media and other digital outlets this way of working is not the best approach anymore. — In this paper, we will cover the challenges that news organizations are facing to adapt their workflows and processes to this new world where the time to air, or rather the time to online, is the most important factor; how the roles and tasks have changed and how the old news production logic needs to evolve to address these new priorities. — We will describe how a story centric approach to news production, supported by emerging networking AI and ML technologies, can help journalists expand their roles and work more efficiently. — We will discuss how the needs to work from anywhere and the adoption of a mobile journalism paradigm are more important than ever, and how the Covid-19 pandemic only accelerated a trend that was already unstoppable. — We will explore the ways that news consumption has changed and how it will drive the way news is produced, and how that is driving the way the production tools are designed and used. From our POV, needs define workflows, and workflows define tools - not the other way around.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "News",
                      "Journalism",
                      "Workflow",
                      "Productivity",
                      "Change Management",
                      "Disruption"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001930"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Identify, analyze and report networking issues in streaming services",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Angshuman Patra",
                    "Ashwyn Tirkey",
                    "Pranav Singh",
                    "Sujay Kumar",
                    "Horia Mihai-Popa",
                    "Andrei Gherghel"
                  ],
                  "abstract": "End-user streaming services have grown exponentially in the past years. The mechanisms to serve the enormous amounts of content available have seen a lot of improvements in reliability, flexibility, and overall quality. However, a plaguing problem is related to the last part of the delivery infrastructure: home networks. These networks are managed in a myriad of ways. Poor configuration and misuse reflect directly in the quality of the video streaming experience. Detecting home network issues and appropriately reporting them is key in providing the right solution when end-users report problems with the streaming services. — We propose a microservices led system that includes a client-side service that collects data and key performance indicators about the home network. The cloud-enabled microservices collect, store, analyze and correlate such data for enabling preemptive or on-demand actions. We propose that the client-side library is available on a variety of platforms for wider acceptance. The cloud-side of the system is proposed to store the telemetry data securely. The analytics systems perform real-time analysis and correlation between various events to create predictions to identify specific issues, or on a per-user basis, or based on a specific network configuration type. — As an outcome of the analytics and predictions, various dashboards and alarms are generated to allow visual representation of the system or tenant or user status and also enable setting up alarms and notifications that can be integrated with other systems that can address them and take actions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Streaming",
                      "Home network issues",
                      "Microservices",
                      "Multi-tenancy",
                      "cloud enabled"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001919"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Server-side Segment Selection For Low-latency Streaming - S4S",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Guillaume Bichot",
                    "Nicolas Le Scouarnec"
                  ],
                  "abstract": "The OTT streaming growth is driven by the increasing number of wireless connected devices such as tablet and phones. An enabler for using these devices is ABR streaming (Adaptive Bitrate) that allows them to select at each moment the stream quality that best fits the available bandwidth. The overall experience is highly dependent on the bandwidth estimation. The current approach to bandwidth estimation in HTTP-based ABR players is challenged by the evolution toward low latency protocols (DASH CTE) or (HLS LL) which result in micro-burst of traffic. Indeed, estimation at the client-side, at the HTTP level, relies on the assumption that a relatively large segment of data is available and can be sent at the link-speed which is not the case anymore with low latency protocols. — To address this issue, we propose a novel scheme S4S, that allows players to interact with an S4S-enabled server in order to improve the overall experience. First, bandwidth estimation is done at the server-side, using transport's congestion control sender-side stats, leading to more precise estimates even in the presence of small burst, especially when using modern congestion control algorithms such as BBR or PCC. Second, we define a protocol for allowing the Network to control the bandwidth versus quality tradeoff.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Low latency adaptive bit rate (ABR) streaming for Live content"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001926"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Perceptually Dithered HDR for 8bit Interfaces",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202020%20Annual%20Technical%20Conference%20and%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robin Atkins",
                    "Robert Wanat",
                    "Jaclyn Pytlarz"
                  ],
                  "abstract": "This paper explores the performance of applying dither when quantizing High Dynamic Range (HDR) achromatic images to lower bit depths. We found that by applying “perceptual dither”, or dither in the ITU-R BT.2100 ICTCP color representation, it is possible to reduce the bit-depth necessary for visually consistent reproduction by 2bits. We conclude that by using perceptual dithering, it is possible to achieve the precision of a 10bit source signal with only 8bits, or the precision of a 12bit source signal with only 10bits.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2020-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range (HDR)",
                      "Dithering",
                      "Quantization",
                      "Banding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001924"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2019",
        "conferences": [
          {
            "conference_name": "SMPTE 2019",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202019/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "1.25-inch 3-CMOS Multi-Functional High-Speed 8K Camera System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ryohei Funatsu",
                    "Toshio Yasue",
                    "Kohei Tomioka",
                    "Kodai Kikuchi",
                    "Tomoki Matsubara"
                  ],
                  "abstract": "We are developing 8K cameras capable of high-speed recording at 120-fps or more to support the highest video format of ultra-high-definition television and shoot slow-motion video. Previously, we developed a 1.25-inch 3-CMOS 8K 240-fps high-speed camera system capable of capturing smooth slow-motion video at 1/4 speed. — In this paper, we describe a multi-functional high-speed 8K camera system with significantly upgraded functionality, compared to the conventional 8K 240-fps camera system. The upgraded high-speed camera has three new features. — The first feature is a 480-fps shooting mode. With this, we achieved twice the frame frequency of a previously-developed camera system by operating the analog-to-digital converter (ADC) at twice the speed in the image sensor and subsampling the image. The video signal was processed in GBR 4:2:0 format for processing on conventional hardware and was output in YCbCr 4:2:0 format. — The second feature is a 120-fps random-noise-reduction shooting mode. We applied the multi-sampling technique to reduce the random noise caused by the readout circuit in the image sensor. This technique can improve the signal-to-noise ratio of the camera by approximately 4 dB. — The third feature is a 120-fps flicker reduction mode. We generated an image with an exposure time of 1/100 s by combining three successive frames of short- (1/600 s), long- (1/150 s), and short-exposure-time images to suppress the 20-Hz flicker caused by illumination with a power line frequency of 50-Hz. From the experimental results, it was found that the flicker could be reduced to 1/10 or less.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "8K",
                      "UHDTV",
                      "high-speed camera",
                      "slow-motion",
                      "480-fps",
                      "noise reduction",
                      "flicker reduction"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001864"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Development of new 4K/8K UHDTV satellite broadcasting system in Japan",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Katsuya Hayashi",
                    "Kazuhiro Kumamaru",
                    "Shinsuke Yokozawa"
                  ],
                  "abstract": "4K/8K UHDTV satellite broadcasts were launched on December 1, 2018 in Japan. One of these services is the first 8K UHDTV broadcast in the world. This broadcasting system adopts HEVC video coding with highly-efficient compression performance, a newly-developed ISDB-S3 transmission system which employs the 16APSK modulation scheme, and other new technologies. In this paper, we provide details of the new 4K/8K services, focusing on standardizing technical specifications and practical ways to introduce new reception systems into households.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHDTV",
                      "4K",
                      "8K",
                      "broadcast",
                      "satellite",
                      "16APSK",
                      "MMT",
                      "HEVC",
                      "receiving equipment",
                      "plastic optical fiber",
                      "frequency conversion system"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001865"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Integrating Machine Learning Based Operators in Visual Effects Toolsets",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nicolas Moenne-Loccoz"
                  ],
                  "abstract": "Post-production workflows rely heavily on image processing and computer vision algorithms for the implementation of their visual effect (VFX) tools. In these fields, machine learning has been shown to be disruptive. By integrating the domain statistics from a given training dataset, machine learning based operators may be more efficient at solving existing problems and may enable new problems to be solved, expanding the VFX toolset. In this paper we are sharing our experience on developing and integrating several machine-learning based operators into software for the Post-production industry. We will present a sky segmentation operator, a depth map estimation operator and an operator to compute face geometric maps (UVs, depth and normals) from sequences of images. More specifically, these operators consist in trained deep convolutional neural networks (DCNN) taking as input an RGB color image and outputting the associated maps, i.e. a matte, depth, normals, and/or UVs maps. Such maps permit to apply many different effects to the input image during color grading, including beautification or even relighting of faces. These works will serve as a case study to review and discuss the multiple challenges posed by the implementation, integration and deployment of machine learning based operators into a VFX toolsets.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Visual FX",
                      "Machine-Learning",
                      "Sky Segmentation",
                      "Monocular Depth Estimation",
                      "Face Relighting"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001866"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "How AI Technology is Dramatically Improving Video Compression for Broadcast and OTT Content Delivery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jean-Louis Diascorn"
                  ],
                  "abstract": "Video compression for broadcast TV services started more than 20 years ago. Since then, there has been a major codec standard created about every 10 years, with MPEG-2 released around 1995, AVC in 2005 and HEVC in 2015. Over time, several key improvements such as dual-pass encoding, statistical multiplexing and software migration were made to compression technology in order to boost performance. Tuning the algorithms and the algorithmic tools also allowed significant improvements to be made. — Now a new and disruptive technology — Artificial Intelligence (AI) — is driving the next frontier of video compression enhancements with the promise of faster advancements. AI is being used to improve several key areas: to achieve better video quality (VQ) at a given bit rate, or lower bit rate at the same VQ. Advances are also being made in other directions, like higher density to where the same VQ/bitrate efficiency will use less computing resources, and in providing better quality of experiences (QoE). — This paper will present three examples of AI applied to video encoding to optimize broadcast and OTT content delivery: Dynamic Encoding Style (DES) for a better VQ /bitrate trade-off, Dynamic Resolution Encoding (DRE) for better QoE and density, and Dynamic Frame rate Encoding (DFE) also for improved density and QoE. — In addition, the paper will explore the operational and end-user benefits enabled by AI and machine learning. Additionally, it will provide measurement for the applications that are presented and address the possible future evolutions of AI for video compression.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "AI",
                      "Artificial Intelligence",
                      "ML",
                      "Machine Learning",
                      "Video",
                      "Compression",
                      "Density",
                      "CPU",
                      "Latency",
                      "Television",
                      "Live"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001868"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "How Will We Archive And Preserve The Movies Of Tomorrow?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre Hugues Routhier"
                  ],
                  "abstract": "In our era of computational imaging, emerging technologies like volumetric video, performance capture, and visual effects are creating images that were never captured in the conventional sense, offering an almost infinite range of creative options once production is over: camera angles can be modified; virtual lenses can deepen or tighten the depth of field, expand or compress perspective, and even mimic the distortion of vintage lenses; actors can be replaced, or even brought back to life. On top of this imaging revolution, the rapidly evolving field of image display means that a final version for today may not be optimal or even adequate for the screens of tomorrow, whether due to increased color gamut, dynamic range, spatial resolution, size, aspect ratio or frame rate. — These issues bring up technical, financial, and ethical considerations about what to conserve, in which form, and for how long, with sometimes-conflicting priorities between the preservation of the original artistic intent and content owners' desire to maximize the revenue and/or lifespan of a particular asset. — In this paper, the author proposes a new definition for “Image-sequence-based Works of Art,” to replace the traditional definition of “film,” and details workflow options that strike the right balance between protection of creative intent and future-proofing of assets, combining technical, ethical, and philosophical considerations. — With all the advances we have witnessed in the last 10 years, and what's to come in the following decade, the author believes in the urgency of answering those questions and standardizing workflows before current practices have an unalterable impact on future generations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "light field",
                      "computational imaging",
                      "volumetric video",
                      "visual effects",
                      "archiving",
                      "motion pictures",
                      "ACES",
                      "scene-referred",
                      "display-referred",
                      "mastering"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001869"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Brightness in Cinema: When is it too bright?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stelios Ploumis",
                    "Ronan Boitard",
                    "Gerwin Damberg",
                    "Anders Ballestad",
                    "Panos Nasiopoulos"
                  ],
                  "abstract": "Recent advances in display technologies enable home and cinema display systems to reach higher peak luminance and perceived Full Screen White (FSW) levels while also improving on black level capabilities. This next generation of imaging technology will help creators deliver content of higher visual quality, increasing the overall Quality of Experience (QoE) of viewers. However, there is growing concern in the cinema industry that possible “mismanagement” or “misuse” of the new luminance capabilities may result in viewers' visual discomfort. A typical example of potential “misuse” is abrupt temporal brightness transitions during a scene change or even within the same scene. Prior studies, which were conducted in home environments, reported that displaying a higher amount of light could potentially lead to viewers' visual discomfort. However, no study has been conducted in cinema environment. In this work, we quantify the human observer tolerance to temporal brightness transitions in a cinema environment by performing four subjective experiments. The different experiments evaluate the impact of various distributions of light on screen, namely full screen, highlights, noise and real images. Results of the experiments indicate that the light distribution as well as the peak luminance values have minimum impact on viewers' tolerance of temporal brightness transitions. Indeed, observers reported visual discomfort only when the total amount of light on screen varied significantly. Specifically, for average on-screen luminance equal to both 0.1 or 1 cd/m2, viewers rated as “slightly annoying” and “annoying” transitions to average on-screen luminance as low as 35 cd/m2 and 75 cd/m2 respectively. It is to be noted that viewers reported visual discomfort at a similar transition intensity for both saturated colors and white. The results of our study could provide useful insight to content creators, for example providing a warning that temporal transitions may cause visual discomfort.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cinema",
                      "High Luminance Levels",
                      "Brightness Perception",
                      "Human Visual System (HVS)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001870"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Uniformity Measurement for French Cinema",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt",
                    "Hans-Nikolas Locher"
                  ],
                  "abstract": "French cinema theaters follow strict rules; there are two French standards involved when granting theater operation licenses. One standard is about architectural considerations, the other about movie reproduction parameters. The main goal of these specifications is to ensure that movies are reproduced uniformly in all theaters while matching the intention of the creative team during final check. Another goal is to allow a satisfying perception by the audience, trying to avoid unnecessary physical or audio-visual stress. — These two standards are currently under periodic revision. The specifications listed in the standard about movie reproduction includes a uniformity formula. Counterexamples demonstrate problems with the validity of this uniformity. A new uniformity method of measurement is under study. — The proposed method unifies projection and display systems in the same measurement. The projection vignetting effect is cancelled using current room and screen dimensions. The formula is also independent of the reproduction system's dynamic range. Nine locations on screen are used as points of measurement. — The proposed measurement of uniformity is based on a statistical measurement called the K-S distance. It compares current results with a standard statistical distribution. The type of distribution is chosen based on practical considerations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Movie projection",
                      "direct-view display",
                      "uniformity",
                      "throw ratio",
                      "luminance spread",
                      "cinema room architecture",
                      "SDR",
                      "EDR",
                      "HDR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001871"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Speed-Distortion Optimization: Tradeoffs in Open-Source HEVC Encoding",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pradeep Ramachandran",
                    "Praveen Kumar Karadugattu",
                    "Alex Giladi",
                    "Dan Grois",
                    "Pooja Venkatesan",
                    "Bhavna Hariharan",
                    "Kavitha Sampath",
                    "Kalyan Goswami",
                    "Kevin Pikus"
                  ],
                  "abstract": "The HEVC video compression standard which drives significant increase in coding efficiency is an essential technology for delivering UltraHD content in HDR. This improved coding efficiency comes at a significant cost in computational complexity. Adaptive streaming results and content adaptive encoding significantly increase the compute required for encoding for the additional encodes, and analysis required to support the corresponding use cases. The emergence of content-adaptive encoding results in an additional major increase in number of encoding. All these factors combined requires a careful analysis of trade-offs in order to avoid exorbitant infrastructure costs of transition to HEVC. — This paper discusses how the throughput of an HEVC encoder can be optimized to enable a cost-efficient distributed encoding system running on commodity hardware. We chose the popular open source x265 video encoder for this study due to its wide adoption. We first examine the x265 presets which combine various performance and encoding efficiency trade-offs into a single operational point. We then detail some additional options that enable additional analysis on a selective sub-set of cases, such as per-frame or per-CTU; these options are representative of several such options that aren't exposed via the presets of x265. Specifically, we discuss options pertaining to selective in-loop filtering, and dynamically re-targeting rate distortion optimization (RDO) tools depending on quality fluctuations encountered at run-time. We present trade-offs results for real-world 4K HDR content to demonstrate the applicability of these coding tools to real content used for OTT and live streaming.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "x265",
                      "opensource",
                      "video encoding",
                      "streaming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001876"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "8K Camera Recorder using Organic CMOS Image Sensor",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shingo Sato",
                    "Takayuki Yamashita",
                    "Masayuki Miyazaki"
                  ],
                  "abstract": "We developed an 8K camera recorder that uses a complementary metal oxide semiconductor (CMOS) image sensor with an organic thin-film instead of photodiodes for the opto-electrical conversion element. The advent of 8K Super Hi-Vision broadcasts and an increase in the production of 8K programs across a variety of genres necessitates development of a sensor with a good signal-to-noise ratio (SNR) and high dynamic range (HDR) in order to capture the full range of HDR video. To ensure successful use of this sensor, we studied the level diagrams (e.g., balancing of sensitivity, SNR and dynamic range) that would best fit the sensor's characteristics and use all of its strengths, then proceeded accordingly. For current 8K location shooting, a workflow is needed to record raw data and post-process them into a practical video format. To implement a more efficient workflow, we chose to use HQX encoding while adding features that make it possible to store video data in a compressed form and simultaneously generate HDTV proxy data. The workflow we envisioned uses proxy data for offline editing and relinks them using online editing equipment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001863"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "An Investigation of Creative Power and the Value Wide Color Gamut Brings to Motion Picture Mastering",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jake Zuena"
                  ],
                  "abstract": "Advancements in cinema and display technologies have allowed for wider color gamuts to become realizable. With this, these technologies have the capability to support and reproduce highly-saturated color content. It is important to remember, though, that the ability to produce colors with an extremely-high chroma component is strictly a capability of the technology and not a necessity that the image content must follow. In short, the decision to utilize the expanded gamut available in advanced cinema technologies is at the discretion of the creative forces behind the project. There are a number of different factors that can contribute to the creative color decisions made for motion pictures, with the primary factor being the aesthetic nature of the content produced. Through creative-preference assessments of saturation adjustments in various image content, the value of the expanded color gamut in motion picture mastering was assessed. Three images of comparable chroma histograms were utilized in the study to feature human skin tones, animated characters, and natural scenery, respectively. Upon being adjusted, each image was rendered with color content outside of the boundaries of the DCI-P3 gamut. A two-alternative-forced-choice psychophysical study was conducted to estimate observer preference of the saturation levels in each image. From the observers' selections, the reaction to the expanded image saturation in the three images was plotted and assessed for statistical significance. Through this study, it was found that there is a preference to incorporate colors exclusive to wider color gamuts that extend past the boundaries of Rec. 709 and DCI-P3. It was also confirmed that the medium in which the content was generated influences the level of saturation preferred. Overall, this research provides a look into how technical capability and artistic vision can be connected.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cinema",
                      "display",
                      "wide color gamut",
                      "saturation",
                      "extremely-high chroma",
                      "creative",
                      "preference",
                      "two-alternative-forced-choice",
                      "psychophysical study"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001883"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Film Grain and Film Scanner Noise in HDR Video",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael D. Smith",
                    "Michael Zink"
                  ],
                  "abstract": "While physical film prints are not widely used for motion picture distribution due to the industry's successful transition to digital cinema distribution, negative film and interpositive (IP) film are still frequently used as a source for motion picture releases in High Dynamic Range (HDR) and Standard Dynamic Range (SDR) formats. Modern productions that use film as the acquisition format typically scan the film negative in a film scanner and then use modern digital production processes such as visual effects, editing and color grading like modern digital camera workflows. Remastering projects leverage the thousands of film negatives and IPs that are stored in Hollywood studios' vaults to create new versions of older titles. IPs were created in traditional photochemical film workflows and are often available for use in remastering projects. — Film scanning is a critical step in both modern film production and remastering workflows as it converts the analog medium of film to a digital format. The film scanning process itself can introduce scanner noise into the digital image which has different characteristics than the more familiar film grain noise. Film grain noise is inherent in the physical film medium itself and its visibility and characteristics vary based on the film format and the type of film used. Filmmakers often consider the characteristics of film grain as a visual aesthetic that can be leveraged creatively to enhance the storytelling. Traditional photochemical film workflows that did not use film scanners also were impacted by film grain noise. — Scanning different types of film elements (e.g. negatives and IPs) in different film scanners with different scan settings can lead to different results. The visibility of these differences change when the scan is used to create an SDR Home Master or SDR Cinema release versus an HDR Home Master due to the increased luminance and contrast often associated with the HDR format. This paper quantifies these differences and explains the visual impact of film grain versus scanner noise with an emphasis on HDR video. Additionally, this paper describes our recent experiments with test films and presents visual examples of scanner noise and film grain noise.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Film",
                      "grain",
                      "scanner",
                      "scan",
                      "negative",
                      "positive",
                      "IP",
                      "HDR",
                      "noise",
                      "visibility",
                      "contrast, CSF"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001884"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Color Errors, Metamerism and Color Ellipses",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt"
                  ],
                  "abstract": "This paper is about calculation of index of metamerism for the change of observer and comparisons with various color errors and tolerances. — There are two major aspects for color measure in visual reproduction. One goal is to measure the performance of reproduction equipment. The other aspect is related to the audience visual perception. On the one hand human perception is characterized by its variability and, on the other hand, technological trends in reproduction are adding new color source characteristics. — Metamerism is ensuring the viability of trichromatic reproduction. In fact, traditionally, any reproduced color is rendered with a mix of three primaries. It is giving a perception similar to that of surfaces in front of the camera which have various complex spectra so long as those spectral surfaces lie within the trichromatic gamut of the selected reproduction primaries. — Various metamerism indexes have been defined to give a measure of the differences in color matching. The metameric index for change of observer may be used to directly evaluate human perception variability found in any audience for a given reproduction system. At least this can be computed for a set of representative colors. — But new reproduction systems are based on primaries spectra differing sensibly from the ones previously used with Xenon light source. The method for calculation of the index of metamerism for change of observer is using the Standard Deviate Observer data in addition to the Standard Observer data. — The magnitude of color errors induced by this phenomenon is compared with JND found in MacAdam study. It is also compared with existing tolerances in color accuracy. — In fact, the tolerance expressed in current standards are much larger than the variations caused by the observer variability.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Metamerism",
                      "Metameric index",
                      "Color difference",
                      "Color ellipse",
                      "MacAdam ellipses",
                      "Color error",
                      "Color space",
                      "Uniform color space",
                      "Color gamut"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001878"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Rotoscope Automation with Deep Learning",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Oscar Estrada",
                    "Nicholas Peretti",
                    "Ricardo Figueroa"
                  ],
                  "abstract": "We present a deep learning based algorithm that can automatically rotoscope people on a given scene, without any user input. Current approaches to image matting require a significant amount of human input, whether by manually rotoscoping or by doing a chroma key. We show that this algorithm can perform comparably and even surpass the rotoscoping capabilities of After Effects' RotoBrush tool, in a variety of scenes comprising different lighting conditions, movements, and subjects. This makes it suitable for an integration within a VFX pipeline.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Instance Segmentation",
                      "Image Matting",
                      "Compositing",
                      "Deep Learning"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001867"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Creating Bandwidth-Efficient Workflows with JPEG XS and ST 2110",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jean-Baptiste Lorent",
                    "Antonin Descampe",
                    "Charles Buysschaert"
                  ],
                  "abstract": "Internet Protocol workflows have arrived and is here to stay. Next to reduced complexity and increased agility, one of the greatest advantages of moving to IP is cost reduction - the simple usage of COTS IP switches and cables. However, with new imaging technologies like 4K, high frame rates, and HDR, we have more pixels to manage, store and transport. SMPTE ST 2110 supports both uncompressed and compressed video. With uncompressed video essences, this requires 10GbE workflows for HD, 25GbE for 4K, and even more for future 8K workflows. Currently many are struggling just to upgrade infrastructures from 1080i or 720p to 1080p60 at 3Gbps; handling 4K video at 60fps, 4:2:2, and 10bit is much more challenging. And with 8K on the verge, a future-proof solution must be found. What if a technology could help? Help to easily manage more pixels over a limited bandwidth. Help to safeguard latency? All with pixel perfect quality? This whitepaper explains how and why the new ISO JPEG XS in combination with part 22 of SMPTE ST2110 for compressed video streams addresses and solves exactly these points.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IP",
                      "ST2110",
                      "JPEG XS",
                      "4K",
                      "UHDTV",
                      "Compression",
                      "Live Production",
                      "Mezzanine",
                      "Ultra High Definition Television",
                      "UHD",
                      "ST-2110-22"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001875"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Using Infrastructure-As-Code and the Public Cloud to Power On-air Media Creation Platforms",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kevin Fornito",
                    "Chris Zembower",
                    "Steve Sneddon"
                  ],
                  "abstract": "Traditionally, the infrastructure required for broadcast media creation has consisted of specialized GPU workstations, high-performance storage arrays, complex networking, and video wiring; all of which are capital intensive and costly to maintain. Over the past year, NBCUniversal has been evaluating a cloud infrastructure model, to provide on-air media creation as a service to its creative teams. Virtual Desktop Infrastructure (VDI) technology has been around for years, but because of media specific challenges (GPU utilization, frame rate, color representation, etc.), it has not been fully adopted in media workflows, until now. Utilizing GPU-enabled cloud-based virtual machines, dynamically scalable high-performance cloud-native storage, and infrastructure-as-code methodologies, we are now able to provide full end-to-end media production workflows in the public cloud. The infrastructure-as-code philosophy treats compute, storage, database, and network systems as software; prioritizing automation, efficiency, versioning, and reusability. Closely aligned, configuration management tools allow us to deploy software and specialized configurations to many systems simultaneously. Using an automation-forward approach, we know exactly what is going to be applied, how it will propagate through the infrastructure, and what dependencies are involved. Elastic scalability of compute and storage eliminates over-provisioning (and its related capital investments), and provides the ability to dynamically add/remove resources as necessary. Additionally, the use of IP video technology enables devices and applications to share audio and video across the network. Through configuration examples and system diagrams, this paper will highlight the technical details of this programmatically reproducible solution, as well as the challenges and benefits of media creation in the cloud. Critically, we seek to offer the broadcast community an insight into “non-broadcast” technologies and tools which are fast becoming crucial to our industry. Key data points and discussion topics include network bandwidth and cloud connectivity requirements, performance metrics for cloud storage solutions, scalability factors and user experience - can creatives tell the difference between traditional workstations and cloud virtual machines?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud",
                      "media creation",
                      "broadcast",
                      "automation",
                      "infrastructure-as-code",
                      "configuration management",
                      "VDI",
                      "GPU"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001872"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "ΔEITP is now ITU-R BT.2124-is the industry ready to move on from ΔE2000?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Catherine Meininger",
                    "Tyler Pruitt",
                    "Vincent Teoh"
                  ],
                  "abstract": "For many years, ΔE2000 has been considered the industry standard for estimating perceptual color differences and evaluating the color accuracy of display technologies. Recently, the International Telecommunications Union (ITU) released Recommendation ITU-R BT.2124, which defines a new metric, ΔEITP, as the new standard for evaluating perceptual color differences. Given this new recommendation, it is important that we become familiar with how ΔEITP performs in practice and what can be expected when using it in existing workflows. A key part in this process is having an understanding of the properties of the color space that the color difference metric is based on and how that relates to the intended application of the metric. In this paper, we explore this relationship as it pertains to the ΔE2000 and ΔEITP color difference metrics, specifically in the context of evaluating color reproduction on self-luminous displays. Simulated data and measured data from calibrated displays are used to compare the metrics' performance. Given that ΔE2000 and ΔEITP are based on significantly different derivation principles, there are notable differences that must be acknowledged between these two metrics, especially as we transition between them. It is highly likely that ΔE2000 has been underpredicting perceptual color differences, significantly so when used for the evaluation of high dynamic range (HDR) and wide color gamut (WCG) displays.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Color difference metric",
                      "ΔE2000",
                      "ΔEITP",
                      "ICTCP",
                      "CIELAB",
                      "calibration",
                      "high-dynamic-range",
                      "wide-color-gamut"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001879"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Cloud Technology Drives Superior Video Encoding",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thierry Fautier"
                  ],
                  "abstract": "New codecs such as AV1 will enable broadcasters and service providers to deliver higher quality, including 4K and 8K VR, but with increased complexity. Since adaptive streaming requires multi-resolution synchronized encoding, the delivery of next-generation video becomes even more challenging. For live applications, the amount of complexity is unmanageable with current CPU or GPU on-premises technologies. This paper will examine the limitations of on-premises server-based encoding and how cloud computing can solve these issues. It will outline how broadcasters and service providers can take advantage of new applications like event-based encoding to successfully deliver superior-quality video on every screen.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Encoding",
                      "Cloud",
                      "Codec",
                      "AVC",
                      "HEVC",
                      "AV1",
                      "VVC",
                      "UHD-1",
                      "UHD-2"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001873"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Engagement with the Next-Gen: SMPTE's Role in K-12, Higher Education, and Other Institutions",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Shike"
                  ],
                  "abstract": "What role should SMPTE play in the encouragement of newcomers to our industry? Where will tomorrow's engineers and technologists come from who can invent, develop, and support professional media, whether it be film, video, or other media? — What is the curriculum that will enable students to pursue successful careers and how should SMPTE influence it as the industry embraces new technologies such as IP, Cloud, and AI? — The journey of new talent begins in K-12 schools, continues through such phases as higher education, apprenticeship, internship, military, and early careers to ultimately become the future generation of SMPTE members and the professional media technologists of tomorrow. How do we engage not only with the students themselves but also with the educators and the institutions that are involved? SMPTE already provides opportunities for scholarships, networking events, and in particular, its student chapters, but the dearth of schools offering courses in broadcast video engineering suggests that a much larger role is needed by on the part of SMPTE and our industry in general. — SMPTE is a community that can offer students personal networking, education, guidance, as well as the technical standards for interoperability for the ecosystem of professional media. — Some ideas that have been offered from students, educators, and SMPTE members are suggested. The new generation needs to be engaged in a way that we are not merely educators but learners as well, so that our conversation is truly two-way.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Students",
                      "Careers",
                      "Educators",
                      "Educational Institutions",
                      "Membership",
                      "Diversity"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001881"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "HDR and WCG Image Quality Assessment Using Color Difference Metrics",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anustup Choudhury",
                    "Jaclyn Pytlarz",
                    "Scott Daly"
                  ],
                  "abstract": "High Dynamic Range (HDR) and Wide Color Gamut (WCG) imagery is now mainstream across content creation. Thus, having a reliable way of evaluating HDR systems is essential. One common way of measuring the quality of an HDR system is measuring the color errors introduced along the imaging pipeline. Unfortunately, development of color difference metrics has been based on test patches, as opposed to natural imagery, with evaluation mostly limited to Standard Dynamic Range (SDR) databases. In this paper, we evaluate several color difference metrics on five publicly available HDR distortion databases consisting of natural images and subjective scores. Distortion types include lower frequency distortions such as those from tone-mapping as well as higher frequency distortions resulting from compression artifacts by the various compression schemes such as JPEG. We analyze these databases with the well-established CIE L*a*b* metrics (ΔE00, ΔE94) as well as two HDR specific metrics: ΔEz (Jzazbz) and ΔEITP (ICTCP). To quantify the performance, we use four standard performance evaluation procedures. We observe that ΔEITP outperforms the other color difference metrics on four out of five databases. We also perform statistical analysis which demonstrates the effectiveness of using ΔEITP to assess overall image quality of HDR/WCG content. Weaknesses of all metrics for one database suggests more advanced spatio-chromatic visual models are worth pursuing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "Wide Color Gamut",
                      "Color Difference Metric",
                      "ICTCP",
                      "ΔEITP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001882"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Auxiliary Image Sequences in IMF",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gillian Reston",
                    "Ulrich du Bosque",
                    "Rowan de Pomerai",
                    "Dan Tatut",
                    "Tim Davis",
                    "Andrew Dunne"
                  ],
                  "abstract": "This paper describes an auxiliary image sequence plug-in that enhances SMPTE ST 2067, SMPTE TSP 2121 suit of documents to enable compositing workflows through the use of the Interoperable Master Format (IMF). — The component-based nature of IMF allows multiple versions of a programme to be created, managed and distributed more efficiently. However, it is currently limited to a single concurrent video track in any composition; a restriction which limits certain use cases that could otherwise realise the benefit of IMF's full capabilities. — Our primary use case for the auxiliary image sequence is the management of sign-interpreted programming. This currently necessitates the creation of a new full-length master for each version created. Instead it is proposed that the video of the sign interpreter will be stored as a separate component. This will allow the implementer to be composited with the main programme when required. — A working prototype of a simple compositing processes has been developed by the DPP in partnership with its member companies. Opportunities for more complex and dynamic compositing via Output Profile List (OPL) and time-variant metadata are also discussed in the paper, along with other use-cases for the functionality described. — The plug-in described in this paper will provide benefit to the implementer throughout the IMF lifecycle by enabling storage, editing, re-positioning and processing of the auxiliary image sequence before compositing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Interoperable Master Format (IMF)",
                      "signed services",
                      "hard of hearing",
                      "access services",
                      "accessibility",
                      "implementation",
                      "virtual track",
                      "multi-layered",
                      "plug-in",
                      "2067",
                      "auxiliary sequence",
                      "AuxImageSequence",
                      "composition",
                      "sign language",
                      "static compositing",
                      "dynamic compositing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001880"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Live Cloud Ingest Using Open Alternatives RIST & SRT",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mikael Wanggren",
                    "Love Thyresson"
                  ],
                  "abstract": "As cloud production becomes an integral part of broadcasters' live workflows, the corresponding cloud infrastructure becomes an integral part of the media transport network. Cloud infrastructure providers, often public in nature, are accessible either through the public Internet or through leased lines. Regardless if public or private, experience shows these connections are not up to the quality standards required for low latency live streaming media, making quality enhancing technologies, such as retransmission or ARQ, an imperative part of the network infrastructure to deliver on the requirements for broadcast quality transmission. Two solutions have emerged as front runners on the quest for being the next de-facto standard for broadcast retransmission - RIST (Reliable Internet Stream Transport), and SRT (Secure Reliable Transport). This report compares these two alternatives from a theoretical and performance perspective and compares them to a commercial reference alternative.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "RIST",
                      "SRT",
                      "Internet",
                      "Transport",
                      "Contribution",
                      "Distribution",
                      "Cloud",
                      "Live",
                      "Ingest"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001874"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "MPEG-5 EVC",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jonatan Samuelsson",
                    "Kiho Choi",
                    "Jianle Chen",
                    "Dmytro Rusanovskyy"
                  ],
                  "abstract": "The MPEG standardization group has produced a large number of standards for video compression over the last three decades. Traditionally, the MPEG standards have either focused on highest available compression efficiency (e.g. MPEG-2, AVC and HEVC) or a desire to produce a royalty-free standard (e.g. IVC and WebVC). In January 2019, MPEG embarked on a new standardization project that can be said to be a hybrid of the two; MPEG-5 Essential Video Coding (EVC). The MPEG-5 EVC standard is being developed with a royalty-free Baseline profile at its base and a royalty bearing Main profile that provides excellent compression performance. The Main profile adds on top of the Baseline profile, 20 different coding tools that each can be individually turned off and, when needed, replaced by a corresponding Baseline profile tool. This structure makes it easy to fall back to a smaller set off tools in the future, if for example licensing complications occur around a specific tool, without breaking compatibility with already deployed decoders.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video coding",
                      "video compression",
                      "Essential Video Coding (EVC)",
                      "Moving Picture Experts Group (MPEG)",
                      "next-generation video codecs"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001877"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Large Scale Deployment of SMPTE 2110: The IP Live Production Facility",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Sneddon",
                    "Chris Swisher",
                    "Jeff Mayzurk"
                  ],
                  "abstract": "In 2016, NBCUniversal began the project to design and build the new global headquarters for Telemundo Enterprises in Miami Florida. The facility that became known as Telemundo Center would feature 13 production studios and seven control rooms supporting scripted episodic content, daily live news and sports programming, beginning with FIFA World Cup 2018. To support the scale and flexibility required for a facility of this magnitude, the key technical design consideration was the use of a software-defined video network infrastructure. At the time of launch in spring of 2018, Telemundo Center was home to the largest SMPTE ST 2110 environment in the world, consisting of over 12,000 unique HD sources and 150,000 multicast streams across audio and video. — This paper will explore the major considerations and challenges in building such a large scale, all-IP broadcast production facility. We will demonstrate design factors around switching of video flows, redundancy, control and orchestration, PTP master clock systems and handoffs to multi-manufacturer SMPTE ST 2110 devices as well as non-IP enabled devices. This paper will also discuss our experience and lessons learned with utilizing a Software Defined Network (SDN) control plane and routing commands that abstract the underlying physical and link-level connectivity. — Some key topics include approaches to pooled resources and management of centralized operations; gaps in existing standards, with strategies to overcome limitations; the promise and the peril of differing ergonomic and performance characteristics of SMPTE ST 2110 endpoints - support for redundancy, clean switching, and audio/video synchronization — We will propose a reference architecture for supporting a GPS-sourced, large-scale PTP distribution to over 500 end points and explore some of the limitations and corresponding solutions encountered in PTP distribution at scale. Finally, we will demonstrate new software-defined infrastructure concepts such as virtual sources and virtual destinations which replaced legacy physical design patterns in this build.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001886"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Strategies for Securing ST 2059-2 PTP Networks",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202019/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Kernen",
                    "Nikolaus Kero"
                  ],
                  "abstract": "As the SMPTE ST 2059-2 standard for accurate time transfer gains further traction in real-world All-IP Studio deployments, it is important for broadcasters and system integrators alike to understand how time transfer using the IEEE 1588 Precision Time Protocol (PTP) profile as defined in the SMPTE standard could be affected by unintentional or malicious tampering of the different system parts that guarantee both stable and accurate delivery of time for all media essence based on standardized IP transports such as those defined in the SMPTE ST 2110 series or AES67 standards. Given the mission-critical nature of broadcast infrastructure, securing time distribution is rapidly becoming a mandatory requirement. Whilst ST 2059-2 defines PTP profile capabilities and PTP parameter values that can be used, it doesn't address how to secure the various parts that define the timing system as a whole. — The IEEE 1588 standard provides a certain level of fault tolerance by autonomously activating an auxiliary reference in case of loss of the primary time source. Yet, the overall synchronization performance is not sufficiently well protected by the protocol to withstand either deliberate attacks or cope with misconfigured or malfunctioning devices. Consequently, both scenarios have to be investigated in detail. This entails a thorough analysis of all the relevant threats ranging from spoofing or jamming attacks on GNSS receivers to misaligned message rates or corrupted messages to name but a few. This paper addresses possible ways how to secure different components of the timing system, ranging from the origination point of the reference clock(s) used as the primary time source(s), across the IP network infrastructure and finally to the media nodes generating or receiving ST 2110 flows. Beyond securing the timing system, special care should be taken to immediately identify any degradation and/or failures using multiple approaches that provide efficient means to correlate events. This is covered by a series of recommendations and best practices to ensure operational stability and reliability.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2019-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IEEE 1588",
                      "PTP",
                      "ST 2059-2",
                      "Security",
                      "GNSS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001885"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2018",
        "conferences": [
          {
            "conference_name": "SMPTE 2018",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202018/",
            "articles": [
              {
                "article_local_id": "8",
                "article_title": "Artificial Intelligence for the automation of robotic cameras in live sports",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Floriane Magera",
                    "Johan Vounckx"
                  ],
                  "abstract": "The demand to cover lower tier sports games is rising rapidly. Unfortunately, it is economically not viable to deploy the traditional production methods, crews and equipment that we know for higher tier sports events. Production approaches requiring much less people are needed. For the last few years, high quality single man operated equipment combining replay video mixing, graphical insertions, … are being introduced. However, one still needs cameramen to operate the different cameras around the sports field. — In this paper we present the concept of a fully automated system creating multiple camera feeds via a series of robotic cameras. These robotic cameras are not human operated but piloted by an Artificial Intelligence based system. This system analyses the complete sports scene for relevant items to capture and uses that information to individually steer the different robotic cameras to generate the desired different camera views. More concretely, the AI backed system points, in real-time, the different robotic cameras to the relevant parts of the game and applies the appropriate zoom factor corresponding to the desired camera views. We will show first results of a prototype system applied to a soccer game. — To further push the limits of automating the production, the automatic camera operation is complemented with an automatic selection of the most interesting camera angle out of the available camera feeds. This automatic direction can either be used to create a fully automatic system or to assist the single operator in charge of a complete multi-camera production. First experiments indicate that the quality of the camera selection comes close to the judgement of real directors. — To achieve human operator quality, both for the camera selection and for the automatic steering of robotic cameras, we designed an Artificial Intelligence based approach, combining several techniques, including a combination of various machine learning components to mimic the behavior of human operators.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "live broadcast production",
                      "sports production",
                      "artificial intelligence",
                      "machine learning",
                      "automatic camera steering",
                      "robotic cameras in searches"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001816"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Exploring Creative Frontiers of AI for M&E Production and Distribution",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Olson",
                    "Rick Singer"
                  ],
                  "abstract": "In recent years, Artificial Intelligence (AI) tools are beginning to revolutionize Media and Entertainment production and distribution industry. As with other industries, such as mobile, business, transportation, gaming, robotics, security, education. Much like non-intelligent automation, artificial intelligence applications can be trained to perform human-like tasks. Some of the common skills currently imitated by AI include visual perception, speech recognition, decision-making, and adaptability — AI tools can be applied to perform tasks that were impossible to accomplish. AI performs tasks faster and with greater precision than their experience human counterparts. AI applications are beginning to augment the creative decision making skills of the production and distribution team, enabling energy, talent and enthusiasm to be focused on what only humans can do. At least for now. — During the M&E creative production process images, sound, and metadata are collected and stored, analyzed, identified and selected. Recovery of content from the media libraries and archives is critical to the creative process. This includes production generated multiple media formats of video, audio, graphics, and other types of data including text, scripts, and playlists. — It takes multiple tools to organize, collate and curate media and data from different formats and types. Metadata creation technologies help create the metadata necessary for content search and retrieval. While several logging and recognition technologies can generate some metadata automatically, the results are often incomplete inaccurate and far from comprehensive. — AI can be applied to myriad applications enhancing, accelerating and increasing the capacity of the media supply chain: AI services such transcription, language and dialect translation. face and object recognition, social media sentiment analysis. geolocation and fingerprinting are just a few examples. — Newly developed artificial intelligence for media asset management fuses the ability to understand all media and data types and perform discovery, synthesize and curate. — Across the media supply chain employing automated technologies that can create the metadata, then index and catalog it during the creation or acquisition process would help the creative process downstream. There is a still a requirement for the creative team to identify relationaships and the preferred clip selection. It needs the legal team to add permissions, control access, contractual distribution and expiration criteria. In news production using ML techniques with pattern matching, additional content can be identified.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "AI",
                      "Artificial Intelligence",
                      "machine learning",
                      "Deep learning",
                      "inference",
                      "semantic",
                      "metadata",
                      "MAM",
                      "DAM",
                      "PAM",
                      "asset management",
                      "media management"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001817"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Beyond Better Pixels: How HDR Perceptually and Emotionally Effects Storytelling",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Aurora Gordon"
                  ],
                  "abstract": "As the push for high-dynamic-range (HDR) content begins to swell, consumers may find themselves wondering what this new content offers at home, beyond gimmicks and more expensive televisions. Content creators may also find themselves wondering what this new standard offers to the stories they tell beyond yet another set of delivery specs. With the bulk of HDR demo material showcasing standalone wow-factor wide shots designed to showcase the physical limits of dynamic range, there is a need to take a step back and examine how HDR and wide-color-gamut (WCG) effects an entire project: putting our brighter and better pixels in the more meaningful context of an entire story. This paper will present observations on the effect of HDR/WCG as it varies through visual styles, using examples from a one hour medical drama, a half hour super hero comedy, and a one hour spy thriller. The author will use data collected from her work as a colorist on over 35 episodes of HDR content to examine the psychophysical, perceptual, and emotional impact of the deeper dynamic range and greater gamut available in larger color volumes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "high dynamic range (HDR)",
                      "wide color gamut (WCG)",
                      "home viewing",
                      "storytelling",
                      "content creators",
                      "perception",
                      "SDR-to-HDR",
                      "standard dynamic range (SDR)",
                      "HDR10",
                      "contrast ratios"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001818"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Using High Dynamic Range Home Master Statistics to Predict Dynamic Range Requirement for Cinema",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ronan Boitard",
                    "Michael Smith",
                    "Michael Zink",
                    "Gerwin Damberg",
                    "Anders Ballestad"
                  ],
                  "abstract": "The High Dynamic Range (HDR) home video format launched several years ago and has been adopted by the industry such that HDR Home Masters are created for most new release titles and are released for home video distribution using Ultra HD Blu-ray and digital formats. Mastering titles in HDR Cinema is the next logical evolution toward higher quality content and is thus greatly anticipated. However, mastering for HDR Cinema is still experimental due to the wide variety of potential HDR Cinema display technologies and their unique dynamic range characteristics. Determining the required dynamic range for HDR Cinema Masters is thus of great interest. In this paper, we propose an estimation of two properties of the dynamic range required for HDR Cinema Masters based on two different datasets. The first dataset corresponds to the dynamic range statistics and cumulative distribution function (CDF) of 41 Warner Bros. HDR Home Masters. Analyzing this dataset indicates that the maximum light level of a frame (the peak luminance values) is directly related to the Frame Average Light Level (FALL) of the frame. In other words, there is a maximum contrast between the intensity of the highlights in an image and the average intensity of the image. The second dataset is composed of matching mastered grades for SDR Cinema (DCI), Enhanced Dynamic Range Cinema (Dolby Cinema theatrical release) and HDR Home formats. Paired matching of content is useful to derive a translation between grades. By performing a cross-analysis between SDR and EDR Cinema content, we estimate a trend on the evolution of the FALL statistic when a higher dynamic range is provided. A second cross-analysis between HDR Home and EDR Cinema characterize the translation of mid-tones between small screens with surround illumination to big screens in a dark viewing environment. Using the different analyses, we predict two optimized properties of the dynamic range needed to represent most future HDR Cinema mastered content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "Mastering",
                      "Digital Cinema"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001819"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "What are the “killer apps” for HDR? Analysis of SDR assets to predict the potential of HDR",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre Hugues Routhier"
                  ],
                  "abstract": "Increasing both the latitude of images and the peak brightness of their display can, in the right conditions, deliver stunning experiences to our viewers. However, there are also conditions where the viewer may not perceive any difference between an SDR and an HDR source, and, even more worrisome, situations where increasing the dynamic range can actually be detrimental to the story. Using a combination of histogrammatic and Exposure Value (EV) analysis methods, the author has reverse engineered the source luminance of a wide array of SDR assets from motion pictures, documentaries, talk shows, cinematic series and sports to determine which assets offer the best potential to amaze viewers in this early wave of HDR introduction to the public.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "High Dynamic Range",
                      "Television",
                      "Motion Pictures"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001820"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "The Automated AI Workflow is here… If you know where to look",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jason Perr"
                  ],
                  "abstract": "Artificial intelligence has long held the promise of making things easier, faster, and better. While many people still believe that A.I. is something coming in the future, people who know where to look and how to leverage it are already using it today. The problem is understanding how to filter out all of the noise about A.I. to find the tools that can empower media workflows to take advantage of what A.I. has to offer. Choosing the right media asset management system to harness A.I. needs to be based on interoperability, not built-in features. If you want to harness the maximum capability of AI and machine learning with your content library, having a strong MAM at the heart of your operation is a tremendous advantage. — The objective of this paper is to show some of the best currently available tools and companies that are offering powerful A.I. capabilities, explain how to access these tools, and discuss the realistic results that can be expected from using them. — Being able to leverage A.I. in any media workflow can provide a signifigant boost to producitivity. Many organizations can benefit from the powerful things that these tools can bring. Too often, companies and individuals work harder than needed by performing manual tasks instead of looking to A.I. for help. These technologies are now more within reach than many people realize.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Artificial Intelligence",
                      "A.I.",
                      "Media Asset Management",
                      "Automated Workflow",
                      "Workflow Intelligence",
                      "Machine Learning",
                      "Content Library",
                      "Digital Automated Studio"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001812"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "New Standards for Immersive Storytelling through Light Field Displays",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Lude"
                  ],
                  "abstract": "Evolving UHDTV display technologies provide a welcome improvement over previous cinema and television images, including higher resolution, improved dynamic range and more vivid colors. But they remain fundamentally similar to the past methods: a flat image in a rectangular frame is used to convey the visual art of storytelling. New technologies are now enabling an altogether more immersive and captivating entertainment experience. Next-generation light field displays hold the promise of even more immersive images, with life-like representation of 3D space, accurate parallax and multiple focal points — all without need for glasses or headgear. In order to benchmark future needs, it is important to understand the many parameters of image reproduction that create the illusion of an immersive image. Based on these parameters, the technical requirements for light field image system — including data volume and transmission bandwidth — can be estimated. It is perhaps no surprise that the storage and transmission of light field data far exceeds available capacity in today's infrastructure. Among the potential solutions is the use of a new method of encoding image data, leveraging vectorized representations rather than traditional image rasters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Light Field",
                      "Plenoptic",
                      "VR",
                      "360-video",
                      "standards",
                      "Virtual Reality",
                      "Raster",
                      "Vectorized",
                      "6DoF"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001811"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Black Level Visibility as a Function of Ambient Illumination",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Scott Daly",
                    "Pavel Korshunov",
                    "Touradj Ebrahimi",
                    "Timo Kunkel",
                    "Robert Wanat"
                  ],
                  "abstract": "One of the key new attributes of HDR imaging and displays is the ability to present many stops of shadow detail, and with the best systems, a perceptually pure black. Displays perform at their best in a dark room as no ambient illumination impinges on the surface of the display, which would elevate the display's perceived black level. In addition, the viewer sees the most shadow detail when the region surrounding the display is also dark. In addition to applications where a display is viewed in a dark surround environment, there are also many viewing conditions where higher ambient light levels occur. Knowledgeable viewers prevent ambient illumination from reflecting from the display, but even for those viewers, surrounding luminance will be increased. To understand the impact of this surrounding ambient illumination on black level visibility and shadow detail, and to further guide ambient compensation algorithms, we performed a psychophysical study to assess the human visual system's ability to perceive detail when impacted by surround luminance. For the stimuli, we used a Gabor signal to probe the visual system's best capability. For the display, we used a Pulsar display with a large 1.0 neutral density filter placed over the display to enable black levels as low 0.0005 cd/m^2, relevant for OLED and cinema applications. The surround luminance levels ranged from fully dark up to 100 cd/m^ 2, and for each of these, shadow detail thresholds were measured as a function of display mean luminance levels from .001 to 400 cd/m^2. The results are useful for perceptual display performance assessment and tone-mapping applications, and PLUGE design. Further analysis found they are consistent with an existing surround effect visual model, which has basis in the cone photoreceptors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Black Level",
                      "Thresholds",
                      "Visibility",
                      "Display Quality",
                      "Psychophysics"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001809"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Maximizing content with cloud, virtualization and AI",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raymond Thompson"
                  ],
                  "abstract": "As more and more consumers rely on viewing content on mobile devices, cut the cord in favor of skinny bundle packages, and turn to subscription services and targeted sports content packages, advertisers are following suit. Digital ad spending outpaced traditional broadcast spending for the first time, putting economic pressure on broadcasters who rely heavily on ad revenue, and cable service providers who rely on subscription revenue. This tectonic shift in content creation and consumption has created unique operational and economic challenges, but it has also created a tremendous opportunity. Creating a connection with a consumer through OTT video services is critical. Media companies must deliver compelling content that engages audiences, and monetize that content to capitalize on the shifting ad spend while maintaining legacy business models. This is what broadcasters, cable and service providers, and even new media companies (Amazon, Netflix, etc.) are all grappling with. — Operationally, organizations are looking to the cloud to streamline costs and operations, which includes implementing virtualized environments and adopting IP-based infrastructures using commercial off-the-shelf (COTS) hardware and on-demand services. Broadcasters are adopting IP contribution and distribution technologies, and using bonded cellular and open source and proprietary protocols for protected content delivery over common internet lines to expand their ability to cover more with fewer resources reliably. Economically, media companies are offering PPV, subscription-based, and ad-sponsored delivery options, and starting to use AI to maximize digital ad spend while also delivering a more personalized experience. — To maximize the opportunity, organizations are building infrastructures that will allow them to control the experience down to the viewer consuming the content at the client side. This can be a very complex delivery challenge with hurdles that include content rights management and protection, error correction to manage jitter and packet loss, and monetizing that content to maximize its value as an asset.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IP",
                      "Contribution",
                      "Virtualization",
                      "Cloud",
                      "Multi-platform",
                      "cloud playout",
                      "Distribution",
                      "live",
                      "Multi-Cloud",
                      "Microservices",
                      "Transcoding",
                      "Automation",
                      "File",
                      "Consumer",
                      "OTT",
                      "OTA",
                      "AI"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001815"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Influence of Ambient Chromaticity on Portable Display Color Appearance",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Trevor Canham",
                    "Michael J. Murdoch",
                    "David Long"
                  ],
                  "abstract": "The share hold of mobile displays in the content distribution market has grown significantly over the past decade. These displays add new complication to media color management as they can be viewed across a wide range of environments over a short span of time. There is currently no consensus within the color science community on the extent to which surround adaptation to ambient chromaticity has a significant impact on the color appearance of image content on these displays. Thus, an investigation into this query has been conducted at the Dynamic Visual Adaptation Laboratory at the Rochester Institute of Technology in Rochester, NY. The study aimed to quantify the color appearance impact of these surround signals. Observers performed an asymmetric memory matching task for a set of images viewed under SMPTE standardized mastering conditions and under a series of ambient illumination conditions with varying chromaticity and luminance. The results suggested that observers adapt partially to the chromaticity of ambient illumination while viewing images on portable displays, and also that this mixed adaptation ratio varies as a function of ambient luminance and stimulus type (self-luminous solid color versus images).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Portable Displays",
                      "color management",
                      "surround adaptation",
                      "content mastering"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001810"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Automating Metadata Logging through Artificial Intelligence",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Witmayer"
                  ],
                  "abstract": "In 2007 NASCAR designed and implemented a media asset management solution for their sport. Now, in 2018, the library has grown to more than 500,000 hours of content containing video, audio and still images dating back to 1933 — one of the most vast sports libraries in the World. — Since the inception of the library, NASCAR has employed a staff to manually apply metadata to each video frame, amassing 10 million entries. While the logging by our staff has been impressive, the incoming data avalanche cannot be addressed by using the current system, let alone the glacier of data hiding in the archive. At present, we have calculated that it would take our existing staff nearly 150 years to log all of the historical content as it stands today. Over the past ten years we have extensively analyzed open-source and proprietary tools aimed at dealing with the data logging gap and have determined Machine Learning is the ideal solution to address metadata logging on large-scale media libraries. — As Machine Learning has become more accessible through the scalability of cloud computing, training and implementing Convolutional Neural Networks is now within the reach of media production companies and asset stakeholders. NASCAR is on the verge of revolutionizing how all data asset management systems can be restructured in the future to integrate machine learning to harness efficiencies in metadata logging.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Artificial Intelligence",
                      "Convolutional Neural Networks",
                      "Machine Learning",
                      "Metadata Tagging",
                      "Video Logging",
                      "Tensorflow",
                      "Visual Field",
                      "Transfer Learning"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001814"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Artificial Intelligence For Media Operations Why AI algorithms will become a must for every network management system",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Gunkel",
                    "Ben Vandenberghe"
                  ],
                  "abstract": "Artificial intelligence already has a big impact on a lot of different segments in the media industry. With the broadcast industry moving to all-IP and data center deployments those environments are more agile and complex than ever before. With fast-evolving technologies and cycles, ever more mission critical systems and constantly changing operational practices and devops style operations, traditional network management systems (NMS) and their paradigms don't fit the bill anymore. This paper explores why machine-learning algorithms must find their way into network monitoring and management solutions to orchestrate a modern media data center dynamically and in a proactive way. The foundation for an AI-driven NMS platform is a solid big data storage architecture; a lack of profound data and data hygiene is often one of the biggest obstacles to successfully deploy big data projects. As in today's all-IP environments nothing is static anymore, an AI entity must be highly intelligent. Unsupervised learning is key to automatically adapt to changing environments. Augmented operation and a zero-configuration and zero-maintenance approach will be crucial to successfully deploy the right management strategy.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NMS",
                      "artificial intelligence",
                      "machine learning",
                      "augmented operation",
                      "forecasting",
                      "intelligent fault detection",
                      "incident detection",
                      "deep root cause analysis",
                      "advanced analytics"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001813"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Good Things Come In Small Packages Microservices For Media",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Lennon"
                  ],
                  "abstract": "The concept of microservices is not new. The notion of breaking down traditional monolithic Application Program Interfaces (APIs) into much smaller, business task focused services is something that has been embraced by many industries. The media industry is just beginning to realize the benefits of this approach, particularly with the move to cloud-based services. We will look at why microservices are now emerging as a hot topic for media, where they make sense, and how standardization within SMPTE can help to leverage this trend for the benefit of the industry at large.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Microservices",
                      "standards",
                      "containers",
                      "virtual machines",
                      "interoperability",
                      "workflow",
                      "media"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001833"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Robust, Repeatable and Interoperable Workflows through IMF Output Profile Lists",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Arjun Ramamurthy",
                    "Raymond Yeung"
                  ],
                  "abstract": "The SMPTE IMF (Interoperable Master Format) has, over the past couple of years, been adopted by content owners (studios and broadcasters) in numerous applications ranging from archival to distribution servicing. The key characteristics of variable composition (via Composition Playlists) and packaging provide proven economy in scaling of versions. An additional feature of the IMF framework, the Output Profile List (OPL), provides the foundation of robust and interoperable workflows through the use of standardized media processing macros (operators) ensuring identical output regardless of systems or facilities. This presentation details how standardized as well as customizable OPL operators can be applied to construct a universally portable processing pipeline for content servicing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "automation",
                      "Composition Playlist",
                      "CPL",
                      "distribution",
                      "file base",
                      "Interoperable Master Foramt",
                      "IMF",
                      "Output Profile List",
                      "OPL",
                      "media processing",
                      "workflow",
                      "servicing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001834"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "In-camera, Photorealistic Style Transfer for On-set Automatic Grading",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Itziar Zabaleta",
                    "Marcelo Bertalmio"
                  ],
                  "abstract": "In professional cinema, the intended artistic look of the movie informs the creation of a static 3D LUT that is applied on set, where further manual modifications to the image appearance are registered as 10-parameter transforms in a color decision list (CDL). The original RAW footage and its corresponding LUT and CDL are passedon to the post-production stage where the fine-tuning of the final look is performed during color grading. — In many cases, the director wants to emulate the style and look present in a reference image, e.g. a still from an existing movie, or a photograph, or a painting, or even a frame from a previously shot sequence in the current movie. The manual creation of a LUT and CDL for this purpose may require a significant amount of work from very skilled artists and technicians, while the state of the art in the academic literature offers promising but partial solutions to the photorealistic style transfer problem, with limitations regarding artifacts, speed and manual interaction. — In this paper, we propose a method that automatically transfers the style, in terms of luminance, color palette and contrast, from a reference image to the source raw footage. It consists of three separable operations: global luminance matching, global color transfer and local contrast matching. As it just takes into account the statistics of source and reference images, no training is required. The total transform is not static but adapts to the changes in the source footage. The computational complexity of the procedure is extremely low and allows for real-time implementation in-camera, for on-set monitoring. While the method is proposed as a substitute for the need to specify a LUT and a CDL, it's compatible with further refinements performed via LUTs, CDLs and grading, both on-set and in post-production. The results are free from artifacts and provide an excellent approximation to the intended look, bringing savings in pre-production, shooting and post-production time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Style transfer",
                      "color transfer",
                      "color grading",
                      "video"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001835"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "The Corporate Integrity Implosion: Strategies for Technology, Media & Entertainment Organizations",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John McCoskey",
                    "Lauren Olinsky",
                    "Lindsey Muller"
                  ],
                  "abstract": "Corporate scandals are increasingly common in the headlines, fueled by the 24-hour news cycle and the ability to record questionable corporate behavior with a mobile device and blast out to social media in real time. The financial and reputational damage — as well as the threat to job security for top executives — can hit harder and faster than ever. Technology, media and entertainment (TM&E) organizations have been particularly hard-hit by these issues. — To explore the attitudes and perceptions associated with issues of culture, specifically integrity, respect, trust, and unethical behavior, new research was performed by surveying 1,506 people across the U.S. adult working population. This research reveals that the majority (54 percent) of workers believe that corporate integrity is on the decline. Integrity is the cornerstone of how employees act and react in both ordinary and extraordinary circumstances. Without a foundation of integrity, all other assets are at risk. — While gaps in integrity can make headlines instantaneously, weaving core values into every aspect of an organization allows for a laser-focus on creating competitive advantages through an investment in a powerful yet invisible resource — organizational culture.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Organizational culture",
                      "core values",
                      "integrity",
                      "talent management",
                      "human capital"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001839"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "A Location-free Commentary Adding System for Live Streaming Using a Cloud Infrastructure",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Naruaki Kato",
                    "So Endo",
                    "Akitsugu Baba"
                  ],
                  "abstract": "In this paper, we present a commentary adding system for http-based live streaming that can add audio of running commentaries to existing streaming video from any place using only internet access and a PC. We also propose the use cases of this simple commentary adding system for live streaming and explain how to implement additional audio in synchronization with the original stream. This system enables the location-free, internet-based remote production of running commentaries and also shows promise to be used in OTT services that are spreading rapidly in recent years.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "live streaming",
                      "cloud",
                      "media distributions",
                      "remote production",
                      "HLS",
                      "MPEG-DASH"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001828"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "A survey on 3D-LUT performance in 10-bit and 12-bit HDR BT.2100 PQ",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "JD Vandenberg",
                    "Stefano Andriani"
                  ],
                  "abstract": "In the cinema industry, during production and post-production, the use of 3D-LUTs has been proven to be a flexible and fast solution to perform color transformations, or to give a particular look to a captured scene. Unfortunately, the dimension of the 3D-LUT is limited by the available space in processing hardware, so there must be a tradeoff between the precision of the transformation (to avoid visual artefacts such as banding), and the space required to store it. Nowadays professional equipment, but also commercial televisions, are able to display gamuts wider than DCI-P3 with higher dynamic range. The new standard for HDR television is now ITU-BT.2100 [11], which has a color gamut that is almost double the size of Rec.709. Our aim was to determine the required minimum size of a 3D-LUT in the ITU-BT.2100 color conversion which avoids unnecessary visual artefacts. We defined a metric, mean3std, to use as the JND threshold allowing us to determine when an image is free of visible artifacts due to 3D-LUT interpolation error. — Tetrahedral interpolation outperformed all other interpolations for both SDR and HDR applications. It can achieve the same quality of the Trilinear interpolation using a 3D-LUT 20% to 25% smaller on average. The widely used Trilinear interpolation generated the largest errors among the tested images. In 10-bit SDR, in order to achieve unnoticeable interpolation errors using the trilinear interpolation method, a 3D-LUT larger than 41×41×41 is necessary. However, using tetrahedral interpolation a 31×31×31 3D-LUT is sufficient. In 12-bit HDR, in order to achieve unnoticeable interpolation errors, a 3D-LUT larger than 72×72×72, is required while a 3D-LUT size of 55×55×55 is sufficient if using the tetrahedral interpolation. The saturated and dark images resulted in a much larger minimum size 3D-LUT to achieve a JND<1 pointing to the possibility that ICTCP is likely not suited for dark images. Further studies are needed with emerging new color difference metrics to evaluate the 3D-LUT size for these types of images. Finally, we determined that reducing the bit-depth from 12-bit to 10-bit will require a 3D-LUT 50% larger on average to maintain a comparable image quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "3D-LUT",
                      "ICTCP",
                      "DeltaICTCP",
                      "ΔICTCP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001821"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Editing in the Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ulrich Ening",
                    "Karsten Schragmann"
                  ],
                  "abstract": "Changing working styles and the globalization of the media industry see a growing need for “remote” working and collaboration - an area where “the cloud” offers promising opportunities. However, cloud-based editing presents a number of challenges to overcome while maintaining an on premise feel and full client experience to editors. In this paper, we will look at how streaming technology and formats can be implemented together with an Adobe Premiere Pro client to enable users to work anywhere without detriment to the user experience. Based on tests carried out together with end users, this paper will consider some of the technical innovations required to maintain that user experience, based on the use of streaming server and SMPTE RDD25-based HD Proxies as a general approach to optimize the “work anywhere” editing possibilities for two use cases addressing producers, journalists and editors working remotely. — 1. Editing with streaming proxy in a cloud-based Video Production Management Suite — 2. On premise installation aiming for a centralized system with different editing sites and remote access. — 3. A hybrid concept that combines the benefits of cloud and on prem solutions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "MAM",
                      "Content Management",
                      "Proxy- & Craft Editing",
                      "Cloud",
                      "Media Management",
                      "Next Generation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001826"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Development of Full-featured 8K Recorder",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kodai Kikuchi",
                    "Takeshi Kajiyama",
                    "Eiichi Miyashita"
                  ],
                  "abstract": "NHK has been researching a full-featured 8K UHDTV system with the high frame-rate of 120-Hz (8K/120-Hz) for future broadcasting. — We have developed 8K encoder and decoder boards that support a popular video codec widely used in non-linear editing (NLE). Installing these boards into our prototype 8K recorder realizes real-time 8K/120-Hz compression and decompression. The recorder can store 60 minutes of a compressed stream in a single removable memory with solid-state drives (SSDs). We constructed an 8K post-production system and performed an 8K/120-Hz editing experiment with recorded content. In the system, an NLE machine was connected to RAID devices through a high-speed interface appropriate for transferring a compressed 8K/120-Hz source. Common NLE software was used that works with 4K/60-Hz video reproduced from original 8K files by applying the resolution scalable decoding function of the codec, and edited scenes were finally rendered at 8K/120-Hz. With the 8K/120-Hz NLE system, approximately 350 minutes of footage were handled, and more than 100 minutes of content were mastered. — To perform an 8K full-frame preview at editing sites, we also developed a peripheral play-out module that incorporates a decoder for the recording codec and 8K/60-Hz output interface (quad-link 12G-SDI) in a single PCIe card. By driving two modules in parallel, we achieved real-time 8K/120-Hz play-out in a workstation. Furthermore, a compact removable memory with a non-volatile memory express (NVMe) interface for offering good connectivity with editing systems was prototyped. — These achievements can provide cost-efficient editing and play-out, which makes 8K/120-Hz post-production more convenient than ever before.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "8K",
                      "UHDTV",
                      "120-Hz frame frequency",
                      "Compression recorder",
                      "Post-production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001825"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "A Threat Analysis of Virtual Reality for the Media Industry",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Diehl"
                  ],
                  "abstract": "This research paper proposes an initial threat analysis of Virtual Reality (VR) for the media industry. It focuses on the use of VR for media consumption or media-related applications. Pure gaming is not within its scope. Nevertheless, this study tackles although casual gaming applications related to movies or TV shows. After introducing a taxonomy of VR (360 VR, Theatrical VR, and Interactive VR) in the media industry, we determine all the assets that may need protection. Indeed, many more assets than the media content may require adequate protection. We describe some specific threats using the Attack Defense Tree (ADT) methodology. This threat analysis discloses a new attack coined Denial of Experience to induce cybersickness. — How should the industry prepare? We propose some priorities in the definition of a proper defense. As an example, the first recommendation is to build a risk aversion table. Some defenses may benefit from a coordinated, standardized approach.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VR",
                      "Virtual Reality",
                      "threat analysis",
                      "security"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001831"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "An Assessment of Reference Levels in HDR Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Erik Reinhard",
                    "Jurgen Stauder",
                    "Michel Kerdranvat"
                  ],
                  "abstract": "The movie and broadcast industries are gaining experience with high dynamic range (HDR) video technologies, and are starting to produce HDR content at scale. This is accompanied by a learning process, particularly involving questions regarding the use of the extra dynamic range afforded by these technologies. To create further insight into the aspects of HDR content, in this paper a variety of different types of content was analysed. Manual annotation processes are used to determine the range of luminance values that, for example, diffuse white objects or white overlay graphics objects have in this content. We find that for each type of object analysed the mean luminance value is reasonably constant across different types of content, but that the spread of luminance values is remarkably large, and strongly content dependent. Our results may form a basis for understanding HDR content, and contribute toward forming opinions on defining reference levels in reports and standards, including ITU-R Report BT.2408.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range Imaging",
                      "Movie Production",
                      "Live Broadcast",
                      "Reference Levels",
                      "Diffuse White",
                      "Graphics White"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001824"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "The Broadcast Transition to IP: Virtualization, The Cloud, The Edge and Application Programming Interfaces (APIs)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Todd Roth"
                  ],
                  "abstract": "The purpose of this paper is to examine the impact of modern IT and software methods and technologies on the adoption IP media in broadcast. Realizing the advantages of media over IP go far beyond the adoption of a SDI packetization standard. Modern trends in networking, cloud and edge technologies, as well as software design, deployment and management tools all need to converge into an interconnected, collaborative technological foundation. — The implications of these technologies, the interrelationships, the changing competitive landscape and the need for cross-sector collaboration will be investigated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud",
                      "Edge",
                      "Virtualization",
                      "Container",
                      "VoIP",
                      "API",
                      "NMOS",
                      "SW Development"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001827"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Variable Frame Rate Technology — Change Is Good!",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ed Callway"
                  ],
                  "abstract": "For over 100 years the motion picture industry has worked to ensure stable frame rates from capture to screen. This was essential when content creation and display were separated by many steps, and mechanical and electronic devices were slow to synchronize to a new rate. Today's content can be multi-rate or rendered on the end consumer's device, and this has consequences. A frame which is not available at the expected time must either be replaced with a repeat, causing motion judder, or switched part way through a sync cycle, causing tearing. Adding enough processing power or bandwidth to guarantee a constant frame rate with arbitrary content is too expensive for the consumer world. — HDMI and DisplayPort standards support holding the current displayed frame until the next frame is ready, then switching quickly. This maintains smooth motion by delivering the delayed frame quickly, without waiting longer for a fixed sync. As an example, at a target frame rate of 60 fps, a 1ms delay can trigger a full frame repeat at 30 fps with a 17ms delay, causing excessive judder. With variable frame rate technology, the frame is delivered just 1ms late for an effective 57 fps rate. — This paper shows how delayed frames lead to judder, the changes required to implement variable frame rates, and the user benefits. Previously delivered in Graphics Processing Units (GPUs) and monitors incorporating AMD FreeSync, it is now available in TVs and gaming consoles, making it accessible to new applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Display",
                      "Frame Rate",
                      "FreeSync",
                      "Judder",
                      "Tearing",
                      "HDMI",
                      "DisplayPort",
                      "VESA",
                      "VRR",
                      "VFR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001823"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "MPEG-I Future Directions",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jill Boyce"
                  ],
                  "abstract": "An overview is provided on MPEG's work on coding for Immersive Media, with a focus on MPEG-I, where “I” denotes “Immersive”. The MPEG-I project roadmap includes plans for a family of standards. — The recently completed Omnidirectional Media Framework (OMAF) systems specification provided support for VR/360$dg video with 3 Degrees of Freedom (3DoF). A planned OMAF version 2 will provide improved support for overlays and multiple viewports, and head-scale motion parallax. MPEG-I will provide support for full 6 Degree of Freedom (6DoF) audio and video, through several activities with target specification dates that range from 2020 to 2022. The MPEG Audio group is developing audio wave field coding, which goes beyond the MPEG-H Part 3 Spatial Audio standard, to provide audio playback from any position or orientation. — A new “VVC” Versatile Video Coding standard is being developed in collaboration with ITU-T Study Group 16 Question 6, which aims at a 50% bitrate reduction vs HEVC. VVC targets a wide range of content types, including High Dynamic Range (HDR) and 360$dg video. Future extensions of VVC may provide support for light fields. — The MPEG-I Graphics group is developing a Point Cloud Coding standard, which targets both lossy lossless compression. Point clouds are typically captured using multiple cameras and depth sensors in various setups, but as usual in MPEG, acquisition is outside of the scope of the standard. The standard targets efficient geometry and attribute compression, scalable/progressive coding, as well as coding of sequences of point clouds captured over time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VR",
                      "360 video",
                      "omnidirectional video",
                      "point cloud coding",
                      "immersive media"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001830"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Massively Parallel Open Source Encoding for Adaptive Streaming",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alexander Giladi",
                    "Blake Orth",
                    "Douglas Bay",
                    "David Leach",
                    "Alex Balk"
                  ],
                  "abstract": "Encoding of premium UltraHD content in adaptive streaming ecosystem trades the number of encode jobs for a wider network and device reach. The recent emergence of content and context adaptive technologies which often require “trial encodes” further raises the amount of computational resources needed to encode a single video. — Distributed encoding, where non-overlapping chunks of the same video are encoded in parallel on different machines, emerged as the mainstream response to these challenges. This approach reduces the overall encoding time and makes the best use of available hardware resources, and is an excellent fit to a cloud or cluster environment. — In this paper we will describe an implementation of the massively parallel approach to video encoding. We will start from defining a chunk encode, “joblet”, and what it entails. Lastly, the paper will demonstrate a dramatic increase in the computational efficiency of high-quality offline video encoding without a significant impact on video quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video compression",
                      "distributed encoding",
                      "distributed processing",
                      "HEVC",
                      "x265"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001829"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "A Subjective Comparison of Broadcast and Unicast Transmission Impairments",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brahim Allan",
                    "Mike Nilsson",
                    "Ian Kegel"
                  ],
                  "abstract": "In this paper we describe a subjective test we have performed with 60 viewers over the age of 18 and 570 young students, the majority being 10 or 11 years old, to understand the relative annoyance caused by various transmission impairments when viewing television content. We wanted to compare errors associated with broadcast and multicast delivery which appear as areas of extreme color or tearing of the image, with errors associated with Adaptive Bit Rate unicast, such as interruptions and quality variations. We also wanted to study the impact of the type of screen the content is viewed on, considering viewing on tablets and on a TV. We have found a significant level of consistency over all of the results we have collected. Interruptions were the most annoying impairment, with multiple short interruptions being more annoying than a single longer one, and with missing content being more annoying than simply pausing. We found more tolerance to quality variation on tablets, and found that younger adults are more annoyed by impairments on tablets and older adults more annoyed when watching on the TV. We have found the young students to have similar views to the adults, and have found them to be capable of participating in subjective tests.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video signal processing",
                      "High definition",
                      "Subjective quality assessment",
                      "Quality of experience (QoE)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001847"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "European Athletics Championships: Lessons from a Live, HDR, HFR, UHD and Next-Generation Audio sports event",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frans de Jong",
                    "Dagmar Driesnack",
                    "Andrew Mason",
                    "Matthieu Parmentier",
                    "Paola Sunna",
                    "Simon Thompson"
                  ],
                  "abstract": "The European Broadcasting Union and several of its member organisations undertook an ambitious trial over the summer period — a live, UltraHD, High Dynamic Range, High Frame Rate, Wide Colour Gamut and Next Generation Audio trial at the European Athletics Championships in Berlin, Germany. The trial included four 2160p/100 cameras with live control of shading/racking, live vision mixing, live recording, live mixing of audio objects, audio-visual synchronisation with audio objects and live encoding. — This paper looks at the lessons learned during the trial — what went well, what needed extra work and what is needed to overcome current technical hurdles.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ultra-high definition",
                      "UHD",
                      "high frame rate",
                      "HFR",
                      "next-generation audio",
                      "NGA",
                      "high dynamic range",
                      "HDR",
                      "hybrid log-gamma",
                      "HLG",
                      "wide colour gamut",
                      "WCG",
                      "BT.2020",
                      "high definition",
                      "HD",
                      "object-based audio",
                      "OBA",
                      "high-order ambisonics",
                      "HOA"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001849"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "CASE STUDY - UHD introduction at the Canadian Broadcasting Corporation",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jonathan Dupras",
                    "Pierre Hugues Routhier"
                  ],
                  "abstract": "In its biggest move since the 1960s, the French Canadian headquarters of the CBC will move out of its current, historical facility into a brand new, all-digital home in 2020. As part of this radical infrastructure change, the CBC has undergone a series of tests on new imaging technologies, to better understand their impact on the viewer as well as the required changes in production and post-production techniques they entail. The tests were designed to validate several engineering and creative challenges facing broadcasters wishing to transition into UHD. Following the successful acquisition of hundreds of reference shots, a post-production workshop helped define the optimal workflows and formats for source archival, mezzanine file generation and OTT / Broadcast distribution formats. A training program is in the works to help creative leads transfer their newly acquired know-how to other members of the CBC. This paper provides insights to broadcasters with significant infrastructure and large teams into how to successfully transition from HD into UHD, and the challenges to expect along the road.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHD",
                      "4K",
                      "HDR",
                      "Broadcast"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001850"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "9 Years of Media and Entertainment Digital Storage Surveys",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Coughlin"
                  ],
                  "abstract": "Digital storage plays a significant role in the professional media and entertainment industry. Digital storage for the M&E industry has demanding characteristics often very different from typical IT storage, because of the performance requirements of real-time video in capture, editing and post-production as well as distribution. These trends are driving demand for flash memory in post-production as well as content delivery. On the other hand, the growing archive of long-tail digital content and increasing digitized historical analog content is swelling the demand for cold as well as warm archives using tape, optical discs and hard drive arrays. The growth of IP based workflows is driving demand for block, file and object storage for various M&E applications. As a result, the prices of digital storage have declined. At the same time the availability of digital storage hardware, software and on-line services has increased. This brings up the question of what sort of storage systems and services M&E professionals require for various parts of their workflows. What drives their storage decisions and how are these demands changing over time? Coughlin Associates, Inc. has been conducting a survey of Media and Entertainment professionals from all over the world on various digital storage topics for nine years. The surveys were broken down into several usage segments to reflect broad differences in storage requirements, these were: content capture, editing and post-production, content delivery as well as archiving and digital preservation. Results from the nine years of the survey will be compared to show changing storage trends for these various M&E applications including storage capacity growth, cloud storage; flash memory, hard disk drive, tape and optical disc demand. These surveys served as a basis for our annual Digital Storage in Media and Entertainment report and some projections on the drivers and growth of digital storage will give insights on the future of digital storage for the media and entertainment industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital storage",
                      "flash memory",
                      "hard disk drive",
                      "HDD",
                      "optical disc",
                      "media and entertainment"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001851"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "Direct View LED in the Cinema: Architectural and Engineering Considerations",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David S. Richards"
                  ],
                  "abstract": "From the inception of motion pictures until recently, the cinema image has always been based on projection. Regardless of the technology: film, DLP, D-ILA, GLV, LCOS — all these technologies project an image onto a white screen. The words movies and projection are so inseparable they are almost synonymous. However in Las Vegas in April 2017 Samsung demonstrated a 4k-resolution, 34-foot wide direct-view LED display in a commercial cinema theater. This marked the beginning of a new era of cinema presentation that no longer involves projecting from a device at the rear of an auditorium. This paper presents a detailed technical evaluation of the aspects to be considered in applying direct LED technology in a cinema theater.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LED",
                      "Direct view",
                      "SDR",
                      "HDR",
                      "DCI",
                      "DCP",
                      "4k",
                      "de-elevation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001853"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "SOUND AND FURY: BRINGING DOLBY ATMOS TO THE NHRA",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Babbitt"
                  ],
                  "abstract": "The National Hot Rod Association (NHRA) approached Dolby Laboratories in early 2017 to explore what value immersive audio might bring to the NHRA's television broadcasts. After site visits, audio captures, video production analysis and production tests, a hybrid production strategy leveraging conventional live and cinematic post production methodologies using both the static placement of objects and the dynamic panning of audio objects in the immersive space and in real time was employed. This approach took advantage of the relatively predictable nature of each NHRA drag race to enable the use of live, dynamically panned audio objects combined with statically panned objects like ambience and crowd paired with substantial use of audio scene changes. This hybrid live/post approach to the creation of live Dolby Atmos immersive audio experiences could be used as a model for other sports, and exposes opportunities for a measure of automated audio production control through the capture and use of telemetry data from spider-cams, jib-cams and the participants themselves.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Audio",
                      "Immersive",
                      "Next-Gen",
                      "Atmos",
                      "Dolby",
                      "Motorsports",
                      "Multichannel",
                      "Panning"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001854"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "Beyond SMPTE Time Code — the TLX Project",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Symes",
                    "Hugh Reynolds"
                  ],
                  "abstract": "SMPTE Timecode (ST 12) and its transport, storage, display, and association to video and audio, has been a cornerstone of media production since the 1970s. ST 12 is both easy to understand and easy to use; its application is almost universal for media, and the standard has found application in other industries. However, ST 12 is constrained by design choices that, while appropriate at the time, represent substantial shortcomings today. — This paper reports on an ongoing project to define a new time label that is more appropriate for modern workflows and new media. This project is expected to produce a new “extensible time label” (TLX), to be defined by the ST 2120 suite of documents. While providing all the capabilities of ST12, TLX is intended to accommodate new user requirements and leverage new system capabilities to provide a comprehensive labeling system. — The paper describes the proposed structure of TLX and its components, and a system of Profiles intended to facilitate configuration of TLX labels to meet the needs of diverse applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Time label",
                      "time code",
                      "PTP",
                      "TLX",
                      "digital birth certificate"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001855"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Blockchain application in Media and Entertainment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shruti Tripathi"
                  ],
                  "abstract": "Blockchain is currently one of the most widely discussed and hyped technologies. It has the potential to disrupt existing but also to enable new business models — The top 3 key takeaways in the blockchain technology in the media industry are: New pricing option for paid content using Blockchain: Blockchain makes even micro-cent payments cost-efficient. Current cryptocurrencies, such as Bitcoin or Ethereum permit transactions as small as fractions of cents. It is thus an enabler for penny price content purchases, such as paying for reading a single news article or streaming a single song. Also, traditionally ad-sponsored content such as YouTube videos can be monetized with an “ad-free” alternative for a small fee. — Consumption of paid content without boundaries: National / regional limitations of paid content subscriptions and DRM complexities will be decreased by the Blockchain. Blockchain is not a technical prerequisite for this endeavor since more sophisticated Digital Rights Management systems are also capable of dealing with complexities like multi-country access. Nevertheless, the blockchain has the potential to make DRM systems obsolete or at least to reduce the complexity of these systems, because every transaction/ consumption is tracked in the blockchain and directly linked to a user. The payment will be automatically initiated according to the underlying smart contract terms for the content. — Smart contracts: Ethereum, the second-largest blockchain network by market capitalization, was the first platform to introduce the concept of a smart contract. Smart contracts enable counterparties to automate transaction tasks that are typically performed manually and that require the involvement of third-party intermediaries. Smart contract technology can result in processes that are faster and more accurate and cost-efficient. — Challenges in implementing blockchain technology: — • Trust in blockchain technologies and platforms — • Opaqueness of blockchain platforms and standards due to quickly-changing market participants — • Usability and reach of blockchain technologies in everyday environments — • Interoperability of platforms and various standards needs to be secured",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "blockchain",
                      "media",
                      "broadcast",
                      "bitcoin"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001857"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Bridging the Gap Between Software and SMPTE ST 2110",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jean Lapierre",
                    "Marwan Al-Habbal"
                  ],
                  "abstract": "Broadcasters worldwide are seeking more flexible, agile, and scalable infrastructures to adapt to media consumption today. These goals can be attained through technological shifts towards software solutions and SMPTE ST 2110 IP infrastructure. — Software solutions can be easily modified, updated, and maintained with minimal overhead. Using SMPTE ST 2110 for IP connectivity meanwhile, breaks geographical restrictions. The flexibility is tremendous—video can be moved to wherever it needs to be, while computing/processing can change and adapt to requirements. In practice, there are gaps that need to be reconciled to reap the benefits of combining software and SMPTE ST 2110. — In broadcast, SDI has set the bar—it is 100% predictable and deterministic. SMPTE ST 2110 is designed to be a low latency and flexible replacement to SDI, but it comes with its own complexities in PC-based platforms: — • Packet pacing (SMPTE 2110-21) is mandatory. Achieving network scalability and predictability imposes that transmitters packet pace data to not overflow internal buffering in the IP infrastructure — • Accurate precision time protocol (PTP) for transmitters is needed to reduce network jitter, latency, and network buffering requirements. — • Network kernel bypass is needed to reduce unnecessary CPU usage. A standard network stack engages CPU cores and reduces data throughput. — • Packet processing for SMPTE ST 2022-7 is needed to optimize CPU usage, and to reduce unnecessary PCIe bandwidth. — Using SMPTE ST 2110-aware NICs, software-based applications can easily process SMPTE ST 2110 flows without compromising system resources or network integrity while guaranteeing deterministic, scalable, and repeatable SMPTE ST 2110 environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SMPTE ST 2110 NIC",
                      "SMPTE ST 2110",
                      "SMPTE ST 2110-21",
                      "SMPTE ST 2059",
                      "packet pacing in software",
                      "narrow transmitter",
                      "wide receiver",
                      "kernel bypass",
                      "SMPTE ST 2022-7",
                      "COTS",
                      "standards-based uncompressed transport",
                      "packet distribution",
                      "network stack",
                      "packets per frame",
                      "CPU load",
                      "real-time data transmission",
                      "Precision Time Protocol",
                      "PTP",
                      "PTP clock",
                      "redundancy",
                      "hitless protection"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001841"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Quantitative Evaluation and Attribute of Overall Brightness in a High Dynamic Range World",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stelios Ploumis",
                    "Ronan Boitard",
                    "Jean-Philippe Jacquemin",
                    "Gerwin Damberg",
                    "Anders Ballestad",
                    "Panos Nasiopoulos"
                  ],
                  "abstract": "Brightness is an attribute of visual perception to describe how intense the light entering the eye is. Since human perception is not linearly related to light intensity, characterizing brightness is a challenging task. In Standard Dynamic Range (SDR) imagery, brightness is often quantified using the Average Picture Level (APL) which is the average of all pixels' code values normalized by the maximum signal code value. APL provides a simple and commonly used brightness metric for SDR however its validity for High Dynamic Range (HDR) content has never been assessed. Due to the higher luminance range that HDR supports, HDR content are encoded using a different transfer function than SDR. Thus different distribution of pixel's code values is to be expected between HDR and SDR content. In this work, we evaluate the efficiency of the APL metric to quantify brightness of HDR content. We describe, using patches and professionally graded images, pixel's distribution where the APL fails to distinguish relative brightness between pair of images. To overcome APL shortcomings, we propose a brightness metric based on the geometric mean and variance of an image luma code values. We then conduct two subjective experiments to compare the efficiency of APL and our metric. Results show that the proposed metric predicts more accurately the relative brightness between two frames.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "Image Attribute",
                      "Brightness Evaluation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001838"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Scene-light conversions: the key to enabling live HDR production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Cotton",
                    "Simon Thompson"
                  ],
                  "abstract": "Live HDR television production has been slow to gain acceptance because it has often been found to compromise the quality of a standard dynamic range (SDR) BT.709 signal derived from the HDR. Whilst parallel SDR/HDR production workflows are possible, they greatly increase the expense and complexity of a production. This paper describes how “scene-light” format conversions, as opposed to the more usual “display-light” conversions, allow SDR and HDR cameras to be intermixed in an HDR production, and an SDR BT.709 output to be derived from an Hybrid Log-Gamma (HLG) HDR production workflow without compromising the quality of the SDR BT.709 signal. — The paper illustrates how these technologies have been deployed in four major international events over the summer of 2018; thereby proving their suitability for live HDR production and paving the way for simpler live HDR production workflows in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HIGH DYNAMIC RANGE",
                      "HDR",
                      "ITU-R BT.2100",
                      "HYBRID LOG-GAMMA",
                      "HLG",
                      "ITU-R BT.709",
                      "CONVERSION",
                      "SCENE REFERRED",
                      "ICTCP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001822"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Visual perceptual entropy measure",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt"
                  ],
                  "abstract": "This paper is about a theoretical framework on perceptual reproduction quality assessment. — Visual perception is the main theme for two approaches on image metrics, visual performance and image quality. Visual performance looks at the perception of standard elementary images, such as gratings, by different observers or by a single observer in different visual conditions; image quality looks at the perception of variations of the same complex scene by a standard observer. — Visual performance, for which Barten proposed a model in 1999, is studying threshold responses in visual perception. For image quality, on the other hand, indexes are built which must evaluate responses to a variety of suprathreshold visual characteristics, attempting to give results as close as possible to human visual perception. — In audiovisual field, all the configurations approved by the creative team must be reproduced in the final viewing. This cannot be measured by visual performance or image quality indexes. A third approach is needed. This may be called perceptual reproduction quality assessment. Visual perception assessment is not measuring defects, per se; it is built to evaluate the perceptual effectiveness of a given scene coding through a given reproduction technology. — It is only dependent on the number of configurations being reproduced by a given theater system relatively to the various configurations reproduced and approved in the review room. As such, it is a statistical measure. It is in fact similar to the definition of relative entropy. One important fact is that this evaluation must include a model of visual perception. — This paper shows how relative entropy, and entropy loss, can be estimated while taking into account the coding transform, the projector performances, maximum light and the characteristics of human visual system. — This scheme is carried easily for monochromatic content. Color, trichromacy, is quite challenging. The size of configurations goes from 212 to 236, around 6 billion configurations. Calculation and memory requirements are huge. Non-linearities are adding complexity leading to calculation of an upper limit only of entropy loss. — Presentation of results is also a challenge. One way to solve this is to process separately lightness and chromatic information. — In summary the main arguments in this paper are: — • Besides image quality and visual performance there is a need for perceptual reproduction quality assessment — • Entropy is the proper statistical estimator to evaluate the perceptual reproduction quality — • Color reproduction quality estimation requires processing lightness and chromatic attributes separately",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Entropy",
                      "Perception",
                      "Sensation",
                      "Quality metrics",
                      "Perceptual quantizer"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001837"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Creative Grading - Or why a new way of broadcast camera control is needed",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Klaus Weber",
                    "Ronny van Geel"
                  ],
                  "abstract": "In the early days of television, camera shading was required to compensate for technical imperfections of the equipment. But today, camera shading is required to achieve a certain look and style or to adapt the camera's capabilities to a given lighting situation. — New formats such as HDR, WCG, 4K, IP and new workflows require more functions to be controlled simultaneously and/or interactively, and it becomes very difficult to oversee all the settings. But tools available for camera shading today are still very much the same as in early days of television; linear controls, trying to keep up with today's nonlinear reality. — The latest still photography graphical applications use a different way of controlling the look of an image, and a broadcast camera control solution which leverages these developments will benefit from new ideas and the new skills grown with these solutions. It's time for a change and creative grading is delivering this change. It's a completely new concept for broadcast camera applications and has the potential to change the way camera shading is done now, more than it ever has before. — This paper will explain the background of today's camera shading solutions and shows how it should develop in the future, based on extensive customer feedback in addition to lessons learned from other widely used image control applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Creative grading",
                      "image acquisition",
                      "CMOS imaging",
                      "camera shading",
                      "UHD",
                      "4K",
                      "HDR",
                      "WCG",
                      "IP",
                      "image processing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001836"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Implementation of 8K vision mixer that transports 8K image as multiple 2K SMPTE ST 2110-20 flows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomofumi Koyama",
                    "Junichiro Kawamoto",
                    "Masahiro Kawaragi",
                    "Takuya Kurakake",
                    "Kyoichi Saito"
                  ],
                  "abstract": "We are developing an IP-based program production system for 8K UHDTV. SMPTE ST2110-20, which is the standard for transporting video over IP network, covers 8K transmission. However, the required bandwidth to transport an uncompressed 8K image (YCbCr 4:2:2, 10bit, 60fps) is about 40 Gbps so devices must use a high bandwidth interface such as 100GbE. Also devices for processing a single 8K stream require far more processing power than 2K and 4K production devices. — To solve these limitations and make it easy to deploy 8K production system, our 8K production system divides an 8K image into sixteen 2K images and transports each image as an SMPTE ST 2110-20 flow. This system has three advantages. First, our system can use lower bandwidth interfaces like 10 and 25 Gigabit Ethernet (GbE) to transport 8K. Second, this transport method enables devices designed for 2K production to be used in 8K and 4K productions, and broadcasters can upgrade their system from 2K to 4K or 8K instead of replacing it. Finally, this method enables us to operate a production facility more efficiently and flexibly. As processing 2K images does not require high performance, production processes can be performed without high CPU usage. We can implement a software production system and run it on generic servers to enable us to deploy and use resources for program production on demand.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SMPTE ST 2110",
                      "IP-based live production",
                      "Dematerialized facilities",
                      "8K",
                      "Ultra high definition (UHD)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001843"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Non-blocking Multicast Networks for Transporting Stream Media",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takeshi Shimizu"
                  ],
                  "abstract": "Leaf-Spine architecture is widely adopted as a scalable multi-stage network. However, for media transport purpose, nonblocking conditions for any combination of multicasts should be taken into account. In this paper, a new approach for building three-stage Clos networks with nonblocking multicast capability is proposed. First, a wide-sense nonblocking (WSNB) condition and a rearrangeable nonblocking (RNB) condition for nonblocking multicast networks are presented. The proposed conditions put focus on the distribution of inputs at the middle stage, rather than the distribution at the output stage. Second, the proposed conditions are evaluated by mapping to leaf-spine networks with commodity building block switches. The network size is evaluated by calculating the sum of required building block switches. In the best case of the evaluation results, up to 50% of the switches can be reduced compared with the best-known WSNB condition, and the proposed WSNB networks show good coverage in relatively smaller but practical sizes of networks. The proposed RNB networks always show better results than the known RNB multicast conditions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "multicast switching",
                      "three-stage Clos network",
                      "wide-sense nonblocking",
                      "rearrangeable nonblocking",
                      "Ethernet switch",
                      "IP multicast switch",
                      "media transport"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001844"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Automated Distribution Workflows Based on IMF Metadata",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomasz Witkowski",
                    "Andrew Dunne",
                    "Saul Mahoney",
                    "Andrew Johnston",
                    "Richard Welsh"
                  ],
                  "abstract": "In IMF (Interoperable Master Format), the mastering framework centres around CPL (Composition Playlist) and OPL (Output Profile List) control files. The Composition Playlist references all source media with assembly instructions. The OPL provides the encoding recipe to produce the finished product. This metadata system based on control lists can be leveraged to commercial advantage for highly automated and timely delivery of versions. This paper will illustrate the feasibility of this approach, and practical examples of distribution workflows via file metadata and control list. — Taking the view that the control metadata encapsulated in the CPL is effectively the “version”, the CPL can become the transactional component in a B-2-B supply chain. In this case the “version push” model where self-contained and complete versions of content must be created and distributed by the supplier can evolve to a component pull model where the assets are stored once and myriad versions distributed on demand. In this model, the OPL is the enabling component. The paper will outline the supply chain demands, a workflow design and the architectural components that are required to enable this model. — Security in the exchange of the assets and endpoint verification is an essential component in today's high risk connected environment. If the CPL becomes a transactional component and the customer can pull the files on demand then additional safeguards may be required, so for example upon presentation of the OPL to the content owner for fulfilment, the OPL would be validated by the source rights management system to ensure it accurately represents the contractual rights. — In the proposed model, the content producer retains full control of the master and controls the transcode and format conversion tools used for the delivered version, thus retaining the desired quality levels and including any watermarking desired. Updates can also be delivered in a more controlled fashion with better audit of the distribution than is currently possible. The conversion can be performed on premises or in the cloud, potentially allowing conversion to occur “in flight”.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Rights Management",
                      "IMP",
                      "Transcoding",
                      "Avails",
                      "Packaging",
                      "CPL Metadata",
                      "automation",
                      "Composition Playlist",
                      "CPL",
                      "distribution",
                      "file base",
                      "Interoperable Master Format",
                      "IMF",
                      "Output Profile List",
                      "OPL",
                      "media processing",
                      "workflow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001832"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Immersive media experiences - what do we need to move forward?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Perkis",
                    "Asim Hameed"
                  ],
                  "abstract": "Discussing the current “state-of-the-art” in eXtended Realities (XR) is challenging as it exists across a large number of companies and sectors in form of fragmented bits, and is changing from quarter to quarter. However, it is important to raise awareness of its generic building blocks to start a discussion on the way to move forward. Some of the the most important building blocks are the definition of immersion, the new necessary tools and ways of digital storytelling and the quality of the final experiences as perceived by the participants. Considering the current wave of technologies in the field, it is essential to cultivate the creative platforms being developed for a lasting success compared to past endeavours. This paper will discuss the technical and creative considerations of immersive media experiences and instantiations of XR in the current transmedia environment. The paper also examines the social impact of such emergent technologies including established business models and the legal, ethical, and political implications of their use. For illustrative purposes, we will include a case study from our own research on using XR for sensor based digital storytelling in motivational training.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Immersive media",
                      "quality of experience",
                      "digital storytelling"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001846"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Where are the Women? The importance of visibility in achieving inclusivity",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Krystle Penhall"
                  ],
                  "abstract": "“If she can see it, she can be it,” is the affecting catch cry of the Geena Davis Institute on Gender in Media. But if she's not seeing it, it's almost impossible to convince a young woman that a career in STEM is even fathomable. It will come as no shock to those of us sitting inside one or more categories of marginalization, that the number of women participating in STEM is extremely low. It's not due to a lack of ability or skill, nor because women lack ambition. Women don't seek out these roles because they don't see representations of people who look like them. — STEM literacy is imperative to our success as individuals, as corporations and as nations. We need to expand the scope of talent pools we currently draw from if we seek to innovate, disrupt, inspire and quite frankly, make more money. If we shine a light on an inclusive cross-section of women, companies will have access to a wider pool of committed, hard-working and creative teammates. This boosts work culture, innovation and output - improving the bottom line. While visibility can't change systemic marginalization overnight, it will chip away at the sometimes-hostile work environments women face. — Women's heightened visibility in film and television creates greater participation in the real world. In 2012, archery participation saw a dramatic surge across the US after the release of The Hunger Games, with the New York Times reporting that Katniss Everdeen was “the major cause of waiting lists for archery lessons from coast to coast.” This year, 21st Century Fox, The Geena Davis Institute on Gender in Media, and J. Walter Thompson Intelligence, completed a study examining ‘The Scully Effect’, about Dana Scully of The X-Files. They researched the effect the character had in motivating women to work in STEM fields. Of the women surveyed, “63% say Scully increased their confidence that they could excel in a male-dominated profession.” — Through examination of statistical analysis and the application of research and theory, I will analyze industry leaders who are creating diverse and inclusive workforces in aerospace and computing, and the positive effects of this change. Alongside this, I will also offer compelling tales of lived experience where women's visibility has directly impacted lives for the better — providing empowering takeaways and actionable suggestions for change.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "STEM",
                      "Visibility",
                      "Women",
                      "Inclusion",
                      "Diversity",
                      "Gender",
                      "Equality",
                      "Representation",
                      "Minority"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001840"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Scalability and Performance of the AMWA IS-04 and IS-05 NMOS Specifications for Networked Media",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Porter",
                    "Gareth Sylvester-Bradley"
                  ],
                  "abstract": "The use of IP networks for professional AV media is becoming prevalent within the broadcast industry with standards such as SMPTE ST 2110 now available for streaming uncompressed video, audio and ancillary data. To allow full interoperability between different manufacturers' equipment, common methods for discovery, registration and connection management of media devices are essential. The Advanced Media Workflow Association (AMWA) has been developing the Networked Media Open Specifications (NMOS) for this purpose, leading to the publication of two interface specifications: IS-04 for discovery/registration of NMOS Nodes and IS-05 for management of connections between Nodes. These use RESTful APIs to communicate between applications and devices and are gaining widespread adoption. — However, a key requirement within the industry is that these APIs scale successfully in the very large installations typical of real world deployments. To help address this, Sony has been leading an AMWA NMOS Scalability study to test these protocols for installations comprising thousands of media devices. — The study includes: confirming that operations such as the registration of thousands of Nodes can occur within an acceptable timeframe; testing recovery of the Registry after a failure; testing behaviour with multiple clustered Registries; testing different methods of Registry discovery; testing connection management at scale; and confirming behaviour for architectures with redundant network interfaces. The test suite has been shared with other AMWA members and tests have been repeated and confirmed with different Registry and Node implementations. — This paper describes our test methodology, provides several results, discusses their implications, identifies best practices for deployment and suggests whether further API enhancements may be beneficial.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Networked Media",
                      "IP",
                      "ST 2110",
                      "AMWA",
                      "NMOS",
                      "IS-04",
                      "IS-05",
                      "API",
                      "Device Discovery",
                      "Device Registration",
                      "Connection Management",
                      "Scalability",
                      "Registry Discovery",
                      "DNS-SD",
                      "mDNS",
                      "Unicast DNS",
                      "Registry Clustering",
                      "Redundancy",
                      "Mininet",
                      "Virtualized Network"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001842"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Stopping Geolocation Fraud Via “Rented” Residential IPs at the CDN Level to Protect Territorial Content Rights",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Artur Pawlak"
                  ],
                  "abstract": "This paper explains the process of VPN detection and blocking at both the OTT interface and CDN level, and gives examples of how it is used to stop the abuse of premium VPNs that are using hijacked residential IP addresses to circumvent the territorial rights licensing of content owners and rights holders. It will also provide information on new techniques for geolocation spoofing and discuss ways to thwart them.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VPN Detection",
                      "DNS Proxy Detection",
                      "CDNs",
                      "Geo-Piracy",
                      "Geolocation Fraud",
                      "Content Piracy",
                      "Residential IPs"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001848"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "The De-centralized Rights Locker",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Niels Thorwirth"
                  ],
                  "abstract": "This paper explains how the distributed ledger technology that has successfully decentralized currencies can be used to enable a decentralized marketplace for digital content rights. Today, multiple centralized rights lockers from companies and consortiums offer similar but incompatible systems to register a consumer's video purchases and manage content rights. Each is representing a monopoly that centrally governs the content rights and is motivated to do so only for as long as it remains profitable. — Blockchain technology can be used to establish a permanent, secure, decentralized and distributed registry for content registration, assignment and archival of rights. The benefits of leveraging blockchain for video content distribution and content rights management provide longevity that is independent of a single standard, company or governance body as well as security of transactions with cryptographic guarantee of entitlements and grants of content licenses that cannot be changed and verified permanently. Lastly, the distributed and replicated nature of the peer-to-peer (P2P) network provides resiliency, eliminating a single point of failure as well as the need to rely on just one single standard, company or governance body. This paper will provide a novel system design that explains how a blockchain can be applied to not only manage content rights but to also secure content by including digital rights management (DRM) and playback control as an integral part of the decentralized network. It also details how to improve common ledger technology to overcome concerns of performance and abuse that are relevant to this application.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Blockchain",
                      "distributed ledger",
                      "Ethereum",
                      "library",
                      "smart contract",
                      "content rights",
                      "video delivery",
                      "digital rights management",
                      "DRM"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001858"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "Implementing Hyperscale and HPC Techniques and Technologies Necessary to Modern Media and Broadcast Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bjorn Kolbeck"
                  ],
                  "abstract": "Across the media production and broadcast industries, studios of every size are accelerating their consumption of vast amounts of storage resources. With increasing quantities of data produced from increasingly higher-resolution digital cameras and content featuring greater color depth across a broader color spectrum, file manipulation and storage capacity have now reached the scale and performance requirements of high-performance computing (HPC) applications. Broadcast, production, post-production and distribution now generate hyperscale workloads with tens to hundreds of petabytes of business-critical data and streams of several gigabytes/second (GB/s) per client. For media companies to remain competitive, they need to apply the lessons learned by hyperscaler and HPC companies to cost-effectively and consistently provide high levels of performance with a very small team while ensuring long-term data protection. — This paper and presentation will utilize customer and industry examples from hyperscaler, HPC, and Media and Entertainment (M&E) organizations to discuss in tutorial fashion and learn how to implement a hyperscaler-like storage infrastructure that provides limitless scalable storage to all applications across a broad range of workloads; utilize commodity servers without hardware redundancy, RAID controllers or NVRAM required for the lowest cost and flexibility; and remove the challenges of deploying and managing infrastructure, enabling new methods of creating and delivering content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Storage",
                      "high-performance computing (HPC)",
                      "hyperscaler",
                      "scalability",
                      "throughput",
                      "capacity"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001852"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "Is Blockchain and Distributed Compute and Store Right for Post Production?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Wong"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001859"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Analysis of User Exploration Patterns during Scene Cuts in Omnidirectional Videos",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dmitrii Monakhov",
                    "Deepa Naik",
                    "Igor D.D. Curcio",
                    "Henri Toukomaa"
                  ],
                  "abstract": "Omnidirectional video can be comprised of several scenes joined together. A scene in a video can change within the same semantic content due to switching to a different camera position (e.g., in a multi-camera sport event), referred to as intra-scene transition; in other situations, a scene in a video can change between different semantic content, referred to as inter-scene transition (e.g., a scene cut from a movie). — In this paper an attempt is made to 1) find the user exploration behavior in terms of the exploration range, angular speed and acceleration metrics; 2) Investigate whether there is any exploration behavioral change in the watching patterns between intra- and inter-scene transitions. — We find that there is an increase in the exploratory behavior for all the above-mentioned metrics, and show that there is a delay (reaction time) between the scene transition and the start of the exploration. Finally, we also show that the exploratory behavior is higher in inter-scene transitions compared to intra-scene transitions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Omnidirectional video",
                      "360 Degrees video",
                      "Exploration range",
                      "Scene transitions",
                      "Watching patterns",
                      "Scene cuts",
                      "Viewport dependent streaming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001845"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "Broadcast Channel Origination as a Service: from Concept to Operational Implementation",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202018/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John McCoskey",
                    "Ron Clifton",
                    "Mark Jahnke"
                  ],
                  "abstract": "Historically, broadcasters have used on-premises channel origination systems requiring periodic replacement, capital expense planning, and asset depreciation. With a shortening replacement cycle caused by rapid technology advances, coupled with difficulty in accurately forecasting future storage, processing, and networking requirements, the traditional channel origination approach has become unacceptable. As stations evaluate options for upgrading, replacing, and re-thinking their infrastructure supporting broadcast, production, and digital operations they are faced with options ranging from simple replacement to implementation of advanced service-based approaches. — From a technical perspective, Channel Origination as a Service leverages a virtualized architecture for all channel functions, each of which is implemented in the cloud. This approach can reliably support frame-accurate and seamless switching between file-based, linear, and live content. Managed security can be provided across all platforms and network infrastructure and can be implemented in world-class datacenters and networks. The full service can be backed up via occasional use satellite to protect for outage scenarios. — From a business perspective, Channel Origination as a Service requires no CapEx investment or recurring technical refresh investments, yielding lower recurring operating cost per channel. Local station or network control of traffic, master control, and operations are still possible on-premises and using traditional staffing configurations and workflows. Alternatively, these functions may be outsourced to a shared-services provider or another third party. It can be implemented with short-term service agreements, providing increased flexibility for future business changes, e.g., the implementation of ATSC 3.0 and UHD distribution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2018-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Broadcast channel origination",
                      "cloud-based broadcast services",
                      "cloud playout",
                      "automation and playout",
                      "cloud computing for broadcast",
                      "archive storage",
                      "near-line storage",
                      "media asset management",
                      "linear video playout"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001856"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2017",
        "conferences": [
          {
            "conference_name": "SMPTE 2017 Annual Technical Conference and Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Display Interfacing 2017: Getting Around the UHD ‘Speed Bump’",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "The growth of UHD imaging and the addition of high dynamic range (HDR), wide color gamut (WCG), and high frame rates (HFR) are pushing display interfaces to ever-higher clock and data rates. However, current interfacing standards are too slow to accommodate many of these rates. We're pushing the limits of copper wire interfaces and are now compressing display signals for the first time. The newest version of HDMI (2.1) won't be widely available for a few years and may require optical fiber connections at higher speeds. In the meantime, DisplayPort (1.4) is ramping up its bus speeds to new highs and adopting support for consumer video formats. This presentation will provide updates on the latest interface architectures and speed challenges, and will also consider network signal transmission as an alternative connection method.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Display interfacing",
                      "HDMI",
                      "DisplayPort",
                      "Display Stream Compression",
                      "Optical fiber"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001752"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "360-Degree Video Streaming and its Subjective Quality",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Igor D.D. Curcio",
                    "Henri Toukomaa",
                    "Deepa Naik"
                  ],
                  "abstract": "Traditional challenges for deploying end-to-end streaming systems are made harder when considering 360-degree media content. One of these challenges relates to the lack of commonly accepted standardized methodologies for subjective 360-degree video quality assessment, especially oriented towards streaming services. The contribution of this paper falls in the area of subjective assessment of 360-degree video. — From traditional standardized test methodologies originally designed for 2D/3D video, we tailored a methodology more oriented towards Virtual Reality (VR) streaming services. The methodology inherits a lot from existing ITU standards for video subjective quality evaluation. The additions incorporate the special properties of 360-video, namely omnidirectionality, as opposed to traditional video. — With this goal in mind, a new metric called Similarity Ring Metric (SRM) is introduced. It measures the degree of similarity in watching patterns of a single subject or between different subjects for several subjective assessment tests. This metric enables an inclusion or rejection criteria for test results in subjective assessment sessions. We also present visual fatigue results related to a subjective quality experiment of 360-degree video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Omnidirectional video",
                      "virtual reality streaming",
                      "subjective quality evaluation",
                      "subjective assessment",
                      "360 degrees video",
                      "test methodology"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001758"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Case Study: Bridging Gaming and Broadcast Technology for High Productivity Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kuban Altan",
                    "Thomas Bradbury",
                    "Eric Minoli"
                  ],
                  "abstract": "Groupe Média TFO bridged gaming technology and traditional broadcast virtual set technology to produce the Laboratoire d'Univers Virtuels (LUV), a facility to quickly and efficiently create new shows and realistic scenes for TFO productions. Gaming technology adds new realism, technical quality and the ability to rapidly change scenes within the virtual set. This paper will discuss the TFO application of gaming based technology to the virtual set and its benefits for production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Groupe Média TFO",
                      "TFO",
                      "Virtual Set",
                      "Gaming",
                      "Gaming based Virtual sets",
                      "Unreal Engine",
                      "Bridging gaming technology to broadcast",
                      "Reality Engine",
                      "Mini-TFO",
                      "Minivers"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001759"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Blockchain & the Hollywood Supply Chain",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Wong",
                    "Bjorn Obermeier"
                  ],
                  "abstract": "The global system behind entertainment is opaque. It impacts content creators who do not know what, when, and how their content is consumed. Imagine the impact if all stakeholders had access to the same facts – Guilds, Unions, Studios, Record Labels, Publishers, Distributors, and Viewers. Blockchain technology offers this opportunity. In this article, we will explore new methods for enabling accountability in pre-production, production, post-production, distribution, and consumption with a secure chain of custody for Intellectual property, royalties and more.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001761"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Notice of Removal: Shoring up Your Dam in the Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Callum Hughes"
                  ],
                  "abstract": "Removed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001762"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "ARnold: A Mixed Reality Short Film using Microsoft HoloLens",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chinmay Chinara",
                    "Greg Feingold",
                    "Aakash Shanbhag",
                    "Kacey Weiniger"
                  ],
                  "abstract": "ARnold is a mixed reality (MR) film built for the Microsoft HoloLens that takes place in the viewer's living room. The film uses the concepts of Spatial Mapping, Spatial Understanding, Spatial Audio, and World Anchors to place multiple scenes on the viewer's actual surroundings; and dynamically changes the storyline based on the objects in the room. ARnold takes these technological opportunities and applies them to traditional storytelling techniques to create a film that is uniquely suited for MR. The main purpose of this project was to explore whether telling personalized experiences with a viewer-chosen setting increases empathy and creates a deeper emotional connection with the story. This paper also discusses the technical limitations of Microsoft HoloLens along the lines of how it affected our entire development cycle and the different techniques we adopted to tackle this challenge. This paper provides a detailed overview of our entire development cycle from both a technical and creative standpoint.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Microsoft HoloLens",
                      "Spatial Mapping",
                      "Spatial Understanding",
                      "Spatial Audio",
                      "Mixed Reality",
                      "Holograms",
                      "Parallax"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001756"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The Immersive Experience Classification System: A New, Strategic Decision-Making Tool For Content Creators",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre H Routhier"
                  ],
                  "abstract": "Since the initial introduction of the first customer-facing VR devices, the diversification of immersive technologies has been exploding. From 360-degree video to virtual reality, augmented reality, mixed reality, volumetric and computational imaging to the introduction of haptic devices of increasing complexity, it seems that innovation in this field knows no bounds. From a content creator perspective, this can have a paralyzing effect: Which technologies have a future, and which do not? Which technologies are more suited for storytelling, education, exploration or gaming? Instead of defining experiences through the technology they use, this paper uses four axes to classify immersion: Seclusion (how isolated the viewer is from the real environment), Navigation (how does the viewer evolve in the environment), Interaction (how does the viewer alter the environment) and Modeling (how is the environment generated). By ordering immersive technologies on those axes and linking them to types of user experiences (i.e. passive storytelling, interactive playing, solitary exploration, etc.), it is easier to select the right combination of immersive technologies. For example, if the goal is to tell a specific story, the use of technologies with limited navigation and interaction options will be more beneficial. If the goal is to provide a simulation, a high degree of seclusion combined with high freedom and interaction will be preferred - but that combination would not be the best choice to provide a specific educational experience, for example. The Immersive Classification System demonstrates that in immersive media, there are no right or wrong technologies. Each technology has a purpose; the goal is to match the content creator's objectives with the right combination of technologies, to provide the best experience to the user within those objectives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VR",
                      "AR",
                      "MR",
                      "Virtual Reality",
                      "Immersion",
                      "Haptics"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001757"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Engineering a live UHD program from the International Space Station",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rodney Grubbs",
                    "Sandy George"
                  ],
                  "abstract": "The first-ever live downlink of Ultra-High Definition (UHD) video from the International Space Station (ISS) was the highlight of a “Super Session” at the National Association of Broadcasters (NAB) Show in April 2017. Ultra-High Definition is four times the resolution of “full HD” or “1080P” video. Also referred to as “4K”, the Ultra-High Definition video downlink from the ISS all the way to the Las Vegas Convention Center required considerable planning, pushed the limits of conventional video distribution from a space-craft, and was the first use of High Efficiency Video Coding (HEVC) from a space-craft. — The live event at NAB will serve as a pathfinder for more routine downlinks of UHD as well as use of HEVC for conventional HD downlinks to save bandwidth. A similar demonstration was conducted in 2006 with the Discovery Channel to demonstrate the ability to stream HDTV from the ISS. — This paper will describe the overall work flow and routing of the UHD video, how audio was synchronized even though the video and audio were received many seconds apart from each other, and how the demonstration paves the way for not only more efficient video distribution from the ISS, but also serves as a pathfinder for more complex video distribution from deep space. — The paper will also describe how a “live” event was staged when the UHD video coming from the ISS had a latency of 10+ seconds. In addition, the paper will touch on the unique collaboration between the inherently governmental aspects of the ISS, commercial partners Amazon and Elemental, and the National Association of Broadcasters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NASA",
                      "live UHD video",
                      "ISS",
                      "International Space Station",
                      "HEVC",
                      "High Efficiency Video Coding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001753"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "A Formal Approach to Change Management (CM) for Dynamic Technology-driven Media Organizations",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John McCoskey",
                    "David Mouser",
                    "Rosemary Pierson"
                  ],
                  "abstract": "Media organizations are experiencing unprecedented and disruptive technological change. While such change presents tremendous opportunities for new products, services, efficiency, and agility, it also has significant and varied impacts to an organization's business performance. Those that treat people and organizational issues as secondary concerns—or overlook them altogether—do so at their own peril. A better approach is to use formal change management, which prepares stakeholders for the change while minimizing negative impacts to the business. Emphasizing the “people side” of change, change management targets leadership and stakeholders at every level of an organization. When done well, change management engages people in the process and empowers them to work collectively toward a common objective. Media organizations can apply structured change management processes and tools to manage the impact and achieve the full potential of technology-driven organizational change.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Change management",
                      "digital transformation",
                      "human capital",
                      "process re-engineering"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001772"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Notice of Removal: Zen and the Art of Media in Motion: The many aspects of quality in the media supply chain",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dominic Jackson",
                    "James Welch"
                  ],
                  "abstract": "Removed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001776"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Access Services for UHDTV: an Initial Investigation of W3C TTML2 Subtitles (Closed-Captions)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Simon Thompson",
                    "Peter Cherriman"
                  ],
                  "abstract": "Ultra High Definition Television and High Dynamic Range has been a focus of research for the past few years, however only now is work starting on the provision of access services for such content. These services are used by a large minority of the audience (up to 25%) and legislation mandates their inclusion in many territories. — The authors present work undertaken to verify the transform for use with HLG high dynamic range video in Appendix P of the W3C Timed Text Markup Language version 2 working draft specification which is likely to be used for subtitling in traditional and IP-based video services. Further they present test results investigating whether there is a perceived brightness variability for subtitles using the TTML conversions when displayed over different HDR video content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "High Dynamic Range",
                      "HLG",
                      "Hybrid Log-Gamma",
                      "Video",
                      "ITU-R BT.2100",
                      "Subtitles",
                      "Closed-captions",
                      "W3C TTML2",
                      "EBU-TT-D"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001777"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "An 8K full-resolution 60-Hz/120-Hz multi-format portable camera system",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomohiro Nakamura",
                    "Takahiro Yamasaki",
                    "Ryohei Funatsu",
                    "Hiroshi Shimamoto"
                  ],
                  "abstract": "NHK is accelerating the development of “full-featured” 8K (RGB 4:4:4, 12-bit, 120-Hz, high dynamic range and wide color gamut) broadcasting equipment. We have developed a 60-Hz/120-Hz multi-format portable single-chip 8K camera system using a 133-megapixel CMOS image sensor. The weight of the camera head is less than one-seventh that of conventional three-chip camera systems and the size of the camera control unit (CCU) is reduced to 3U. It can use both commercial 35 mm full-frame lenses and Super 35 mm lenses by using lens adapters. It employs a compact 100 Gbps optical transceiver to transmit signals between the camera head and the CCU. In the 60-Hz operation, all the lines of the sensor are read progressively and a full-resolution 8K image is captured. In the 120-Hz operation, the even and odd lines in an 8K video domain are read alternatively every 1/120 second by a 2:1 inter-line scan, and line interpolation with local motion detection is performed to configure the 8K image. The modulation transfer function in vertical direction without motion was 40% at 3200 TV lines, which was the same as that in the 60-Hz operation. The signal-to-noise ratio of the 120-Hz inter-line video was 58 dB, which can be improved to 1 dB at the area without motion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Full-resolution 8K",
                      "120-Hz Inter-line scan",
                      "Noise reduction",
                      "Ultra high definition (UHD)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001780"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "A User Study of Story Presence in an Immersive Narrative Experience tested with Variant Levels of Immersion",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anna Dining"
                  ],
                  "abstract": "Immersive narratives experienced in Head Mounted Displays (HMD's), whether involving real environments or computer generated, allow the participant to be visually immersed in the story. This study acknowledges three broad variables of immersion in narrative experiences: existence, experience, and environment. The narrowed focus of this user study is on employing perspective as a tool to test the effect of active and passive existence on the sensation of story presence. Two active permutations of a narrative story will be tested against a controlled passive experience using a subjective questionnaire to collect data and analyze the user's experience. The narrow treatment of the study is combined with a broad exploration and attempt to define the language for storytelling in immersive environments as compared to traditional cinema.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Virtual Reality",
                      "Immersive Media",
                      "Presence",
                      "Visual Immersion",
                      "Storytelling",
                      "Interactive"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001755"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Notice of Removal: Stream Privacy for ABR TV and OTT Services",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Prabhu Navali",
                    "Raj Nair"
                  ],
                  "abstract": "Removed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001763"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Notice of Removal: Applying an agile approach to next generation Media Management",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ben Davenport",
                    "Christian Siegert"
                  ],
                  "abstract": "Removed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001766"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Parameters Affecting the Performance of 12G Digital Patching Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dimitrios Antsos"
                  ],
                  "abstract": "The ongoing transition from 3G to single-link 12G digital patching systems in the broadcast, audio and video industry has introduced new challenges requiring higher performance components. To optimize signal performance from input to output through coaxial transmission systems, it is helpful for engineers and users to familiarize themselves with the concepts of frequency dispersion, group delay, impedance discontinuities and reflections, and to understand how these ultimately affect the error-free transmission of information, which is crucial to avoiding intrusions and artifacts in the received video and audio. As signals move through digital patching systems, patching system design engineers must also keep their eyes on how time domain parameters affect the performance of jacks and other high-speed components within the patching workflow. This paper will analyze how these parameters affect the performance of 12G patching systems, explore the various problems that can be anticipated, and how to proactively mitigate them, by understanding every step of the signal flow in relation to the various components of the system. This paper will also detail the use of eye pattern graphs to visualize how noise and reflections in the signal flow may result in decoding errors, ultimately impacting the received image quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "12G",
                      "4K",
                      "UHD",
                      "Digital Patching",
                      "Reflections",
                      "Group Delay",
                      "Frequency Dispersion",
                      "Power Spectral Density",
                      "Single-Mode Propagation",
                      "Eye Pattern",
                      "Bit Errors",
                      "Conductive Loss",
                      "Dielectric Loss"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001764"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "State of the Art Virtual Reality Streaming: Solutions for Reducing Bandwidth and Improving Video Quality",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thierry Fautier"
                  ],
                  "abstract": "VR 360 video applications typically require bandwidths of at least 15 Mb/s to 20 Mb/s while providing limited video quality. This is because users only observe a small part of the VR panorama at any time; about 12 to 15 percent. But, the full panorama needs to be provided to users on a continuous basis. — This paper summarizes the state-of-the-art in VR streaming, detailing how Tiled VR streaming technology can reduce bandwidth requirements by an order of magnitude while improving video quality. This is achieved by dividing a VR panorama into “tiles” and streaming only those tiles that users actually look at while wearing head-mounted displays (HMDs). This solution is based on HEVC tiling features as well as the DASH extension. — A major challenge for any viewport dependent VR streaming technology is motion-to-photon delay. Using a combination of selective tile transfer, a low-resolution base layer, smart packaging, and very low-latency protocols, Tiled VR streaming can offer extremely low motion-to-photon delay even when streaming from existing CDNs. This paper will conclude by showing the trade-offs between quality and bitrate when tiling from 4K or 8K sources to produce HD and UHD experiences respectively on HMDs, based on field trials and realistic use cases.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VR 360 video",
                      "Virtual Reality",
                      "Streaming",
                      "Viewport Dependent",
                      "Tile-based"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001760"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Proposed Measured Display Characterization File for HDR Consumer Displays",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tyler Pruitt"
                  ],
                  "abstract": "The advent of wide color gamut (WCG) and high dynamic range (HDR) imaging has upended long-established standards for display monitors and changed the very definition of display calibration. With the ITU-R BT.7091 standard, which in retrospect looks like a calm and pastoral monoculture, the nature of display calibration was straightforward: adjust the behavior of the video display until its output matched the standard as closely as possible. — The changes created by HDR can be seen most clearly by describing the way HDR color volume mapping works: An HDR TV's color volume-mapping algorithm looks at the metadata that shows how the content was mastered, compares that metadata to the definition of the HDR TV's capabilities, and applies some very intelligent mapping to make the HDR content appear as accurately as possible on the TV. — A new kind of calibration process is needed to provide color accuracy, while at the same time not affecting the intended behavior of the TV's Color Volume Remapping algorithm. No standard exists for the format or mechanism of this process. This paper proposes a standard for selfdescription in video displays that will allow mapping algorithms to best display a variety of HDR content on a variety of display devices with differing capabilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "HDR",
                      "Wide Color Gamut",
                      "WCG",
                      "Color Volume",
                      "Calibration"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001754"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "An Internet of Things Architecture for Cloud-fit Professional Media Workflow",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Cartwright"
                  ],
                  "abstract": "Flexibility, agility and scale are key benefits of moving media production infrastructure to the cloud and/or commodity data centre platforms, enabling content providers to respond to changing consumer habits. This includes new formats and new propositions, such as personalised immersive social television. Can a “lift and shift” approach - deploying existing production tools designed for enterprise computing environments into the cloud - deliver these benefits? — This paper presents an alternative architecture that is designed to be cloud-fit, using a software-only approach for deploying dynamic software infrastructure. The paper starts by outlining both the benefits and constraints of cloud-based systems, including issues related to virtualised systems being inherently non-real-time. An architecture that overcomes these limitations is then presented, along with an approach for dealing with security and scaling. This consists of a combination of mainly IT tool sets (e.g. monitoring tools, orchestration engines, cloud APIs, automated software deployment) with media-specialist software components. — A key aspect of the architecture is to use media transport mechanisms that can take advantage of the modern data centre platform in a secure and scalable way. The media and entertainment industry is now just one of many industry sectors that streams data through clusters of commodity computers. The paper outlines a big-data approach to stream-based processing designed to make use of today's multi-core architectures, something that the family of SMPTE ST 2110 standards is not well placed to do. — An instance of this architecture has been created using an open source IoT wiring tool. This is being trialed as part of BBC Northern Ireland's IP proof-of-concept activity, working jointly with Streampunk Media and Cinegy through AMWA Labs. The lab environment has enabled the testing and measurement of aspects of this approach, including gesture-based control (e.g. via smartphone/tablet), HTTPS media transport, fast networking with consumer devices and virtual infrastructure replacing traditional hardware solutions - including a virtual video mixer. Results from the lab will be presented, along with a description and pointer to the open source tools used to produce the results, further analysis and next steps.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Internet of Things",
                      "media workflow",
                      "IP",
                      "cloud",
                      "virtual"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001769"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Programmable Data Plane for Professional Media Networking",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Edwards",
                    "Nick Ciarleglio"
                  ],
                  "abstract": "Programmable data plane pipelines are now available in line rate packet processors implemented in commercially-available Ethernet switches. This development can provide useful functionality for professional media IP networks. Programmable data plane technology enables a more flexible method of controlling packet processing than previous fixed-function software defined networking (SDN) methodologies. The packet processor parser can be programmed to extract any header desired, and match+action tables based on those headers can be more complex than in nonprogrammable switching solutions. An application of this technology is the ability for an Ethernet switch to parse the RTP timestamp field for frame-accurate video switching of SMPTE ST 2110-20 video flows. Another application is enabling fair multi-link transport of RTP “elephant” flows. And a further application is to extract ST 2110-20 video header fields and make switching decisions based on sample row number fields for video compositing. This paper provides descriptions of these applications in the P4 data plane programming language, and discusses implementations of some of these applications on actual network processors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "PMN",
                      "IP",
                      "2110",
                      "SDN",
                      "P4",
                      "programmable data plane",
                      "RTP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001765"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "IMF End-to-End Workflows in Media Asset Management Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Julian Fernandez-Campon"
                  ],
                  "abstract": "IMF is becoming a reality for content distribution due to the benefits of cost reduction and straightforward processing: the generation of IMF Packages for masters, localized versions and editorial versions to manage and optimize the media exchanged. But adopting IMF in Media Asset Management systems to implement truly end-to-end workflows has several implications that must be handled to efficiently map the incoming IMF packages into a logical structure representing the title as interconnected objects without media replication while making it ready for delivery. It's important to understand that MAM systems need to be able to deliver IMF packages that were never received, i.e. a new combination of languages (audio/subs), new editorial versions, etc., so the challenge is not only to ingest the IMF packages as they arrive but also to be able to generate new ones according to the SMPTE specifications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IMF",
                      "IMP",
                      "CPL",
                      "Media Workflows",
                      "Content Preparation",
                      "Content Delivery"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001767"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Cloud Transition Patterns for Media Enterprises",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shailendra Mathur",
                    "Gerald Tiu"
                  ],
                  "abstract": "Media enterprises are increasingly looking at how the cloud can be harnessed to support operational and business agility. With these transformations they are evaluating the implications to their business models, workflows and technology for content production. Multiple hosting choices are available to move equipment investment from machine rooms to centralized data centers and cloud environments. In moving the process running on bare metal in the machine to shared resource infrastructure in data centers or cloud, multiple choices of virtualization technologies are also present. On one hand, fast transformations are to be achieved by lifting and shifting known applications and appliances using virtual machines. On the other hand, use of containerized microservices and cloud native architectures offer promise of agility and cost efficiency. The usefulness of each option will be presented by understanding current media production infrastructure needs and its mapping to virtualization as hosting technologies become available. The post production industry's deployment preferences leads to a notion of a common software platform to host media processes across the various cloud infrastructure choices available. In hybrid deployment models, the message bus based communication framework provides tremendous value and flexibility in order to ease the technology transformations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud native",
                      "microservices",
                      "lift and shift",
                      "containers",
                      "VMs",
                      "Platform",
                      "Message Bus",
                      "Azure",
                      "MediaCentral",
                      "Avid",
                      "Microsoft"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001770"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Leveraging Hybrid Cloud Workflows in Media and Entertainment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joan M. Wrabetz"
                  ],
                  "abstract": "Production, broadcast and distribution companies are increasingly collecting high-resolution content from every stage of the workflow. Studios are struggling to find efficient infrastructure solutions to create and maintain comprehensive digital libraries that will support a global organization. By leveraging hybrid cloud storage and processing resources to make the workflow more efficient, media and entertainment companies can leverage the C4 standard and object storage solutions to create a video platform with indelible metadata. This paper talks about use cases of how media and entertainment companies are using the cloud and on-premise object storage to cost-effectively store all captured footage and accelerate its production workflow. It explores infrastructure technologies that are effectively being used to improve productivity and lower total cost of ownership for 2K, 4K, 6K, HFR and UHD workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "ActiveScale",
                      "Object Storage",
                      "Media Archive",
                      "Media Repository",
                      "Long-Term Storage",
                      "Storage Economics",
                      "Optimizing Storage",
                      "Storage Efficiency",
                      "C4 standard"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001768"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "8K-TICO Codec for Miniaturized and Simplified UHDTV Production Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Masayuki Miyazaki",
                    "Tsuyoshi Sakiyama",
                    "Takayuki Yamashita",
                    "Michael Van Dorpe"
                  ],
                  "abstract": "We developed a TICO (SMPTE RDD35:2016) codec for 8K ultrahigh-definition TV (8K-UHDTV). The bitrate of an 8K uncompressed stream can reach 48 Gb/s (59.94 Hz, 10 bits, 4:2:2), and interfaces consisting of 16 bundled 3G-SDI cables have been used for its transmission. However, increasing the cable count can sometimes complicate the wiring-up of production systems. The novel developed codec works at a compression rate of 1/4, and the resulting 8K code stream can be transmitted with a single 12G-SDI cable. Not only is TICO well known for its visually lossless video quality and very low latency, but is also characterized by a quality degradation that is almost independent of the number of successive encoding/decoding operations, which makes it suitable for production systems. The benefits of decreasing the cable count are exponential. We estimate that, when compared to systems of a comparable scale based on uncompressed 3G-SDIs, the use of the proposed codec will reduce the cable count to less than 1/5, and the number of cross-points in the matrix switcher to less than 1/200. Although in this study 12G-SDIs—which have become internationally available—have been adopted, 8K-TICO is fit to be used with IP interfaces, an option that may become mainstream when the problems of interoperability between different formats are overcome, or when unified standards emerge. In this paper, we will discuss the specifications and image quality of the developed codec, and present a plan for 8K-UHDTV production systems. We will also discuss the expected emergence of an adequate IP interface, a technology which has the potential to become mainstream in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "8K",
                      "Mezzanine compression",
                      "TICO",
                      "12G-SDI",
                      "SDI/IP infrastructure"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001785"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Notice of Removal: JPEG-XS - A high quality mezzanine image codec for video over IP",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Richter",
                    "Siegfried Foessel",
                    "Joachim Keinert",
                    "Antonin Descampe",
                    "Gael Rouvroy",
                    "Jean-Baptiste Lorent"
                  ],
                  "abstract": "Removed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001786"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Next-Generation Video Compression Techniques",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thierry Fautier"
                  ],
                  "abstract": "MPEG is working on requirements for a new video codec, expected to be completed by 2020. The future-generation codec is anticipated to provide a 50 percent bitrate reduction compared with HEVC Main profile for the same perceptual quality. While this is sufficient for certain use cases, it may justify a future video coding standard for other use cases that require bitrate reductions higher than 50 percent. This paper will look at the target applications for the new video codec that include 8K, VR in 3DoF and 6DoF, the state of IP networks. This paper will present how new techniques can be used to reach a factor four compression efficiency vs. HEVC by 2020 using the next-generation MPEG codec. This is possible by leveraging new techniques such as content-aware encoding, elastic encoding, machine learning techniques, and pre- and post-processing pairing that uses metadata to signal how to post process video after decoding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Codec",
                      "HEVC",
                      "MPEG",
                      "AV-1",
                      "VP-9",
                      "JVET",
                      "Bitrate",
                      "Video Compression"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001787"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Projector Contrast Performance in a Cinema Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Martin Richards",
                    "Barret Lippey",
                    "Peter van Kessel",
                    "Dave Schnuelle"
                  ],
                  "abstract": "A new breed of premium cinema formats has emerged recently called Premium Large Format, or PLF, to enhance the consumer cinema experience. Dolby Laboratories' PLF, called Dolby Cinema® features projectors with dramatically improved dynamic range. In this paper we explore the impact of room and optics-related factors and assess how these impact the perceived contrast ratio of the images produced by the projector.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cinema Contrast",
                      "Projector Contrast",
                      "Theatre Contrast",
                      "Theatre Ambient Light",
                      "Theater Contrast",
                      "Theater Ambient Light"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001788"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "VR Theater, a Virtual Reality based Multi-Screen Movie Theater Simulator for Verifying Multi-Screen Content and Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kyunghan Lee",
                    "Gaetan Guerrero",
                    "Seunghoon Cha",
                    "Younghui Kim",
                    "Sungmin Cho"
                  ],
                  "abstract": "The needs for a more immersive viewing experience in modern cinemas have given birth to novel movie theater technologies such as Barco's Escape and CJ-CGV's ScreenX; which utilize the side walls of a movie theater to project peripheral content to auxiliary the main content projected in the center screen. However, because theaters that support such application are each different in structure, producers need to modify the content for each theater which is a cumbersome task. In addition, the recent advances in Virtual Reality technology allows users to create unexplored solutions in the area of games, industry and simulation of spaces. VR based theater simulators are already in the market but restrict users from modifying certain aspects of the cinema and are limited to ordinary theaters. This paper introduces VR Theater, a VR based multi-screen movie theater simulator that enables researchers and multi-screen producers to provide a testing platform for multi-screen content and environment with arbitrary settings. VR theater can simulate any movie theater with different structures in the world as long as the correct dimensions of the cinema are provided, play custom main content and wing content for the side walls, select the view of a certain seat in a movie theater, mask out certain areas of the wing content to prevent projection light from entering moviegoers eyes and correct the size of the content being projected in the simulated VR movie theater. In addition, auxiliary functions that allow rearrangement of seat positions, lighting, wing projector position and side wall texture material editing is provided. We predict that multi-screen producers and researchers will be able to make use of this application when producing and researching for multi-screen content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Virtual Reality",
                      "Multi-Screen Movie Theater",
                      "Simulation",
                      "Verification",
                      "Multi-Screen Environment"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001790"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Why Diversity Programs Fail – And How to Fix Them",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kylee Pena",
                    "Katie Hinsen",
                    "Meaghan Wilbur"
                  ],
                  "abstract": "In recent years there has been a rise in diversity initiatives throughout the entertainment and STEM industries in response to mounting criticism. While college programs have been found to represent the general population well in terms of diversity, that drops off sharply after graduation, and our industry becomes largely homogenous in top-tier positions. Many initiatives are struggling to make a meaningful impact, especially when it comes to changing the face of our industry's above-the-line professionals. This is because from entry-level through the development of top talent, the established system favors a narrow range of individuals who have fewer barriers to opportunity. — This established system can easily be changed without major disruption. Having studied the efforts and impact of current programs, it is apparent that many tend to approach the issue backwards, addressing barriers from top down instead of from the bottom up. Through case studies and the application of research and theory, we will present analysis of current trends in diversity programs such as those offered by networks and studios for minority writers and directors. We'll offer practical adjustments, considerations and solutions to significantly improve the effectiveness of investments in diversity by companies and organizations across the film and television industry. — Those reading the paper or attending the session will have tangible, actionable takeaways they can implement within their organization right away. Rather than scold, this session is meant to educate and lead decision makers and influencers toward more effective uses of time and money spent on diversity, shifting the goal toward inclusiveness.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Diversity",
                      "Women",
                      "People of color",
                      "Inclusiveness",
                      "Diversity programs"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001773"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Begin with the End in Mind: A Unified End-to-End Quality-of-Experience Monitoring, Optimization and Management Framework",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Zhou Wang",
                    "Abdul Rehman"
                  ],
                  "abstract": "There has been an increasing consensus in the video distribution industry that the design and operation of the full video delivery chain needs to be driven by the quality-of-experience (QoE) appropriate to the end-user. In practice, however, this is an extremely difficult task, largely due to the lack of effective mechanisms to instantaneously measure or predict every viewer's QoE. Moreover, existing quality assurance methods operate independently at different points along the delivery chain, reporting partial, inopportune, and incoherent measurements. This siloed structure leads to a fragmented understanding of the resulting video as it moves through each stage of the delivery network - from the acquisition point and head-end down to the media data center, the network, and eventually the end-user's viewing devices. — Here we propose a new framework that uses a unified end-to-end solution to produce consistent QoE scores at all points along the delivery chain under the same evaluation criterion. This is a framework that produces a clear picture instantaneously to operation engineers, managing executives and content creators about how video QoE degrades along the chain, a framework that allows immediate issue identification, localization and resolution, a framework that enables quality and resource usage optimization of the delivery chain for each of its individual components or as a whole, and a framework that provides reliable predictive metrics for long-term strategic resource and infrastructure allocations. — The main challenge in the implementation of such a framework is to create a unified QoE metric or process by which to measure QoE that not only accurately predicts human QoE, but is also light-weight and versatile, readily plugged into multiple points in the video delivery chain as either a single-ended or double-ended measure, producing real-time QoE scores across a wide range of bitrates, video resolutions, frame rates and dynamic ranges, and combining presentation picture quality with video freezing and adaptive streaming events. We show that the SSIMPLUS metric offers the best promise to such a solution. Once such a framework and the QoE metric is deployed in a video distribution system, many benefits come naturally. We demonstrate the benefit using bandwidth optimization as an example.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Quality-of-experience",
                      "video distribution system",
                      "video quality assessment",
                      "video streaming",
                      "end-to-end quality assessment",
                      "video encoding",
                      "video transcoding",
                      "adaptive streaming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001774"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Beyond 4K: Can We Actually Tell Stories In Motion Pictures And Television In 8K?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre H Routhier"
                  ],
                  "abstract": "Even though the full-scale implementation of 4K (Ultra HD) is not yet achieved, demos showcasing 8K (Super Hi-Vision) are already introduced at major industry conferences and trade shows. While it is part of the strategic plan of some public and private parties, and already standardized (Rec. ITU-R BT.2020, SMPTE ST 2036-1, ARIB STD-B56) the question of the value of 8K (or, more precisely, 7680p) as a storytelling tool deserves further consideration. — In this paper, we analyze the relative worth of achieving such a resolution through the lens (pardon the pun) of the cinematic language, as it has been defined over the last 120 years. From a technical perspective, the resolving capacity of the human eye, proxemics (the science of interpersonal distances) and dynamic resolution (motion) are applied to cinematic conventions to determine whether this increase in spatial resolution yields an improvement in viewer experience. — The paper demonstrates that there are very few cinematic shots that actually benefit from 8K. In most cases, framing conventions would need to be drastically widened, and motion reduced to almost nothing, defeating the purpose of motion pictures. — In the opinion of the writer, progress in sensor technology, bandwidth and compression would be more effectively leveraged in the delivery of “better” pixels, instead of “more” pixels. The author describes several avenues that could be explored using this philosophy, namely the use of ultra high frame rates (240Hz), lesser compression, higher dynamic range and more immersive media.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ultra HD",
                      "UHD",
                      "Super Hi-Vision",
                      "4K",
                      "8K",
                      "Cinematography",
                      "Motion",
                      "High Dynamic Range",
                      "HDR",
                      "High Frame Rate",
                      "HFR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001778"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Choosing Encoding Parameters for High-Dynamic Range Streaming",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sean T. McCarthy"
                  ],
                  "abstract": "This paper provides data and analysis on the impact of various High-Dynamic Range (HDR) encoding options on video quality and bitrate. Specifically, this paper examines permutations of PQ, HLG, Y′CBCR, ICTCP, encoded resolution, and bitrate using the open-source encoder x265. Video quality for each permutation is measured using publicly-available non-proprietary objective video quality metrics. Background: Today, we have two different ways of mapping light to HDR code values: Perceptual Quantizer (PQ) and Hybrid-Log Gamma (HLG). We also have the option of representing color and luminance as either Y′CBCR or the newer alternative ICTCP. For HDR adaptive bitrate streaming, we need to choose which compression levels and encoding resolutions to use when we create adaptation sets; but we don't yet have a complete understanding of how resolution and compression could interact to alter the highlights and deep darks that make HDR so visually potent. When viewed altogether, the many permutations of HDR encoding can make designing an HDR streaming service complicated and uncertain. This paper provides practical data and analysis that can be used to make designing HDR streaming services easier and more predictable.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "HEVC",
                      "x265",
                      "PQ. HLG",
                      "Y′CBCR",
                      "ICTCP",
                      "streaming",
                      "video quality"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001781"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Notice of Removal: Towards Scalable Automated Analysis of Digital Video Assets for Content Quality Control Applications",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Subhabrata Bhattacharya",
                    "Adithya Prakash",
                    "Rohit Puri"
                  ],
                  "abstract": "Removed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001775"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "QBR Metadata To Improve Streaming Efficiency and Quality",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Cooper",
                    "Sue Farrell",
                    "Kumar Subramanian"
                  ],
                  "abstract": "QBR improves the efficiency of adaptive bitrate video delivery by providing additional metadata describing the visual complexity and encoding quality of each media segment at each data rate. This enables a compatible player to make better adaptation decisions about when to switch between different data rate renditions. In addition to factors such as the state of the local buffer and previous data transfer rates, the heuristics employed can now include information about the relative visual complexity and encoding fidelity of future segments at different data rates. The media player can use this to plan and optimise media requests. Segments with simple scenes that do not benefit from encoding at higher data rates can be replaced with encodings at a lower data rate. — The result is a typical reduction in the volume of data delivered by 30% or more without reducing perceived quality. This efficiency gain can optionally be used to deliver higher data rate segments for more complex scenes, increasing perceived quality where it matters most, while still reducing delivery costs. Effectively, this brings the benefits of variable bitrate encoding to the multi-bitrate schemes that are widely used for adaptive bitrate streaming. — The key to this approach is the provision of information to characterise each video segment at each encoded data rate. This metadata can be produced by video encoders or be extracted from rapid analysis of encoded segments. Formalising the semantics and syntax of this metadata allows interoperability across the ecosystem. — The system is backwards compatible with existing compression schemes, including H.264/AVC and H.265/HEVC, and current HLS, HDS, Smooth Streaming and MPEG-DASH formats. Integrations are already available with popular encoders and players to provide plug-and-play compatibility, enabling service providers and media distributors to benefit from QBR. — This paper presents the benefits of the approach, provides examples of the results that can be achieved, and discusses the opportunities for standardisation of the metadata, while enabling differentiation in implementation for its generation and use.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "QBR",
                      "ABR",
                      "streaming",
                      "metadata"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001784"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Non-iterative Content-Adaptive Distributed Encoding Through ML Techniques",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sriram Sethuraman",
                    "Nithya V. S.",
                    "Venkata Narayanababu Laveti D"
                  ],
                  "abstract": "Distributed encoding is desired in content preparation workflows in the cloud to reduce turnaround times. Content-adaptive bit allocation at title, chunk, and even frame level, as opposed to using a fixed ladder of content-independent bit-rates and resolutions, have been proposed to achieve efficiencies in storage and delivery. Many of these methods tend to be iterative in nature and consume significant additional compute resources over 2-pass Variable bit-rate (VBR) encoders. With live use-cases attempting to use a set of distributed encoders to achieve higher bit-rate savings (both through use of higher compression presets and through content-adaptive bit allocation) and consistent quality, there is a need to limit the increase in computational complexity. In this paper, we propose a non-iterative codec-agnostic approach that employs machine learning techniques to perform consistent quality content-adaptive encoding within the constraints of a maximum bit-rate in a manner that makes it equally suitable for live and on-demand workflows. The method has the ability to take a target subjective rating level and allocate appropriate bits for each group of frames to achieve that. The proposed approach also anticipates automatic selection of the right resolution and frame-rate for a given representation within an ABR set, and content-specific encoding parameters to maximize the bit savings and/or visual quality. Test results are presented over a wide range of content types comparing the performance of the proposed approach against 2-pass VBR methods. Initial results indicate that the proposed approach can recover ~85% of the bit-savings possible with exhaustive techniques. The computational complexity of the proposed approach is only 15-20% of 2-pass VBR encoding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Distributed encoding",
                      "content-adaptive bit-rate/resolution ladder for adaptive bit-rate (ABR) streaming",
                      "HLS",
                      "DASH",
                      "machine learning (ML)",
                      "consistent quality encoding",
                      "non-iterative",
                      "live and on-demand over-the-top (OTT) streaming",
                      "content storage/delivery efficiency"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001783"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Moving to the Cloud: Current Risks & Rewards: An analysis of the state of the art for cloud-based production pipelines",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Julie M. McDonald",
                    "Corban Gossett"
                  ],
                  "abstract": "Cloud based production pipelines are quickly becoming a new reality. Pressure on production pipeline efficiency, distributed geographic dispersion of labor, production turn around speed requirements, open source tool availability and iteration are pushing creative firms in the media production market to explore, and adopt cloud based pipelines. Are the benefits of this new wave of creative and technical democratization fact or myth? What is the state of the art in 2017? What are the primary technical and operational challenges? What are the primary benefits? How does the CTO, CFO, business manager, product manager, producer and production manager navigate this complex new environment? What are the current operational and business upsides? Where are the hidden risks? This application/implementation case study examines live action and animation media production environments currently taking place in the “cloud”, summarizes the current state of the art and provides a road map for individuals and businesses considering moving to the cloud. Workflow challenges, infrastructure pricing, remote personnel management, creative control, internet security, licensing, metered rendering are discussed. Cost expectations are reviewed – with examples of areas for savings and area where costs increase. Cloud based pipelines are coming, how do we prepare?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "cloud",
                      "cloud based rendering",
                      "streaming media production",
                      "remote collaboration in the cloud",
                      "cloud based pipelines",
                      "animation in the cloud",
                      "post-production in the cloud",
                      "metered streaming applications",
                      "platform as a service",
                      "metered rendering"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001771"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Content Production Technology on Hybrid Log-Gamma",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yuji Nagata",
                    "Kenichiro Ichikawa",
                    "Takayuki Yamashita",
                    "Seiji Mitsuhashi",
                    "Hiroyasu Masuda"
                  ],
                  "abstract": "NHK produces a variety of contents for 8K test satellite broadcasting. Recommendation ITU-R BT.2100 was standardized only during last year and we are currently in the process of testing and verifying the hybrid log-gamma (HLG) productions accordingly. For 4K-8K satellite broadcastings, which will be launched in 2018, we plan to extend the broadcasting time for longer than that of the test broadcasting. Therefore, producing considerably more contents is necessary. Currently, our main broadcasting service is HDTV; hence, it is important to produce the 8K, 4K and HD contents effectively. To decrease the burden of content production, we developed two signal converters and plan to use them for the content production including not only conversion of the signal formats but also simultaneous production of UHDTV and HDTV. One signal converter processes the signal conversion between two high dynamic range (HDR) transfer functions–HLG and Perceptual Quantization (PQ)–by means of Recommendation ITU-R BT.2100. In addition, we installed a semiautomatic conversion system between HDR and standard dynamic range (SDR) to adjust a few video parameters; gain, black offset, and compression level of high luminance. It allows video engineers to compare HDR with SDR, which is converted from HDR side by side at the simultaneous production. The down-converter from UHDTV to HDTV, however, supports conversion of color gamut and dynamic range simultaneously. To reduce the deterioration of the color gradation in the conversion from Rec. 2020 to Rec. 709, we used a method based on the color perceptual model. In addition, it features a function that enhances the edge of the images based on specific spatial frequency after the down-conversion. In this paper, we describe the use cases of HLG content production using the converters and evaluate their effectiveness. Moreover, we show the high quality content production using the specific parameters for simultaneous production of UHDTV and HDTV contents.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "8K",
                      "HDR",
                      "HLG(Hybrid Log Gamma)",
                      "SDR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001782"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Implementation of Closed Captioning System for Terrestrial UHD based on ATSC 3.0",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yunhyoung Kim"
                  ],
                  "abstract": "In South Korea, the terrestrial UHD broadcasting based on the ATSC 3.0 standard is aired officially from the end of May 2017. To provide closed captions for the UHD programs, we developed the ATSC 3.0 closed captioning system. The closed captions in the ATSC 3.0 standard are based on IMSC1 (Internet Media Subtitles and Captions 1.0) which is mainly used in the online video streaming industry, while the captions in the previous ATSC 1.0 standard are based on CEA-708 (Consumer Electronics Association 708). The UHD programs broadcasted on the Korean UHD TV networks are the ones simulcasted on the HD TV networks, that is, the HD programs and the UHD programs are the same except the video quality. Accordingly, we reuse the captions for the HD programs produced by the live stenography for the UHD programs since the contents of the captions for the HD and UHD programs are the same. We implemented the closed captioning system, both for the MMT (MPEG Media Transport) and the ROUTE (Real-time Object Delivery over Unidirectional Transport), which are transport protocols in the ATSC 3.0 standard, and verified it by testing on commercial ATSC 3.0 UHD TV receivers. This is the world's first development of the IMSC1 closed captioning system on the terrestrial TV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHD Closed Caption",
                      "UHD Closed Captioning System",
                      "IMSC1",
                      "TTML"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001779"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "Assessing Psychophysics Functions for Frame Rate Perception",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Elizabeth DoVale",
                    "David Long"
                  ],
                  "abstract": "In past research at Rochester Institute of Technology (RIT), a temporal texture space was defined. It was used to classify what attributes contribute to the perceived motion quality of stroboscopic reproductions. One of these attributes was determined to be the content's captured and displayed frame rate. Using knowledge from this and other past frame rate research and psychophysics, a comprehensive experiment was set up to see if a just noticeable difference (JND) could be found for changes in frame rate. Thresholds were tested starting with base conditions of 24 FPS, 48 FPS, and 72 FPS due to their significance to the motion picture industry. After a verification pilot study, 77 observers in total participated in the experiment. The collected data points to a resulting JND threshold between 26 FPS and 28 FPS for the 24FPS test point, but a significantly noisier signal was determined for both the 48FPS and 72 FPS test points. Explanation for this nosier signal could be a lack of consistent detectability in human perception at these higher frame rates. This experiment is presented as one in a series of studies into stroboscopic motion perception at RIT.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HFR",
                      "High Frame Rate",
                      "Frame Rate",
                      "FPS",
                      "JND",
                      "Perception",
                      "Motion Quality"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001801"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "Hitting the Mark - A New Color Difference Metric for HDR and WCG Imagery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Elizabeth Pieri",
                    "Jaclyn Pytlarz"
                  ],
                  "abstract": "With the emerging demand for high-dynamic-range (HDR) and wide-color-gamut (WCG) technologies, display and projector manufacturers are racing to extend their color primaries in the cinema and in the home. With these brighter and wider colors, the question is: in calibration, how close is close enough? This answer is increasingly important for both the consumer and professional display/projector market as they balance design trade-offs. With HDR/WCG technology, an increasing issue is that many of the color difference metrics in common use today, such as ΔE00, substantially deviate from human perception and become unreliable for measuring color differences. This causes under and over prediction of color differences and can to lead to sub-optimal design decisions and difficulties during calibration. There is a large amount of perceptual color difference data in the field today, however the majority was collected using reflective surfaces and very little reaches the boundaries of modern display capabilities. To provide a better tool for facilitating design choices, this paper will present a “ground truth” visible color difference dataset. These visual experiments were conducted between luminance levels of 0.1 and 1000 cd/m2 on high dynamic range laser cinema projectors with approximate BT.2100 color primaries. We will present our findings, compare against current metrics, and propose specifying color tolerances using the ΔICTCP metric for HDR and WCG imagery.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "WCG",
                      "measurement",
                      "vision perception",
                      "calibration",
                      "Delta E2000",
                      "Delta ICTCP",
                      "laser",
                      "projection"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001802"
                  }
                }
              },
              {
                "article_local_id": "52",
                "article_title": "Is seeing still believing: a critical review of the factors that allow humans and machines to discriminate between real and generated images in the context of News & Factual content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/52/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Martyn Gates"
                  ],
                  "abstract": "The growing photorealistic capabilities of 3-D Animation and CGI poses potential issues for Broadcasters, Regulators, Governments and viewers. What happens if a news story is broadcast, or available on a website, which is CGI or a combination of CGI and camera-acquired images? Can we rely our human visual perception to be able to discriminate between CGI and “real’ moving images? There are already instances of video where there is polarized debate as to the degree of CGI present in published content, a prime example being the ISIS video of the burning of a person. An analysis of the artefacts seen in the video that gave rise to the truthfulness debate are presented. The factors that humans use to discriminate, or to evaluate the realness of photographs includes shadow softness, surface smoothness, scene complexity and composition, and number of light sources. Initial studies showed a human ability to discriminate, however, recent studies have shown that the ability to discriminate is getting more difficult, although with training the ability improves. Computer Vision research has evaluated image features and descriptors that discriminate between photographs and CGI. No such studies with quantitative data or experimental methodologies seem to exist for evaluating the CGI moving image by humans or computers. Possible temporal assessment factors for human discrimination (motion parameters) for computer vision (optical flow), and for artificial intelligence (semantic scene analysis) are presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "faked news",
                      "human visual perception",
                      "computer vision",
                      "cgi",
                      "photorealism",
                      "isis",
                      "compression artefacts",
                      "cgi artefacts",
                      "optical flow",
                      "semantic scene analysis",
                      "artificial intelligence"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001803"
                  }
                }
              },
              {
                "article_local_id": "53",
                "article_title": "Closed Captioning and Subtitling for Social Media",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/53/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Giovanni Galvez"
                  ],
                  "abstract": "Unlike closed captions and subtitling for TV Broadcast, social media platforms offer very limited support for TV producers who are looking to publish promotional content on social media. Often, critical formatting such as positioning on the screen and splitting captions are not possible with popular social media platforms. In addition, many content producers are burning-in their subtitles to get more attention on Social Media feeds. In some cases, a social media platform may not support captions of any kind when streaming live feeds or uploading pre-recorded promotional videos. This becomes a challenge to broadcasters who want to repurpose TV closed caption data to social media. While captions and memes seem to be all the rage in viral social media posts, content producers are publishing promotional videos with captions to stay competitive. The captions and subtitles are becoming important to all mobile users. The average user does not use audio when using social media on the go. Therefore captioning and subtitling is an essential part of publishing to social media. — Publishing captioned and subtitled content to social media doesn't have to be a difficult manual task. There are many ways to automate this process along with transcoding and delivery of video with captions or subtitles. Today broadcasters can leverage speech to text tools, caption authoring, and transcoding mechanisms that support publishing video with captions to social media. This paper takes a look at the challenges and formats associated with publishing captioned and subtitled content in Social Media. We will discuss the various caption files that are currently supported by the popular social media platforms. Also, we will examine the pros and cons to doing burn-in subtitles. As some broadcasters are obligated to publish content with captions due to strict government regulations, social media platforms may need to change their caption deliverables to support proper accessibility standards. Finally, we can look at various pitfalls of captioning that could cost broadcasters time and money when publishing to social media.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "closed captioning",
                      "subtitling",
                      "social media",
                      "automation",
                      "speech to text",
                      "publishing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001804"
                  }
                }
              },
              {
                "article_local_id": "54",
                "article_title": "Out of Band SCTE 35",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/54/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roger Franklin",
                    "Alan Young"
                  ],
                  "abstract": "SCTE 35 - “Digital Program Insertion Cueing Message for Cable” - is now routinely used to identify the location and composition of programming content and advertising breaks in linear television for OTT providers. SCTE 35 specifies metadata that can be inserted into the MPEG-2 Transport Stream carrying the compressed content. SCTE 35 contains the precise frame of the beginning and end of video segments, content identifiers and rights-related information. However, the real-world implementation of SCTE 35 by content providers is inconsistent despite SCTE 67 - “Recommended Practice for SCTE 35 Digital Program Insertion Cueing Message for Cable”. Worse, the ever-increasing complexity of distribution and transcoding for delivery to multiple devices has taken its toll on SCTE 35. It rarely survives delivery to the OTT provider without being corrupted. This is obviously a problem for both the OTT providers and the content providers not only because it limits their ability to monetize the content but also because it makes it much harder to effectively automate the implementation of the complex rights associated with online content in an auditable manner. This technical paper will describe a method of delivering SCTE 35 out of band using temporal fingerprints to re-synchronize the SCTE metadata with the video at each receive point. This not only solves the core problem but provides many side benefits including automatic lip sync error correction, enabling broadcast adverts to become ‘clickable’ and enabling graphics to become customizable and user selectable.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SCTE 35",
                      "SCTE 67",
                      "SCTE 104",
                      "Lip Sync",
                      "SCTE 224",
                      "Ad Insertion Signaling",
                      "OTT Content Replacement/Blackouts"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001805"
                  }
                }
              },
              {
                "article_local_id": "55",
                "article_title": "Automatic, Fast and Perceptually Accurate Gamut Mapping Based on Vision Science Models",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/55/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Syed Waqas Zamir",
                    "Javier Vazquez-Corral",
                    "Marcelo Bertalmio"
                  ],
                  "abstract": "Gamut mapping transforms colors of the original (image or video) content to the color palette of the display device with the simultaneous goals of (a) reproducing content accurately while preserving the artistic intent of the original content's creator and (b) exploiting the full color rendering potential of the target display device. The rapid advancement in display technologies has created a pressing need to develop automatic and fast gamut mapping algorithms that can deal with imagery intended for both conventional and emerging displays. In this paper, we propose a novel framework based on retinal and color perception models from vision science that offers a functionality to perform both gamut reduction and gamut extension, while preserving hue and taking into account the analysis of the colors of the input image. We evaluate the performance of the proposed framework visually and by using a perceptually-based error metric, according to which the gamut-mapped results of our framework outperform those of the state-of-the-art methods.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Gamut mapping",
                      "wide color gamut",
                      "color reproduction",
                      "gamut mapping algorithms"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001806"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Variable Frame Rate Display for Cinematic Presentations",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Ryan"
                  ],
                  "abstract": "While motion pictures have traditionally been captured and presented at a frame rate of 24 frames per second, recent advancements have enabled the capture and presentation at higher frame rates of 48, 60, and even 120 frames per second. Capture and presentation at higher frame rates provide improvements in clarity and motion rendition, but come at the cost of increased storage space, processing, and workload for the entire motion picture. Motion picture creators want the capability to reduce the motion judder, and blur associated with capturing moving images while still maintaining the cinematic feel of their creations. By introducing a method where the projector can vary the frame rate during playback, the scenes that most benefit from higher frame rates can be captured and presented at that rate, while the scenes that do not benefit from higher frame rates can be captured and presented at lower frame rates. The engineers working with DLP Cinema at Texas Instruments have come up with a method to allow changes to the displayed frame rate to be communicated effectively through the entire playback chain during a presentation with no visible artifacts on screen before, during, or after the transition. This Variable Frame Rate (VFR) capability enabled by the latest DLP Cinema systems is further described in this paper.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "DLP",
                      "DLP Cinema",
                      "Digital Cinema",
                      "D Cinema",
                      "Variable Frame Rate",
                      "VFR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001789"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Automating Digital Asset Production with SCTE Messages",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Duval",
                    "Eric Openshaw"
                  ],
                  "abstract": "The rich syntax of SCTE 104 and SCTE 35 is the basis for precise and robust automation workflows for the repurposing of broadcast content for VOD, OTT and social media distribution. Unlike automation and master control systems that manage single channel playout, embedded commands in the video stream can provide the context and timing to create multiple live and on-demand derivatives and new viewing experiences from a single video source.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SCTE",
                      "SCTE-104",
                      "SCTE-35",
                      "VOD",
                      "OTT",
                      "Digital Asset Production",
                      "Automation",
                      "Automated Production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001791"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "Real-Time Measurement of Ultra-High Definition Camera Modulation Transfer Function",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenichiro Masaoka",
                    "Kazuyuki Arai",
                    "Kosuke Nomura",
                    "Tomohiro Nakamura",
                    "Yoshiro Takiguchi"
                  ],
                  "abstract": "The authors are solely responsible for the content of this technical presentation. The technical presentation does not necessarily reflect the Abstract. This paper presents a system capable of measuring the modulation transfer function (MTF) of a broadcast camera based on its knife-edge responses in real time. This method can be applied to multiple edges in arbitrary directions, unlike the conventional slanted-edge method in the ISO 12233 standard in which only a near-horizontal or vertical edge in a rectangular region of interest (ROI) can be analyzed. The new measurement system significantly facilitates the evaluation of the performances of the camera and lens as well as accurate focusing in an objective manner. Analysis of multidirectional edges on a starburst chart yields a contour plot of the multidirectional MTF for direct observation of the anisotropy due to not only the misalignment of the optical axis of the imaging system but also the pixel arrangement of the image sensor and image processing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Multidirectional MTF",
                      "real-time measurement",
                      "knife-edge response"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001795"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Notice of Removal: IMPlementation: IMF in Practice",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Reynolds",
                    "Eric King"
                  ],
                  "abstract": "Removed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001792"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "Building a Cognitive Data Management Strategy (And Why Doing So is Suddenly So Important)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Floyd Christofferson"
                  ],
                  "abstract": "Data management is the core task of IT, yet it has been sadly undervalued and largely ignored for the past thirty years. Data management problems are often approached from a storage perspective, which leads to vendor lock-in, management complexity, and difficulty incorporating emerging technologies in a heterogeneous environment. — However, the unprecedented growth of data – in the 10-60 zettabyte range by 2020 – has larger firms and public cloud services, who are concerned about how they will store all the data cost-effectively, suddenly very interested in developing a data management strategy that combines the latest technologies into a serviceable cognitive data management capability that can help bridge incompatible point solutions. — Media and entertainment has, in many respects, been on the leading edge of the data explosion. It makes sense that M&E will also be on the cutting edge of solutioneering to realize the cognitive data management vision. — This paper looks at the drivers of, the requirements for, and the essential functionality of cognitive data management strategy, and how these principles may apply to M&E workflows. In addition, the paper will show how such a metadata-centric approach can help companies overcome data silos and enable IT planners to take advantage of any storage technology without impacting users, or adding IT management complexity.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Data Management",
                      "metadata managment",
                      "storage resource management",
                      "data migration",
                      "archive",
                      "cognitive computing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001796"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Exploring Image Corruption in the Workflow, and how to Stop this from Happening",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keith R. Hogan"
                  ],
                  "abstract": "LTO tape Systems, SAN, NAS, Object Store, RAM, and WAN Optimizers all have configurations available to protect the fidelity of image contents in the workflow. Each system has different methods to ensure that frames contents aren't corrupted, and each method protects against a variety of different failure conditions. And yet, unrecoverable frame corruption still occurs at an unacceptable level. This problem is even more serious in an archive scenario, where content may sit untouched for a long duration, and with the corruption staying undetected for extended periods of time. Media and Entertainment workflows rely solely on the protections provided by the underlying compute, storage, and transmission technologies to ensure the fidelity of the data in the workflow. These protections are very difficult to fully characterize and track, because the technologies are generally deployed deep in the hardware or at the lowest software levels of the IT infrastructure. Depending on the path a frame takes through the workflow, it will be treated to a varying set of protection technologies, like RAID, erasure coding, ECC Memory, and parity checking. To overcome the uncertainty of associated with how these methods ensure fidelity, the industry employs failure detection at each stage of the workflow (generally MD5 checksums). When a corrupt image is detected, the entire file must be restored from a backup copy. This approach is very expensive and introduces significant delays in the production when errors occur. This paper will explore the IT technology utilized in the workflow, and discuss the protection mechanisms provided or employed by each workflow element. In this context, the paper will discuss how frame corruption can occur, even when all of the protection technologies are working as designed. The paper will also discuss a method for providing protection to images at the frame level using Forward Error Correction, such that there is uniformity of protection for images applied throughout the workflow, and such that media errors may be recovered in most cases without having to access a backup copy.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Data Corruption",
                      "Forward Error Correction",
                      "FEC",
                      "Storage",
                      "Archive",
                      "SSDs",
                      "Object Store",
                      "SAN",
                      "NAS",
                      "ECC",
                      "RAID",
                      "Erasure Coding",
                      "Raster Data",
                      "Metadata",
                      "MD5",
                      "Hash"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001797"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "An Open, Standards Based Framework for Audio Metadata Transport in Live Content Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kent Terry"
                  ],
                  "abstract": "Described is a model for open audio metadata transport in live workflows that will meet the requirements for next generation audio systems such as ATSC 3.0. The framework is standards based and essence agnostic. The format groups audio metadata into logical payloads that can be customized for specific use cases. It allows for bit efficient coding of audio metadata, but also allows for full, structured syntaxes, including XML based syntaxes. The format is also not tied to a specific metadata standard. Current audio metadata standards are supported, but the format is open to support new audio formats as they arise, as well as private and/or non-standard metadata. — Realization of the framework using KLV for the base structure of the format is proposed. ST 2109 targets applications for transport in AES3 streams, for operation with existing SDI and AES3 based infrastructures. Methods for transport over IP are proposed including native KLV transport using RTP over IP, which can be utilized by ST 2110 media flows. — While targeted at live production and distribution, the format takes into consideration metadata paths for emission to enable a seamless “microphone to speaker” metadata path for efficient delivery of audio metadata from content creator to the end user. Interoperation with file based formats and workflows is also considered in the design.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Audio",
                      "Metadata",
                      "ATSC 3.0",
                      "KLV",
                      "Object Audio",
                      "Immersive Audio",
                      "Live",
                      "Audio over IP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001799"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "NABA DPP: Specifications, Standards, and Content Delivery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Lennon",
                    "Clyde Smith"
                  ],
                  "abstract": "The seemingly simple act of getting content from its producers to major media outlets and then creating versions required to meet technical, geographic and regulatory requirements for distribution on many platforms is far from simple. Content delivery specifications spanning dozens of pages leave many bewildered, and often result in content being delivered in far from an on-air ready state. The North American Broadcasters Association (NABA), in conjunction with the Digital Production Partnership (DPP), has been hard at work fixing this. Through the novel use of both specifications and standards, the NABA DPP effort has resulted in a standardized set of tools that enable a far simplified and more automated workflow when it comes to delivery of content to those who get it to the consumer. Existing SMPTE standards, such as IMF and BXF, have been leveraged to make delivery of Air Ready, Library, and Archive Masters possible in a way that allows for greater interoperability and automation, resulting in great advances in efficiency and in quality of these files. We will outline how this approach of utilizing both specifications and standards together results in a whole that is greater than its parts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NABA",
                      "Standards",
                      "Specifications",
                      "BXF",
                      "IMF",
                      "DPP",
                      "Workflow",
                      "Masters"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001798"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Microservices: Building blocks to new workflows and virtualization",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Darren Gallipeau",
                    "Sara Kudrle"
                  ],
                  "abstract": "As the media production and broadcast industry continues to transition toward IP and commercial off-the-shelf (COTS) equipment it is clear there is a looming gap between how nontraditional media companies leverage cloud and datacenter environments and how broadcasters think about those same networks. Companies like Facebook, Google, and Amazon see their networks as being dynamic, living environments that are defined on demand and provisioned at will for scale. The traditional broadcast view would have those same networks more locked down and fixed in functionality, but control over scale is certainly a requirement for future deployments. For broadcasters and other media companies to remain competitive, it is imperative that they transition operations to a more agile and flexibly workflow design architecture. This is where microservices, a component-based approach to application and service design, come into play. The Facebooks and Googles of the world have already jumped into the world of microservices, building large-scale, high-performance networks that maximize the efficiency of COTS platforms. The success that those companies have experienced in their move to microservices is undeniable, but how does that apply to the video-centric world and the requirements of nonlinear and live broadcast? Can microservices be leveraged for all aspects of television? — This tutorial-type paper will explain what microservices are and how they compare to virtual machines (VMs), Containers and Software Oriented Architectures (SOAs), as well as how they potentially interact. The paper will look at platforms and potential hardware, as well as software-based architecture decisions. Finally, the paper will consider how software strategies used in other industries can translate to media production and broadcast, ensuring that the industry can successfully respond to continually changing consumer demand.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Next-generation architecture",
                      "microservices",
                      "micro services",
                      "micro-services",
                      "containers",
                      "virtualization",
                      "COTS",
                      "cloud",
                      "cloud-native",
                      "Docker",
                      "SOA",
                      "VM",
                      "Virtual Machine"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001793"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "How Artificial Intelligence and Machine Learning Will Change Content Creation Methodologies",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Ohanian"
                  ],
                  "abstract": "For almost 30 years, Digital Nonlinear Editing Systems (DNLEs) have functioned as a practical replacement for film and videotape editing. While DNLEs have progressed in their capabilities by offering increased video resolutions and visual effects, they have not fundamentally changed their operational constructs. Editors must still choose in and out points of shots and then methodically edit those shots into a cohesive sequencing. — Technology improvements in Artificial Intelligence (AI) and Machine Learning (ML) have the potential to profoundly impact how DNLE systems operate and, in turn, content creation methodologies will dramatically change. This paper will examine the effects of image recognition, natural speech processing, language recognition, cognitive metadata extraction, tonal analysis, and data and statistical integration on the creation of content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital Nonlinear Editing",
                      "Artificial Intelligence",
                      "Machine Learning",
                      "Cognitive Metadata",
                      "Speech Analysis",
                      "Language Recognition"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001794"
                  }
                }
              },
              {
                "article_local_id": "57",
                "article_title": "Core Color Rendering Algorithms For High Dynamic Range Display",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/57/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos",
                    "Doug Walker"
                  ],
                  "abstract": "As is well-known, colors as they exist in the real world must be adjusted so as to look correct and pleasing when displayed on a television or cinema screen. In color science, the process of converting these “scene-referred” colors to “display-referred” colors is termed “rendering.” The Academy's ACES system is a good example of a set of open-source picture rendering algorithms. In this paper the authors, who both participated in the development of ACES, discuss the pros and cons of various rendering techniques and share the results of their latest work. Specifically we present a method of applying a tone curve that preserves color ratios and has better noise properties than earlier techniques. This algorithm has been successfully used as part of a larger parametric rendering system for HDR display. One of the nice properties of this algorithm is that it has a simple and robust inverse.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "ACES",
                      "OOTF",
                      "Color Rendering",
                      "Tone Curve",
                      "End-to-End Gamma"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001808"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Metadata based audio production for Next Generation Audio formats",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Poers"
                  ],
                  "abstract": "The next generation immersive audio formats will require changes in the audio production workflow. Monitoring the audio along with authoring and verifying of dynamic metadata will become a new challenge. — New procedures for managing object based encoded content the same way as for personalization of services through the selection of alternative audio objects (such as commentator languages) needs to be established. — Object based audio will give the end user the option to personalize their experience by selecting from a number of audio sources and controlling the level and maybe even the position in the mix. In object based audio, an “object” is essentially an audio stream with accompanying descriptive metadata. The metadata carries information for the playback rendering process in the final decoder/receiver. — What does this all mean for the production of future audio content? A total re-think about the workflows and the audio processing equipment will be required? There will be inevitably some additions to production and distribution equipment. In the case of Immersive Audio and object based audio, all the metadata appropriate for the final codec needs to be created and must reach the final emission encoder. File based processes needs to perform this similar to stream based real-time live content production. The way of mixing and mastering will change and more auto-production procedures will be used to run NGA audio and legacy formats simultaneously the same time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Next Generation Audio",
                      "Object Based Audio",
                      "Dynamic Metadata",
                      "Descriptive Metadata",
                      "Audio Rendering",
                      "Legacy Formats"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001800"
                  }
                }
              },
              {
                "article_local_id": "56",
                "article_title": "Color-matching Shots from Different Cameras Having Unknown Gamma or Logarithmic Encoding Curves",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202017%20Annual%20Technical%20Conference%20and%20Exhibition/56/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raquel Gil Rodriguez",
                    "Javier Vazquez-Corral",
                    "Marcelo Bertalmio"
                  ],
                  "abstract": "In cinema and TV it is quite usual to have to work with footage coming from several cameras, which show noticeable color differences among them even if they are all the same model. In TV broadcasts, technicians work in camera control units so as to ensure color consistency when cutting from one camera to another. In cinema post-production, colorists need to manually color-match images coming from different sources. Aiming to help perform this task automatically, the Academy Color Encoding System (ACES) introduced a color management framework to work within the same color space and be able to use different cameras and displays; however, the ACES pipeline requires to have the cameras characterized previously, and therefore does not allow to work ‘in the wild’, a situation which is very common. We present a color stabilization method that, given two images of the same scene taken by two cameras with unknown settings and unknown internal parameter values, and encoded with unknown non-linear curves (logarithmic or gamma), is able to correct the colors of one of the images making it look as if it was captured with the other camera. Our method is based on treating the in-camera color processing pipeline as a combination of a 3x3 matrix followed by a non-linearity, which allows us to model a color stabilization transformation among two shots as a linear-nonlinear function with several parameters. We find corresponding points between the two images, compute the error (color difference) over them, and determine the transformation parameters that minimize this error, all automatically without any user input. The method is fast and the results have no spurious colors or spatio-temporal artifacts of any kind. It outperforms the state of the art both visually and according to several metrics, and can handle very challenging real-life examples.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2017-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Color stabilization",
                      "color matching",
                      "non-linearity estimation",
                      "logarithmic encoded images",
                      "gamma corrected images"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001807"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2016",
        "conferences": [
          {
            "conference_name": "SMPTE 2016 Annual Technical Conference and Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/",
            "articles": [
              {
                "article_local_id": "38",
                "article_title": "A Biologically-Inspired Approach to Making HDR Video Quality Assessment Easier",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sean T. McCarthy"
                  ],
                  "abstract": "Quality is easy to recognize by eye. Putting a number on it can be more problematic. For HDR, it is even harder because convenient methods like PSNR and SSIM don't work well. Some newer HDR-aware metrics are now available; however, they can be slow and computationally cumbersome enough to discourage use in real time monitoring. This paper introduces an alternative simple technique intended to be more convenient. Specifically, this paper will present a biologically-inspired method of creating a “Spatial Detail” representation that can be used instead of the original HDR image as a basis for calculating PSNR that has several added advantages. For one, simple correlation analysis of the luma and chroms Spatial Detail signals yields a highly intuitive and sensitive metric of distortion in HDR video. Another advantage is that the Spatial Detail signal provides a guide by which to evaluate distortions of perceptually potent features and highlights separately from distortions of background textures and noise fields. Yet another operational advantage is that the Spatial Detail signal is easy to calculate and thus a candidate for use in real time monitoring.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "Wide Color Gamut",
                      "HDR",
                      "Spatial Detail",
                      "WCG",
                      "Ultra HD",
                      "UHD",
                      "video quality",
                      "video distortion"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001679"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "A Cinematographic Spectral Similarity Index",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jack Holm",
                    "Tom Maier",
                    "Paul Debevec",
                    "Chloe LeGendre",
                    "Joshua Pines",
                    "Jonathan Erland",
                    "George Joblove",
                    "Scott Dyer",
                    "Blake Sloan",
                    "Joe di Gennaro",
                    "Dan Sherlock"
                  ],
                  "abstract": "As solid state lighting (SSL) sources have gradually replaced tungsten sources, new challenges in color rendition have emerged. CRI is often quoted for sources but is limited to a human observer, without purporting to predict potential color differences for cameras. A new color index is proposed that is based upon the similarity of a luminaire's spectrum to a reference spectrum that eliminates the need for any assumption of a specific observer or camera spectral sensitivity. The index yields a “confidence factor,” where a high score implies predictable color rendition for cinematography, and a moderate score implies possible color rendition challenges.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SSL",
                      "LED",
                      "CRI",
                      "CCT",
                      "TLCI",
                      "SSI",
                      "cinematographic",
                      "spectral",
                      "similarity",
                      "index",
                      "Academy",
                      "AMPAS",
                      "Sci-Tech",
                      "Council"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001680"
                  }
                }
              },
              {
                "article_local_id": "58",
                "article_title": "A Comparison of Intra-Frame Codecs Considered for IMF",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/58/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wolfgang Ruppel",
                    "Theresa Baier"
                  ],
                  "abstract": "RheinMain University has conducted a study on the performance of intra-frame codecs currently used or considered for mastering and programme interchange applications. — The results include figures of PSNR versus bitrate, subjective assessments, transcoding and multigeneration encoding performance. The codecs under study were AVC Intra and HEVC Intra, compared to JPEG 2000 as constrained in IMF (ST 2067-20/-21). The comparison has been done for both HDTV (720p, 1080i, 1080p) and UHDTV (2160p). — The results of the comparison show that the performance JPEG 2000 is comparable to the performance of AVC and HEVC for the majority of the use cases. However, particular attention should be paid when transcoding from a block based codec into JPEG 2000 and vice versa. The paper gives recommendations how to limit transcoding loss in that case.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IMF",
                      "Codecs"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001681"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "8K-UHDTV Production Equipment and Workflow which Realize an Unprecedented Video Experience",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tsuyoshi Sakiyama",
                    "Kenichiro Ichikawa",
                    "Mayumi Abe",
                    "Seiji Mitsuhashi",
                    "Takayuki Yamashita",
                    "Masayuki Miyazaki"
                  ],
                  "abstract": "NHK has developed equipments and facilities for 8K-UHDTV production such as cameras, recorder-players, OB trucks, editing rooms, and so on. We have started 8K test broadcasting on August 1st 2016, so it is becoming mainstream for us to produce spectacular content using HDR (High Dynamic Range) and WCG (Wide Color Gamut) technologies. — This paper describes 8K content production equipment and workflow with HDR and WCG technologies. A new single-chip color 8K camera can capture high-quality video clips with HDR and WCG, and the compact 8K recorder can record and play them. The latest 8K editing system with a color grading function can input and output the 8K clips in real-time. In the design of the total system, we have considered how to keep the 8K qualities when importing and exporting in an editing workflow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "8K-UHDTV",
                      "Broadcasting",
                      "Workflow",
                      "HDR",
                      "WCG"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001676"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Broadcast and Network Integration using the Network Control (SDN) API",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Subha Dhesikan",
                    "Pradeep Kathail"
                  ],
                  "abstract": "IP based Live Broadcast production is almost here and a production-ready system requires more than basic management of media flows. A production-ready system must have orchestration, security, diagnostics, scale, and redundancy capabilities. A richer integration between the broadcast systems and the network is required to achieve these capabilities. — There needs to be an interoperable interface between the Broadcast Controller and the Network to permit an open, flexible, and multi-vendor environment. This paper explores architectural aspects of the interface (Network Control API) between the Broadcast and the Network Controller. The presentation will describe how Network Control delivers the abovementioned capabilities and extends the interactions of the Broadcast systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "PMN SDN API",
                      "API",
                      "SDN",
                      "IP Network. Controller",
                      "REST API",
                      "Network Control"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001691"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Advances in Coaxial Cable Design",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen H. Lampen"
                  ],
                  "abstract": "As the bandwidth of video signals has increased, the viability of using coaxial cable (commonly called coax) has been questioned. Alternatives such as twisted pair data cable (Category cables) or fiber optic cables, have been suggested and employed. — The real question is, can coax be used for acceptable distances at these increased bandwidths? Recent advances in the design and manufacturing of these cables have changed the predictions that “coax is dead”. To paraphrase Mark Twain, the reports of the death of coax are, at the very least, “exaggerated”. — This paper outlines work done by Belden to improve the performance of coaxial cable for high bandwidth applications, such as 4K (6 GHz and 12 GHz) video. The paper concludes with a look toward future improvements in video signals and the possibility of coax for these improved signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Bare copper",
                      "BC",
                      "BNC",
                      "braid",
                      "braid spikes",
                      "cable",
                      "Category 5e",
                      "Cateogry 6",
                      "Category 6a",
                      "center conductor",
                      "coax",
                      "coaxial",
                      "copper",
                      "coverage",
                      "clock frequencies",
                      "dielectric",
                      "digital video",
                      "DIN",
                      "fiber",
                      "fiber optic cable",
                      "foam",
                      "foil",
                      "4K",
                      "harmonics",
                      "HD",
                      "insulation",
                      "jacket",
                      "nitrogen gas injected",
                      "Nyquist limit",
                      "premise/data cable",
                      "RG-6",
                      "RG-59",
                      "6 GHz",
                      "silver",
                      "silver-coated copper",
                      "shield",
                      "tri-shield",
                      "shield effectiveness",
                      "SMPTE",
                      "SMPTE 259M",
                      "SMPTE 292M",
                      "SMPTE 424M",
                      "SMPTE 2081-1",
                      "SMPTE 2082-1",
                      "SDI",
                      "SPC",
                      "3G",
                      "12 GHz",
                      "Type 7"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001685"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "A 100Gbps Interface for 4k/8k UHDTV Signals",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shigeyuki Yamashita",
                    "Kazushige Takahashi"
                  ],
                  "abstract": "A“100Gbps Real Time Interface” has been developed specifically to transmit 4k and 8k UHDTV image formats. This 100Gbps interface can carry 8k/50P-60P/4:4:4/12bit or 8k/100P-120P/4:2:2/10bit image formats. The DC balance and clock recovery was secured by adopting the 8b/10b coding. A transmission distance of 2km the same as those of the HD/3G-SDI optical interfaces was achieved by adopting the 1.3um QSFP28 optical module. The QSFP optical module has evolved and treats the data as 4×28Gbps. This 100Gbps Interface can be the next generation Real Time Interface that can cover all the 4k and 8k signal formats defined by SMPTE ST 2048-1 and SMPTE ST 2036-1 as well as SMPTE ST 274 and SMPTE ST 296. It also maintains backward compatibility because its I/O supports HD/3G-SDI.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "100Gbps",
                      "100GbE",
                      "4k",
                      "8k",
                      "UHDTV",
                      "QSFP28",
                      "SMPTE ST 2036-1",
                      "SMPTE ST 2048-1",
                      "SMPTE ST 274",
                      "SMPTE ST 296",
                      "HD/3G-SDI",
                      "8b/10b",
                      "Real Time Interface"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001678"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "A Modern Approach to HDR Color Timing",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Postma",
                    "Richard Kirk",
                    "Daniele Siragusano"
                  ],
                  "abstract": "HDR displays and projectors pose new challenges for mastering content while still supporting traditional TVs and cinema projectors. The traditional workflow, taking images straight from the camera and adjusting color correction knobs until they look good on a display, is no longer practical. Nor can a single color appearance LUT give the best results on HDR and SDR displays. Color correction and creative grading must be based on comprehensive color management and color appearance modeling. Color grading controls based on scene radiance and human vision can balance images more naturally, and impart creative looks that translate easily to HDR and conventional displays in varying viewing conditions. This paper summarizes the fundamental color science framework needed for color space conversions between cameras, grading tools, and displays; and proposes a core set of perceptually based color correction tools.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "high dynamic range",
                      "HDR",
                      "color management",
                      "color correction",
                      "color grading"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001682"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "An Extension of the Output Profile List for Semi-Automated Quality Control using IMF",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Heiko Sparenberg",
                    "Matthias Martin",
                    "Siegfried Foessel",
                    "Ronny Paduschek"
                  ],
                  "abstract": "New distribution channels for video-content arise almost daily. While generating appropriate media formats for such channels, intensive quality control is applied. Both, workflow-compositing and verification, requires plenty of undesirable human interaction. Thanks to the Interoperable Master Format (IMF), there is already a solution for defining transcoding-workflows by using the Output Profile List (OPL). An OPL can define how an IMF-Package (IMP) is converted into a particular distribution format. — For automated Quality Control (QC) of these formats, the authors will present a technology demonstrator allowing for QC'ing of IMF-Packages as well as the derived distribution formats based on the OPL. Therefore, typical quality issues introduced by video transcoders are shown, before the concept of the OPL and its role within the IMF is explained. Based on those findings, the authors suggest an extension of the current IMF-OPL standard for covering (semi-) automated quality control of audio, video and auxiliary data.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "OPL",
                      "IMF",
                      "QC",
                      "video transcoding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001686"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Adapting Content to Different Display Capabilities and Viewing Environments",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jack Holm"
                  ],
                  "abstract": "The emergence of HDR content and displays requires methods for adapting content to different display capabilities. This paper addresses mastering and encoding considerations, and presents methods for adapting HDR-mastered content for viewing on displays with different capabilities and viewing environments. Specifically, HDR grading considerations and coordinated methods for dealing with reductions in highlight and/or shadow range are presented, along with methods for adjusting mid-tone brightness to compensate for reductions in dynamic range and/or different surround luminances. The degree to which such adaptations can and should preserve the mastered appearance are discussed. Issues in converting between SDR (1886), HLG and PQ EOTFs are also addressed. Conclusions note the importance of creating high quality, well-defined masters on well-behaved displays in appropriate environments, and some problems that can arise when displays aggressively re-map images. Recommendations include mastering for a target HDR display, methods for adapting content for different receiving displays, and coordination of display and surround luminances to preserve the mastered appearance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High dynamic range",
                      "HDR",
                      "wide color gamut",
                      "WCG",
                      "display adaptation",
                      "PQ",
                      "HLG",
                      "ITU-R BT.2100",
                      "mastering",
                      "color grading",
                      "reference display",
                      "converting HDR",
                      "OETF",
                      "OOTF",
                      "EOTF"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001684"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "12G SDI over RF Coaxial Structures",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Owen Barthelmes",
                    "David Weinstein"
                  ],
                  "abstract": "With the rapid growth of ultra-high-definition television, there is an urgent industry need to transmit 12G SDI signals per SMPTE 2082 over RF coaxial structures. For a system to operate effectively, the cumulative performance, considering all system components, must meet minimum requirements. Key components in these systems include, RF connectors, printed circuit boards, and discrete board level active and passive components. This paper will highlight the actual development of a 12G SDI system and discuss the technical challenges and solutions for each critical component to achieve effective transmission.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "RF",
                      "connector",
                      "12G SDI",
                      "bandwidth"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001677"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Is There an Uncanny Valley in Frame Rate Perception?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sean Cooper",
                    "Elizabeth Pieri",
                    "David Long"
                  ],
                  "abstract": "High frame rates for cinematic exhibition open the industry to a new realm of creative and perceptual control. Most recent research has been targeted at how fast our pixels need to refresh to mimic real motion, but we have taken a fundamentally different approach. Rather than a simple binary segmentation of motion artifact visibility in intermittent image presentation, we look to explore the gradient of motion appearance across the frame rate dimension. What would a frame-rate perception curve look like? Does it conform to Weber/Fechner psychophysics? Is it univariate or multidimensional? Is it monotonic, or perhaps an ‘uncanny valley’? Our study begins to investigate the dimensionality and structure of temporal stroboscopic perception in cinema, and takes first steps towards formalizing a temporal perceptual space.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HFR",
                      "Frame-Rate",
                      "Psychophysics",
                      "Subjective Study"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001703"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "It's all Backwards: Rethinking Frame Rate and Temporal Fidelity in a Cinema Workflow",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tony Davis"
                  ],
                  "abstract": "In pursuit of greater fidelity in motion picture images, it is important to carefully consider the frame rate, and particularly the way in which it is handled from acquisition to final exhibition. In typical workflows, the frame rate is decided prior to acquisition, and that frame rate is carried through editing to exhibition without change. Then, when slightly different frame rates are needed for international presentation or on devices with a fixed frame rate, complex algorithms are employed to make the slight increase or decrease in the frame rate from the fully finished product. This often results in substantial degradation to the temporal domain. — The first question addressed is: why is frame rate conversion so difficult? Without very complex algorithms, slight changes to the frame rate result in unacceptable motion distortion. Because of the enormous level of temporal aliasing introduced by conventional cameras, it's not feasible to use one-dimensional resampling algorithms, and instead highly nonlinear “optical flow” algorithms must be employed. — If, however, steps were taken to substantially reduce the temporal aliasing of the capture system, the frame rate conversion problem would be reduced to a straightforward one-dimensional resample with nearly no distortion. This result then leads to the next conclusion: for best temporal fidelity, frame rates should be as high as possible throughout production, with the aesthetic look controlled by adjusting the frequency response within that frame rate. Then the final output frame rates for any deliverable is created from that high-bandwidth master, in exactly the same way spatial resolution is currently handled.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Frame rate",
                      "HFR",
                      "standards conversion",
                      "resampling",
                      "temporal aliasing",
                      "judder"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001704"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Beyond the Limits of Visual Acuity: The Real Reason for 4K and 8K Image Resolution",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward Reuss"
                  ],
                  "abstract": "Several commentators have put forward the argument that 4K and 8K image resolutions are unnecessary because the human visual system cannot resolve the additional image resolution at normal viewing distances, either for viewing a large screen television at normal living room distances, or on a handheld display, such as on a smartphone or tablet. While this argument has some merit, it ignores several other reasons for increasing the image resolution beyond the limits of human visual acuity. This paper presents some of these, including minimizing image spatial sampling artifacts, for traditional television viewing as well as novel display formats like VR systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "visual acuity",
                      "UHD",
                      "display resolution",
                      "spatial artifacts",
                      "anti-alias filter"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001689"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Automatic, Viewing-Condition Dependent Contrast Grading based on Perceptual Models",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Praveen Cyriac",
                    "David Kane",
                    "Marcelo Bertalmio"
                  ],
                  "abstract": "Cameras automatically apply non-linear transformations to the sensor data, allowing for perceptually-uniform quantization suited to standard dynamic range displays in dim conditions. In the cinema industry, data is recorded in raw (linear) format and non-linearly corrected in post-production by a skilled technician who optimizes image appearance for cinema (dark) conditions. We propose a method that automatically performs this non-linear transformation taking into account the intended viewing conditions. It is based on visual perception models and produces results that look natural, without any spatio-temporal artifacts. User preference tests show that our method outperforms state of the art approaches. The technique is fast and could be implemented on camera hardware. It can be used for on-set monitoring on regular displays, as a substitute for gamma-correction, and as a way of providing the colorist with content that is both natural looking and has a crisp, clear image.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High dynamic range",
                      "tone mapping",
                      "human visual system",
                      "psychophysics",
                      "natural image statistics",
                      "contrast grading"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001687"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "Building The World's Most Complex TV Network (A Test Bed for Broadcasting Immersive and Interactive Audio1)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Bleidt",
                    "Herbert Thoma",
                    "Wolfgang Fiesel",
                    "Stefan Kraegeloh",
                    "Harald Fuchs",
                    "Rinat Zeh",
                    "Jim De Filippis",
                    "S. Merrill Weiss"
                  ],
                  "abstract": "Fraunhofer and its partners have developed a TV audio system based on the new MPEG-H Audio standard, now part of the ATSC 3.0 A/342 standard adopted for Korean broadcasts in 2017. Given its complexity, a complete broadcast plant was built to test the features envisioned. At NAB 2015 we demonstrated “The MPEG Network” on the show floor. It was perhaps the most complex combination of broadcast audio content ever made in a single plant, involving 13 different formats. The network was designed to handle immersive audio in both channel and HOA-based formats, with each using audio objects for interactivity. Live mixing at a simulated sports remote was contributed to a network operating center, with distribution to affiliates, and then emission to a consumer living room, all using the MPEG-H audio system. Both system and equipment design are presented, including an Audio Monitoring and Authoring Unit to mix signals using existing consoles.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "MPEG-H Audio",
                      "Immersive Audio",
                      "Interactive Audio",
                      "ATSC 3.0",
                      "Dialogue Enhancement",
                      "Loudness",
                      "Audio Objects",
                      "Object Audio",
                      "3D Audio",
                      "Barrier-free",
                      "Metadata",
                      "Splicing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001692"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Breaking out of the 100-Nit Box - A Colorist's View of HDR Grading",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shane Mario Ruggieri"
                  ],
                  "abstract": "While the process of grading high dynamic range (HDR) is no more complicated than grading standard dynamic range (SDR), there is some unlearning and relearning needed. Good storytelling in HDR will require a deviation from the baseline grading techniques for, and self-imposed constraints applied to SDR content, and experimentation will reveal the transformative power that HDR brings to the way stories are experienced. A colorist himself, the author relates the struggle of learning about and understanding the nuances of working with HDR, and will share experiences of relearning, offering insight into practices that may help better navigate and define the burgeoning arena.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "Color Correction",
                      "Dolby Vision",
                      "SDR-to-HDR",
                      "100 nit",
                      "4000 nit",
                      "Unlearning 100nit",
                      "SDR Grading",
                      "Language of HDR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001690"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Development of an 8K Production System with 120 Hz Frame Frequency",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tetsuya Hayashida",
                    "Takuji Soeno",
                    "Jun Yonai",
                    "Atsushi Iwasaki",
                    "Yoshitaka Ikeda",
                    "Daiichi Koide",
                    "Takayuki Yamashita",
                    "Yoshiro Takiguchi",
                    "Eiichi Miyashita",
                    "Yukihiro Nishida"
                  ],
                  "abstract": "8K Super Hi-Vision test broadcasting has commenced in Japan in August 2016. With a futuristic view, NHK STRL(Science and Technology Research Laboratories) has been researching a full-featured 8K with a 120-Hz frame frequency. We have developed a signal interface called the ultra high definition signal/data interface (U-SDI) for transmitting 4K and 8K signals using a single optical cable. The interface was standardized as the SMPTE ST 2036-4. In this paper, we discuss the details of the technologies used in the development of various pieces of 8K/120-Hz equipment incorporating the U-SDI that includes an 8K waveform monitor comparable in size to HDTV waveform monitors, a real-time-processing color-grading system, a 17-inch liquid crystal display, and a blanking switcher capable of handling a video data rate of approximately 144 Gbps. In addition, we discuss the integrated system capable of operating both with the full-featured 8K and with the HDTV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "8K",
                      "UHDTV",
                      "U-SDI",
                      "120 Hz frame frequency"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001696"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "Automating The Exchange of Video Files",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Lennon"
                  ],
                  "abstract": "A lot of activity has occurred in recent years around the area of file-based workflows. However, one area that hasn't fully been addressed until now was automating the exchange of files by standardizing file delivery specifications that networks provide to those they get content from. The North American Broadcasters' Association (NABA) has been hard at work on this, in conjunction with SMPTE, with the NABA DPP activity. Learn how a new extension of BXF will be used to solve this problem, and also facilitate simpler automated QC of incoming files.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NABA",
                      "DPP",
                      "JTFFFMI",
                      "BXF",
                      "Workflow",
                      "File based"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001688"
                  }
                }
              },
              {
                "article_local_id": "53",
                "article_title": "Cutting The Cord @ 60 GHz",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/53/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "The 60 GHz EHF wireless band, long dormant, is finally coming alive as more companies announce chip sets and products for high-bandwidth wireless display and video connectivity. Signals in this band can link up at distances to 100 feet, using multiple antenna arrays and beam-steering on TX/RX chips. With four channels allocated worldwide from 57 to 64 GHz, it's now practical to consider high-bandwidth wireless display connections to ‘cut the cord’ from mobile devices, set-top boxes, and laptops at UHD resolutions. Hi-speed data connections emulating USB can also be made at these frequencies.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "60 GHz",
                      "SiBEAM",
                      "WiHD",
                      "WiGig",
                      "Wireless Gigabit",
                      "Keyssa",
                      "SNAP",
                      "Qualcomm",
                      "Lattice",
                      "Peraso"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001695"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Efficient Monitoring of ST2059-2 based Time Transfer Performance",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nikolaus Kero",
                    "Thomas Kernen",
                    "Tobias Muller"
                  ],
                  "abstract": "In any mission critical broadcasting application, reliable synchronization is mandatory. For traditional black burst or tri-level based synchronization redundant sync signal generators are used, whose quality is monitored together with their respective switch-over units. To make best use of a single shared communication medium within an All-IP studio, synchronization is accomplished using the IEEE 1588 Precision Time Protocol. Although multiple sync sources are deployed for redundancy purposes, the monitoring of their availability and precision is not sufficient to guarantee the defined level of accuracy. — Additional data has to be gathered and analyzed by every node prior to deployment and as part of its ongoing operation. After briefly describing the main effects influencing PTP accuracy, several monitoring methods using both in-band and out-of-band are described including how this benefits operations in the broadcast plant. Finally, we verify their respective merits through a series of measurements in a Datacenter class multi-hop network architecture.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IEEE 1588",
                      "PTP",
                      "ST 2059-2",
                      "Time & Sync",
                      "Redundancy",
                      "Monitoring"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001697"
                  }
                }
              },
              {
                "article_local_id": "56",
                "article_title": "Challenges of Delivering Superb Viewing Experience while Streaming UHD 4K and HDR Content in the Adaptive Bitrate (ABR) Era",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/56/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rotem Epelbaum",
                    "Ravid Hadar"
                  ],
                  "abstract": "The adoption of UHD 4K and HDR formats by streaming video content providers introduced tremendous challenges for network infrastructure, as the delivery of large files created network congestions, impacting end user experience. The rise of Adaptive Bitrate (ABR) Streaming Protocols was supposed to provide a solution to the viewing experience degradation, by varying video bitrates and subsequent quality of viewing in accordance to the available bandwidth. Today, OTT providers are stuck in a user experience paradox; whereby ABR is actually impairing the user experience, due to lower quality it sometimes provides the consumer in order to mitigate video re-buffering issues, as well as Quality-of-Service issues, in the form of constant bitrate switches that are much more visible to the human eye with UHD 4K content, and in particular with HDR. This paper, supported by expansive field testing, examines the impact of ABR protocols implementation on user experience in the new era of UHD 4K and HDR, discusses its challenges and further recommendations for delivery of greater viewing experience within the current network infrastructure.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media streaming",
                      "user experience",
                      "adaptive bitrate streaming",
                      "UHD",
                      "4K",
                      "HDR",
                      "bandwidth",
                      "bitrate",
                      "protocols",
                      "broadband",
                      "buffering",
                      "quality of service",
                      "quality of experience",
                      "network",
                      "field testing",
                      "interne"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001693"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Common Mezzanine Distribution Format (CMZF): For ABR TV Distribution",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Prabhu Navali",
                    "Raj Nair"
                  ],
                  "abstract": "Pay TV service providers need a way to re-use their extensive multicast MPEG-2 TS based infrastructure with scalable and reliable workflows for Ad Insertion and Fast Channel Change for managed (and OTT) ABR TV services. — Recent industry developments provide Common Media Application Format (CMAF) as a normalized playout format for efficient storage and distribution. CMZF proposes carriage of CMAF (ISOBMFF) fragments over MPEG-2 TS streams. — Video can be packaged in CMZF using existing workflows, and stored securely in origins and caches. The desired final CMAF (and HLS/DASH/SS) format is generated as needed via a simple container transformation in the gateway or STB without the need for re-encryption.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "OTT",
                      "ATSC 3.0",
                      "Mobile",
                      "IP Media Distribution",
                      "IP Media Infrastructure"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001694"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "A UHD 2/3-Inch CMOS Imager with Dynamic Pixel Management -an Enabler for New Format Flexibility",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Klaus Weber",
                    "Peter Centen"
                  ],
                  "abstract": "The broadcast market currently faces changes which are very challenging for imaging solutions; the change from HD to UHD, and the introduction of HDR. In phases of change, more flexible solutions are needed. The Dynamic Pixel Management (DPM) technology already available in some FT-CCDs offered a unique solution for lossless switching between 4:3/16:9 aspect ratios, as well as between all the different HD formats, including 2.37:1 widescreen. Smaller UHD pixels do not offer the same performance as larger HD pixels and, until now, CMOS imagers have not allowed the pixel size to be changed. This is a real limitation for anyone who needs to produce in UHD as well as in HD. The new CMOS-based XensiumHAWK imagers with DPMUltra technology offer a solution to select the pixel size for native UHD or native HD, to deliver UHD or HD performance with no compromise. This paper explains the background and the development of the flexible pixel size through the DPMUltra technology.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHD",
                      "4K",
                      "HD",
                      "HDR",
                      "CMOS",
                      "DPM",
                      "dynamic pixel management"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001683"
                  }
                }
              },
              {
                "article_local_id": "57",
                "article_title": "HEVC Mezzanine Compression for UHD Transport over SDI and IP infrastructures",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/57/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Juan Jose Anaya",
                    "Damian Ruiz"
                  ],
                  "abstract": "The industry expects that the Ultra-HD (UHD-1) format will become the mainstream in the next few years, improving the consumers' viewing experience by introducing a higher resolution, a wider color gamut (WCG), a higher dynamic range (HDR) and a higher frame rate (HFR), among others. These remarkable improvements demand bandwidths beyond the ones provided by 3G-SDI interfaces and 10GbE IT infrastructures. In order to ease the UHD-1 format adoption over current production facilities, several lightweight compression schemes have been proposed by the industry. — The new Range Extensions (RExt) recently approved as the HEVC Version 2, introduce advanced coding tools giving support for 4:2:2 and 4:4:4 schemes, bit-depth up to 16-bits, and high throughput. This paper analyzes how the HEVC Intra-coding architecture can be adapted to meet the quality, latency and complexity requirements demanded by the UHD-1 mezzanine compression. — Three experimental lab tests were conducted for lossless, near-lossless (4:1) and cascaded encoding modes, and the results of the HEVC quality performance and robustness were compared to the popular JPEG2000 and SMPTE VC-2 video coding standards, among others.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "mezzanine compression",
                      "Range Extensions",
                      "3G-SDI",
                      "10GbE",
                      "Lossless Compression",
                      "Low-Latency",
                      "Low-Complexity",
                      "JPEG2000",
                      "VC-2"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001701"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Flexible SDI - The Universal Transport for Streamed Media",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nigel Seth-Smith"
                  ],
                  "abstract": "SDI was invented to carry all commonly used professional digital video formats in a single data rate of 270 Mb/s. With HDTV it added a 1.5Gb/s layer to carry all HD formats. SDI infrastructures automatically carried both 270 Mb/s and 1.5 Gb/s signals, and so were universal. — In 2005 a 3Gb/s layer was added, and UHDTV has recently raised the game once again, by increasing the data rates, and also with an explosion of different formats. — SDI has responded with multi-link 3G-SDI, and by adding layers at 6Gb/s and 12Gb/s, with a 24 Gb/s layer in the pipeline. — This paper describes how SDI is used to transport all streamed media, from SD to UHD. In particular it highlights the use of gearbox technology for seamless zero-latency bridging between SDI layers. This flexibility allows an evolutionary move from HD to UHD without wholesale replacement of expensive and mission-critical infrastructure.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SDI",
                      "UHDTV",
                      "HDR",
                      "HFR",
                      "Infrastructure",
                      "Standards"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001698"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Open-Source Spatial Audio Compression for VR Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jamieson Brettle",
                    "Jan Skoglund"
                  ],
                  "abstract": "With the advancements of VR environments and 360-degree video, ambisonics have reemerged as an important technique in providing immersive audio experiences. An alternative to channel based 3D sound, ambisonics represent full-sphere sound independent of loudspeaker location. This paper discusses how open-source compression technologies can efficiently transport audio for next-generation immersive media. Two open source codecs, Vorbis and Opus, are compared to AAC for first-order ambisonics. The presented work shows that open and free audio compression is reasonable and promising for delivery of spatial audio content over Internet.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Spatial audio",
                      "360 video",
                      "VR",
                      "Ambisonics"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001712"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Perceptually-based Gamut Extension Algorithm for Emerging Wide Color Gamut Display and Projection Technologies",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Syed Waqas Zamir",
                    "Javier Vazquez-Corral",
                    "Marcelo Bertalmio"
                  ],
                  "abstract": "While wide color gamut (WCG) capabilities are a key element of emerging display and projection technologies, at present most image content is recorded using standards such as DCI-P3 for cinema or BT.709 for TV that have a reduced color gamut. Therefore, there is a need for gamut extension methods that process regular content and allow to appreciate the full color potential of new displays, improving user experience. We present a gamut extension algorithm that is based on visual perception models and explicitly takes into account low chromatic colors such as skin tones. It produces results that look natural, are free of artifacts of any kind, and outperform the state of the art. The method is fast, allowing for operation interaction if needed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Wide color gamut",
                      "gamut mapping",
                      "color management",
                      "gamut extension algorithms"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001713"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Practical Transition Strategies of SDI Facilities Utilizing Newer IP Baseband A/V Signals",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Scott Barella"
                  ],
                  "abstract": "Operators who have significant investments in large-scale SDI plant are going to face technical and budgetary challenges as they transition to newer IP-based topologies while still maintaining current SDI workflows. This paper has been written to provide some practical guidance for operators, system designers and manufacturers, with a focus on constructing ‘islands’ within current infrastructures. Given that SDI is the predominant topology, the center of these plants lies within SDI routing cores. Therefore, any transition will have to address key SDI architectures and augment an existing plant. The paper addresses a number of key parameters such as control systems, SDI-to-IP conversion, and 12G SDI. The conclusion of the paper points to an ‘island’ approach as a practical means of providing a low-risk transition to the world of uncompressed IP video, audio, data and timing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "(The SMPTE disclaimer is on a footer on this page, and will show in Print Preview or Page Layout view.)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001714"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Return Loss: What, Why, How, and Where",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marc S. Walker"
                  ],
                  "abstract": "This paper discusses aspects of return loss and signal integrity in serial digital video systems. Return loss goes beyond just SDI interfaces. It is a factor in all high speed transmission systems. This paper demonstrates some of the causes of return loss errors, and how to mitigate them. Test equipment will be discussed for measuring return loss, and locating the cause of return loss errors. Simulation is demonstrated as a low cost tool for self-education and experimentation, to research return loss issues and possible mitigation options. Aspects of SDI interface design, construction, and manufacturing are discussed in relation to return loss. SDI interconnection systems are discussed with regard to selection of cabling, connectors, and other system components.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Serial Digital Interface",
                      "SDI",
                      "Network Analyzer",
                      "Return Loss",
                      "Return Loss Bridge",
                      "Standing Wave Ratio",
                      "SWR",
                      "Time Domain Reflectometer",
                      "TDR",
                      "Simulation",
                      "SPICE",
                      "LTspice"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001719"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Large scale PTP: How big can it get?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nicholas Ciarleglio",
                    "Thomas Edwards",
                    "Robert Welch"
                  ],
                  "abstract": "Precision Time Protocol (PTP) is a standard to synchronize clocks across a network with sub-microsecond accuracy. In the area of professional media networking, PTP is poised to replace traditional black burst sync methods, allowing both media and synchronization to be carried over the same network connection. To be useful, vendor PTP protocol implementations must scale to the size of the largest broadcast plants. This paper describes the results of PTP tests with over 1,000 “slave” clocks, including an examination of scaling performance with both boundary and transparent modes of operation on the network devices. It also discusses the pros and cons of the end-to-end delay and peer delay mechanisms, and provides details on the performance seen using a range of sync message intervals and delay request intervals. These tests suggest several best practices for large-scale PTP installations using commercial-off-the-shelf (COTS) equipment, and provide real world data to assist in planning and implementing a professional media Ethernet network leveraging PTP synchronization.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SMPTE ST 2059-2",
                      "IEEE-1588",
                      "PTP",
                      "Ethernet",
                      "10GbE",
                      "boundary clock",
                      "transparent clock",
                      "grandmaster",
                      "two-step"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001705"
                  }
                }
              },
              {
                "article_local_id": "54",
                "article_title": "How's your Hooper Rating?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/54/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andy Rosen"
                  ],
                  "abstract": "Since the golden age of radio, audience measurement inefficiencies have hindered some and enabled others. To appreciate the relationship between the ATSC Content Recovery standard and the SMPTE Open Binding project, we have to consider the unique history of ad-supported entertainment in the United States. — Experts from the field of demographic research previously worked in private. Today, statistics analysts are talking to broadcast engineers. Pitchmen, TV networks and their agents are working together because the future of big numbers depends on councils, collectives, coalitions and cooperatives. To ensure that cross-platform impression-tracking resources can interoperate, an unprecedented effort is underway.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "OBID",
                      "OBID-TLC",
                      "ATSC 3.0",
                      "A/334",
                      "A/336",
                      "MRC",
                      "CIMM",
                      "TAXI",
                      "The Clearinghouse Initiative",
                      "Watermark",
                      "Audience Measurement",
                      "Ratings",
                      "C3",
                      "Media Currency",
                      "Jingles",
                      "Network"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001702"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "Loudspeaker Requirements in Object-Based Cinema",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Peace"
                  ],
                  "abstract": "Object-based cinema formats presents acoustical design challenges in the loudspeakers used in theaters that require analytical study. This paper presents an in-depth analysis of the acoustic delivery requirements in a typical theater utilizing these formats. Further, the paper proposes a metric for loudspeaker placement and selection to be used in theater design. This becomes particularly useful for surround loudspeaker specification knowing object-based theaters utilize venue specific rendering engines. The metric provides a means to both improve performance and reduce system cost as compared to current methods.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Loudspeakers",
                      "Object-Based Cinema",
                      "Immersive Cinema",
                      "Immersive Audio"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001707"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Objectively Evaluating High-Dynamic-Range and Wide-Color-Gamut Color Accuracy",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jaclyn Pytlarz",
                    "Elizabeth Pieri",
                    "Robin Atkins"
                  ],
                  "abstract": "Color accuracy plays a vital role in the motion picture and television industry where it is analyzed all the way from lighting during production, through compression, to television sets in the home. The most common pixel-based metric used for evaluating color quality is ΔE2000. This metric was designed using standard-dynamic-range signals and is based upon the perceptually non-uniform L*a*b* color space. It has not yet been well tested or optimized for high-dynamic-range and wide-color-gamut signals. In this paper, we will present an extension to existing color difference data sets that includes data from high-dynamic-range and wide-color-gamut displays. From these results, we propose an alternative color differencing metric, ΔICTCP, which improves the performance and efficiency of objectively evaluating color accuracy.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Color difference metric",
                      "high-dynamic-range",
                      "wide-color-gamut",
                      "ΔE2000, ICTCP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001711"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "NDR - A Machine-Readable Model for News Content Distribution Control",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael L Palmer"
                  ],
                  "abstract": "Stations share news content with third-party services and other stations on a daily basis, but no machine-readable standard exists for identification or distribution control. NDR (News Distribution Rules) defines structured metadata and logic which unambiguously describe where news content originated, who is allowed to use it, and in what manner. — NDR is software-interpretable with human-readable core metadata, enabling automation and interoperability in production and distribution systems while being compatible with long-established editorial workflow models. An optional formatting specification allows structured NDR metadata to be written into existing text-based rights description fields within existing media wrappers, transports and standards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NDR News Distribution Content Sharing Editorial Workflow Metadata Rights Description"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001710"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Looking Deep into the Future Infrastructure Prospects for the Media Enterprise in 2036",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Al Kovalick"
                  ],
                  "abstract": "What will media enterprise infrastructure look like in 2036? Current trends of IT/IP/cloud provide some guidance for the structure of future systems. This paper takes a deep look at the evolution of system's components and architecture and examines some possible scenarios for infrastructure choices. Considered will be; extrapolated trends for transport, networking, storage, compute and cloud futures. Discussion of exponential technology growth and its impact on media creation, production and distribution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Infrastructure",
                      "Moore's Law",
                      "exponential growth",
                      "public/private cloud",
                      "Iaas",
                      "SaaS",
                      "artificial intelligence",
                      "SDMI"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001706"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Luminance-Preserving Colour Conversion",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Florian Schweiger",
                    "Tim Borer",
                    "Manish Pindoria"
                  ],
                  "abstract": "With the advent of new television standards introducing UHD and HDR, backward compatibility with older devices becomes an issue. — We propose a method for converting footage produced in BT.2100 colorimetry to a BT.709 compliant representation. The process preserves each pixel's luminance and is fully reversible. — Technically, our approach determines the exact polygonal shape of the effective BT.2100 and BT.709 gamuts at a given luminance and maps colours from one to the other by desaturating them.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ultra-high-definition TV",
                      "colour conversion",
                      "BT.2100",
                      "BT.2020",
                      "BT.709",
                      "High Dynamic Range"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001708"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "HDR Perception Challenges and Measures in Cinematographic Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt"
                  ],
                  "abstract": "Technical capabilities of moving picture projection are evolving. Higher dynamic range is one of the most promising improvements in cinematographic visual experience. But various factors are limiting the effectiveness of technical developments. Physical limitations such as optical diffusion and room reflectivity have been shown to affect significantly scene contrast. Building on previous model, fully automatic room reflectivity measurement is demonstrated. Diffusion measurement follows directly from the model. One assumption of the model is the uniformity of reflection. This is only an approximation and further work is necessary to assess how non-uniformity is affecting the perception of HDR. Therefore, non-uniformity measurement method and simple descriptor are required and proposed. HDR image quality results should be evaluated from the point of view of cinematographic experience. The best course of action is to evaluate how optical diffusion, room reflectivity and non-uniformity limiting factors are affecting contrast sensitivity.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "image quality",
                      "sequential contrast",
                      "intra-image contrast",
                      "optical diffusion",
                      "room reflectivity",
                      "automatic measurement",
                      "non-uniformity",
                      "contrast sensitivity"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001700"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "NABA DPP Files Specifications for North America",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Clyde Smith",
                    "Michael McEwen",
                    "Robert Zitter",
                    "Andy Quested",
                    "Bruce Devlin"
                  ],
                  "abstract": "This paper examines some of the problems and issues that impact interoperability in file-based workflows, as well as issues that are coming to the industry that will threaten interoperability in existing workflows. It also addresses the work currently underway by a technical committee consisting of members of the North American Broadcasters Association (NABA), the Digital Production Partnership (DPP) and other industry partner organizations to resolve them.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "NABA",
                      "DPP",
                      "workflow",
                      "File-Based",
                      "BXF",
                      "Specifications",
                      "Standards"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001709"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "The Perceived Intra-Frame Dynamic Range in a Cinema Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dirk Maes",
                    "Tine Vyvey",
                    "Jan Van Looy",
                    "Bruno Vandevelde",
                    "Goran Stojmenovik"
                  ],
                  "abstract": "When considering a higher contrast and luminance range in cinema, it's important to understand the limits of the Human Visual System (HVS) under cinema specific conditions. A user experiment with 36 participants was conducted in a cinema theatre. We assessed how the perceivable dynamic range evolved with different background gray levels and with the presence of local highlights in the image; how the size, position and intensity of these highlights affected the results. We found that the perceptual visibility of details in black depends greatly upon the image composition and the average luminance of a given image or image sequence. We found that in a fully dark frame the average person can detect black details down to 0.005 cd/m2. However if a 0.25 cd/m2 gray background in the central field of view is presented this rises to 0.009cd/m2 and with a 2.5 cd/m2 gray background the black level threshold further increases to 0.015cd/m2. In addition to the limitations of the HVS one needs to consider the limitations of a theatrical projection setup where bright elements in the image via reflections on the walls, ceiling, floor, seats and audience contaminate the black elements of the image. Even with special precautions in our test design to reduce those effects with a factor 20, with the presence of very bright highlights they were still found to be significant.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "high dynamic range",
                      "cinema",
                      "visual perception"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001727"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "The Special Challenges of Offering High Quality Experience for VR Video",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mary-Luc Champel",
                    "Sibastien Lasserre"
                  ],
                  "abstract": "The recent invasion of Virtual Reality (VR) headsets on the consumer market leaves little doubt that the media & entertainment industry sees VR as a promising experience for users. Nevertheless, there is still very little VR video content available and the gaming industry remains the foremost user of VR headsets. VR video content available today is often produced and delivered through traditional video workflows and while it offers an interesting user experience, video quality is significantly lower than with traditional video. The lack of interoperable formats and adapted delivery solutions for VR video content is for no doubt a first obstacle for the media industry. Fortunately, Standards Development Organizations and Industry Forums have now embraced the VR topic. The present paper aims at presenting these new technical challenges for offering high quality VR video content. More specifically, focus will be put on format, compression and delivery of VR video content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Virtual Reality",
                      "VR",
                      "interoperable formats",
                      "compression",
                      "delivery"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001729"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "Scaling IMF: How to Manage 10,000 IMF Packages",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Carson",
                    "Simon Adler"
                  ],
                  "abstract": "As more businesses switch to IMF for B-to-B interchange and internal mastering, they see real operational benefits, but at what cost? To begin with, IMF is extra folders here and there with multiple XML files, but as it scales, the increase in the complexity of managing hundreds / thousands of folders with cross referenced XML files becomes a major challenge. Creating and consuming IMF at business workflow boundaries makes a lot of sense but as we scale, the need for an abstraction layer in the form of workflow orchestration and MAM becomes key. Paper highlights include fundamental IMF concepts that need to be mapped into a MAM, mapping advanced features and private data between MAM and IMF, and the importance of an abstraction layer to get the most out of IMF.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IMF",
                      "media asset management",
                      "MAM",
                      "change management",
                      "file-based workflows"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001720"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "GPU-Based Real-Time System for Cinematic Virtual Reality Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas True",
                    "Dennis Sandler",
                    "Pablo Odorico"
                  ],
                  "abstract": "Relatively inexpensive Head Mounted Display (HMD) devices made possible by advances in digital imaging technology are moving the immersive virtual and augmented reality mediums into the entertainment mainstream. This departure from the traditional art of linear story telling requires a richer production workflow and toolset capable of seamlessly integrating numerous potential narratives. An effective Virtual Reality (VR) workflow requires low-latency real-time synchronized capture of multiple live high-resolution video streams, real-time stitching and viewing of the captured assets, and real-time composition with Computer Generated (CG) elements optimally rendered for the HMD. This paper presents a real-time system for virtual reality production that encompasses optimal high-bandwidth data transfers, Graphics Processor Unit (GPU) -based video stitching, and techniques for optimally rendering to the individual display characteristics of specific VR HMDs for on-set preview.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Virtual Reality",
                      "Video Stitching",
                      "GPU",
                      "Post Production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001699"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Re-Energize Entertainment Engineering: How to Blend the Experience of Yesterday with Millennials' Vision of Tomorrow",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kellie McKeown",
                    "Jennifer Zeidan",
                    "Joshua Berkowitz",
                    "Matthew Donato",
                    "Abel Lawal",
                    "Jaclyn Pytlarz",
                    "Stephanie Wu"
                  ],
                  "abstract": "With the average age of SMPTE members increasing, the entertainment industry needs to attract and retain young engineers to strengthen our ranks and our future. Millennials are key consumers of our products, but how do we attract them to the industry as technical professionals? The differences between Baby Boomers, Generation Xers and Millennials are vast in everything from work philosophy, to pace, to professional goals. Is the entertainment industry properly equipped to recruit, manage, mentor and retain this new generation? — This paper is a compilation of the essays listed below by Millennial engineers in the entertainment industry - all in their 20s - with observations, ideas and recommendations on how to engage with their generation. Highlights include the benefits of a corporate program targeted at recruiting and training Millennials, SMPTE education outreach and hiring non-engineers for engineering positions. • “Evaluate Millennials On Our Potential, Not Our Experience”, by Joshua Berkowitz • “How Motion Pictures and Television Found Me”, by Abel Lawal • “Education and Engagement with the Millennial Generation”, by Matthew Donato • “Working Together: A Bridge of Understanding from Millennials to Baby Boomers and Generation X”, by Jaclyn Pytlarz • “Competition vs. Collaboration: How Entertainment Engineering can Benefit from the ‘Open Source’ Generation”, by Jennifer Zeidan • “It's All About Personalization”, by Stephanie Wu — It is hoped that these essays will be widely read, considered and embraced to help the entertainment industry fully benefit from the talents and energy of the Millennial generation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "millennial",
                      "millennials",
                      "generations",
                      "generational",
                      "cross-generation",
                      "baby boomers",
                      "generation X",
                      "generation Y",
                      "generation Z",
                      "gen X",
                      "gen Y",
                      "gen Z",
                      "diversity",
                      "entertainment industry",
                      "engineers",
                      "engineering",
                      "entertainment engineers",
                      "entertainment engineering",
                      "television engineers",
                      "motion picture engineers",
                      "careers",
                      "recruiting",
                      "hiring",
                      "students",
                      "graduates",
                      "applicants",
                      "college",
                      "university",
                      "mentor",
                      "mentoring",
                      "collaboration"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001716"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Research on the Movie Theater Requirements for Multiple-Screen Projection",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sungmin Cho",
                    "Yanghyun Choi",
                    "Chongwook Chang",
                    "Younghui Kim"
                  ],
                  "abstract": "Thanks to digital technology, the current theater has developed a way of viewing which targets to further enlarge the sense of immersion. Recently, a new technique called “ScreenX” which utilizes multiple screens has been introduced. ScreenX uses the existing theater screen at the center and projects both sides of the theater walls directly, which then helps audiences to feel more immersed and experienced. We concentrated on the subject of how multiple-screen environments affect fatigue and presence to the audience through experiments based on ScreenX. Experimental results showed that fatigue got lower and presence went higher when the frame rate went up. The rear seat had a lower sense of existence than the central seat. In terms of brightness and resolution, spectators were not affected on fatigue and presence. We found that the relationship between the position of the spectator and the space of the multiple screens greatly affected presence and fatigue more than any other media.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "multiple-sreen",
                      "visual fatigue",
                      "visual discomfort",
                      "presence"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001718"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Reinventing Content Storage to Solve Today's and Tomorrow's Media Workflow Challenges : Making the Case for Intelligent and Agile Storage Platforms",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Colantuoni"
                  ],
                  "abstract": "The content storage landscape is changing rapidly as media professionals face new challenges, new technologies, and new ways of working. Media organizations will increasingly need to rely on cloud storage and services, and media services and asset management in the cloud to give them the flexibility and scale to effectively manage higher resolution formats and huge volumes of ingested content, drive efficiency, and enable any member of the production team to access content from everywhere. — This paper will provide an overview of the evolving digital media ecosystem and the fundamental need for streamlined storage. It will outline the challenges media professionals face with storage today, and explore technology innovations that can help overcome them. It will describe the technology underlying Avid NEXIS, the first software-defined storage platform for media that enables true storage virtualization for any media application.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud storage",
                      "software defined storage",
                      "platform",
                      "virtualization"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001717"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Securing IMF",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Diehl"
                  ],
                  "abstract": "The Interoperable Media Format (IMF) may become the preferred method for Business to Business distribution of content. Unfortunately, it lacks some useful features such as security. Secure IMF (sIMF) is an add-on to IMF that solves this issue without modifying the current IMF specifications. The proposed key management allows a content provider to use the same IMF package for all its licensees without compromising security and traceability. An optional watermarking module serializes the decrypted package uniquely for each recipient. Thus, sIMF would reduce the preparation and distribution costs while boosting the security.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IMF",
                      "security",
                      "encryption",
                      "watermark"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001722"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Screen Brightness Uniformity: Analysis and Comparisons",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dave Coleman"
                  ],
                  "abstract": "Many competing factors must be evaluated in order to optimize the visual theatrical presentation. For example, considering only visual factors, when choosing the projection screen one must consider brightness, brightness uniformity, dynamic range (contrast ratio), and uniform field contrast ratio (screen texture, perforations, and speckle). Notably, the brightness uniformity is especially difficult to address because it varies from seat to seat depending upon auditorium geometry and screen curvature. Furthermore, the brightness uniformity requires some form of multipoint measurement that must be analyzed to compare different configurations. We will present both modeling and measurements of screen brightness and brightness uniformity. We will then introduce both a seat and an auditorium “Q-Factor” to quantitatively compare the brightness uniformity between different setups. We will then use this metric to define an optimum screen curvature.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Projection",
                      "Brightness Uniformity",
                      "Screen",
                      "Measurement",
                      "Cinema",
                      "3D"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001721"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Security in the Cloud with IMF",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bruce Devlin",
                    "Eric Carson"
                  ],
                  "abstract": "With the number of media platforms increasing and the demand for regionalization and localization increasing, technology such as IMF from SMPTE opens the door for standardized interchange of versioned content. This paper looks at the security concerns that might need to be addressed and some of the technologies that address those concerns when high quality versionable masters are stored in the cloud for rendering directly into a customer's delivery format. The paper considers many issues of security and efficiency including • identity of the parties trading an asset • establishing trust between parties • encrypting the media • authenticating access to the media • ownership of media components, technical metadata, delivery profiles and transaction metadata • compromises between security and efficiency.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IMF",
                      "security",
                      "encryption",
                      "transformation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001723"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "“The Suitcase”: Using C4, Semantics and NoSQL for Managing Motion Picture Data",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nancy Silver",
                    "Kaki Ettinger",
                    "Joshua Kolden",
                    "Michael Malgeri",
                    "Erik Weaver"
                  ],
                  "abstract": "Today's television and motion picture production workflows make it incredibly challenging to preserve and manage data throughout the production lifecycle. The Entertainment Technology Center at the University of Southern California addresses this data dilemma through “The Suitcase” Project. “The Suitcase” is a short film created by Abi Damaris Corbin with a technical test led by the ETC Production in the Cloud Working Group. This paper examines the process of upstream authoritative metadata extraction so that it does not have to be recreated downstream, as well as processes for creating and enhancing metadata farther downstream when necessary. This document discusses how to effectively use C4 framework - Cinema Content Creation Cloud, semantics and NoSQL technologies to manage motion picture content, tagging metadata so that it can be leveraged for software applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Metadata",
                      "C4",
                      "NoSQL",
                      "Semantics",
                      "Data Integration",
                      "Production in the Cloud"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001715"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Techniques to Detect Modified Video",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward T. Grogan"
                  ],
                  "abstract": "In today's multimedia world billions of photographs and videos are generated each day. Of these, about 30,000 are obtained by the U.S. government for law enforcement and intelligence purposes. These could be photos and videos of people, to include child pornography, that are of interest to the FBI, videos from surveillance cameras, or photos and videos obtained from foreign adversaries that may be a threat to the United States. Material may also be multimedia submitted to news services or posted to the internet that portray world events that could affect decisions made by our leadership. — Of these images or videos, some could have been altered to improve the artistic appearance or story telling aspects of the material, but some of the alterations may have been done to change the narrative to influence events, spread false information, or provide misdirection. — This paper will discuss two aspects of detection of alteration: first the DARPA program MediFor, which is a large program to develop software that would automatically scan every piece of material received and flag those pieces that have indications of being altered. The second part will describe some of the tests that have been done manually through the years to identify falsified material without the aid of the technology that is now being developed for the Medifor program.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Forensics",
                      "video",
                      "photographs",
                      "forgery",
                      "fake",
                      "spoof",
                      "modifications"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001724"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "The Challenges of Forensic Watermarking UHD/HDR Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mehmet U. Celik",
                    "Jaap Haitsma"
                  ],
                  "abstract": "For the past decade forensic watermarking has become an important tool for major content owners to protect their high value content against piracy. Tracking the advances in consumer electronics, content owners are making higher quality content directly available to consumers in the form of video with 4K resolution, Wide Color Gamut (WCG), High Frame Rate (HFR) and High Dynamic Range (HDR). — Watermarking algorithms face new challenges due to the introduction of new formats, better displays and higher quality video. More elaborate visual models are needed to ensure imperceptibility under better reproduction, whereas dramatically increased uncompressed data rates challenge computational efficiency. At the same time, the watermark should survive down conversions in resolution, color gamut, frame rate and dynamic range. This paper describes how 4K, WCG, HFR and HDR formats impact watermarking algorithms and presents approaches to handle these challenges.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Watermarking",
                      "forensic tracking",
                      "UHD",
                      "HDR",
                      "WCG",
                      "HFR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001725"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "The Resolution Revolution: How Many Bits Do We Really Need?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Cooper",
                    "Sue Farrell"
                  ],
                  "abstract": "As technology develops, the resolution of audiovisual reproduction is rising rapidly in every dimension in the quest for increasing quality and fidelity. Technical standards previously considered sufficient to reproduce sounds and images in the digital domain may no longer be adequate. Image resolution is increasing but even 4K frames are only 8 megapixels, which is relatively low in photographic terms. Higher resolutions and bit depths may be required. Video frame rates have been sufficient to provide the illusion of continuous movement, but higher frame rates may be beneficial. This paper challenges conventional wisdom on the resolutions required to reproduce convincing audiovisual representations. It proposes that digital compression may be used to allow increased sampling resolution and precision while maintaining practical data rates.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "perception",
                      "images",
                      "visual",
                      "video",
                      "resolution",
                      "sampling",
                      "quality",
                      "fidelity",
                      "bit depth"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001728"
                  }
                }
              },
              {
                "article_local_id": "59",
                "article_title": "VP9 Encoder and Decoders for Next Generation Online Video Platforms and Services",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/59/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mukund Srinivasan"
                  ],
                  "abstract": "VP9, an emerging compression technology, promises up to 2x bandwidth gains over the current H.264 and VP8 formats. As a result, VP9 contributes to enhanced user experience for video consumption and is driving adoption of higher resolutions like 4K/UHD enabling stronger growth in online video. The advantages offered by VP9 have been extensively leveraged by Google and YouTube to enhance its video services. — With most advancements in video codec technologies, big gains in compression are accompanied with a significant increase in processing complexity. Ittiam, in collaboration with the Google webM team and the Alliance for Open Media (AOM), has worked extensively on VP9 codecs to improve the usability and practicality of VP9 software. This paper provides an overview of the VP9 standard, its relevance and benefits to the online video industry. It also includes an objective comparison of VP9 with H.264 software on parameters like bandwidth compression and encoding complexity. Through the comparison, the paper identifies key challenges with currently available VP9 implementations and provides an overview of the performance and quality gains achieved by Ittiam's VP9 software.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VP9",
                      "Alliance for Open Media (AOM)",
                      "OTT",
                      "Video Compression",
                      "GPU",
                      "OpenCL",
                      "Video Optimizations",
                      "Video Quality"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001734"
                  }
                }
              },
              {
                "article_local_id": "55",
                "article_title": "Through The Smoke: A Look At Industry Trends",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/55/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matt Eaton",
                    "Kim Lucin",
                    "Blake White",
                    "John Footen"
                  ],
                  "abstract": "Ultra-high-definition services are poised for greater adoption and drive customer engagement, especially among sports fans. Meanwhile, consumers are turning to OTT and “second screens” to broaden the scope of their viewing experiences and engage more interactively with content and communities. These evolving viewing behaviors bring about new opportunities in the area of social analytics. Broadcasting companies are also focusing on content planning, supply-chain, discovery and production. Telcos and new-age OTT entrants are changing the content rights landscape. Change remains constant.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Enabling technologies",
                      "D2C",
                      "OTT",
                      "4K",
                      "UHD",
                      "HDR",
                      "HFR",
                      "metadata/content discovery",
                      "end-to-end",
                      "IP workflows",
                      "cloud-based",
                      "storage",
                      "distribution",
                      "consumer behavior",
                      "business opportunities",
                      "second screen",
                      "content rights",
                      "VOD",
                      "Analytics",
                      "UGC"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001730"
                  }
                }
              },
              {
                "article_local_id": "52",
                "article_title": "The Future's So Bright, I Gotta Wear Shades: Test Patterns for HDR",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/52/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "R. Norman Hurst"
                  ],
                  "abstract": "High Dynamic Range (HDR) and Wide Color Gamut (WCG) technology present challenges to the design of a test pattern for visual verification of systems. The previous “Rec. 709” paradigm defined a “zero-to-one-hundred-percent” scale, and the entire system and any reasonable display could be expected to show the full range of code values. However, SMPTE-2084 defines an absolute correspondence from code values up to 10,000 nits (candelas per square meter) and even professional monitors will clip at some lower brightness level unique to their particular design. Furthermore, the BT-2020 color gamut “container” exceeds the gamut of any professional monitor, so colors that are outside of a monitor's particular gamut capability will be modified by the monitor. This lack of dependable behavior of monitors at the extremes of color and brightness creates additional challenges for the design of visual test patterns.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "HDR",
                      "Wide Color Gamut",
                      "WCG",
                      "Test Patterns",
                      "Testing",
                      "Video Testing",
                      "nits"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001726"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Virtualization: Changing the Face and the Pace of Master Control Projects",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Openshaw"
                  ],
                  "abstract": "While the cloud and virtualization are no secrets to IT professionals, broadcasters and content creators are actively discussing the ways in which moving more processes to the cloud makes sense. Large data centers are a perfect fit for storage and distribution of file-based media, but what about live broadcast playout of fully-featured channels? There is a growing desire to quickly and efficiently deploy or contract IP-based channels in an instant without the burden of racks of complicated hardware, and weeks or months of setup and provisioning. However, broadcasters are a risk-averse group by nature. Have virtual machines running in secure data centers matured to the level required for 24/7 reliable broadcast applications? This paper will explore how virtualization, software-defined video pipelines and intelligent orchestration are changing the face, and the pace, of playout and master control projects.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Master control",
                      "virtualization",
                      "virtualized playout",
                      "cloud",
                      "IP video",
                      "orchestration",
                      "popup channel",
                      "fast deployment",
                      "video pipeline",
                      "data center"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001732"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Titling for Live Streaming and File-Based Broadcast Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Scott Matics",
                    "Todor Fay"
                  ],
                  "abstract": "Animated titles, like lower thirds, bugs, tickers, and scoreline readouts have become a standard for live, over-the-air broadcasts. For live streaming, and for video on demand (VOD) content, however, adding these same rich, animated, and variable title assets can present significant challenges for broadcasters and content creators. Modern streaming and VOD workflows need to leverage template driven graphics and titling workflows that look great on both large screens as well as mobile devices. This paper explores new and emerging technologies for creating rich, animated titles, and for applying them to streams and assembling them into on demand and online broadcast workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "broadcast graphics",
                      "streaming graphics",
                      "live titles",
                      "animated titles",
                      "automated title assembly",
                      "live streaming playout graphics automation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001731"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Virtually Perfect: Factors Affecting the Quality of a VR Experience and the need for a VR Content Quality Standard",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202016%20Annual%20Technical%20Conference%20and%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre Routhier"
                  ],
                  "abstract": "New virtual reality (VR) capture, gaming and viewing devices are hitting the shelves at an accelerated pace. While this commercial push favors the integration of VR devices into everyday life, the quality of experience is not always up to par: Improperly produced content can generate physical stress and/or interrupt a viewer's suspension of disbelief. Without clear and common standards, it is hard to achieve a consistent product that will meet customer expectations beyond the initial novelty factor. The paper suggests a foundation for a content quality standard, based on the author's experience shooting and analyzing hundreds of 360-video experiences, with criteria for stitching, physical integrity, artifacts, stereoscopic 3D, framing and composition. For each criterion, the paper describes a suggested benchmark, issues to avoid, causes, effects on the viewer, plus preventive and corrective measures.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2016-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VR",
                      "360-video",
                      "quality",
                      "standards",
                      "HMD",
                      "Virtual Reality"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001733"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2015",
        "conferences": [
          {
            "conference_name": "SMPTE15: Persistence of Vision - Defining the Future",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/",
            "articles": [
              {
                "article_local_id": "5",
                "article_title": "Broadcast in the Age of Disruption",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Aude Vignelles",
                    "David Marshall"
                  ],
                  "abstract": "Technology evolution is disrupting traditional television consumption, resulting in varying levels of broadcast audience decline across the globe. Although the TV screen remains the centrepiece of the living room, the way we consume content has gone through a radical change. Changes in business models underpinning content delivery are required. This paper will examine the dynamics of audience shift, how advances in broadband technology have introduced a new channel to deliver content, how this has led to new content service delivery, and how innovation in video-playing devices has created a competitor to the TV. It will focus on how traditional broadcasters and pay TV operators can not only deal with the threat of Internet TV but grow their brand in doing so.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Disruption",
                      "television",
                      "internet TV",
                      "traditional broadcasters",
                      "pay TV operators"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001600"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "The Connected Media Ecosystem",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Jones"
                  ],
                  "abstract": "This presentation discusses how emerging technologies such as SDN, NFV, Cloud and OTN will integrate to support current and emerging video business requirements. — We will explore the potential and the possibilities whilst also investigating the substantial technical challenges that need to be overcome. — The presentation will centre on contribution video networks and expand into the adjacent platforms and technologies through to distribution to develop an end to end appreciation of the landscape.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "DVN",
                      "DVN2",
                      "Contribution",
                      "SDN",
                      "OTN",
                      "SMPTE-2022",
                      "SMPTE- 2059",
                      "NFV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001615"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Changing the Game: A Guide to Cost-Efficient Software-Based HEVC Video Processing Deployment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Cousins"
                  ],
                  "abstract": "The new HEVC/H.265 codec offers many advantages vital to new revenue-generation opportunities and service game changers across the industry, such as: • Addition of more channels and increased quality at lower bitrates • Improved consumer quality of experience • Multiscreen CDN opex reduction • 4K Ultra HD enablement • Faster file downloads for mobile video viewing • Improved streamed content quality • Reduced video storage in device memory. • More storage capacity for large libraries — The transition to HEVC video processing infrastructures– particularly for large installed MPEG-2 and H.264 installed bases – must also make economic sense. There are a set of common, tough questions to pose when planning transitions to HEVC-enabled video processing infrastructure: • Can it deliver a fully functional implementation of real-time HEVC encoding at 1080P? • Is it optimized for easy migration from legacy compression codecs? • Can it handle the increased processing power and decision/tradeoff complexity required to power HEVC? • Is it optimized to minimize total cost of ownership? • Will it evolve your infrastructure or leave you stranded as the HEVC codec evolves? — Software-upgradeable solutions can incorporate these new compression approaches much more quickly and cost-efficiently than fixed-hardware encoding platforms, such as ASICs and DSPs. This presentation will provide a practical guide to software-based HEVC deployment through the evolving video ecosystem.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High-Efficiency Video Coding (HEVC)",
                      "H.265",
                      "software-defined video",
                      "video compression",
                      "4K",
                      "Ultra HD",
                      "video processing",
                      "MPEG-2",
                      "H.264",
                      "CDN",
                      "Content Delivery Network",
                      "MPEG-DASH",
                      "Codec",
                      "Red Bull",
                      "Akamai",
                      "Samsung",
                      "World Cup",
                      "Olympics"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001597"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "DASH 2015: Where are We at and what Next",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Sinclair"
                  ],
                  "abstract": "MPEG-DASH has promise as a multi bitrate format supporting a wide range of features including live, on demand, DRM, captions and more that would supersede existing standards such as Smooth Streaming, HDS and HLS. It now has wide ranging support from major software and device manufacturers with the notable exception being Apple. While it is now possible to have DASH play on just about any device the implementation to date has not been consistent. This is partially due to MPEG-DASH the standard having been developed by many parties with specific existing requirements. One of the issues is that as a specification that has many variations, every player developer is free to support the parts of the specification that they require and as a result what works for one player doesn't work on another. One of the particularly large issues that is emerging in this area is the adoption of DRM in the browser and what is looking to be a very fragmented adoption of Media Source Extensions, Encrypted Media Extensions and Content Decryption Modules. This paper covers an overview on where we are at in regard to existing variations on the DASH standard, what is available in the content generation tool chain, what players we have supporting what elements of the standard and what is developing in the coming year in regard to DRM.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Dynamic Adaptive Streaming over HTTP",
                      "DASH",
                      "DRM",
                      "Encrypted Media Extensions",
                      "EME",
                      "Media Source Extensions",
                      "MSE",
                      "Content Decryption Module",
                      "CDM",
                      "MPEG-DASH",
                      "Common Encryption",
                      "CENC",
                      "Smooth Streaming",
                      "HTTP Dynamic Streaming",
                      "HDS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001598"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Moving High to Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fabio Gattari"
                  ],
                  "abstract": "Technology is moving from the traditional tape to file and from file to cloud but, how can you manage your private cloud? What is changing in the cloud and why it is better, is it because it's easy to learn?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001599"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Maximizing the Potential of Legacy Content in New Media Asset Management Deployments",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Savva Mueller"
                  ],
                  "abstract": "Media asset management systems provide excellent tools for managing new content that you ingest and create, but are often limited in their ability to manage legacy content that existed before the asset management system was commissioned. Tape access standards such as LTFS and advanced file wrappers enhance asset portability and interchange going forward, but additional technology is required to address legacy archives and leverage valuable metadata in their associated databases. Meanwhile, the ability to leverage unstructured metadata including related documents and closed captions can provide the asset management system with rich, otherwise-unavailable metadata for legacy content without significant manual effort.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media Asset Management",
                      "MAM",
                      "Content Storage Management",
                      "CSM",
                      "archive",
                      "asset management",
                      "metadata",
                      "unstructured metadata",
                      "LTO",
                      "LTFS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001612"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Effect of UHD High Frame Rates (HFR) on DVB-S2 Bit Error Rate (BER)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Urvashi Pal",
                    "Horace King"
                  ],
                  "abstract": "In this paper, signal performance of High Frame Rates (HFR) of Ultra High Definition (UHD) and High Definition (HD) video transmission has been analyzed using the future broadcast scenario of multiple resolution (1080p, 2160p), frame rates (25fps, 50fps) and video compression methods (Moving Picture Experts Grough/ MPEG-4 and High Efficiency Video Coding/ HEVC). Sixteen different video samples are transmitted through the Digital Video broadcasting using Satellite Second Generation (DVB-S2) module with 8PSK modulation scheme and 5/6 code rate, in the presence of Additive White Gaussian Noise (AWGN). The results show that the Bit Error Rate (BER) decreases as the frame rate increases; UHD videos have higher BER than HD; and HEVC video compression results in a lower BER than MPEG-4. These results will contribute towards developing the DVB-UHD broadcast standards and the migration strategies, from HD to UHD.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HD",
                      "HD+",
                      "UHD",
                      "4K",
                      "HFR",
                      "MPEG-4",
                      "HEVC",
                      "DVB-S2",
                      "8PSK",
                      "BER"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001606"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "What can We Learn from the Last 100 SMPTE Years? What will Tell Us about the Next 10?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gerard Hosier"
                  ],
                  "abstract": "SMPTE celebrates its 100th Anniversary and a lot has changed in those years. B&W film, colour film, television with its evolving quality, computing, Internet, handheld computing, 3D, Smart TV's and the emerging technologies of data-mining with Deep Data Analysis. Does the history of these ideas give us a clue as to what the next big thrust is. Perhaps we should not only look through the front door but also the back door. Be surprised.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "History",
                      "Big Data",
                      "DDN",
                      "plenoptic photography",
                      "Near Field photography",
                      "Artificial intelligence",
                      "NextVR",
                      "360 cameras",
                      "robot",
                      "picture recognition",
                      "facial recognition",
                      "voice recognition",
                      "smart TV",
                      "Lytro",
                      "ambient intelligence",
                      "Google",
                      "B&W Film",
                      "colour film",
                      "television",
                      "computing",
                      "Internet",
                      "handheld computing",
                      "3D",
                      "Smart TV",
                      "data-mining",
                      "Deep Data Analysis",
                      "future",
                      "robots",
                      "cloud",
                      "history",
                      "Futurama"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001601"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Workflow Optimised Storage Key Differentiator in High Resolution Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alex Grossman",
                    "Skip Levens"
                  ],
                  "abstract": "High resolution content is everywhere — fickle consumers with giant digital appetites demand the highest available resolution of content on an ever-multiplying array devices with ‘always on’ high-speed connections. Content services are noisily adopting ‘ultra high definition’ - and cameras, TV's and more are all moving to 4K resolution or higher. — To keep up with this demand, content creators must evaluate their entire content creation and production workflow and ask: “Can my current production workflow keep up with the pace of operation and the higher resolution content? Is every aspect of my workflow – from editing to content management to storage and delivery able to meet the challenge?”",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Storage",
                      "Workflow",
                      "Ultra-High Resolution",
                      "4K",
                      "UHD"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001613"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Into Thin Air: The Cloud Conflict",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Danny Wilson"
                  ],
                  "abstract": "Continued advances in compression techniques have resulted in higher quality content over ever declining links. Furthermore, the internet services continue to speed up. This critical combination is putting additional pressure on the traditional TV players as consumers have more consumption avenues, added distraction, and increased sources of content (for example, user-generated content). — Some have said the rise of the internet, Cloud-based encoding and playout centers offer tremendous new opportunities for broadcasters to provide better service at lower cost. However, at the same time, surging smart phone penetration and the consequent escalation in mobile data usage is driving mobile operators to seek out more RF spectrum needed to offer LTE and other 4G services. Broadcasters are inadequately equipped and under-funded compared to the wealth of the telecom industry. Therefore, this spectrum competition from mobile operators spells a bleak picture for the traditional cable, satellite, and terrestrial delivery of TV. — So, what does the future look like, and how can you “grab hold of” the cloud? This paper presents a non-vendor, plain language introduction and review of key cloud technologies, presents the political and economic changes now underway, and presents the growth opportunities (or risks of extinction) of the broadcast industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud Computing",
                      "OTT",
                      "IT for Television"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001602"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Why is High Dynamic Range Critical to Live Ultra HD and How Might it be Implemented?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ian Trow"
                  ],
                  "abstract": "Improved resolution has been the principle justification for the adoption of 4K / Ultra HD to date, leading many to question the benefit of UHD when compared to existing HD 1080p services at typical access bandwidths available to viewers. Since resolution alone isn't enough to give UHD the fidelity expected, there has been renewed interest in implementing High Dynamic Range (HDR) along with the related issue of Wider Color Gamut. To date HDR has been demonstrated on content prepared offline, leaving the question of how HDR can be implemented on live content? This paper will explain why HDR is needed, outline the likely implementations, discuss the impact on existing workflows and implications for existing and future screen requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ultra High Definition",
                      "UHD",
                      "4k",
                      "4K",
                      "Wide Color Gamut",
                      "WCG",
                      "Video Workflow",
                      "UHD VoD",
                      "OTT",
                      "ITU-R Rec.2020",
                      "ITU-R Rec.709",
                      "High Dynamic Range",
                      "HDR",
                      "Video Usability Indicator",
                      "VUI",
                      "Supplemental Enhancement Informtation",
                      "SEI",
                      "HDR Static Metadata Extensions",
                      "HDMI2.0a"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001605"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "4K/UHD Viewing: The Whole Truth and Nothing but the Truth",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Josef Marc"
                  ],
                  "abstract": "When watching video, we assume we're seeing everything - “the whole truth.” But really we're seeing a version of the truth; adjustments have been made based on whatever the display interface can accommodate. But it is possible to see the whole truth on any screen, even in 4K and UHD. You simply need the right display interfaces. — This paper will explain how choosing the right cables can make all the difference in getting the video from the player to the screen. Using video from several historical eras and 4K 60p, the presentation will demonstrate how to determine the best connections for any situation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHD",
                      "SDI",
                      "HDMI",
                      "DisplayPort",
                      "4K digital cinema",
                      "IMF",
                      "high dynamic range",
                      "HDR",
                      "high frame rate",
                      "HFR",
                      "wide color gamut",
                      "BT.2020",
                      "P3"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001604"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Looking to the Cloud for Multiscreen Video Contribution Management",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bogdan Frusina"
                  ],
                  "abstract": "In today's highly complex video and broadcast operations, broadcasters are constantly challenged to reliably deliver low-latency, high-quality video to multiscreen audiences on-air and online. Media operations have plenty to learn from today's corporate IT environments, many of which have migrated to a virtualized computing model that shifts processing away from physical hardware on premises and locates critical functions, such as video distribution, in the cloud. In this presentation, we will describe a cloud-based management system for a broadcast facility that performs routing of contribution content and online publishing services within a virtual, centralized cloud infrastructure, while providing real-time and historical analytics. The cloud-based setup can manage live feeds, remote transmissions from bonded wireless transmitters, and network feeds, while allowing users to also record and transfer files effortlessly. Acting as a type of virtual sub-router for the main HD router, this solution integrates into a wide range of broadcast IP-based workflows and gives the operator a single dashboard for managing contribution assets and viewing and routing content—thereby offering a powerful toolset for simultaneously distributing low-latency, high-quality live content across multiple delivery platforms.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud",
                      "Virtualization",
                      "High-quality Video",
                      "Low Latency",
                      "Multiscreen",
                      "Cloud Infrastructure",
                      "Live Content",
                      "Video Over IP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001608"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "“Ensuring a Persistence of Vision – Preserving Archival Footage for Future Generations”",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dominic Hundleby"
                  ],
                  "abstract": "This presentation is intended to provide an overview of the National Archives of Australia's digitisation process for non-theatrical motion picture film. The Archives has one of the largest collections in Australia comprising approximately 260,000 films, ranging from early nitrate to modern polyester. The vast majority of the collection is 16mm, although nearly all types of film (from original and intermediate components to prints) are represented. These films vary considerably in their overall condition, which affects both long-term preservation and viewing. Discussion will focus on the differing requirements of archival preservation as opposed to restoration activities, as well as the importance of experience and skills in this area.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Film preservation",
                      "digitisation",
                      "archival"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001611"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Camera Raw for High Dynamic Range Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward Reuss",
                    "Lars Borg"
                  ],
                  "abstract": "This paper presents how all camera raw formats work in common, and also the different approaches used by several vendors to preserve the highest fidelity image information, while managing the large amounts of data required to represent those images. Camera raw workflows provide a variety of techniques to convert from the sensor data into RGB image formats suitable for mastering, along with methods for generating a specific “look” to the images. The tremendous dynamic range afforded by a camera raw format permits a wide range of exposure during acquisition, which can be mapped into either the limited standard dynamic range of conventional output image formats or leveraged for use in the new High Dynamic Range (HDR) image formats. However, looks and camera specifications can be deceiving and one must know what is happening within the workflow to obtain the best image quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Camera raw",
                      "image processing",
                      "demosaic",
                      "video compression",
                      "JPEG 2000",
                      "VC-5",
                      "CineForm",
                      "Dynamic Range",
                      "noise",
                      "High Dynamic Range",
                      "HDR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001618"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Better Color Conversions for HDR and UHD TV Productions",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lars Borg"
                  ],
                  "abstract": "The introduction of high-dynamic-range (HDR) color spaces and ultra-high-definition's (UHD) wide-color-gamut (WCG) color space in television creates a need to match colors on HDR and WCG displays with colors on conventional high-definition (HD) displays. Many contemporary color conversion methods that apply to conversion from HD to standard definition (SD), and color conversion methods mandated by current television standards, fail to produce a good color match when converting colors from the HDTV color space to HDR or WCG color spaces. This impairs the quality of HDTV contributions to HDR and UHD productions, as well as the quality of distribution of programs originating in HDR or UHD to HDTV viewers. This paper illustrates the color errors caused by the application of several of these conversion methods, and recommends one method, using display-referred colorimetry, for better color matching between narrow-gamut, wide-gamut and high-dynamic-range displays.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High dynamic range",
                      "HDR",
                      "wide color gamut",
                      "Ultra-HD",
                      "Rec. 2020",
                      "color conversion",
                      "BT.1886",
                      "display-referred colorimetry"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001609"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Colour Grading with Colour Management",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Postma",
                    "Bob Chorley"
                  ],
                  "abstract": "Many productions today shoot with more than one model of camera which create images in different colour spaces. The final project also often needs to be mastered for delivery to different displays (Rec709, P3, Rec2020, HDR). This is a problem best addressed with carefully constructed colour management, yet there is an overwhelming trend in the industry for colourists to simply take images as they come out of the camera, look at them on their display, and twist the knobs until it looks “good.” This is something colour grading tools were never designed to do well, leaving many scrambling to try and find LUTs to achieve the desired look without generating image artefacts. There is a better way — using comprehensive colour management as a foundation for creative colour correction. — Comprehensive colour management takes into account the colour space of cameras and displays, and connects everything through a common colour space for grading. The space chosen to grade in needs to be carefully chosen as it can have a huge impact on the look, quality, and dynamic range of the images that can be produced with common colour grading tools. The Academy Color Encoding System (ACES) is an example of a framework that can be used in whole or in part to provide comprehensive colour management.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "colour management",
                      "colour correction",
                      "ACES"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001610"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "An Analysis of the Impact of HEVC on Existing Media Businesses",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Marshall",
                    "Erica Robinson"
                  ],
                  "abstract": "In 2013 the MPEG consortium ratified the h.265 High Efficiency Video Coding (HEVC) compression standard, and manufacturers are beginning to implement this. The paper examines the likely adoption curves and timelines for viable HEVC-based television, mobile and PC/laptop-based audiences, and covers both the consumption/decoder and operator/encoder domains. The paper uses a percentage-based approach for all analysis, modeling and prediction, to identify “inflection points” rather than quantify a number of units and to give the findings a wider applicability. Analysis shows that mobile phone and PC/laptop-based video audiences already have sufficient processing power on their devices to handle software decode of most 720p/1080p HEVC video content, with tablet audiences reaching this point by late 2017. Mobile phone-based audiences will be over 95% hardware decode capable by 2017, with tablet audiences reaching this point by 2020 and PC/laptop audiences by 2021. Television-based audiences (whether via Smart TV or other attached device such as STB, Blu-ray player or games console) will be 10% hardware decode capable my mid-2016, 50% capable in mid-2019 and 95% capable by 2023.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "h.265",
                      "codec",
                      "adoption",
                      "timeline",
                      "service delivery",
                      "h.264",
                      "AVC"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001596"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Layered Division Multiplexing: Basics Concepts, Application Scenarios and Performance",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pablo Angueira"
                  ],
                  "abstract": "This paper presents Layered Division Multiplexing (LDM), a technology that may be used to provide a flexible multi-layer system transmission by means of spectrum overlay. This technology can be used to simultaneously deliver multiple program streams with different characteristics and robustness for different services (mobile TV, HDTV and UHDTV) in one RF channel. — In Layer Division Multiplex (LDM) the signal to be transmitted consists of a number of different independent signals superimposed together at different injection levels to form a multi-layer signal. Each layer can have its own characteristics. The top layer is the most robust one, which has a negative Signal to Noise Ratio (SNR) system threshold value, and can be used for robust mobile service. The lower layer(s) can be used to provide fixed high data rate services, such as multiple High Definition Television (HDTV) and Ultra High Definition Television (UHDTV). For example, DVB-T2, or an alternative design of a high data rate transmission system can be used for the second layer. The upper layer signal can be a separate program, or be used for delivering supplementary bit rate to be combined with the lower layer signal to provide additional features or achieve higher quality of service (e.g., scalable video coding and placing audio on upper layer for extra robustness).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital Terrestrial Television",
                      "DVB-T2",
                      "ATSC 3.0",
                      "Layered Division Multiplexing",
                      "Cloud Transmission",
                      "UHDTV",
                      "SHEVC",
                      "Mobile TV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001607"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "SCAsat Audio Distribution “Best of Satellite, Best of WAN”",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matt Steadman",
                    "Steve Adler"
                  ],
                  "abstract": "When a new broadcasting corporation was formed from the merging of several existing broadcaster groups, challenges arose in terms of cost, compatibility, and consolidated operations. The mergers had resulted in the continent-wide contribution / distribution audio network being a patchwork quilt of incompatible networks and systems. Centralised, or even efficient management was impossible. Engineers from the broadcaster, along with software, hardware, and IT professionals, working together over two years fully developed, extensively tested, and have now deployed an ideal audio contribution / distribution solution. Each individual piece of technology works together providing a cost-effective, reliable, and user-friendly audio and metadata network. The solution incorporates persistently redundant delivery, backup head-ends, multiple contribution points, plus full metadata and GPIO, to provide multiple channels of scheduled and ad-hoc audio. This paper and presentation describe the parameters, challenges, and technical solutions such that other engineers and broadcasters may integrate or even duplicate the process and results.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Radio",
                      "Audio Distribution",
                      "Audio over IP",
                      "Satellite",
                      "Codec",
                      "Encoding",
                      "Decoding",
                      "Broadcast"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001603"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Using IMF for International Distribution? What Does that Mean?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bruce Devlin",
                    "Raoul Cospen"
                  ],
                  "abstract": "IMF is nothing to do with the International Monetary Fund. It is an Application Specification of MXF being developed within the SMPTE. The goal is to create a delivery format that meets the business needs of shipping versioned content around a country and around the world. This presentation will be in 3 parts - (1) a review of IMF technology and how it works (2) a review of IMF workflows that could exist when an IMF ecosystem exists (3) Some of the savings that might be realised by using IMF. The presentation will consider not only the file formats and processes, but also the preservation of multi-platform captions, metadata and media life cycles within MAM systems as well as the benefits that can be achieved by considering versioning from the initial concept of a programme.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IMF",
                      "MXF",
                      "distribution",
                      "file based"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001614"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Ungluing Audio and Video - How Audio over IP Enables the Future",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Tankel"
                  ],
                  "abstract": "After decades of work to successfully carry audio and video over the same serial digital interface (SDI), arguably the time has come to split them apart again. Audio embedding and de-embedding was never perfect and remains limited. Carriage of metadata, which will become more essential with new services, is currently inaccurate and complex. Unbelievably, lip sync issues are worse than ever before. Further, channel based audio is heading for replacement by carriage of the objects that make up the channels. This enables flexibility and enhanced consumer experiences for broadcast and OTT services. SDI is, at heart, a video format and it cannot support the future of audio. Alarmingly, the future is ringing the front bell today. AES67, Livewire+ and related standards offer a path to making all of this work – including lip sync! AES and SMPTE are working together, and the results will enable the sub-sample accurate linking of Audio over IP (which has existed in radio for over a decade and is growing in TV) and video, all without requiring it to be glued together until the very end.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001619"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "How AES-67, the New Audio-over-IP Standard, Will Bring the Convergence of Telecommunications, Intercom, Radio and Television Broadcast Studio Audio",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gregory F. Shay"
                  ],
                  "abstract": "Traditionally, due to previous practical technical limitations, the audio quality of telecommunications and intercom systems was not as high as studio audio. Applications requiring long distance high quality audio required the use of specialized provisioning and equipment in parallel to the existing telecommunications systems. — IP computer networks have long since erased the distinction between the local LAN and global networks. As high speed wide area networks (WANs) with better performance and reliability have come online, the reality of erasing the difference of local vs remote audio presents itself. — AES67 is the protocol designed to take advantage of this capability for audio. Using AES67, the audio quality of telecommunications and intercommunications can be the same as in-studio audio, and furthermore, the systems directly interconnected by using the single interoperability protocol. — This shift is more significant than eliminating the economic redundancy of parallel systems. It fundamentally enables new workflows, coordinating and combining the efforts of production staff and talent, in geographically combined or diverse locations. — Audio traffic is no longer just communication; it can be contribution as well. — Combining the ease of making a connection like a phone call, the practically unlimited flexibility of routing of the network, with the pristine high fidelity of digital studio audio, AES67 brings the convergence of telecom, radio and television studio audio and intercom.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "AES67",
                      "convergence",
                      "least common denominator audio",
                      "SIP",
                      "WAN",
                      "telecom",
                      "intercom",
                      "radio",
                      "TV audio",
                      "broadcast production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001620"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "The Safe and Legal Operation of Commercial Drones in Australia",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Fleming"
                  ],
                  "abstract": "The use of drones and drone technology is on a rapid increase due to advances in modern technology. This poses considerable safety concerns as inexperienced operators scramble to utilize these technologies to get the edge in their chosen industries. — The Motion Picture and Television industries will be heavily influenced by the use of drones and drone technology, and therefore it is vitally important that the industry as a whole has an understanding of the rules, regulations and safety concerns whilst operating these machines commercially. — Where once seen as toys, these are now tools of the trade, and as such their use and the safety aspect of such use is something to be respected and taken seriously.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Drones",
                      "UAVs",
                      "RPAS certification",
                      "legislation",
                      "safety",
                      "CASA",
                      "remote control",
                      "multicopter",
                      "multirotor",
                      "aerial photography",
                      "aerial videography"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001617"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Subtitles on OTT Platforms - Ensuring Consistency across Broadcast and IP Platforms",
                "article_url": "https://journal.smpte.org/conferences/SMPTE15:%20Persistence%20of%20Vision%20-%20Defining%20the%20Future/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Boulton"
                  ],
                  "abstract": "Ever more content is being delivered over IP connections and viewed on non-broadcast devices such as tablets, mobile phones and computers. Yet the position of standards to enable the effective delivery of subtitling on such platforms is confusing to say the least. Proprietary implementations are commonplace leading to inconsistencies that can mar the viewing experience, in the worst cases this can lead to a complete absence of text. — This paper assesses the challenges involved in presenting broadcast quality subtitles on web video players, compares some of the methods currently used to deliver timed text on to the screen, proposes a workable solution for current implementation and looks to the evolution of standardisation in the near-future with WebVTT and the ISMC and EBU-TT variants of TTML.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Subtitles",
                      "subtitling",
                      "captions",
                      "closed captioning",
                      "timed text",
                      "TTML",
                      "ISMC",
                      "WebVTT",
                      "OTT"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001616"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "SMPTE 2015 Annual Technical Conference and Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "Color Fidelity for High Dynamic Range Signals",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Houston"
                  ],
                  "abstract": "HDR transfer functions extend the dynamic range of images but will likely operate with displays that have diverse capabilities in luminance and color space. In addition, video assumptions such as system gamma, visible black level, and the 0 to 1.0 video coding domain must be reexamined for high-dynamic range and wide-gamut color. Only part of an HDR signal may contain valid content and it may need to be ‘re-rendered’ for the capabilities of a display including techniques such as tone curve operators, gamut mapping, viewing environment corrections, and other color adjustments. Choice of a color space for manipulation of the signal can have a significant effect on color fidelity, and the use of tone mapping operators and color grading is reviewed. A color signal processing diagram is described to improve interoperability of HDR signals on displays with smaller ranges than the original HDR/WCG signal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "color reproduction",
                      "Rec.2020",
                      "high dynamic range",
                      "wide color gamut",
                      "color spaces",
                      "transfer function",
                      "tone mapping",
                      "system gamma"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001622"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Enabling Watermarking in a Diverse Content Distribution Infrastructure",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Niels Thorwirth"
                  ],
                  "abstract": "Forensic watermarking embeds a robust identifier into content in order to identify sources of illegal leaks. Enabling technologies have matured, and requirements have emerged, in particular for high-value UHD content. A successful implementation requires embedding unique information in the media data for each client. This can take significant resources depending on the implementation and application. To enable different delivery scenarios; ranging from DVB with one-way communication and physical media, to adaptive bitrate streaming with different integration workflows, components and embedding technologies need to be considered. This paper will explain different scenarios, tradeoffs, and practical solutions for implementation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "watermarking",
                      "anti-piracy",
                      "tracing",
                      "content security",
                      "rights management",
                      "UHD security"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001638"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "High Dynamic Range: Compression Challenges",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre Larbier"
                  ],
                  "abstract": "Experiments have shown that High Dynamic Range provides a significant appeal to viewers by adding a level of realism that cannot be achieved with currently deployed broadcast standards. Several technologies are available to implement High Dynamic Range, some of them relying on the SMPTE-2084 Opto-Electronic Transfer Function. While codecs like HEVC (High Efficiency Video Coding) can support signaling this transfer function, no specific tools were developed to compress this format. — Extensive research conducted using High Dynamic Range graded content shows that HEVC video encoders that were not specifically designed for this new format will produce new types of coding artifacts. This paper will explore these specific issues and show how video encoders could overcome those defects, keeping the promise of an outstanding video quality while retaining full compatibility with decoders.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "UHD",
                      "HEVC"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001639"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Color Rendering Index Value Requirement for Wide-Gamut UHDTV Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hiroaki Iwasaki",
                    "Tetsuya Hayashida",
                    "Kenichiro Masaoka",
                    "Masanori Shimizu",
                    "Takayuki Yamashita",
                    "Wataru Iwai"
                  ],
                  "abstract": "In this paper, we propose color rendering index (CRI) values for light-emitting diodes (LEDs) for use in ultra-high definition television (UHDTV) production. UHDTV cameras, designed with ideal camera spectral sensitivities according to the system colorimetry of Recommendation ITU-R BT.2020, can achieve highly accurate color reproduction in daylight. Because LED lighting is increasingly used in television production, it is important to elucidate the effects of its spectral power distribution on color reproduction. In this study, we performed subjective evaluations by comparing reference images captured under simulated standard lights with test images captured under LEDs of various CRI values. Based on our results, we recommend a CRI Ra value of 90 or higher and R9 of 80 or higher.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Light-emitting diode (LED) lighting",
                      "spectral power distribution",
                      "color rendering index (CRI)",
                      "ultra-high definition television (UHDTV)",
                      "color reproduction"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001627"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "UHD in a Hybrid SDI/IP World",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Hudson",
                    "Nigel Seth-Smith",
                    "Randy Conrod"
                  ],
                  "abstract": "Marketing efforts over the last year have generated a lot of excitement around the transition to IP in the broadcast environment but SDI still plays a vital role. — The hybrid SDI/IP models that will be adopted by most operations still need to consider the role that SDI plays for HD, but especially important is the role of SDI as it pertains to the introduction of UHD-1 (commonly referred to as 4K). — The SDI interface is the only standardized means for interconnecting UHD devices today, and those who are looking to roll out UHD-1 need to have a much better understanding of the challenges and issues that may result in a hybrid environment. This paper highlights some of those challenges; provides an update to the current technologies and discusses why SDI will continue to be an enabling technology for the roll out of UHD-1 (and UHD-2).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHDTV",
                      "SDI",
                      "Serial Digital Interface",
                      "3Gb/s",
                      "3G-SDI",
                      "6G-SDI",
                      "12G-SDI",
                      "24G-SDI",
                      "100Gbit/Sec",
                      "stereoscopic 3D",
                      "2K",
                      "4K",
                      "8K",
                      "SMPTE standards",
                      "SFP+",
                      "QSFP+",
                      "IEEE",
                      "OIF"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001624"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "How Independent are HDR, WCG, and HFR in Human Visual Perception and the Creative Process?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sean T. McCarthy"
                  ],
                  "abstract": "UHD, HDR, WCG, HFR are bound to be powerful creative tools with which to engage the viewer. Such acronyms (and would-be logos) could also prove to be influential marketing aids. But how justified would standards bodies, content creators, and distributors be in thinking of each feature as independent? — This paper will provide principles of applied vision science to quantify the extent of interdependence of luminance, field—of-view, color perception, and temporal sensitivity. This paper will also identify situations in which luminance, color, and frame rate should perhaps be considered in concert rather than as independent creative dials.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ultra HD",
                      "UHD",
                      "vision science",
                      "visual perception",
                      "high dynamic range",
                      "HDR",
                      "color gamut",
                      "WCG",
                      "high frame rate",
                      "HFR",
                      "creative intent",
                      "content distribution"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001630"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "High Frame Rate Capture and Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Corey Carbonara",
                    "Jim DeFilippis",
                    "Michael Korpi"
                  ],
                  "abstract": "This paper describes the challenges of capturing at high frame rates (typically 120fps) including issues of lighting, camera movement and shutter angle (exposure time). We report on the results of testing a variety of typical motion sequences (sports, dance, fighting, vehicles) with both camera pans, steady-cam, zooms and locked-off shots. In addition green screen captures have provided insight into matting scenes at high frame rates to determine if there is benefit to using higher frame rates for that application — We discuss how these factors affect the ability to post produce content both in high frame rate (120) as well as lower frame rates (24, 25, 30, 50 and 60). There are a variety of frame rate conversion techniques and we will explain how these techniques work as well as describe the results of using these techniques. — We have explored the ability to control motion blur in a scene by adding synthetic blur to a HFR sequence. The motion blur can be adaptive to the scene content as well as different elements in the scene. Future work and areas of interest will be discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HFR",
                      "Production",
                      "Frame Rate Conversion",
                      "Shutter Angle",
                      "Exposure",
                      "Green Screen"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001625"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Prospects for Software Defined Networking and Network Function Virtualization in Media and Broadcast",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Ellerton",
                    "Andrew Lord",
                    "Paul Gunning",
                    "Kristan Farrow",
                    "Paul Wright",
                    "Daniel King",
                    "David Hutchison"
                  ],
                  "abstract": "Software Defined Networking (SDN) and Network Function Virtualization (NFV) provide an alluring vision of how to transform broadcast, contribution and content distribution networks. In our laboratory we assembled a multi-vendor, multi-layer media network environment that used SDN controllers and NFV-based applications to schedule, coordinate, and control media flows across broadcast and contribution network infrastructure. — This paper will share our experiences of investigating, designing and experimenting in order to build the next generation broadcast and contribution network. We will describe our experience of dynamic workflow automation of high-bandwidth broadcast and media services across multi-layered optical network environment using SDN-based technologies for programmatic forwarding plane control and orchestration of key network functions hosted on virtual machines. Finally, we will outline the prospects for the future of how packet and optical technologies might continue to scale to support the transport of increasingly growing broadcast media.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Software Defined Networks",
                      "Network Function Virtualization",
                      "Ethernet",
                      "Broadcast",
                      "Contribution",
                      "Optical Switching"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001633"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Scaling UHD Live Production Workflow with Mezzanine Compression",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chuck Meyer",
                    "Jean-Baptiste Lorent",
                    "Sara Kudrle"
                  ],
                  "abstract": "Ultra High Definition Television (UHDTV) bandwidth requirements are exceeding the capabilities of traditional serial video transports. Since 1998, Serial Digital Interface transport rates have increased from 270 Mbps to 12 Gpbs, while Ethernet has increased four times more, from 100 Mbps to 25 Gbps. UHD 120 frame per second video requires up to 24 Gbps, rendering a 12 Gbps SDI infrastructure immediately obsolete. HEVC technology is being deployed in smart TVs, and next generation set top boxes as a way to deliver UHD to the home with the least bandwidth. Over-The-Top services are available today, and Over-The-Air capabilities have been successfully demonstrated. Using this infrastructure, UHD TV provides compelling picture quality which scales across screen size and delivery method. It is certainly poised to be the successor to HDTV. Live content production is essential to this transition. The challenge of managing variable input data rates combined with variable output formats, requires a workflow which scales from today's 3 Gbps infrastructure to the 96 Gbps capacity of tomorrow's facility networks. Mezzanine compression is one clear option for providing this scalability. Four to one mezzanine compression provides an optimal balance between workflow and scalability. Requirements for low latency, low power, and minimal computing resources which are essential for affordable, live production workflows are met with this technique.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IP",
                      "4K",
                      "UHDTV",
                      "Compression",
                      "Live Production",
                      "Mezzanine",
                      "Ultra High Definition Television",
                      "UHD"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001629"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Reference-Based Color Volume Remapping",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Redmann",
                    "Pierre Andrivon",
                    "Philippe Bordes",
                    "Fabrice Urban"
                  ],
                  "abstract": "Since wider color space formats combined with higher dynamic range (HDR) will be offered to consumers soon, compatibility with legacy devices must be considered. High Efficiency Video Coding (HEVC) video compression standard includes a new Supplemental Enhancement Information (SEI) message that makes it possible to remap the colors of reconstructed pictures to other video formats. Dynamic reference-based metadata are included in the Ultra HD Blu-ray Disc specification as an optional feature for converting an HDR signal into standard dynamic range images, in a manner that respects the artistic intent of the content creator. In this paper, a new workflow is described — and a robust algorithm is presented — for automatically deriving dynamic reference-based metadata. Performance of this technology is evaluated on a reference set of test sequences. The results of these subjective experiments have demonstrated good-to-excellent outcomes in terms of the quality of color remapping fidelity.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range",
                      "Wide Color Gamut",
                      "Content-based Dynamic Metadata",
                      "Color Volume Transformation",
                      "HEVC",
                      "Ultra HD Blu-ray",
                      "Color Remapping Information"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001623"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "4K, HDR and Further Image Enhancements for Live Image Acquisition",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Klaus Weber"
                  ],
                  "abstract": "Image acquisition for live broadcast applications faces many challenges. The increase in spatial resolution for UHD, in combination with the additional requirements of the UHD standards such as an increase in temporal resolution, higher dynamic range, and the need to achieve all of this with a good sensitivity and S/N-ratio will require some compromises and design decisions. This paper will discuss some of the potential solutions to these challenges, and will outline the latest developments in the imaging technology and some new functions in the image processing systems, that give enhanced image performance with improved perceived image sharpness and a higher dynamic range in live broadcast applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Colorimetry",
                      "2K",
                      "4K",
                      "8K",
                      "UHD",
                      "HFR",
                      "HDR",
                      "SDR",
                      "DOF",
                      "MTF",
                      "Qmax",
                      "Fps",
                      "Mpixel",
                      "lp/mm",
                      "TVL"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001626"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Content-Dependent Metadata for Color Volume Transformation of High Luminance and Wide Color Gamut Images",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lars Borg",
                    "Raymond Yeung"
                  ],
                  "abstract": "When displaying High Dynamic Range (HDR) or Wide Color Gamut (WCG) content on displays with smaller color volumes, such as High-Definition TV (HDTV), a color conversion from HDR or WCG to Standard Dynamic Range (SDR) is required. To maintain the creative intent, this color conversion needs to take into account the characteristics of both the content and the target display. As the content characteristics change from scene to scene, the optimal conversion will change as well. For example, a very dark scene will be mapped differently from a very bright scene when converting from a large color volume to a more restricted color volume. The converter(s) can be represented as metadata synced with the frames of the original stream. The metadata can be created in the mastering process, when images are creatively approved, and later applied in media conversions deferred to the distribution stage. This presentation discusses how such metadata can be captured and carried.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "WCG",
                      "High Dynamic Range",
                      "Wide Color Gamut",
                      "Color transform",
                      "dynamic metadata"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001621"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Best in Show",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Suzanne Farrell"
                  ],
                  "abstract": "How does one become ‘the best’? You run faster; jump further; eat the most hot dogs. In these examples the winner is objective. They are the Usain Bolts, the Joey Chestnuts. But how do you define ‘the best’ when dealing with subjective matter? Milk chocolate or dark chocolate? Rec.2020 and 1,000 cd/m2 or P3 with 4,000? In terms of image quality, both consumers and creators want to know what makes ‘the best’. Consumers want a number or a letter grade, and creators and engineers want to know how to make that image or television rate the highest. It comes down to creating a metric that factors in all image attributes and weighting them by how each are valued by consumers. We will discuss the challenges faced in creating such a metric, and our study that compared image quality dimensions such as dynamic range, color primaries, bit depth, and contrast.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High dynamic range",
                      "image quality metric",
                      "subjective experiments",
                      "subjective testing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001631"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Building a New Digital Archive Management Infrastructure for the RIT School of Film and Animation",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alex Etienne"
                  ],
                  "abstract": "The Rochester Institute of Technology's School of Film and Animation in the College of Imaging Arts and Sciences has a dedicated archive room and a Storage Area Network for storing student media created to receive class credit. Once submitted, the media may go through several processes, such as public screenings and online streaming, which complicates how the media is categorized. Also, the methods of storing digital and physical assets have become outdated and disorganized due to lack of regular, documented maintenance. To remedy these issues, a workflow that streamlines media and metadata ingest through SOFAtube.cias.rit.edu, a video streaming and media ingest website that is being redesigned in collaboration with the new digital asset management system, will be proposed. The workflow will include open source tools and well-established practices, such as the Open Archive Information System reference model and metadata dictionaries used by other archives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Open Archive Information System (OAIS)",
                      "Metadata Dictionary",
                      "Unified Modeling Language (UML)",
                      "Archive Exchange Format (AXF)",
                      "Extensible Markup Language (XML)",
                      "PBCore",
                      "Preservation Metadata: Implementation Strategies (PREMIS)",
                      "Hypertext Markup Language (HTML5)",
                      "ExifTool",
                      "Digital Asset Management (DAM)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001644"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Storyteller — Marrying Real-time Metadata with Live Events to Automate Production for Multi-screen",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Chen",
                    "Srikanth Rao",
                    "Rohan Warey"
                  ],
                  "abstract": "The sports consumer of today not only has a variety of content choices, they also enjoy the convenience of consumption when they want it, the way they want it. In this multi-choice environment, competition to deliver live, high quality and engaging content across multiple platform-devices combination is fierce. This has in turn created the need for a newer, faster production environment that is collaborative, facilitates real time storytelling and is able to deliver to multiple platforms at one go. — This paper highlights innovation done using Cloud technology enabled systems to automate and ease each step of the story telling process that can aid live sports production. This with the additional flexibility for various teams involved to operate from different physical locations. — The result — an integrated and quick story telling cloud based system that facilitates collaboration between multiple teams and vendors to create content that is contextual, engaging & delivered quickly.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Sports",
                      "OTT",
                      "over the top",
                      "metadata",
                      "story",
                      "contextual"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001646"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Building the HDR Economy Nit by Nit",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Goeller"
                  ],
                  "abstract": "UHD has been touted as the de facto format. While Ultra HD 4K TV shipments are exceeding initial estimates, UHD has yet to captivate Hollywood as a format that delivers a highly differentiated experience. This is evident by the limited number of new releases in the UHD format. HDR is widely considered to be a much better viewing experience. — However, CE manufacturers and distributors see the UHD format as compelling to drive new TV sets and launch new services. As such, the entertainment industry can ill afford to ignore UHD. Some level of UHD format support is necessary to continue to drive consumer excitement and momentum while preparing for HDR. To address near term demand for UHD, the optimal experience at acceptable bitrates to support today's networks and bandwidth is dependent on the relationship between the source material, size of the master file and the quality of output in the transcoding process. — While HDR provides a never before seen increase in contrast, color and luminance across all screens, the pace in which content will roll-out is dependent on several factors: HDR projector footprint to drive theatrical; HDR TV deployments to drive HDR live sports broadcasting, followed by TV episodics and then movies. Add to this other factors such as market confusion around the various 4K/UHD/HDR “brands”, lack of standards, and new business models grounded in outsource vs. internal investments, building the HDR economy will be nit by nit and not a wholesale roll-out.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K",
                      "Ultra HD",
                      "UHD",
                      "High Dynamic Range",
                      "HDR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001649"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Scene-Based Audio Implemented with Higher Order Ambisonics (HOA)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nils Peters",
                    "Deep Sen",
                    "Moo-Young Kim",
                    "Oliver Wuebbolt",
                    "S. Merrill Weiss"
                  ],
                  "abstract": "Scene-based Audio uses a sound-field technology called “Higher Order Ambisonics” (HOA) to create holistic descriptions of both live-captured and artistically-created sound scenes that are independent of specific loudspeaker layouts. For efficient representation, the audio can be carried as a set of PCM channels that contain predominant sounds and ambience in separate tracks. Standard audio bandwidth-compression techniques then can be applied to the PCM channels. This approach is in contrast to conventional channel-based sound representations, in which one signal is used for each loudspeaker of a target reproduction system, with the implication that upmixing or downmixing is required when loudspeaker configurations other than the intended one are used for actual reproduction. This paper examines how, with Scene-based Audio, there can be satisfactory reproduction of immersive sound at bitrates corresponding to the equivalent of just 6 channels, while an alternative sound-field method that exclusively employs audio objects typically involves much higher bitrates.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Scene-based Audio",
                      "HOA",
                      "Spatial Audio",
                      "Next-Generation Audio",
                      "MPEG-H",
                      "ATSC 3.0"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001651"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Elementary Flows for Live IP Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Edwards",
                    "Michael Bany"
                  ],
                  "abstract": "Live IP flows promise significant benefits in enhancing media processing flexibility in the broadcast plant. Existing SDI formats in use today carry a multiplex of active video, ancillary data, and embedded audio over 75Ω coaxial cable. Although SMPTE ST 2022-6 encapsulates this entire SDI multiplex signal using IP, it is unclear if this is the optimal payload format for a networked broadcast plant. There is a large amount of wasted space within the ancillary area of an SDI signal. Also system flexibility can be enhanced by placing video, audio, and ancillary data into elementary flows that can be individually and independently switched at the network layer, without the penalty of demultiplexing or remultiplexing the SDI signal. This paper describes a recommendation for the carriage of elementary media flows for live IP production, including mechanisms to describe the logical relationships between these elementary flows for composition and synchronization.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IP",
                      "RFC 4175",
                      "AES67",
                      "RFC 3190",
                      "SVIP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001635"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Perceptual Uniformity for High Dynamic Range Television Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Borer",
                    "Andrew Cotton",
                    "Peter Wilson"
                  ],
                  "abstract": "High dynamic range (HDR) television promises a qualitatively better viewing experience, but to fully realise its potential, and to achieve consistent high quality images, the psychovisual aspects of human vision must be taken into account. — The paper reviews the non-linearities inherent in conventional SDR television and discusses how these are required to accommodate psychovisual effects. The thresholds at which changes in brightness can be detected, embodied in Weber's and De Vries-Rose's laws, are discussed in the context of the need to minimise “banding” artefacts due to quantisation. This effect also provides a simple psychovisual definition for the dynamic range of video. — The second important psychovisual effect considered is that of surround brightness on the perception of emissive images in dim or dark surroundings. This effect is accommodated by implementing an overall system non-linearity, the rendering intent, which is typically a gamma (power law) function. The appropriate gamma exponent is considered in special cases and interpolated to provide a general formula. — Based on these psychovisual effects, an HDR television system is proposed that supports the highest quality HDR images with a simultaneous dynamic range substantially beyond the limits of the human visual system in a single adaptaion state. It is defined by a single optical-electric transfer function (OETF), with a variable display electro-optic transfer function (EOTF) to accommodate the eye's adaptation. It is also compatible with existing, SDR, displays and infrastructure and requires no metadata.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001632"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Sample Variants: A Standardized Framework for Forensic Marking of ISOBMFF Files",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Julia Kenyon"
                  ],
                  "abstract": "Forensic marking enables tracing an unauthorized copy of content to its source, which encourages content providers to broadly distribute high-value content. Today, forensic marking techniques are proprietary technology. Sample Variants address the need for a standardized framework for forensic marking, building on ISO Base Media File Format (ISOBMFF) files protected with ISO Common Encryption (CENC). — This paper provides an overview of Sample Variant data structures, as well as a discussion of how these structures can be used to optimize number of possible permutations while minimizing data overhead (to the point of determining player model number and other forensic data), and outlines various configurations that can be set up within this framework.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "content protection",
                      "forensic marking",
                      "ISOBMFF",
                      "common encryption (CENC)",
                      "watermarking",
                      "fingerprinting",
                      "Sample Variants"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001637"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Journey of 9's — High Availbility for IP Based Production Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pradeep Kathail",
                    "Charles Meyer"
                  ],
                  "abstract": "IP based video production systems must provide high availability characteristics that are similar to today's SDI system including five nines of availability. Without which it will be difficult to migrate live production to IP. This paper compares and contrasts characteristics of SDI routers with that of IP routers and the fault domains of two systems. It also provides example topologies for IP demonstrating flexibility and scale beyond SDI. Various techniques used in IP networks to improve fault detection will be discussed. Network protocols, deployment practices and the use of application level protocols like SMPTE 2022-7 will be analyzed in regard to improving overall system availability. This paper will demonstrate that properly designed and deployed IP networks can provide five nines of availability and the use of application level protocols like SMPTE 2022-7 can improve the overall availability of the system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Redundancy",
                      "resiliency",
                      "high availability",
                      "SMPTE2022-7",
                      "routers",
                      "swtiches",
                      "leaf and spine",
                      "BFD",
                      "production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001634"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Ultra HD Blu-ray™ Format Video Characteristics",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael D. Smith"
                  ],
                  "abstract": "Structure of this presentation: — Mandatory, Optional and Out-of-Scope features — Video Characteristics — resolution, compression, bit depth, chroma format, frame rate, color primaries — dynamic range, EOTF and quantization performance — Static Metadata — Optional Technologies — Disc Capacity",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001641"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "High Frame Rate Compression Efficiency and Backwards Compatibility using HEVC",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Juan Jose Anaya",
                    "Antonio Sanchez",
                    "Jordi Joan Gimenez",
                    "Damian Ruiz"
                  ],
                  "abstract": "Current UHD services use barely a couple of enhancement features compared to HD formats, by increasing spatial resolution and pixel bit-depth, which are insufficient to improve user experience when using large screens. This could led to a certain frustration on consumers, arising the fear that 4K technology could fail in the medium term as recently happened with 3DTV services. Aware of this, the audiovisual industry is involved in the agreement of the new generation of UHD, so-called UHD-1 Phase-2, which improves the immersive viewing experience features, such as Wider Color Gamut (WCG), High Dynamic Range (HDR), and High Frame Rate (HFR) technologies. — In this paper, we focus on the encoding of HFR formats, which provides a crystal clear image, avoiding effects such as image blurring in scenes with high-motion, especially for sports and fast-action content. We describe the temporal scalability mechanism implemented in the HEVC standard, which can be useful for the encoding of HFR services in a backward-compatible manner, avoiding the need to carry out the simulcast of the same UHD service with different temporal resolutions. The HEVC coding efficiency for UHD@120Hz services is also reported, showing the bandwidth requirements for DVB-T2 and ATSC 3.0 networks. — Finally, we describe the trial carried out at the University Campus, by broadcasting a scalable UHD@120Hz service using a DVB-T2 network, which proves backward-compatibility of the HFR services with the current UHD-1 TV sets, and also shows the HFR compatibility over low performance devices such as tablets and smartphones with low frame rates capabilities, by using in-home WiFi streaming.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Frame Rate",
                      "Temporal Scalability",
                      "Backward Compatibility",
                      "HEVC",
                      "Blur",
                      "DVB-T2"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001642"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Better, Faster and More Pixel Handling with SMPTE VC-3 Codec Updates",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shailendra Mathur",
                    "Al Kovalick"
                  ],
                  "abstract": "As the industry moves towards Better—High dynamic range, Faster—high frame rates, and More—higher resolutions, the SMPTE VC-3 video codec standard has been improved to meet the challenges. The extension to the standard allows for resolution independent encoding of arbitrary raster resolution, any frame rate, multiple bit-depths and different color spaces. New features of the codec include new quality levels, 4:2:0, 4:2:2, 4:4:4, Alpha channel, SDI-safe and graphics level, out-of-band encoding and support in various container types. As a low-complexity codec appropriate for editorial intermediates and collaborative editing, the high performance characteristics and predictable bit-rates properties are discussed. Its value as a mezzanine format is illustrated with the ability to preserve original resolutions, color and temporal properties from acquisition formats, post-production and VFXeffects rendering. Working together with corresponding metadata defined in popular wrapper formats such as MXF and QuickTime, its use for post-production workflows involving HDR, wide gamuts and Super Hi-Vision will be shown.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VC-3",
                      "ITU-R.2020",
                      "12-bit",
                      "high-resolution",
                      "high dynamic range",
                      "high frame rate",
                      "HDR",
                      "HFR",
                      "RGB",
                      "4:4:4",
                      "4:2:2",
                      "4:2:0",
                      "Alpha",
                      "visually lossless"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001643"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "The Interaction between Transfer Function and Compression in High Dynamic Range Video",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Olie Baumann"
                  ],
                  "abstract": "Recent advances in television display technology have resulted in an increase in the dynamic range of display luminance offering the potential to deliver more of the information captured by the camera to the viewer. Amongst the potential solutions for delivering this additional information is the use of a non-linear transfer function which exploits the relative sensitivity of the human visual system to contrast differences in light and dark areas. This paper investigates the interaction between these transfer functions and HEVC video compression in terms of the perceptible artefacts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Dynamic Range (HDR)",
                      "compression",
                      "Electro-Optical Transfer Function (EOTF)",
                      "Opto-Electrical Transfer Function (OETF)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001640"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "What does “Broadcast Quality” Mean Now?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Josef Marc"
                  ],
                  "abstract": "“Broadcast quality” used to be a meaningful standard for communicating a quality level sufficient to satisfy the broadest range of requirements. “Cinema quality” meant better, “VHS quality” meant “that's bad enough, now stop,” and “master quality” meant the very best available. This author has been translating those terms into technical requirements and measurements since the 1980's through today, using and making tests, using and designing quality control systems. This paper presents a perspective on how technical and non-technical people alike can begin to develop a new common lexicon to describe moving image, sound, and timed text qualities in today's emerging era of 4K, UHD, 8K, wide color gamuts, high dynamic ranges, high frame rates, and the file-based media that carry them to a new era of displays.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K",
                      "UHD",
                      "HDR",
                      "HFR",
                      "WCG",
                      "BTU.2020",
                      "quality",
                      "color"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001660"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Extending Cable Workflows to OTT: Decoupling Content Generation from Delivery Technologies",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yasser F. Syed",
                    "Alex Giladi",
                    "Neill Kipp",
                    "Wendell Sun"
                  ],
                  "abstract": "The term “OTT”, for “Over-the-Top” video, typically refers to video file streaming services over the open Internet, irrespective of the underlying network characteristics and ownership. Netflix, Hulu, and Amazon were among the pioneers of the approach, providing subscription-based and transactional services “over-the-top” of the broadband networks built and maintained in turn by the earlier pioneers of Broadband IP which was essentially invented by cable service providers through the introduction of the cable modem. — Cable operators are transforming their IP distribution networks to handle video services directly and rapidly adopting OTT techniques as a part of that service, thus the underlying Adaptive Bit Rate Streaming (ABR) technologies are of interest to the cable industry. OTT means many different things to different people — when we discuss it here we discuss it in its technological capacity (network-independent reliable streaming over IP), rather than the underlying business model. — ABR technologies are enabling client adaption to changing network conditions, as well as adapting to device heterogeneity — a multitude of IP-based user devices such as TVs, computers, tablets, and smart phones with vastly different capabilities. As opposed to provisioned set-top boxes configurations of the past, crops of different devices are used today to consume OTT content. The multichannel video programming distributors (MVPDs) have to now handle this device heterogeneity. Unfortunately, in reality, MVPDs must also adapt to ABR technology heterogeneity. That's because the number of codecs and number of supported media formats are growing — the latter much faster than the former. — The most logical conceptual approach to the problem of such combinatorial growth in codec-format-encryption permutations involves decoupling transcoding from packaging—in part because compression of audiovisual information does not have too many interdependencies with systems-level encapsulation, encryption and signaling. This decoupling brings multiple benefits to large-scale deployments, such as cost reduction, improved resilience and greater service velocity. — In specific, decoupling of transcoders from packagers enables both to grow at their own organic rates. For instance, content storage (e.g. for VOD) grows on the basis of aggregate titles/assets, while content caching and content data networks (CDNs) use (e.g. for live/linear) grows as a function of the number of requesting client devices. By separating them, scaling happens faster, better, and at lower cost than the alternative. — Decoupling transcoding from packaging requires a common on-the-wire interface—a single intermediate format that will contain a sufficient amount of information to enable packaging while leaving transcoders unaware of the final media delivery formats. A simple, backwards-compatible technology that fits well into existing architectures and workflows is what makes incremental adoption and extension possible. — In this paper, we explore the design of a multicast/unicast intermediate ABR format and the resulting architecture for just-in-time and linear packagers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Adaptive Bitrate Streaming",
                      "IP Distribution",
                      "Packagers",
                      "DASH",
                      "OTT",
                      "MVPD",
                      "JITP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001647"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Recipes for Creating and Delivering Next-Generation Broadcast Audio",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sripal Mehta",
                    "Tim Onders",
                    "Jeff Riedmiller"
                  ],
                  "abstract": "Next generation audio systems and codecs allow content creators to engage their audiences with more accessible, immersive and personalized sound experiences. While these systems provide a great deal of flexibility in the amount of audio that can be delivered and the amount of control given to consumers, the industry can benefit from a set of pre-defined operating profiles for the first incarnations of next-generation audio. — This paper provides a practical overview of some basic audio profiles and mechanisms for delivering stereo, surround, personalized and immersive content in next-generation audio systems. Legacy stereo and surround content benefits from new system features including enhanced loudness management and improved dialogue intelligibility for pre-mixed sources. Personalized and immersive content can be created and delivered in ways that ensure that every consumer receives a premium experience across every device. New delivery systems and encoders ensure seamless and robust switching between different content types and layouts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Next-generation audio",
                      "immersive audio",
                      "personalized audio",
                      "accessible audio",
                      "AC-4",
                      "audio mixing",
                      "object-based audio",
                      "audio objects",
                      "loudness",
                      "Dolby",
                      "dialogue enhancement",
                      "personalization",
                      "3D audio",
                      "Dolby Atmos"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001655"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "The Future of Audio Post-Production using Virtual 3D Scenes",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nuno Fonseca"
                  ],
                  "abstract": "Many motion pictures use 3D computer graphics software to generate imagery - moving 3D objects are positioned on a virtual space where a moving virtual camera is responsible for the rendering of the scene. Unfortunately, the same concept is not used for audio post-production. Even for immersive audio, the current audio post-production workflow is based only on Digital Audio Workstations (DAW), the audio equivalent of a video editing software, where hundreds of audio tracks are mixed together, but lacking a true integration between sound sources and the virtual sound “camera”. — This paper presents the concept of a virtual 3D scene audio software, its advantages and disadvantages, based on a particle system software developed for sound design, which is currently being tested in major audio post-productions studios, capable of creating virtual 3D audio scenes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Immersive",
                      "Audio",
                      "Sound",
                      "Post-production",
                      "Particle systems",
                      "3D",
                      "Virtual scene"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001652"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Listening Test Methodology for Object Based Audio Rendering Interoperability using Artificial Reference Signals and Artistic Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Claypool",
                    "Markus Mehnert",
                    "Bert Van Daele"
                  ],
                  "abstract": "The preservation and representation of artistic intent are driving key words for the emerging SMPTE Immersive Audio Standard. This paper proposes a listening test methodology that will ensure that a single interoperable immersive audio OBAE bitstream, regardless of what prevailing speaker format creates the content, will allow a level of representation in commercial cinemas that achieves a baseline performance profile necessary to preserve artistic intent. Artistic intent can be preserved without disclosing rendering technologies by comparing different spatial audio renderers as a black box approach using artificial and artistic audio test content. The artificial test content shall provide maximum range evaluation of critical features and the artistic test content shall guarantee maximum acceptance from the community by using real world examples and allows for a path forward to a true single inventory immersive audio bit stream for the cinema industry and potentially other downstream deliverable.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Immersive sound",
                      "OBAE",
                      "Test",
                      "Methodology",
                      "Listening",
                      "Object Based Audio",
                      "Rendering"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001653"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Monitoring and Authoring of 3D Immersive Next Generation Audio Formats",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Poers"
                  ],
                  "abstract": "The next generation immersive audio formats will require changes in the audio production workflow. Monitoring the audio along with authoring and verifying of dynamic metadata will become a new challenge. — New procedures for managing object based encoded content the same way as for personalization of services through the selection of alternative audio objects (such as commentator languages) needs to be established. — Loudness control during production and the loudness definition for the final output formats are other topics to consider. — The NGA formats will offer a new surround sound experience and the use upmix, format rendering and downmix algorithms will be essential for creating and monitoring the audio programs. — A Multichannel Monitoring & Authoring Unit (MMA) must be compatible with upcoming immersive multichannel 3D audio formats and should offer a platform to host all the emerging immersive 3D audio encoding formats from different vendors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D immersive audio",
                      "next generation audio",
                      "multichannel surround audio",
                      "metadata authoring",
                      "loudness control",
                      "surround upmix"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001654"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Black and White = Chroma!",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andy Rosen",
                    "Dan Brunner"
                  ],
                  "abstract": "Hands-on craftsmanship is essential to what we do. Mindful of the blazingly fast introduction of high frame rate and high dynamic range cameras and tools, my co-author and I do what we've always done—we make practical test patterns. Newly introduced color and contrast standards1 and practices have formidable ramifications for the future of our entire imaging chain. More than ever before, basic display settings such as frame rate and white balance must be rock solid and provably consistent. — Seemingly innocuous variations on familiar test patterns have revealed, and now make completely reproducible, a couple of curious and sometimes substantial inconsistencies found in most LCD monitors. These content-dependent temporal and chromatic distortions—which have long been suspected—can now be isolated, measured, and scrutinized. Our test patterns, which we have released to the Standards Community, raise important questions as to the limits of our ability to preserve artistic intent. Today's explosion of low-cost, highly oversampled “super-cameras” is certain to expose these display shortcomings even more dramatically, and with increasing frequency. — LCD technology is core to our production and distribution ecosystems. This will continue to be the case for a long time. We believe any sustainable discrepancy management practice will likely touch on several different places in the entertainment workflow. We seek guidance from the community on the best path forward.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LCD",
                      "overdrive",
                      "test patterns",
                      "frame rate",
                      "temporal",
                      "smear",
                      "lag",
                      "white balance",
                      "calibration",
                      "interoperability",
                      "match",
                      "monitor",
                      "chroma shift",
                      "chromatic",
                      "color",
                      "inverse ghosting",
                      "zone plate",
                      "reference monitor",
                      "flicker",
                      "moiré"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001657"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "The Calibration Conundrum: Towards Standardizing a Reference White Chromaticity for HDTV",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matthew Donato",
                    "David L Long"
                  ],
                  "abstract": "High definition displays have pushed tremendous engineering and color reproduction boundaries. While they have become more widely accepted into the consumer landscape, post-production professionals often experience problematic color appearance mismatches amongst new display technologies. — Rendered imagery that is visually mismatched is an example of a metameric failure: a phenomenon that occurs when spectrally unique stimuli (which are intended to appear identical) are perceived differently. — Both a simulation and psychophysical assessment are developed in an attempt to quantify variability in color perception when using different displays. A mean visually-corresponding chromaticity offset is calculated as a replacement calibration aim. This offset is intended to satisfy a greater population of observers than existing calibration methods.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "metamerism",
                      "chromaticity",
                      "calibration",
                      "HDTV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001658"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Optimizing Large Media Networks for Highly Accurate Time Transfer via PTP",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nikolaus Kero",
                    "Thomas Kernen",
                    "Tobias Muller",
                    "Martin Schimandl"
                  ],
                  "abstract": "In all-IP studio environments synchronization is provided via the Precision Time Protocol (PTP) replacing legacy technologies like genlock. PTP profiles such as SMPTE ST 2059 or AES 67 deliver optimal performance when operated in fully PTP-aware networks. To avoid costly reinvestments existing state-of-the-art network infrastructure should be retained whenever possible, adding PTP devices only at critical locations in the network. For a set of topologies typically found in large media networks synchronization quality is measured both with respect to accuracy and lock time. The presented measurements are performed in presence of a varying amount of media traffic. Subsequently, the networks are enhanced by exchanging single components with PTP aware devices at distinct locations carrying out the identical measurements. Configurations with PTP aware components located at the edge of the network are compared with topologies where PTP aware components reside in the core providing guidelines for optimizing existing networks for PTP",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "1588",
                      "PTP",
                      "mixed networks",
                      "IP",
                      "ST 2059"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001636"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "4K Video over SMPTE 2022-5/6 Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marc Levy",
                    "Laura Reshetar Richardson",
                    "Gael Rouvroy"
                  ],
                  "abstract": "The next generation of live television is here! Unfortunately, the necessary bandwidth for UHDTV resolution video and higher frame rates for live uncompressed video transport is not. Uncompressed 4K video at 60fps 4:2:2 requires 12Gbps and even more for 4:4:4, which causes a problem for video transport across 10Gbps Ethernet networks. “Lightly compressed” 4K is needed to fit in a single 10GE cable. For the industry's existing and deployed infrastructure, the compression has to be capable of leveraging already deployed SMPTE 2022 5/6 equipment. Visually lossless compression for a single 4K stream over a 10GE link is also ideal. This paper explores the issues described and suggests the technologies required to fix the problem.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K",
                      "compression",
                      "FPGA",
                      "Video Transport",
                      "SMPTE 2022-5/6",
                      "TICO"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001628"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Achieving BT. 2020 Color with LCDs: A Tale of Two Applications",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James Hillis",
                    "James Thielen",
                    "Josh Tibbits",
                    "John Van Derlofske",
                    "Dave Lamb"
                  ],
                  "abstract": "One constraint on a complete transition to the ITU BT.2020 broadcasting standard is the limited availability of displays that achieve the recommended color space. However, several technologies are capable of coming close. Our research addresses the question of how close the primaries must be to the standard to be acceptable for different applications (e.g. professional vs. consumer). In previous research, we measured color difference detection thresholds for colors along the Rec. 2020 boundary with simple test patterns. In our current study, we measured color discrimination rates for photographic images rendered in color spaces near Rec. 2020 in two tasks: (1) images viewed sequentially and (2) images viewed side-by-side. We discuss how to use these data to define tolerance criteria for different applications and examine if prototype quantum-dot enabled LCDs meet these criteria.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Rec. 2020",
                      "color",
                      "quantum dots",
                      "perception"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001659"
                  }
                }
              },
              {
                "article_local_id": "52",
                "article_title": "Exploring New Technologies for Non-Destructive Adjustment of Running Times of File Based Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/52/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Scott Matics"
                  ],
                  "abstract": "A generation ago, a 60 minute broadcast program slot was filled with a fairly static mix of program material, commercials, and other content. That all changed beginning in the late 1990's, when the number of minutes of non-program material began inching up, and by 2013 had increased to more than 14 minutes of every hour. — This change resulted in tens of thousands of previously produced episodes and other material no longer fitting into the program block, and left broadcasters with two not-so-great choices for adjusting the running time of original programming: cut scenes out, or use destructive baseband re-timing options. — Today, there are sophisticated algorithms that utilize modern GPU video processing and transcoding techniques that can re-time content with virtually no decrease in video or audio quality. — This paper will focus on the history of content re-timing for broadcast, and delve into the legacy and modern technologies for re-timing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video retiming",
                      "audio retiming",
                      "multimedia retiming",
                      "file retiming",
                      "running time adjustment",
                      "movie retiming",
                      "editing for time"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001672"
                  }
                }
              },
              {
                "article_local_id": "54",
                "article_title": "Content Monitoring for SDI, Files and IP using Algorithmic-based Media Signatures",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/54/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Shike",
                    "Geoff Bowen"
                  ],
                  "abstract": "Unique signatures are used to provide a content monitoring solution that may be deployed in SDI or IP-streaming broadcast environments. The signatures can be stored and compared at every stage of the production chain to provide automatic checking and verification of video and audio streams—allowing for a fully automated business model. Various aspects are handled including identification of correct media, track mapping, lip-sync, logo assurance, and other essential data. The solution is resilient to format, frame-rate and aspect ratio conversions and encode/decode processes and allows monitoring of the content delivered to the end customer. In order to provide true monitoring by exception, the solution responds reliably and rapidly to changing material and content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media Signatures",
                      "Workflow",
                      "Quality Control",
                      "QC",
                      "Fingerprinting"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001674"
                  }
                }
              },
              {
                "article_local_id": "55",
                "article_title": "File-Based Closed Captioning System without Captioning Delay",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/55/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yunhyoung Kim",
                    "Sunghee Han",
                    "Sungwoo Choi",
                    "Byunghee Jung"
                  ],
                  "abstract": "There have been complaints on the time delay between closed captions and dialogues on TV occurring due to live stenography. The problem can be solved if captions are generated beforehand, but it is practically impossible to enforce pre-production for all the broadcasting programs. To cope with it, we propose a new file-based closed captioning system based on speech recognition and audio-fingerprinting. The system aims at rerun episodes—episodes with pre-prepared caption files produced by live stenography at the first-run, thereby containing delayed captions. To match the delayed captions with the dialogues, the system adjusts timelines of the captions based on automatic speech recognition. When it comes to rebroadcasting, since there would be video editing in the rerun episodes, the system finds differences between the rerun and the first-run by comparing their audio-fingerprints and generates new closed caption files. The proposed system is implemented and applied in KBS (Korean Broadcasting System).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Closed Caption",
                      "Speech Recognition",
                      "Audio-Fingerprinting",
                      "File-based Closed Captioning System"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001675"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Big Data Analysis for Effective Monetization of over the Top TV Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Arnav Mendiratta",
                    "Steve Wong",
                    "Reinhard Grimm",
                    "Jay Yogeshwar",
                    "Shane Archiquette"
                  ],
                  "abstract": "Consumption of digital-media is shifting to Over-the-Top (OTT) delivery model and no longer requires involvement of multiple system operator in content distribution. These benefits are balanced by lack of standards for delivery platforms, audio-levels and advertising delivery. Inadequate industry standards, ad-block use, limited bandwidth and differing viewer-experience challenges content monetizing and delivery. With availability of inexpensive processing power and efficacy of real-time analysis technologies for big metadata, industry focus has shifted to content-recommendation and hyper-targeted advertising resulting in enhanced customer experience and efficient content distribution. The metadata managed by OTT platform can create partial-differential-equations containing unknown multivariable functions and partial-derivatives that can be analyzed in real-time. This paper presents the challenges and opportunities for a telco-grade OTT management-and-delivery-platforms as an ecosystem for collection of big-data from content-owner and client. This metadata could be fed to robust real-time analytic systems for augmenting end-user experience while generating revenue for content-owners and service-providers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Over the top TV",
                      "advertising and media",
                      "electronic commerce",
                      "big data analytics"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001648"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "Modelling of Achievable Contrast and its Impact on HDR Projection in Commercial Cinema Environments",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Claude Tydtgat",
                    "Dirk Maes",
                    "Goran Stojmenovik",
                    "Augustin Grillet"
                  ],
                  "abstract": "There is a growing interest in High Dynamic Range Imaging for cinema projection applications. It has been reported that the observable cinema contrast ratio is not only determined by the native projector contrast, but even more by various parameters such as the projection lens, port window, screen, theatre setting and audiences. We have derived a mathematical model to characterize the influence of these parameters and to assess their relative importance as a function of the projected image content. Further a fast measurement method was developed to determine the various parameters across different theatres, providing a good match with our model.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "Projection",
                      "Cinema",
                      "Contrast",
                      "Model",
                      "Measurement"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001668"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "An Analysis of System Contrast in Digital Cinema Auditoriums",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Miller Schuck",
                    "Pete Lude"
                  ],
                  "abstract": "High Dynamic Range for digital cinema projectors demands both increased brightness and darker black levels. Projector contrast is commonly described as the ratio of peak white luminance to black state luminance, where these extremes are measured sequentially. But in a typical movie, bright highlights and deep blacks coexist in the same frame, introducing a number of other factors greatly affecting perceived dynamic range. This paper reports on the relative impact of such factors, including lens veiling glare, port glass, room reflectivity, audience reflectivity and room ambient lighting. We will report on recent studies that have measured typical auditorium and lens parameters, as well as a representative luminance of recent movies - which greatly impacts the degree to which stray light is reflected back onto the screen. Based on these factors, the resulting “system contrast ratio” of typical cinema screenings is calculated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Projection",
                      "Dynamic Range",
                      "Contrast",
                      "Measurement",
                      "Laser",
                      "Cinema",
                      "3D"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001667"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "Zero Infrastructure Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Ohanian"
                  ],
                  "abstract": "Is it reasonable to expect that broadcasting operations can occur with no on-premise infrastructure? In this paper, we will explore the necessary hardware and software configurations, cloud-based models, and on-demand coordination of necessary resources. Examples of the technologies and methodologies that will be discussed include: Services, Network Service Orchestration, Control of Workflow Applications, Virtualized Infrastructure and Software Applications, and the Physical Infrastructure Layer. — This paper will highlight the usage of Flexible Media Clusters, Software Defined Networking and Network Function Virtualization, OpenStack, Packet Media Networking solutions to replace SDI, software defined storage and resource reservation layers to elastically and dynamically provide a highly scalable all-IP based broadcasting architecture.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Virtualized Infrastructures",
                      "Pop-Up Broadcast Channels",
                      "Media Clouds",
                      "Software Controlled IT Systems",
                      "IT Broadcasting",
                      "IP-based Broadcasting",
                      "Media Data Centers"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001663"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "My Boss Wants to Transcode in the Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Duval"
                  ],
                  "abstract": "The use of cloud computing platforms for video production workflows has become a reality for many media organizations. Cloud computing platforms offer several unique capabilities for application deployment that enable new and different interactions for viewers and partners. Technical teams are receiving the mandate to evaluate, test and deploy on cloud computing platforms. — Successful implementations of cloud video applications are the result of applying cloud technology to remove business constraints. The goals were not replication of existing infrastructure on the cloud platform but instead to provide on-demand capacity, world-wide accessibility and dynamic scaling of application and storage resources. — This paper describes how three media companies have structured their workflows using cloud technology to deliver successful application deployments, with far less effort, on or under budget. It is important to recognize that cloud platforms are NOT a one-size-fits-all, silver bullet solution for every problem but do: ▪ Provide capability for new products and services that are not practical with enterprise systems. ▪ Add a powerful technology suite to your tool set. ▪ Enable new possibilities for those who embrace a different perspective.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud video",
                      "cloud video workflows"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001662"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Object-Based Audio for Live TV Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steven A. Silva"
                  ],
                  "abstract": "Object-Based Audio (OBA) is the next breakthrough in live television production. It will provide an enhanced listening experience and personalization as revolutionary as sound was to motion pictures in the 1930's. The age of personalization has arrived and TV consumers can view any program, at any time and on virtually any media device. — The next generation of audio encoders will have the capabilities to create OBA in live television production and post-production. Features of OBA include audio personalization for language selection, dialogue enhancements and options for the hearing impaired. OBA will provide the viewer with the ability to customize their viewing for any type of program in any viewing setting. — The future audio codec technologies will enable the creative chain to produce customized audio for the viewer. This process begins at the original mix location and continues through the broadcast chain to any consumer device. These encoders will have the capability to emit surround sound and immersive sound with objects either separately or in combination with each other. Scene based audio will also be a feature of the next generation codecs enabling the mixer to represent the sound image instead of channels.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Object-Based Audio(OBA)",
                      "immersive sound",
                      "next generation audio encoder",
                      "objects",
                      "live production TV",
                      "personalization",
                      "enhanced listening",
                      "audio codecs",
                      "metadata"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001650"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "The Academy Color Encoding System: Standards for Digital Image Interchange, Color Management and Long-Term Archiving",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andy Maltz"
                  ],
                  "abstract": "The Academy Color Encoding System, known as ACES, was released to the industry in December 2014 as a production-ready suite of technical standards, best practices and support tools. Developed and tested by equipment manufacturers, facilities and filmmakers over the last 11 years, ACES is intended to be the standard digital production infrastructure that enables the industry to take full advantage of new high dynamic range and wide color gamut capture, processing and display technologies. This paper will review the SMPTE standards that are the foundation for ACES, how those standards are used in practice today, and will discuss the roadmap for standardizing ACES transforms, metadata and additional color encodings",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001664"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Thought-Provoking Ideas for Increasing Diversity in Entertainment Engineering",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kellie McKeown",
                    "Wendy Aylsworth",
                    "Andrea Berry",
                    "Cindy Hutter Cavell",
                    "Marilyn Pierce",
                    "Renu Thomas",
                    "Jennifer Zeidan"
                  ],
                  "abstract": "With the average age of SMPTE members increasing, we need to attract younger engineers to strengthen our ranks and our future. By widening our search to fully include women and minorities, we can maximize the opportunity to attract top engineers, while broadening the demographics, perspectives and capabilities of our industry. — This paper is a compilation of essays by women engineers in the entertainment industry including 3 women of color, with observations, ideas and recommendations on how to increase and sustain diversity. — The essays include: • “Start Early through Partnerships with High Schools and Universities”, by Andrea Berry • “Increase Gender and Ethnic Diversity with Internships”, by Marilyn Pierce • “Take a Risk — Give Opportunities to Young Women and Minorities”, by Renu Thomas • “Women in Technology — More than a Pretty Face”, by Jennifer Zeidan • “Colleagues Are Colleagues, No Matter Their Demographic”, by Kellie McKeown • “How to Create Demographically Blended Engineering Teams”, by Cindy Hutter Cavell • “Mentoring 101”, by Wendy Aylsworth — It is hoped that these suggestions will be widely read, considered and implemented, so the Entertainment Industry can benefit from the talents and energy of all demographics.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Diversity",
                      "women",
                      "minority",
                      "minorities",
                      "ethnic",
                      "of color",
                      "demographics",
                      "engineers",
                      "engineering",
                      "careers",
                      "recruiting",
                      "hiring",
                      "STEM",
                      "STEAM",
                      "students",
                      "graduates",
                      "candidates",
                      "applicants",
                      "high school",
                      "college",
                      "university",
                      "intern",
                      "internship",
                      "mentor",
                      "mentoring",
                      "advisor"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001669"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "Using BPMN to Simplify IMF Caption & Subtitle Creation",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bruce Devlin",
                    "Simon Adler"
                  ],
                  "abstract": "Many organisations spend a lot of money trying to streamline caption and subtitling workflows. This paper looks at the use of BPMN (Business Process Model & Notation) in an automated workflow controller to simplify the movement and migration of captions between media files and proprietary authoring formats. It focusses on multi-language workflows using IMF to describe versions. It will include a brief overview of BPMN, IMF and captioning formats, illustrated with some real life examples. It will conclude with a prediction of how far away the panacea of a truly automated captions workflow might be.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IMF",
                      "Captions",
                      "Subtitles",
                      "BPM",
                      "MAM",
                      "Workflow",
                      "MXF"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001671"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "Introduction of a File-System with Integrated Scaling Capability",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Heiko Sparenberg",
                    "Siegfried Foessel"
                  ],
                  "abstract": "For decades, scalable image coding — also referred to as hierarchical-coding — has been an integral part of several standardization activities at JPEG and MPEG. Designed to compensate for slow data-networks, storage-devices or insufficient decoding resources, one may find it surprising, that only very few commercially-available products use this technology today. So why are we not using scalability, even if the advantages sound so convincing? Well, a major disadvantage is certainly the complexity coming with this technology. Often, scalability could solve a technical issue, but workarounds are simply easier to realize. Especially, since each hard- and software would have to implement scalability on its own. To address this issue, we introduce a centralized component within a computers operating system taking care of the scalability. Implemented as a file-system using so-called “parametrized file-requests” we demonstrate a first prototype of such a centralized component, enabling 3rd-party software to use scalability without any additional implementation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Scalable media",
                      "hierarchical image compression",
                      "virtual file system",
                      "JPEG 2000"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001670"
                  }
                }
              },
              {
                "article_local_id": "53",
                "article_title": "Native Resolution Detection of Video Sequences",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/53/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ioannis Katsavounidis",
                    "Anne Aaron",
                    "David Ronca"
                  ],
                  "abstract": "We present a method to detect the lowest resolution that a video sequence segment has undergone before being rendered and presented at some higher resolution. The method is based on extracting homogenous regions within a given video sequence, performing Discrete Fourier Transform on each one of the color components (Y/Cb/Cr) for each video frame, normalizing the magnitude of the spectrum such that the total AC energy is one and then taking its logarithm. Average log-magnitude spectra demonstrate certain patterns that are typical of re-sampling techniques that video frames are undergone during post-production. The method is demonstrated on a few video sequences, showing typical up-sampling of video content, as a result of inherent camera resolution limitations, special effects overlaying at lower than the natural video scene footage and chroma subsampling.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Image resolution",
                      "video format",
                      "Fourier analysis",
                      "aliasing",
                      "image resampling",
                      "interpolation",
                      "chroma sub-sampling"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001673"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Display Technology: The Next Chapter",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "Ultra HD and 4K have arrived and will become “everyday” formats for both consumer and professional applications in short order, thanks to mass production and ever-lower prices. But the transition to UHD, along with adoption of HDR, HFR, and the wider BT.2020 color space, has created some major challenges for display manufacturers. This paper will provide attendees with useful definitions and explanations of the key technologies that are finding their way into next-generation direct-view displays, including IGZO thin-film transistors, quantum dots, organic light-emitting diodes (OLEDs), DisplayPort 1.3 and super MHL interfaces, and high-efficiency LED emitters for projection.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IGZO",
                      "quantum dots",
                      "OLEDs",
                      "DisplayPort",
                      "superMHL",
                      "HLD"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001656"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "Is There a Standard Observer in the House?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt"
                  ],
                  "abstract": "Digital technology is allowing a better color control for all kinds of display. At the same time digital evolution brings new challenges with wider color gamut, higher dynamic range and new color gamut conversions. Color measurements are based on age-old definition of a standard observer. For many reasons, there is little chance for a given spectator to match this average. Worse, new projection systems are causing larger perception deviations. And color sensations and perceptions are strongly influenced by language, culture and education. There is a visible contradiction between reduced calibration tolerances and uncertainties inherent to human perception. How can we use measures and calculations to ensure that every potential viewer is experiencing an audio-visual work as consistent as any other viewer? The solution is to be found by understanding the mechanisms of perception. This knowledge must be applied to the specific situation of audio-visual work projection, using metameric rendition. This means also the perception of whole images and not of a set of single colors. It is even necessary to include whole scenes. It is suggested that digital content analysis is the way to ensure a coherent metameric rendition for any theatrical audience.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Standard observer",
                      "color perception",
                      "metamerism",
                      "color gamut conversion",
                      "color measurement",
                      "color constancy",
                      "Retinex",
                      "Gestalt theory"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001665"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Preservation and Archive: The next 100 Years",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Walter Hinton",
                    "Philip Sciuto",
                    "Lynn Orlando",
                    "Alain Dufaux",
                    "Caryl Jones"
                  ],
                  "abstract": "With companies transferring and collecting vast amounts of digital information being recorded daily, studios are tasked with finding long-term sustainable solutions to create and maintain digital libraries that support content retention. Even as LTO-5 moves to LTO-7, and beyond, higher storage capacity and faster transfer rates using tape technology are not enough to rival the capacity and ease of digital storage systems. This session will look at how Object Storage/Erasure Codes and Ultra-High-Density HDD options are challenging the traditional long-term data storage model and driving a new, more powerful model for archived storage.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Object Storage",
                      "Erasure Coding",
                      "Shingled Magnetic Recording",
                      "RAID",
                      "LTO Tape",
                      "Heat-Assisted Magnetic Recording",
                      "Hard Disk Drives",
                      "Archival Storage",
                      "Montreux Jazz Festival",
                      "Claude Nobs Foundation",
                      "EPFL"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001645"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Technical Analysis, Standard Interpretation, Inspection and Assessment Study for Digital Cinema Stereoscopic Projection",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bo Gong",
                    "Hu Qin",
                    "Dengke Chen",
                    "Feng Wang"
                  ],
                  "abstract": "This paper analyzes and explains the technical parameters of digital cinema stereoscopic projection (luminance, sequential contrast, intra-frame contrast, crosstalk, light efficiency, etc.) based on the newly released GD/J 047-2013 Technical Requirements and Methods of Measurement for Digital Cinema Stereoscopic Projection. Methods of inspection and evaluation for stereoscopic projection are discussed and guidelines for improving the stereoscopic projection quality are also suggested.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital cinema",
                      "stereoscopic",
                      "projection quality",
                      "inspection",
                      "luminance",
                      "light efficiency"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001666"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Utilising Massive Compute Resource in Public Cloud for Complex Image Processing Applications",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202015%20Annual%20Technical%20Conference%20and%20Exhibition/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Welsh"
                  ],
                  "abstract": "This paper explores the deployment of complex image processing applications in public cloud in order to make massive processing jobs practical for post production budgets and timescales. Using an illustrative example of an iterative motion-compensated super-resolution pixel re-construction technique deployed in a cloud platform, which can process what was an 8 week job on local hardware in a few hours using public cloud. However the method is not without its pitfalls and even large public cloud data centres have practical limits which cannot be ignored. Real world examples ranging from 35mm restoration for digital 3D re-release to the latest Hollywood 120fps, 4K, 3D HDR content are discussed. Huge scale resource can be leveraged for otherwise impractical techniques, opening the door to a new breed of high end media processing tools and making them accessible to post-production facilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001661"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "SMPTE17: Embracing Connective Media",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/",
            "articles": [
              {
                "article_local_id": "8",
                "article_title": "How to Coordinate the Streamlined Operations for Commercial Purposes Successfully?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fabio Gattari"
                  ],
                  "abstract": "In today's digital age where audiences are able to access the content they want quickly, Content Delivery Network (CDN) is the new media. The goal of CDN is to serve content with high availability and high performance based on the geographic location of the user, the origin of the webpage and a content delivery server. For every broadcaster, the real challenge lies in how to go into the new media. For instance, legacy transmitters require a television set to receive content. On the other hand, the internet has broadened its reach to PC, tablets, mobile phones and even television users.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Content Delivery Network",
                      "CDN",
                      "Media Asset Management",
                      "MAM",
                      "New Media",
                      "IP",
                      "Broadcast"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001742"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "IT-Based Switching Brings Francis Ford Coppola's New “Live Cinema” Project to Life",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James Stellpflug",
                    "Mike Snell"
                  ],
                  "abstract": "While there's been tremendous advances in broadcast technologies in recent years, the underlying bus matrix and M/E architecture of video switchers has remained much the same. As today's live production projects have grown more complex with greater numbers of smaller, increasingly portable cameras and more content-enhancement capabilities, the limits of traditional switchers have grown, requiring larger crews to ensure quality and reliability, and additional resources “bolted on” as needed for larger, more complex switchers. — A newer generation of production switchers delivers a software-defined approach. Fully scalable, distributed live production platforms brings the benefits of advanced IT technology and uses industry-standard hardware and optimized software. Its production-centric architecture combines three key technologies: GPU-based processing, IP interconnection over any distance, and modular resource and control provisioning. — While these next-generation switchers are ordinarily used within the broadcast environment, legendary writer/ director/producer Francis Ford Coppola selected DYVI (EVS' software-defined switcher) for his recent project, Distant Vision, a “live cinema” project that combines the immediacy of a live event with the sophisticated cinematic grammar of film. Live cinema utilizes feeds from cameras, instant replay servers and other sources, which director can switch live with advanced broadcast equipment. — DYVI was used to cut together feeds from Distant Vision's 40 cameras. Its 17 scenes each had their own distinct camera requirements, so each scene's inputs and sources were pre-set for each one in DYVI, dramatically reducing set-up times, simplifying the production, and ultimately enabling a new kind of moviemaking— performed live and viewed by audiences in real-time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Live video switching",
                      "software-defined",
                      "IT architecture",
                      "Francis Ford Coppola",
                      "Distant Vision",
                      "live cinema"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001737"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Lost in the Clouds? Cloud Storage Fits Into Media Workflows—Just Not Everywhere",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dave Frederick",
                    "Christopher Jenkins"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001739"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "How Automation Can Help Broadcasters and Production Companies Reach Video Production Nirvana",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paula Minardi",
                    "Bea Alonso"
                  ],
                  "abstract": "The global TV & video industry is experiencing disruption and evolution with the rapid growth of video streaming services like Netflix and Amazon. ABI Research forecasts that live linear OTT video services will grow to approximately $7 billion dollars of worldwide revenue by 2021, from a little more than $1 billion in 2016. How is this trend impacting production studios and content creators? — To engage their audience and drive viewership, Netflix promised to double content production and Amazon committed to tripling the number of its original shows. The uptick will continue with some predicting that 2017 output could reach more than 500 scripted shows. Consequently, it will be a steep, new challenge for content producers, broadcasters and VOD service providers to keep pace with increasing demands. Some say this massive increase in programming — coined “peak TV” in some parts of the world—is unsustainable and producers may simply run out of resources and bandwidth. Ultimately, content creators and distributors need creative solutions to address the current surge in demand with lean resources. — This report will discuss the importance of eliminating silos of production through tight integrations across the ecosystem, and introducing production automation to eliminate manual tasks, shorten production cycles and increase productivity. These recommendations will include global examples from broadcasters and production companies who were facing some of these industry challenges. — It's all in effort to meet the TV demands of tomorrow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media logistics",
                      "automation",
                      "video production",
                      "media production",
                      "production",
                      "workflow",
                      "productivity",
                      "efficiency",
                      "streamline workflows",
                      "ingestion",
                      "complexity",
                      "metadata",
                      "collaboration",
                      "AI",
                      "Artificial intelligence",
                      "syndication",
                      "visibility",
                      "curation",
                      "distribution",
                      "recommendation",
                      "monetisation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001738"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Arts and Science – Building the Educational Bridge",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stuart Pointon"
                  ],
                  "abstract": "In the Motion Picture and Television industries, the Arts and Sciences are interdependent. — The massive changes that took place from the 1990's saw the education process that been part of industry collapse. At the same time, the digitisation of media introduced complex new changes in terms of formats, colour spaces and encoding. The introduction of new technologies such as HDR has now further expanded on the complexity of the film and television industry. The democratisation of technology has made it available to a very large cohort. There is a very large gap in the basic technical knowledge of the creatives, and some in engineering with the new choices of technology such as HDR/WCG. Experience has shown that the technical education of creatives in the film schools is limited. Yet it falls to these creatives to make significant choices when they prepare and pursue their project. This paper explores building a bridge between the arts and sciences and the value this brings to the entire industry. The particular requirements in explaining technical jargon and science to be comprehendible and meaningful to the creatives and engineering is explored.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Education",
                      "training",
                      "arts",
                      "sciences",
                      "creative"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001735"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Quality Control & Monitoring in OTT Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ramandeep Singh Sandhu",
                    "Manik Gupta"
                  ],
                  "abstract": "In the OTT world, viewers are watching content when they want, where they want and on the device they want. Content needs to be streamed as per user requirements, on demand and as per the resolution of the playing device. Broadcasters need to ready their content for this mode of playback - they don't control the delivery, consumer does. OTT technology is evolving, and the requirements for monitoring are also changing. Monitoring tools need to be architecturally versatile in order to accommodate this environment and allow broadcasters to figure out which issues are the most critical. Ultimately, broadcasters should choose an OTT monitoring solution for Live and VOD assets that works in tandem with a file-based Quality Control (QC) tool. By deploying a complete QC and monitoring solution for ingest to delivery, broadcasters can deliver the best Quality of Service (QoS) and Quality of Experience (QoE) to viewers in the OTT world.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "OTT",
                      "Over the Top",
                      "VOD",
                      "Video-on-Demand",
                      "Live Event",
                      "QoE",
                      "QoS",
                      "Quality of Experience",
                      "Quality of Service",
                      "File-based QC",
                      "Real-time Monitoring"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001741"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Media Storage in the Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kiran Patel",
                    "Mark Cousins"
                  ],
                  "abstract": "This paper provides insight into the emergence of cloud-based storage services and illustrates how video providers and content distributors are leveraging the scalability, reliability and speed of Internet storage to meet their requirements. Readers will learn about challenges using storage in the cloud; best practices to achieve the highest level of security and performance, together with cost optimization; transitioning to cloud-based video infrastructures; and, optimizing the performance and cost of their cloud storage. Use cases highlight how media and entertainment companies can benefit from cloud object storage.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud storage",
                      "cloud-based video infrastructure",
                      "cloud performance",
                      "cloud object storage",
                      "object storage",
                      "managing storage",
                      "OTT",
                      "VOD",
                      "video on demand"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001744"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Delivering Drama for Extreme Screen",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "These images were the first point of reference for what we needed to deliver on for Wild Squad Adventures. These were the architect's mockup of Taronga Zoo's Centenary Theatre where the finished film is now showing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001745"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "HDR from the Perspective of a Camera Manufacturer",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Jonas",
                    "Harald Brendel"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001751"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Linear Sales Automation and Data Insight As a Step Towards Programmatic TV",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Klaus Schelp",
                    "Dong Zheng"
                  ],
                  "abstract": "As audiences and advertising revenues shift from linear to digital platforms, data-driven automation of linear sales processes provides a key stepping stone towards programmatic TV and cross-platform trading, which promise to provide operational efficiencies and increased revenue. This paper will examine how correlating linear and digital audience data and establishing converged data management and insight capabilities can increase understanding of audience engagement, consumption and behaviour. The paper will conclude by discussing how broadcasters can develop and implement the required shifts of technologies and operating models, and illustrating the ways in which these can enable improved business performance and business controls.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Advertising",
                      "cross-platform",
                      "audience insight",
                      "DMP",
                      "audience measurement",
                      "programmatic trading",
                      "campaign optimization",
                      "inventory optimisation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001740"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Cost Increase due to UHD Video Broadcasting as Compared to HD",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Urvashi Pal",
                    "Horace King"
                  ],
                  "abstract": "It is well known that the television industry has been working passionately to bring UHD content to the viewer's home. 4K production cameras, broadcast equipment and television sets are ready to go, but the actual transmission of the UHD content is yet to begin due to transmission cost constraints. Therefore, in this research, cost increase due to UHD video transmission is compared to HD, using signal quality parameters, in a Rician Fading Channel. Results show that the increase in cost for UHD video transmission is negligible when transmitted through 8PSK, but significant for QPSK.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHD",
                      "DVB-S2",
                      "BER",
                      "Transmission Cost"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001750"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "LTE Managed Media Contribution",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Monique Gleeson"
                  ],
                  "abstract": "Broadcasters are shouting out for more flexible and instant ways that they can provide their audio and video feeds from Outside Broadcast (OB) locations into their studios. Current approaches of deploying OB vans at the venues is both costly and effort intensive. This paper presents the research findings and approach to integrate the 4th Generation mobile (LTE) network with fixed Wide Area Network (WAN) to provide customers with a flexible, reliable and non-contended mechanism to contribute audio and video back to their studio locations while preserving the quality of the feeds, minimising latency and guaranteeing delivery.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LTE",
                      "Contribution",
                      "Video",
                      "audio",
                      "Outside Broadcast"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001747"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Why Does Cinema Sound Quality Mostly Fail to Realise Its Potential? Some Interesting Results from The SMPTE's 2014 Report on Cinema Sound Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glenn Leembruggen",
                    "Philip Newell",
                    "Brian Vessa"
                  ],
                  "abstract": "In late 2014, SMPTE issued a substantial report titled “Frequency and Temporal Analysis of Cinema Sound Systems”, which has become an important milestone for the SMPTE's review of the B Chain systems. Presented in the report are detailed measurements of the time and frequency domain performances of the multi-channel sound systems in four commercial cinemas and two dubbing stages, and a detailed commentary about the process and results. This paper examines some of the interesting results and trends in those measurements, which point to reasons why cinema sound is currently far from ideal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "cinema sound systems",
                      "dubbing stage",
                      "B Chain",
                      "X curve",
                      "frequency response",
                      "impulse response",
                      "cumulative energy",
                      "time windows",
                      "frequency responses with different length windows",
                      "screen losses"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001746"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Capturing Sound for VR & AR",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James Waldron"
                  ],
                  "abstract": "This presentation is based largely on Papers delivered at two previous AES assemblies; Giordano Jacuzzi, Sofia Brazzola, and Johannes Kares at the 142nd AES convention in Berlin in May this year [1] and Johannes Kares and Véronique Larcher at the AES Conference on Audio for Virtual and Augmented Reality in Los Angeles in September/October 2016 [2].",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001748"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Designing Spatial Sound: Adapting Contemporary Screen Sound Design Practices for Virtual Reality",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Damian Candusso"
                  ],
                  "abstract": "The introduction of 360° film and Virtual Reality has meant practitioners have had to adapt to a multitude of new platforms and specifications, with no existing pathways or working methodologies. Audio for Virtual Reality is continually being redefined, with contemporary film sound practices having to adapt to new forms of audio spatialisation and headphone delivery. The variations in virtual reality platforms also necessitates different delivery requirements, with the audio often a secondary consideration. Sound designers and editors are either delivering a non-spatial soundtrack, or they are having to adapt to various spatial plugins and/or game engine platforms in the creation of a cohesive spatial soundtrack. This paper will examine and discuss the current state of sound for Virtual Reality from a creative practice perspective.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Sound Design",
                      "Virtual Reality",
                      "Virtual Reality Sound",
                      "360°",
                      "Film Sound",
                      "VR",
                      "VR Sound",
                      "Immersive Sound",
                      "Immersive Audio",
                      "Game Sound",
                      "Game Audio",
                      "Binaural",
                      "Ambisonics",
                      "HMD",
                      "Interactive Film"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001749"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "IP Workflow and Scalable Video Performance",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Cross",
                    "Stephen W. Bowie",
                    "William Waters",
                    "Jason Pruett"
                  ],
                  "abstract": "The transition from analog to digital took nearly a quarter of a century and an act of Congress; the nonlinear revolution consumed another decade. By contrast, the transformation to an IP workflow is arriving like a bullet train, without legislation, sanction, or specification. In this article we will examine what is driving this headlong rush, and how it will lead to much more elemental transformations. — We will make the case that high-performance IP workflows offer meaningful advantages in productivity and can often be achieved without extravagant expenditures or disruptions. — We will also ask whether, in the rush to adapt and replace SDI workflows, we have fully grasped the potential of IP. This paper highlights IP's promise of affordability, simplicity, and scalability, and points to its potential to transcend the creative limits of linear, point-to-point workflows. — We will also deliver information on a technology that addresses the aforementioned questions, arguing that capability and capacity can be realized today.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001743"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Calibrated Color and Software for LED Luminaires",
                "article_url": "https://journal.smpte.org/conferences/SMPTE17:%20Embracing%20Connective%20Media/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Wagner"
                  ],
                  "abstract": "LED luminaires have become increasing sophisticated over the past several years. Lamp heads are essentially computers with light engines attached to them. Some manufacturers have been able to take full advantage of this by pairing advanced electronics with versatile software features. More importantly, professionals are now able to utilize calibrated LED systems to create precise and accurate colors. With a calibrated LED system, software can be developed over the lifetime of the fixture to create new and better ways of generating color. In this paper, we will discuss the possibilities and advantages of such a system and what it means for the way we pick and generate colors using LED luminaires.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2015-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LED",
                      "Lighting",
                      "Color",
                      "Calibration",
                      "Software",
                      "Luminaire",
                      "Pixel Mapping",
                      "Digital Cameras"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001736"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2014",
        "conferences": [
          {
            "conference_name": "SMPTE 2014 Annual Technical Conference & Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Ethernet AVB Overview and Status",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jan Eveleens"
                  ],
                  "abstract": "This paper provides an up-to-date overview of the IEEE Ethernet AVB (Audio Video Bridging) technology and standards. It describes the basics of the key elements of Ethernet AVB (time synchronization, bandwidth management, transport layer protocols, etc) and why Ethernet AVB is an excellent candidate for next generation digital (live) broadcast infrastructures. Also covered in the paper is a summary of the ongoing activities in the various AVB related IEEE working groups including the work on the second generation of AVB (also referred to as Time Sensitive Networking or TSN). Interoperability will be a crucial factor in the success of video networking in broadcasting infrastructures and the paper introduces the AVnu Alliance and its role in relation to Ethernet AVB standards compliance testing and product certification.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Live Broadcast",
                      "IEEE",
                      "Video over Ethernet",
                      "Audio-Video-Bridging",
                      "AVB",
                      "Time Sensitive Networking",
                      "TSN",
                      "synchronization",
                      "bandwidth management",
                      "transport protocol",
                      "low latency",
                      "interoperability",
                      "AVnu Alliance",
                      "certification"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001535a"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Can COTS Ethernet Switches Handle Uncompressed Video?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Edwards",
                    "Brian Keane"
                  ],
                  "abstract": "The carriage of real-time video over Ethernet networks promises significant benefits to the broadcast industry. But there has been some concern about whether commerical-off-the-shelf (COTS) Ethernet switches can meet broadcast quality of service (QoS) requirements. This paper describes the results of a range of static and dynamic tests of Ethernet switches using packet flows that are representative of uncompressed HD video, looking specifically at packet loss, packet reordering, latency, and packet delay variation (PDV). Flow test generators and analyzers include a new flexible FPGA architecture controlled using a RESTful API.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Networked Media",
                      "2022-6",
                      "Ethernet"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001543"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Management of Consequent Sounds in Immersive Sound Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Redmann"
                  ],
                  "abstract": "Immersive audio is appearing more frequently in modern cinematic storytelling. In traditional sound mixing, scenarios can occur in which a first sound has a tight semantic coupling to a second sound, for example a gunshot and ricochet, or a handclap and its reverberation. In immersive sound systems, such precedent and consequent sounds may be directed to different locations so as to envelope the audience. When consequent sounds are not managed, the psychoacoustic principle known as the “Haas Effect” can result in portions of an audience misunderstanding the placement of precedent sounds, momentarily disrupting their experience. A series of immersive sound examples demonstrates the resulting problem and the effectiveness of a proposed management technique, applicable to object-based, wave field synthesis, and ambisonic reproduction.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Immersive Sound",
                      "Theater Audio",
                      "Evaluation Procedure",
                      "Haas Effect",
                      "Precedence Effect",
                      "Directional Cues",
                      "Channel-Based",
                      "Object-Based",
                      "Wave Field Synthesis (WFS)",
                      "High-Order Ambisonics (HOA)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001545"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Object-Based Audio: Opportunities for Improved Listening Experience and Increased Listener Involvement",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Bleidt",
                    "Arne Borsum",
                    "Harald Fuchs",
                    "S. Merrill Weiss"
                  ],
                  "abstract": "A new TV audio system based on the MPEG-H Audio standard is being designed and tested to offer interactive and immersive sound, employing the standard's audio objects, height channels, and Higher-Order Ambisonics features. Object-based interactive audio offers users the ability to personalize their listening experience, setting their preferred language and dialogue level, or selecting elements to “hear their home team” or listen to their favorite race driver's radio. A four-stage process is introduced for implementing the complete system in TV networks. Additionally, the plant design, creative, and operational implications of producing content are discussed, based on the design and field testing of the system. Consumer reproduction implications are also presented, such as a “3D Soundbar” prototype, the control of loudness in the system, and rendering for playback on both traditional and new media devices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "MPEG-H Audio",
                      "Immersive Audio",
                      "Interactive Audio",
                      "ATSC 3.0",
                      "Dialogue Enhancement",
                      "Loudness",
                      "Audio Objects",
                      "Object Audio",
                      "3D Audio",
                      "Barrier-free"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001546"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "PTP Deployment in Large Networks – Traps and Pitfalls",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nikolaus Kero",
                    "Thomas Kernen",
                    "Tobias Muller"
                  ],
                  "abstract": "The IEEE 1588 Precision Time Protocol (PTP) is a proven method to distribute highly accurate time information over Ethernet networks allowing devices to synchronize their clock to a common time source to less than 100ns. Deploying and operating PTP in large networks with a high number of PTP nodes with differing demands for synchronization accuracy requires detailed planning of the network topology itself. If the network infrastructure is shared with other applications, especially those with considerable bandwidth demands, the PTP performance will be impacted. PTP precision relies on the optimal configuration of all network devices as well as the appropriate settings of all relevant PTP parameters. The principles for designing and configuring large broadcasting networks are described together with PTP performance optimization techniques. The benefits and efficient use of PTP enabled network devices are covered as well. For typical network topologies, measurement results show the effect of individual optimization tasks.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "1588",
                      "PTP",
                      "large networks",
                      "IP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001547"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Internet Protocol Networks in the Live Broadcast Plant",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Buttle",
                    "Charles Meyer",
                    "Sara Kudrle"
                  ],
                  "abstract": "Data Network Technology has advanced to the point where packet video infrastructure can realistically be considered for different workflows. SMPTE 2022-6 provides full bandwidth video transport in the OSI Protocol Stack and by doing so, further enables the transition from SDI to packets. Encapsulation provides flexibility, extensibility and interoperability not otherwise available with existing SDI baseband video standards. Some argue that the overhead costs associated with encapsulation can be prohibitive for HD-SDI and UHDTV data rates push the cost curve potentially higher. But, these cost curves fall with Moore's Law, and in the long run, the flexibility of using packet video to enable intelligent workflows provides better monetization of content and extends the life of CAPEX investments. Examining the different approaches to facility signal routing and distribution demonstrates the tradeoffs between different network technologies and their suitability for various work flows. Using Ethernet AVB, which includes PTP, is one approach, and COTS IP networks equipment with NTP is another. Using an IP Gateway as part of system design today provides a compelling solution bridging today's SDI with tomorrow's packets. Comparing and contrasting these methods provides insight into their suitability for a given workflow, the costs, and event timelines for implementation. Understanding these timelines is critical to business planning.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Live production",
                      "SMPTE 2022",
                      "AVB",
                      "UHDTV",
                      "SDI",
                      "IP Gateway",
                      "COTS IP networks",
                      "NTP",
                      "PTP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001536"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "IP for Contribution Broadcasting: The Next Step of IP Ubiquity",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chin Chye Koh"
                  ],
                  "abstract": "While many rights owners and broadcasters now embrace IP for content distribution, the road has been rockier for IP's adoption for content contribution and production. Pointing to the enormous bandwidth needed to carry high quality live content and the inherent “best-effort” principle underlying the technology that seem incompatible with the need for real-time, no-downtime content transport, media professionals remain skeptical. — But massive affordable bandwidth is now available and technology exists to overcome IP's risks and limitations, bringing easier ways to implement IP and enjoy its economies of scale, built-in flexibility, lower network operating and capital costs, greater flexibility and ability to push more content. — This paper will explore the specifics behind IP infrastructures that include built-in service provisioning, connection management, service analytics, network inventory, and fault-, configuration-and performance-management functions. How to create IP networks—encompassing hardware and software components—that include monitoring and management for systems that are resilient, reliable and easily managed are described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SMPTE ST2022",
                      "Ucompressed Transport",
                      "RTP Switching",
                      "Centralized management"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001538"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "A Practical Approach to IP Live Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Toshiaki Kojima",
                    "John J. Stone",
                    "Jian-Rong Chen",
                    "Paul N. Gardiner"
                  ],
                  "abstract": "SDI infrastructure has been a fundamental building block for video and audio communications within studios for many years. Meanwhile, the bandwidth of generic IP networks has continued to increase alongside falling costs, such that 10G infrastructure is now commonly available. Exploiting this high-bandwidth commodity infrastructure, an IP network could be deployed in the studio to form an IP Live Production system. — This paper explores the technical requirements, design considerations and standards approaches for IP Live Production to be able to deliver business benefits compared to current SDI technology whilst retaining familiar SDI-based production practices. — This paper also describes a sample implementation of an IP-based AV router showing how the discussed technologies can be applied to realize the same functionality as a conventional SDI router.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SDI",
                      "COTS",
                      "4K",
                      "Standardization",
                      "Network Synchronization",
                      "SDI-IP Mapping"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001537"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Perceptual Video Quality Analysis for HEVC in Packet Loss Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bhupender Kumar",
                    "Shekhar Madnani",
                    "Advait Mogre",
                    "Muneesh Sharma",
                    "Shailesh Kumar"
                  ],
                  "abstract": "HEVC provides a significant increase in compression efficiency over legacy standards, such as MPEG-2 and AVC. It is well known that an increase in compression efficiency typically results in decreased coding redundancy. This leads to subsequent vulnerability to error propagation resulting from transmission of stream(s) on a network under packet loss (PL) conditions. Here, incorporating/formulating a perceptual Video Quality (VQ) metric and analyzing VQ over a range of bit rates, PL profiles and a variety of content; would be of interest. Although a number of statistical/opinion models have been proposed and tested for H264 and earlier codecs in various packet loss environments, the parameters of such models have not been defined for HEVC. These statistical models have been designed on the basis of bit rates, packet loss rate, resolution and other parameters. It is assumed that the model parameters will remain same for the entire video sequence. These models do not take content specific properties into consideration, so these are not reliable; different profiles of spatial and temporal variations of content will affect the perceptual video quality differently. Even for the same content, effect of packet loss on perceptual video quality can be very much different depending upon the data lost with the packet. e.g. the effect of loss of a packet corresponding to an I frame can be higher than that of P or B frames because of temporal referencing. So, a new method has been devised and tested over the content with varying profiles of content, bit rate and other characteristics.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "Packet Loss",
                      "VQ metric"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001539"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "State of HEVC Bit Rates in 2014 - Comparing HEVC, H.264 and MPEG-2",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Pallett"
                  ],
                  "abstract": "This paper presents the results of empirical testing of HEVC for SD, HD and Ultra HD, including data from hundreds of test encodes across a variety of bit rates. The paper then compares HEVC quality results with the quality achieved by common MPEG-2 and H.264 distribution profiles, to determine HEVC bit rate recommendations for SD, HD and Ultra HD distribution. — The paper presents the following recommended bit rates for HEVC encoding: SD at 860Kb/sec., HD at 2703Kb/sec., and Ultra HD at 23922Kb/sec. These represent a 45% bit rate savings compared to H.264. — HEVC encoding was done using x265 version 1.2, and all quality measurements were done using PSNR and SSIM. The paper uses HEVC Main profile (8-bit) to allow quality matching with H.264 and MPEG-2 8-bit encoding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "MPEG-2",
                      "H.264",
                      "Bit Rates",
                      "Encoding",
                      "Comparing HEVC",
                      "x265"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001541"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "“Improving Video Streaming and File Compression Efficiency without Affecting Quality”",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yves Faroudja"
                  ],
                  "abstract": "Available network bandwidth can be enhanced while preserving image quality at bitrates reduced by 35% to 50% using any existing compression system, via the use of processing technologies. From archiving and cloud storage to video-on-demand, and from production to distribution, bandwidth can be optimized while preserving video quality in a manner satisfactory to the most demanding content owners and home viewers. — This paper will provide a snapshot into how the efficiency of digital video compression systems may be improved through the use of a pre-processor (before compression) and a post-processor (after compression decoding). The system may include a support layer in parallel with the conventional compression path. The scheme complements conventional compression standards such as MPEG 2, MPEG 4, and HEVC without requiring any modifications to the standard codecs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Compression",
                      "Bandwidth",
                      "Reduced Bitrate",
                      "Video Streaming",
                      "Without Affecting Quality",
                      "Beauty",
                      "Internet Video"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001540"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "A Better Color Matching between HD and UHD Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lars Borg"
                  ],
                  "abstract": "The introduction of a wide-gamut color space in Ultra-HD television creates a need to match colors on wide-gamut UHD displays with colors on conventional HD displays. Many contemporary color conversion methods that apply to conversion from HD to SD, and color conversion methods mandated by current television standards, fail to produce a good color match when converting colors from HD or narrow-gamut UHD color spaces to the wide-gamut UHD color space. This paper illustrates the color errors caused by the application of several of these conversion methods, and recommends one method, using display-referred colorimetry, for better color matching between narrow-gamut and wide-gamut displays.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHDTV",
                      "wide gamut",
                      "color conversion methods",
                      "display-referred colorimetry",
                      "BT.1886",
                      "matching colors"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001557"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "High Dynamic Range Intermediate",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "There is a need to exchange high dynamic range wide gamut moving images that embody creative intent. Simple definitions using CIE 1931 chromaticity having extended gamut may not suffice. It may be desirable to extend gamut beyond P3, even for material mastered using P3 displays and projectors. It is also clearly useful to master to a dynamic range that may exceed a given mastering device. Reduced gamut and dynamic range used temporarily during mastering provides a means of checking image integrity outside of device gamut and range limits. However, additional information about mastering emission spectra is also useful, yet is difficult to interpret as gamut widens further. This paper seeks to explore these issues, and to propose approaches to defining a High Dynamic Range (HDR) Wide Color Gamut (WCG) Intermediate that can be exchanged with increased confidence with respect to creative mastered intent.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "LDR",
                      "WCG",
                      "DI",
                      "ACES",
                      "Mastering"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001558"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Camera Raw Workflows - Like Film, but Digital",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward Reuss",
                    "Lars Borg"
                  ],
                  "abstract": "If you liked working with film, then the techniques to control exposure will feel very familiar to you in camera raw formats. This paper presents how all camera raw formats work in common, and also the different approaches used by several vendors to preserve the highest fidelity image information, while managing the large amounts of data required to represent those images. Camera raw workflows provide a variety of techniques to convert from the sensor data into RGB and YCbCr image formats suitable for mastering, along with methods for generating a specific “look” to the images. Similar to film, the tremendous dynamic range afforded by a camera raw format permits a wide range of exposure during acquisition, which must be mapped into the limited dynamic range of the final output formats in the workflow. However, looks and camera specifications can be deceiving and one must know what is happening within the workflow to obtain the best image quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Camera raw",
                      "workflow",
                      "demosaic",
                      "video compression",
                      "JPEG 2000",
                      "VC-5",
                      "CineForm"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001559"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Smarter Workflows for Multi-platform Delivery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Isaac Hersly"
                  ],
                  "abstract": "The media landscape, with second-screen and online delivery increasingly significant, has changed dramatically. Along with these changes comes the need to fundamentally alter media asset workflows. Managing content from a central repository, where operators can produce files for broadcast, mobile and web on one seamless workflow is the future. This paper will detail how integrated web-based technologies allow asset delivery to any platform in one workflow, enabling content packaging and optimized delivery speed while wrapping in branding and graphics. We'll show technologies that allow content updating right up to the point of transmission, empowering journalists' creativity. Techniques such as storing the edit decision list (EDL) and graphic information as metadata, with the video and graphics playlist then sent to the control room, with the final piece played back in real time on-air-automatically sized and distributed online and to mobile devices-dramatically save storage space and time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media asset management",
                      "MAM",
                      "Video",
                      "EDL",
                      "multi-platform",
                      "IP workflow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001562"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Cinematic Sound Scene Description and Rendering Control",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles Q Robinson",
                    "Nicolas Tsingos"
                  ],
                  "abstract": "Surround sound has been making cinematic storytelling more compelling and immersive for over 30 years. The first widely deployed surround systems used magnetic recording. Later, optical recording became standard, enabling up to 7.1 channels of audio. Most recently, a new paradigm for distribution and playback of cinema sound has been deployed that carries audio streams as well as parameters (metadata) to render the audio customized to the available loudspeaker configuration. In the process of developing this system it has become clear that the art of cinema sound requires more than a physical description of sound sources and the acoustic environment. The audio distribution format must allow the sound designer, mixer, and director to express their intent in ways that go beyond audio scene description and includes explicit instructions on how to render the content in exhibition. In this paper we will describe the metadata charateristics that enable preservation of the essential characteristic of a surround mix to ensure consistent and reliable translation to cinemas. We also present data collected from resent cinema soundtracks to show how such data is used in practice.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cinema",
                      "Surround",
                      "Sound",
                      "Spatial Audio",
                      "Metadata"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001544"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "“Immersive & Personalized Audio: A Practical System for Enabling Interchange, Distribution & Delivery of Next Generation Audio Experiences”",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jeffrey Riedmiller",
                    "Sripal Mehta",
                    "Nicolas Tsingos",
                    "Prinyar Boon"
                  ],
                  "abstract": "Recent advancements in cinema audio continue to bring more lifelike experiences to theatre audiences. These advancements are also driving a transformation across the remaining audio ecosystem and are poised to enable a richer experience in the living room and on-the-go. This paper proposes several practical methods that enable accessible, immersive and personalized experiences from production through playback across broadcast, cable, satellite, IPTV and OTT platforms.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Immersive audio",
                      "object-based audio",
                      "personalized audio",
                      "ED2",
                      "Dolby E",
                      "Dolby AC-3",
                      "Dolby Digital Plus",
                      "Distribution",
                      "Contribution"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001549"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Loudness vs. Speech Normalization in Film and Drama for Broadcast",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Lund",
                    "Esben Skovenborg"
                  ],
                  "abstract": "This paper extends a previously published study of the differences between level normalization of programs using the two dominant methods: Loudness normalization and speech (“dialog”) normalization. Instead of adding to the continuing debate of the subjective merits of one method over the other, important technical aspects are examined empirically. — The difference in normalization level between Loudness and speech measures was up to 14 dB. For all films, the Loudness method provided the greatest headroom. Half the films could be broadcast at a fixed target level of −24 LKFS (loudness, K-weighted, relative to full scale) without dynamics processing. — When it was speech normalized, not a single film could be broadcast at the same target level without applying dynamics processing. The study furthermore found a systematic difference between manual speech measurement and automatic speech measurement. — The measured movies were also compared to the 2013 season of a high profile TV drama production. The loudness properties of the drama were found to be comparable to the movies. In addition, different broadcast/playback paths were found to have markedly different effects on the Loudness Range of the drama series. — Uncertainties in classification, definition, and measurement are summarized and compared to the requirements for precision in Advanced Television Systems Committee (ATSC) and the European Broadcasting Union (EBU) loudness-based standards. Finally, consequences of these findings are discussed relative to ITU-R BS.1864, the International Telecommunication Union's standard on broadcast program exchange.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Loudness normalization",
                      "speech normalization",
                      "dialog intelligence",
                      "metadata",
                      "PLR",
                      "headroom",
                      "measurement uncertainty",
                      "Loudness Range",
                      "ATSC A/85",
                      "EBU R128",
                      "ITU-R BS.1770",
                      "ITU-R BS.1864"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001550"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Integrating HEVC Video Compression with a High Dynamic Range Video Pipeline",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raul Diaz",
                    "Sam Blinstein"
                  ],
                  "abstract": "Today's technology infrastructure allows for the cost-effective delivery of high resolution video. Television displays with 4K resolution are increasingly available and affordable [1], and even mobile devices such as laptops, tables and smartphones are able to display resolutions well in excess of 1920×1080 (HD). Internet bandwidth using broadband and cellular technology continues to increase, and in some countries, both 4K cable and broadcast television are being mandated [2, 3, 4, 5].",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001542"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Digital Audio Transmission Impairment and Link Failure: Test Data, and Recommendations for Improved Industry Standards and Reference Designs",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jon D. Paul"
                  ],
                  "abstract": "Broadcast and cinema applications for digital audio transmission with sample rates (FS) over 48 kHz (e.g. FM digital composite) have experienced signal dropouts and link failures over cables longer than 30 m. Engineers may assume that digital transmission works regardless of source, cable, destination or sample rate. The cables, interface ICs, EMI filters and components for digital audio transmission are designed according to AES-3-4, AES-2id-2012 and ANSI/SMPTE 276M-1995 standards. — The paper presents field observations and test results for 100 m lengths of many types of balanced and unbalanced cables at FS 48-192 kHz, revealing huge variations in cable transmission and received spectra and eye-patterns. — The author includes review and recommendations to update the standards for FS, rise times, bandwidths, eye pattern masks, and circuit designs, to apply to higher transmission rates. The result will be improved and more reliable signal transmission for all sample rates and cable lengths.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "AES-3-4",
                      "AES-2id-2012",
                      "ANSI/SMPTE 276M-1995",
                      "digital audio cable",
                      "digital audio transformer",
                      "AES/EBU cable",
                      "AES-2id",
                      "AES3id",
                      "96 kHz sample rate",
                      "192 kHz sample rate"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001548"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Re-Inventing the Wheel or Choosing the Right One for the Job? Frame Rate Manipulation for the File-Age",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bruce Devlin",
                    "Simon Adler"
                  ],
                  "abstract": "“You shouldn't re-invent the wheel” I was told by one of my university professors. “Why not”? I replied. “I want a lightweight wheel optimised for a bicycle, not a skateboard nor a 747”. My professor taught me a valuable lesson, no-one likes a smart-arse. — In this modern, file based, multi-platform world where more performance is required for a smaller budget, Dalet will present the (AT)3 concept – An Adaptive Temporal Transform Toolbox. Choosing the frame rate or interlace nature of content is a business problem fulfilled by technology; this paper will explore how the right tool selection can minimize costs and maximize quality depending on the requirements of the output media. The paper will consider, OTT deliverables, Internationalisation and Versioning requirements as well as CPU, GPU, cloud and the fault-tolerant technology to make the correct tool choice and deliver those requirements in a cost-sensitive file-based world.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Frame rate",
                      "conversion",
                      "files",
                      "OTT",
                      "versioning"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001552"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Color Management for Wide-Color-Gamut UHDTV Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenichiro Masaoka",
                    "Takayuki Yamashita",
                    "Yukiko Iwasaki",
                    "Yukihiro Nishida",
                    "Masayuki Sugawara"
                  ],
                  "abstract": "UHDTV is a wide-color-gamut system, as standardized in Recommendation ITU-R BT.2020 and SMPTE ST 2036-1, that covers most real object colors and encompasses the gamuts of HDTV, Adobe, and DCI-P3. The development of wide-gamut displays and high-quality gamut mapping are major challenges in the workflow of UHDTV production today. While monochromatic light sources, such as lasers, are ideal for UHDTV wide-gamut displays, wide-gamut LCDs with non-monochromatic backlight sources, such as quantum dot LEDs, may well be used from the viewpoint of both cost and performance. Furthermore, a high-quality gamut mapping algorithm between UHDTV and HDTV for live broadcast production is essential. This paper offers solutions to these challenges.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHDTV",
                      "Rec. 2020",
                      "Rec. 709",
                      "Colorimetry",
                      "color management",
                      "gamut mapping"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001555"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Quality Assessment Framework for Color Conversions and Perception",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt",
                    "Valerie La Torre"
                  ],
                  "abstract": "This paper is an attempt to provide a framework to measure the informational changes brought about in a gamut conversion framework. We build our computations on relative error calculation, and entropy loss evaluation. We compare relative errors after pre-compensation methods, and entropy loss due to different transfer functions in the monodimensional case. The three-dimensional case is also addressed, and the resulting calculations are applied to a multidimensional quality vector, summarizing all the distortions undergone by image digitized content. — Gamut conversion, color transformation, relative error, entropy, quality assessment, display, pre-compensation, OETF, EOTF",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001556"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "HEVC Efficiency Assessment for Contribution Services of HD Interlaced Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Juan Jose Anaya",
                    "Damian Ruiz"
                  ],
                  "abstract": "In April 2014 a new family of HEVC (High Efficiency Video Coding) profiles named “Range Extensions” has been approved in order to cover the needs of high-quality production environments, such as primary distribution, contribution services, and editing/post-production. HEVC Range Extensions support the 4:2:2 and 4:4:4 chroma subsampling formats and pixel depths beyond 10-bit, using the same coding tools as the first version of HEVC. — The new “Main 422@10” HEVC profile will become the successor of the successful “High 422” profile of the H.264/AVC standard, achieving a high efficiency for emerging formats beyond HD, such as the 4k and 8k formats. However HD interlaced content is nowadays the mainstream for broadcasting production, but HEVC profiles do not include specific tools for interlaced content as H.264/AVC did. — This paper addresses the issues involved in HD interlaced contribution services under the HEVC Main 422@10 profile, with the aim to identify its real HEVC efficiency in comparison to the Hi422P profile of H.264/AVC. The simulation results will report the bandwidth saving and other quality improvements that broadcasters and network operators can achieve for HD interlacing encoding using the new HEVC profiles.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "Main 422 10 Profile",
                      "High 422 Profile",
                      "Interlaced Content",
                      "Contribution Services",
                      "High Definition",
                      "Sequence Adaptive Field Frame",
                      "Compression Efficiency"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001554"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Automating Closed Caption Verification, Timing, and Language Identification",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Colin Blake",
                    "Jacob Garland",
                    "Drew Lanham"
                  ],
                  "abstract": "The rapid increase in content due to growth in OTT, foreign distribution, and broadcast channels, combined with recent regulatory requirements related to closed captions accuracy, synchronicity, and completeness, have created scalability and cost-management challenges faced by both video program owners and distributors worldwide. — These challenges are too significant for manual approaches, but can be automated to ensure that all caption files correctly appear against the right media in the right language at the right time. This paper describes the technology behind automated speech analysis that not only flags and reports, but also corrects captions within an accelerated QC automation process.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Closed captioning",
                      "QC",
                      "caption verification",
                      "caption alignment",
                      "language identification",
                      "caption timing",
                      "caption retiming",
                      "video description",
                      "FCC Caption Quality",
                      "caption standards",
                      "CVAA",
                      "Ofcom",
                      "subtitles"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001553"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Utilizing Unique Information from File-based Media for Automated File Detection",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "MICHAEL BABBITT"
                  ],
                  "abstract": "In the United States, the inception of the Commercial Advertisement Loudness Mitigation Act, aka the CALM Act, has created some confusion and uncertainty within broadcast organizations regarding both infrastructure (tools, workflow, logging, etc.) and compliance. While the Federal Communications Commission (FCC) has defined compliance in relatively concrete terms in FCC Report and Order (R&O) 11-182, “Implementation of the Commercial Advertisement Loudness Mitigation (CALM) Act1”, how esactly to achieve compliance relative to the FCC's implementation directives remains unclear. For many broadcasters and operators, CALM compliance remains somewhat of a mystery and most frequently involves a significant amount of manual effort and expense. — This paper proposes a new method of achieving CALM compliance through a novel approach to program detection using existing file-based media processing tools and widely accepted “cloud-based” network systems and a new, out-of-band, data analysis system to create a fully automated method of program measurement, logging and CALM compliance reporting. Accurate identification of programming subject to the CALM Act additionally allows high value programming like movies and scripted shows to be conveyed with cinematic audio attributes like high dynamic range and not be inadvertently or purposefully processed unnecessarily to achieve compliance according to CALM statute requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CALM Act",
                      "Loudness Control",
                      "Automated Program Detection",
                      "Fingerprint",
                      "Logging",
                      "Reporting",
                      "Compliance",
                      "Program Boundary",
                      "Cloud",
                      "Identification"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001571"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "The Origins of Audio and Video Compression: Some Pale Gleams from the Past",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jon D. Paul"
                  ],
                  "abstract": "The paper explores the history that led to all audio and video compression. The roots of digital compression sprang from Dudley's speech VOCODER, and a secret WWII speech scrambler. The paper highlights these key inventions, details their hardware, describes how they functioned, and connects them to modern digital audio and digital video compression algorithms. — The first working speech synthesizer was Homer Dudley's VOCODER. In 1928, he used analysis of speech into components and a bandpass filter bank to achieve 10 times speech compression ratio. — In 1942, Bell Telephone Laboratories' SIGSALY was the first unbreakable speech scrambler. Dudley with Bell Laboratories invented 11 fundamental techniques that are the foundation of all digital compression today. The paper concludes with block diagrams of audio and video compression algorithms to show their close relationship to the VOCODER and SIGSALY.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Audio compression",
                      "speech compression",
                      "video compression",
                      "spread spectrum",
                      "Coded Orthogonal frequency-division multiplexing",
                      "COFDM",
                      "mobile phone compression",
                      "speech synthesis",
                      "speech encryption",
                      "speech scrambler",
                      "MP3",
                      "CELP",
                      "MPEG-1",
                      "AC-3",
                      "H.264",
                      "MPEG-4",
                      "SIGSALY",
                      "VOCODER",
                      "VODER",
                      "National Security Agency",
                      "NSA",
                      "Homer Dudley",
                      "Hedy Lamarr"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001572"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Development of Super Hi-Vision (8K) Baseband Processor Unit “BPU-8000”",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenichiro Ichikawa",
                    "Seiji Mitsuhashi",
                    "Mayumi Abe",
                    "Akira Hanada",
                    "Mitsutoshi Kanetsuka",
                    "Kohji Mitani"
                  ],
                  "abstract": "NHK is developing Super Hi-Vision (SHV), a new television system capable of providing a highly realistic viewing experience. NHK and Sony have recently developed a baseband processor unit (BPU-8000) that works in combination with a Sony F65 camera to produce 8K video, 4K video, and HD video output signals in real time. — The F65 is a commercial digital cinema camera and has an image sensor that is over 4K in resolution. Using the BPU-8000, it is easy for us to use F65 and 8K cameras together to produce 8K live broadcasts. Furthermore, we facilitate 8K post-production after location shoots by equipping the F65 camera with a portable recorder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001573"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Progress in 4K Single-Link Coaxial Cable",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen H. Lampen"
                  ],
                  "abstract": "This paper is an exercise in prediction motivated by the desire to produce single-link coax for 4K (12 GHz) video. Can this be done? And, if so, can such a cable carry these 12 GHz signals far enough that the required infrastructure can be designed and built? And can this cable be produced at a reasonable cost? — It should be recognized that, as this is being written, there is no SMPTE standard for 4K. Until a standard is ratified, this entire discussion is theoretical and based on a best guess as to what the requirements and limitations will be, or should be, for these new cables. — This paper is therefore a conversation between the designers and factory engineers and our customers, the system integrators, installers, designers and end-users as to what will be acceptable performance. Further, it will be demonstrated that any improvements in cable performance will result in changes in many related products. Improvements in cable performance, for instance, will require corresponding improvements to connectors, bulkhead/feedthrough adaptors, patch panels, patch cords and all other passive devices. None of these components are addressed in this paper, and other manufacturers are encouraged to present similar papers for each of these product types.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K",
                      "8K",
                      "Ultra HD",
                      "UHD",
                      "Quad HD",
                      "SMPTE",
                      "HD-SDI",
                      "3G-SDI",
                      "high definition",
                      "serial digital",
                      "1080p/50–60",
                      "lines",
                      "resolution",
                      "pixel",
                      "bits",
                      "color depth",
                      "frame rate",
                      "3D",
                      "quad-link",
                      "dual-link",
                      "single-link",
                      "shields",
                      "foil",
                      "braid",
                      "velocity",
                      "propagation",
                      "dielectric",
                      "gas injected foam",
                      "6 GHz",
                      "12 GHz",
                      "18 GHz"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001574"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Viewing 4K and UHD in an HD World",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Josef Marc"
                  ],
                  "abstract": "HD infrastructure will not, and should not, convert to UHD/4K/8K overnight. The next few years will be experimental and educational. People will need to see, hear, and understand UHD/4K/8K video on HD screens, and HD video on UHD/4K/8K screens. — Drawn from 1 1/2 years of real-world experience in production, postproduction, mastering, quality control, and exhibition, this paper details the practical implementation of SDI, HDMI, DisplayPort, and DVI with UHD/4K/8K video on HD screens, and HD sources on 4K/UHD screens.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHD",
                      "4K",
                      "8K",
                      "SDI",
                      "HDMI",
                      "DisplayPort",
                      "scaling",
                      "multichannel audio",
                      "Dolby"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001575"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Options for Camera Raw in the Digital Workflow",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keith Hogan"
                  ],
                  "abstract": "Raw camera data is an important component in the digital workflow. But, with higher resolution, the ability to get all of the sensor information out of the camera is challenged by the speed of existing interfaces. Additionally, the cost of storing this data for a high shooting ratio projects is cost prohibitive. This paper explores the workflow options that are available for compressing Bayer/Mosaic Pattern data. Topics will include the data layout of the Bayer Pattern for specific cameras resulting in interface speed requirements for different resolutions, compressibility of Bayer Pattern data vs. debayered DI images (entropy differences between Camera Raw and DI images and the impact on Compression Ratio), dynamics of uploading Camera Raw from On-Set to the Cloud, and options when applying compression at various stages of the Production and Post Production workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Bayer Pattern",
                      "Compression",
                      "Lossless",
                      "Cloud",
                      "Entropy",
                      "Workflow",
                      "ARRIRaw",
                      "Canon c500 Raw",
                      "Color Filter Array"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001560"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Identifying Media in the Modern Era the Domains of Media Identity",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steven Posick"
                  ],
                  "abstract": "Identity is the property of an object that distinguishes it from all other objects within a domain, a domain being a physical or logical system by which objects are bounded. Objects may exist within many domains simultaneously, however the object must posses an Identity for each domain to which it is bound. Media, like any other object, may also be bound to many domains, each domain representing or defining some aspect of that Media. For instance, Media can exist within a physical domain where each Media instance represents a unique physical asset or file, while simultaneously belonging to a logical domain in which each Media instance represents a dataset describing a unique set of sights and sounds, without a physical representation. These Domains of Media Identity define the relationships that connect real world events to physical Media and provide the various groupings required to facilitate complex Media workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Identity",
                      "Identity Domains",
                      "Media Identity",
                      "Media Identity Domains"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001561"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Is the Future of Content Protection Cloud(y)?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Diehl Eric"
                  ],
                  "abstract": "As the adoption of cloud computing continues to progress and becomes a critical element in the production and post-production processes of the movie industry, new strategies for protecting content will have to emerge. The lack of sufficient content protection may hinder the adoption of cloud in the industry, which could deprive the community of the many operational and financial benefits that this new approach to delivering technology services can offer. — This paper defines four types of trust assumptions and their relative strength in the different cloud deployment models. It addresses the major threats associated with cloud – such as data breaches, account hijacking, denial of services, or malicious insiders – with a particular focus on content protection. — The cloud increases exposure to risk. The paper explores two use cases: digital delivery and processing. They demonstrate that the clever use of hybrid cloud and new advanced technologies, associated to proper security, may allow secure deployment in the cloud without sacrificing content protection.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Security",
                      "cloud",
                      "hybrid cloud",
                      "encryption",
                      "watermark",
                      "digital screener"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001567"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Remote Content Access and the Rise of the Second Screen",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James Stellpflug",
                    "Stephane Houet"
                  ],
                  "abstract": "Technological advances are allowing operators, editors and producers to remotely access media production servers for content editing and repackaging for distribution and archiving-in realtime, anywhere in the world. Advanced remote production gives unprecedented capability to work remotely, enhance content on the fly, and deliver original content to users' second screens. The paper will analyze the technology, challenges, results, and opportunities behind new capabilities that are changing the media landscape. Real-world examples, including multimedia distribution for the 2014 FIFA World Cup—delivering live streams, multi-angle clips, stats, and social network feeds to viewers' connected screens through broadcaster apps—will be explored. The complex World Cup workflow, encompassing live streaming of six HD camera angles and up to 24 multi-angle replays instantly pushed to a central cloud-based platform, access to 3,000 hours of stored content, on-the-go transcoding and distribution to FIFA's Media Rights Licensees (MRLs), drives an estimated 50 million downloaded apps.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Multimedia",
                      "Multilateral",
                      "HLS",
                      "Streaming",
                      "VOD",
                      "Distribution",
                      "RTMP",
                      "SaaS",
                      "Syndication"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001563"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "High Frame Rate Video Conversion",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paola Hobson"
                  ],
                  "abstract": "SMPTE is discussing high frame rates within the UHDTV Study Group, and in particular, conversions from high frame rates to today's integer and fractional standards. — Although it seems an easy problem to up and down convert between frame rates when there is a simple multiplier e.g. between 119.88Hz and 59.94Hz, in this paper, we show that adequate quality results cannot be obtained by simple frame doubling or frame dropping. — We present a high quality, low complexity frame rate conversion method, suitable for all high frame rate conversions e.g. 120Hz to 59.94Hz or 50Hz to 120Hz, thereby obviating the need to include fractional frame rates in the UHDTV standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHDTV",
                      "standards conversion",
                      "high frame rate"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001565"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "A Tutorial on Photometric Dimensions and Units",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "George Joblove"
                  ],
                  "abstract": "Numerous units are used to measure light, representing a variety of photometric dimensions. In the study of image capture, reproduction, and display, the differences between these various dimensions are important but often a source of confusion. This tutorial enumerates and describes these dimensions and their corresponding units, and explains their appropriate applicability and usage. These dimensions include luminous energy, luminous power, luminous intensity, illuminance, luminance, and luminous exposure. The SI base unit candela is explained, and the derivations of the SI units for the other photometric dimensions are described. An example is provided for the case of sunlight.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Photometry",
                      "photometric units",
                      "dimensions",
                      "tutorial"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001568"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "120fps as a Universal Production Format for Motion Pictures",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Richards"
                  ],
                  "abstract": "For decades motion picture production was locked into the 24 fps frame rate as the release standard for cinema exhibition, despite the shortcomings of that rate for representing movement of both the photographed subjects and the camera. With the advent of digital projection in theaters there are more frame rate options, as some recent movie releases have shown. Not only may movies be photographed and exhibited at higher rates, but the prospect of digital cinematography combined with digital projection has opened up the possibility of new filmmaking workflows, including the intentional decoupling of capture and display frame rates. — By using a frame rate of 120 fps during original photography, DCP masters with frame rates of 24, 30, 40, and 60 frames/sec may be generated from the same source material. One might call this concept “oversampling motion,” and has many of the same benefits as does oversampling in audio processing. — There are several additional benefits: the director can control the effective shutter angle thereby optimizing motion blur versus aliasing artifacts; decide whether to employ a slow motion effect, and if so how much – all in post-production. Additionally the method eliminates the need to implement 3-2 pulldown for subsequent broadcast or home video release. The method combines frames using a simple blending scheme and doesn't introduce the motion artifacts typical with frame rate conversion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Frame rate",
                      "HFR",
                      "The Hobbit",
                      "Avatar",
                      "James Cameron",
                      "Peter Jackson",
                      "Doug Trumbull"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001564"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Addressing Issues in File Based Workflows: The Joint Task Force on File Formats and Media Interoperability",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Lennon",
                    "Harold Geller",
                    "Clyde Smith"
                  ],
                  "abstract": "When it comes to media, measurement is what it's all about. We are all in the business of monetizing our media assets, but without accurate measurement of their consumption, we really can't do a good job of this. 2014 has seen some very important advances in technologies that enable not only the management, but also identification, and measurement of media consumption. SMPTE is standardizing the representation of Ad-IDs and EIDRs, as well as how to handle those in MXF files. They are also working on the embedding of these identifiers in content in such a way that it can survive all means of transformation and distribution to viewers. Couple this with work that has already been done, and we are on the cusp of having a very powerful toolset for media management and measurement.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ad-ID",
                      "Joint Task Force",
                      "File Based Workflows",
                      "standards",
                      "workflow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001551"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Quality Advancements and Automation Challenges in File-Based Conversion: Noise-Reduction, Deinterlacing, High Frame Rates, and Compression Efficiency",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keith isovdeo Slavin",
                    "Chad isovdeo Fogg"
                  ],
                  "abstract": "With continued expansion of IP infrastructures and better compression schemes, the age of explosive growth in video online content has arrived. Bigger (UHD/4K/8K), faster (HFR) and better display technologies offer the potential for a truly immersive viewing experience. However, the shortcomings inherited in archive material, such as noise, and other artifacts, are increasingly visible. All content needs to compete for bandwidth and viewership, so high quality pre-processing prior to compression is becoming more important. Pre-processing can help to achieve the best possible picture quality while saving significant compressed bit-rates, in particular for remastering. This paper shows detailed compression efficiency results relating to deinterlacing, noise reduction, and simulated motion-blur. Additionally, an overview on an innovative clustered server system is given, with emphasis on advancements in flexibility, automation, efficient scalability, and latency. Various clips showing processing quality are available on request.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HFR",
                      "Noise reduction",
                      "Motion-compensated",
                      "Deinterlacing",
                      "Frame-rate conversion",
                      "Remastering",
                      "File-based",
                      "Standards conversion",
                      "Up-scaling",
                      "GPU",
                      "IP-based",
                      "UHD",
                      "4K",
                      "SD",
                      "HD",
                      "AVC/HEVC Compression",
                      "Online distribution",
                      "Workflow",
                      "Low latency",
                      "Scalability",
                      "Flexibility",
                      "Automation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001566"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Quantum Dots and Rec. 2020 – Bringing the Color of Tomorrow Closer to Reality Today",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James Thielen",
                    "James Hillis",
                    "John Van Derlofske",
                    "Dave Lamb",
                    "Art Lathrop"
                  ],
                  "abstract": "The International Telecommunications Union (ITU) has recommended a broadcasting standard (Rec. 2020) for ultra-high definition (UHD) television that is aimed at providing a better visual experience. They recommend a color gamut that exceeds previous broadcasting standards and is currently only achievable by laser-based display technologies. Quantum dot (QD) enabled liquid crystal displays (LCDs) provide one alternaltive with potential to meet Rec. 2020's standard color gamut while taking advantage of existing manufacturing capacity. We examined how existing QD and LCD technology could be optimized to meet the Rec. 2020 color standard. Our analysis revealed that up to 94% gamut coverage can be achieved.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LCD",
                      "Quantum Dots",
                      "3M™ QDEF",
                      "Rec. 2020",
                      "High Color Gamut",
                      "Color"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001570"
                  }
                }
              },
              {
                "article_local_id": "52",
                "article_title": "Design Considerations for Cinema Exhibition Using RGB Laser Illumination",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/52/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Houston",
                    "William Beck"
                  ],
                  "abstract": "Laser light sources used in digital projectors have the potential to increase quality for several image parameters including high brightness, dynamic range, and color space. This paper discusses advantages of laser illumination for digital projection as well as considerations for design of future cinema parameters such as luminance standards, high dynamic range projection and a wider color space, including the practicality of Rec. 2020 as a projection gamut. Practical concerns and limits of lasers are examined in the context of near term implementations, and suggestions for future theater and projector design are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital Cinema",
                      "next generation cinema",
                      "Laser Illuminated Projectors",
                      "LIP",
                      "laser light sources",
                      "RGB laser projection",
                      "human visual system",
                      "HVS",
                      "projection design",
                      "theater design",
                      "Premium Large Format",
                      "PLF",
                      "high dynamic range",
                      "HDR/EDR",
                      "wide color gamut",
                      "WCG",
                      "Rec. 2020",
                      "theater luminance"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001586"
                  }
                }
              },
              {
                "article_local_id": "53",
                "article_title": "Toward Real-Time Detection of Forensic Watermarks to Combat Piracy by Live Streaming",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/53/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Rudman",
                    "Mathieu Bonenfant",
                    "Mehmet Celik",
                    "Joe Daniel",
                    "Jaap Haitsma",
                    "Jean-Paul Panis"
                  ],
                  "abstract": "Over the past several years, anti-piracy analysts have documented the transition of casual content piracy away from Torrent networks to streaming sites which provide immediate access to not only live TV broadcasts, but also file-based pirated content, such as movies and TV episodes. — Since Live Content such as professional sports or Pay Per View events have only one release window, they will lose market value immediately if they can be streamed live, thus there is a recognized need to act quickly in the case of piracy and hence to shorten the time needed to extract the forensic watermark payload to as close to real-time as possible. — In working toward inline detection of forensic watermarks from streaming content, we seek to enable a new tool designed to identify the pirate source in minutes. With the ability to detect a session-based forensic watermark directly from a video stream, it is possible for an operator to disable a set-top box or streaming client while the transmission is still in progress.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Forensic watermarking",
                      "piracy",
                      "content monitoring",
                      "live streaming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001587"
                  }
                }
              },
              {
                "article_local_id": "55",
                "article_title": "4K: Models for Motion Control to Ensure True 4K Detail at Capture",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/55/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre Hugues Routhier"
                  ],
                  "abstract": "The advent of 4K bears the promise of resolutions 4 times larger than 2K Digital Cinema. For images to take advantage of this increase, capture systems must be configured and operated to maximize detail. — One of the critical components for maintaining image detail is motion blur, dictated by optical flow (motion, as seen by the sensor) and shutter speed (to ensure smoothness of motion). — In this paper, the author details mathematical models and practical methods to optimize motion during 4K capture and provides recommendations based on his experience in 4K. — One of the significant conclusions of this research is that with ultra high resolutions, given the low frame rates of cinema (24 and 48 fps), motion blur is the most significant factor limiting detail beyond 2K and needs to be managed closely during production, as much as depth of field is with conventional cinema.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K",
                      "UHD",
                      "Motion",
                      "Detail",
                      "optical flow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001589"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "2014 Survey Summary for Storage in Professional Media and Entertainment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas M. Coughlin"
                  ],
                  "abstract": "Digital storage plays a significant role in the professional media and entertainment industry. Digital storage for the M&E industry has demand characteristics often very different from typical IT storage because of the performance requirements of real-time video in capture, editing and post-production as well as distribution. On the other hand, the ever growing archive of long-tail digital content and increasing digitized historical analog content is swelling the demand for cold as well as warm archives using tape, optical discs and hard drive arrays. — In March through May of 2014 Coughlin Associates, Inc. conducted a survey of professional media and entertainment professionals on various digital storage topics. The survey was broken down into several segments: content capture, editing and post-production, content delivery as well as archiving and digital preservation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital Storage",
                      "Hard Disk Drive",
                      "Flash Memory",
                      "Optical Disc",
                      "Content Capture",
                      "Post Production",
                      "Content Delivery",
                      "Archive",
                      "Preservation",
                      "Survey"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001576"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "The Control of Media within an Internet of Things Using SMPTE ST2071",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steven Posick"
                  ],
                  "abstract": "The “Internet of Things” (***IoT) refers to an Internet like structure consisting of uniquely identified objects that expose services. These services are typically designed using traditional Object Oriented methodologies that encourage the coalescence of features into a single consolidated view. This may work well for homogeneous environments but can be problematic for heterogeneous environments, such as media control systems, where objects may be modular and change their behavior dynamically at runtime. To better represent objects within these environments, and the IoT, the SMPTE ST2071 standard allows objects to be described using sets of uniquely identified features, known as Capabilities. Capabilities can be used in much the same way as building blocks to construct object behaviors and the objects can change their behavior dynamically by changing the set of Capabilities exposed. In addition, the use of Capabilities also allows objects to be discovered within the IoT by the features they support.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Internet of Things",
                      "IoT",
                      "SMPTE ST2071",
                      "Media",
                      "Device Control",
                      "Media Control",
                      "Web of Things",
                      "Web Service",
                      "Capabilities",
                      "Capability-based Programming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001581"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Taking Remote Production to the Next Level CBC's Coverage of the 2014 Sochi Olympic Games",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Johnston"
                  ],
                  "abstract": "In 2012 CBC was awarded the Canadian broadcast rights for the 2014 & 2016 Olympics. The Olympic broadcast experience is a nation-building event that embraces partnerships, cross platforms and be shared in multiple languages. Content will be delivered on TV, desktop, mobile, tablet and radio platforms with all sport available to watch live in both official languages; emphasizing a need for a production model that is flexible, robust and cost effective. To meet this challenge, CBC/RC has chosen a remote production model that utilizes a transmission concept that will extend the reach of our Olympic headquarters in both Montreal and Toronto not only to the IBC (International Broadcast Center), but directly to the sporting venues. — This presentation will cover new concepts of remote production, next generation live remote event delivery, and transmission concepts that allow CBC/RC to make innovative production and cost minimizing decisions. Remote production, as it applies to the CBC/RC, is a concept of producing content with minimal infrastructure deployed at the remote site. With only the necessary resources on site costs are reduced, but more importantly quality and accessibility of media are increased utilizing existing robust infrastructure at home to support remote talent. Remote production on this scale required the development of new transmission concepts. Subjects covered will include file based delivery of content, IP technology at the venue, minimizing frame rate conversion, remote audio and video production, and next generation transmission. The presentation will also provide insight into the technical and operational challenges that were overcome and production opportunities that were realized during the design and implementation of the plan.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Remote Production",
                      "Olympics",
                      "Transmission",
                      "Standards/Frame Rate Conversion",
                      "5.1 Audio",
                      "Surround Sound",
                      "File Sharing",
                      "File Based Workflow",
                      "Web",
                      "Mobile",
                      "Streaming",
                      "Encoding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001583"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "Concept for a File Based Content Exchange Ecosystem Using Scalable Media",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Heiko Sparenberg",
                    "Siegfried Foessel"
                  ],
                  "abstract": "This presentation introduces a concept of a file delivery ecosystem, especially exploiting the features of scalable (or hierarchical) media like JPEG 2000. The innovation of this concept is the possibility that the recipient may start to work with the transmitted content even before completion of the transfer due to the scalability feature. For this, a reduced sub-variant, derived from the scalable sources, will be transmitted in the first phase, until the full media data reaches its destination. The recipient is therefore able to get a preview faster. Subsequent phases will add more and more information to the sub-variant transmitted in the first phase. Due to a concept called Substitution Method — which has been presented at ATC 2012 — the software running at the destination is able to rebuild the file-structure of each media file and to simulate missing data so that the images can be used for further processing before the overall transmission is completed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Scalable media",
                      "JPEG 2000",
                      "Material eXchange Format (MXF)",
                      "Interoperable Master Format (IMF)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001578"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "LTFS Transforms LTO Tape into Nearline Storage: Accelerating 4K Media Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tridib Chakravarty"
                  ],
                  "abstract": "Linear Tape-Open (LTO) has emerged as an economical, long-term storage medium for the increasing amounts of high resolution content in file-based workflows. LTO is a serial access storage medium where files cannot be directly accessed, and requiring files be restored prior to use. While this model has worked well for users of smaller file sizes, restoring large files from LTO to disk presents a new set of challenges. In addition to requiring complex and costly storage architectures, restoring immense amounts of high resolution content (2K, 4K, UHD) from LTO causes bottlenecks in file-based workflows and make it difficult and time consuming to repurpose content. — Linear Tape File System (LTFS) technology has the potential to turn LTO tape into a direct access storage medium, much like disk. While LTFS alone does a good job of presenting a file system, it does little to alleviate the inherent serial access latencies of LTO tape. In most cases, when an LTFS file system is exposed to an application, unacceptable response times caused by tape latencies result in a poor end user experience. — Direct access technology, DNA Evolution™ “Smart Access”, works together with LTFS to enable intelligent, selective caching of portions of files on LTO in a manner that allows third-party applications to have seamless access to LTFS-formatted LTO tapes. By combining “Smart Access” with LTFS, the LTO tape can become a nearline storage medium capable of supporting tasks such as: transcoding, shot selection, partial restore, remote transfers, and distribution, for faster and more cost-effective media pipelines.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LTO",
                      "LTFS",
                      "Direct Access",
                      "File-based Workflows",
                      "4K",
                      "HD",
                      "asset management",
                      "HSM",
                      "Active Archiving"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001577"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Off-the-shelf IP Routing Switchers in the Hybrid IP/SDI Television Broadcast Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "With the transition of video content from analog to digital, and the computerization of TV production equipment, the incorporation of IP technology into the broadcast infrastructure is a logical next step. The use of video, audio, and ancillary data as IP streams provides specific advantages and challenges as compared to SDI-carried content; the core component for this infrastructure will be a system to support the routing of these IP-based content streams in the broadcast environment. How to best manage the streams; what are the best mechanisms and hardware devices suitable for achieving the specific requirements for broadcast in terms of content quality, reliability and time-base? The contention of this paper is that carrier-grade, off- the-shelf IP routing switchers are more than capable, indeed represent an ideal solution for routing IP-based video content in what will become a hybrid SDI and IP infrastructure.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001580"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "Development of an Accurate and Repeatable Measurement Method for Speckle in Laser Illuminated Projectors",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rick Posch",
                    "Pete Lude"
                  ],
                  "abstract": "With the emergence of lasers as a replacement for xenon arc lamps in ultra-high brightness digital projection applications, it is desirable to preserve the best possible image. Speckle is one aspect of image quality that has been fundamentally difficult to measure, due the unique physical characteristics of coherent light and the absence of a single focal plane for the speckle image. In this paper, the success criteria for a speckle measurement method are identified, and industry work to date is surveyed. The challenges of measuring low values of speckle are identified as: a large number of variables; system interaction among variables; and noise. The concept of Uniform Field Contrast Ratio (UFCR) is introduced to distinguish between Speckle Contrast Ratio (SCR) and contrast due to non-speckle noise sources that can affect SCR measurement. We expect that ultimately two different measurement methods will be needed: one optimized for low noise, and one optimized for commercial cinema installations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Speckle",
                      "measurement",
                      "laser",
                      "projector",
                      "projection",
                      "illumination",
                      "SCR",
                      "UFCR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001585"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Next-Generation Display Interfaces: Smaller, Faster & Denser",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "UHDTVs, tablets, smartphones, Blu-ray players, and ultrabooks all have one thing in common: They're equipped with a new generation of smaller, faster, and more sophisticated display interfaces. These 100%-digital connectors not only carry high-resolution video, but multichannel audio, control signals, high-speed serial data, and even Ethernet connections – and some do all of this with just five pins. — As pixel counts, clock rates, and color bit depths increase, these new interfaces become a critical link in the content chain. But are they fast enough? Is it finally time to employ compression on display signals? How many signals can be multiplexed through a display connection? Does the future of display interfacing still have room for differential signaling, or is it time to move to a 100% packet-based interface?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDMI",
                      "DisplayPort",
                      "MHL",
                      "SlimPort",
                      "Thunderbolt",
                      "DockPort",
                      "Micro HDMI",
                      "HDBaseT"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001569"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "Monitoring Video Services in an IP Connected World",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chuck Wester",
                    "Yasser F. Syed",
                    "Joseph Badro"
                  ],
                  "abstract": "Applying traditional methods of video quality and service delivery monitoring to highly evolved and changing delivery methods to customers using all manner of viewing devices anytime/anywhere just doesn't work. Video service monitoring must evolve with video service delivery methods in a reasonable, cost effective, scalable manner. This paper examines how to approach quality and service monitoring in next generation IP-enabled services such as CloudTV, cDVR, and cVOD and how to take advantage of the new IP architectures being deployed. It will examine what issues will be encountered using a traditional monitoring and data collection approach. It will then look at alternative approaches using new paradigms on what to monitor, how to monitor it, and what data not to store. Creating a monitoring system around this approach is easier because of the IP infrastructure already in place in the network and also built into equipment. We propose that doing less checking of individual faults and shifting more towards system health monitoring of the data network, through trending and automated testing strategies, will be a way to proactively handle multiple potential faults at the same time, while paving the way to predictive outage detection.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001582"
                  }
                }
              },
              {
                "article_local_id": "54",
                "article_title": "4K-to-8K TV Up-converter with Super Resolution",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/54/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Seiichi Gohshi"
                  ],
                  "abstract": "The 8K system is intended to be the ultimate high-resolution broadcasting system. However, 8K equipment is still under development, and there will be a lack of 8K content once broadcasting begins. It would thus be very useful if 4K content could be converted to a sufficient resolution level to be viewed on 8K systems. Conventional up-converters, from SDTV to HDTV, change the video format with interpolation technology and enhancers. They cannot create higher frequency elements than those of the original content. The same problem affects up-converted 8K content; simply up-converting 4K to 8K does not produce high-resolution 8K content. This paper describes a 4K-to-8K up-converter that uses a novel form of super resolution (SR) technology. The SR technology creates frequency elements that are higher than those of the original 4K content. It can even create elements above the Nyquist frequency, which had been considered a theoretical limitation The 4K-8K up-converter can create content with the same resolution as that of an 8K camera operated in real time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001588"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "A Holistic Approach to Digital Preservation",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bjorn H Brudeli"
                  ],
                  "abstract": "Archivator, presented at Archiving 2012, is a solution for secure, migration-free long-term preservation of digital data. It consists of equipment and processes needed for writing and retrieving digital data. During the development, we realized the need of a truly holistic solution for digital preservation. Subsequently, two industrial consortiums funded by EU's Eurostar program and Norwegian Research Council were set up; MiLoS and AStoR. — The outcome is a turn-key solution designed specifically for digital preservation requirements. It includes all components needed in a full work-flow; digital data-writer, data-reader, software, hardware, processing machines, storage solution and storage medium. Yet it is an open technology where users are not locked in by any vendors. All materials are tested to ensure data integrity remains intact for 500 years. National Archives of Sweden has successfully tested the Archivator workflow on various digital data objects in an OAIS [1] context.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Preservation",
                      "archiving",
                      "OAIS",
                      "Piql"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001579"
                  }
                }
              },
              {
                "article_local_id": "56",
                "article_title": "Beyond HD - The Status of the Image Acquisition Solutions for the Next Generation Broadcasting Formats",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/56/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Klaus Weber"
                  ],
                  "abstract": "Many discussions inside the broadcasting community are focused on next generation broadcast formats. For content producers and distributors, the question remains, “what will be the best solution for the next generation broadcast format?” Is it just the double pixel count in horizontal and vertical directions? Will a higher frame rate and/or a higher dynamic range and extended color range provide viewers a higher value? Or which combination of these improvements need to be included in a next generation broadcast format? The answer will likely depend on the type of production and/or content delivery. All these points have a direct influence on the imager technology and this paper explains the different potential solutions of “4K” or UHD image acquisition including their strengths and limitations with the focus on live broadcast productions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HFR",
                      "HDR",
                      "color gamut",
                      "CCD imagers",
                      "CMOS imagers",
                      "FT-CMOS",
                      "rolling shutter",
                      "global shutter",
                      "single super35 imager",
                      "color pattern filter",
                      "prism beam splitter"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001590"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "A Cinema Luminance Range by the People, for the People: Viewer Preferences on Luminance Limits for a Large Screen Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Suzanne Farrell",
                    "Timo Kunkel",
                    "Scott Daly"
                  ],
                  "abstract": "Display technology has been improving rapidly, in some areas faster than others. Televisions, tablets, and smart phones bring images to life through a combination of a brighter maximum luminance, a deeper black level, and/or a wider color gamut. Preference studies in this area also confirm that viewers are looking for these increased capabilities in their displays. One such study performed on a TV-sized display at Dolby Laboratories [4] found that to satisfy 90% of viewers a luminance dynamic range of 0.005 to 20,000 cd/m2 would be required. — Translating results from small displays to the larger screens of the cinema is not always straightforward because of the conjecture that large screens will influence a viewer's preferences differently. For example, it is assumed that, in comparison to a smaller display (i.e. television), the brightness preference for the cinema is dimmer. This generalized assumption, however, includes multiple aspects such as contrast increased flickering with higher luminance, and different fields of view. To investigate those aspects, we have conducted a study on viewer preferences for the cinema environment isolating the maximum diffuse luminance, the minimum luminance, and highlight luminance from these other factors. We used a 6 kW cinema projector and 13 foot, 2.8-gain screen, producing a luminance dynamic range of 0.002 to 2100 cd/m2, and concluded that the most demanding viewers prefer 22 stops of cinema dynamic range — double the number of stops of the existing dynamic range of the cinema.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cinema dynamic range",
                      "luminance",
                      "shadow detail",
                      "display",
                      "highlights",
                      "subjective study"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001584"
                  }
                }
              },
              {
                "article_local_id": "61",
                "article_title": "IT-TV-Live an Integrated Concept for IP-based Distributed Broadcast Production with ‘SDI Quality’",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/61/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alfred Krug"
                  ],
                  "abstract": "Broadcast production has been growing in complexity for several decades. This growth has been incremental, based on a largely unchanged broadcast architecture. Key components necessary for production-centric functions have evolved continuously in quality and functionality, but have brought increased complexity in signal routing and control interconnections. — Today, signal routing is joining control in exploiting IP-based solutions; productions with widely-distributed acquisition and control locations must now be supported; new emerging control systems must be user-friendly; SDI-based studio quality must not be compromised in this transition. — The paper describes a new, fully-scalable production-centric architecture, with software virtualization of a modular hardware device's network location. GPU-based on-demand video processing with compression-free interconnection via IP routing allows natural execution of creative intent in live productions. The linking network is scalable from studio to intercontinental access level. The enhanced functionality and flexibility now demanded in today's live productions is elegantly achieved in this major rethink.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "major rethink",
                      "distributed remote production",
                      "IP-based live production",
                      "scalable",
                      "low latency",
                      "SDI quality"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001595"
                  }
                }
              },
              {
                "article_local_id": "57",
                "article_title": "IP to the Camera - Completing the Broadcast Chain",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/57/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Jachetta"
                  ],
                  "abstract": "Extending studio data networks to cameras located anywhere around the globe is the logical endpoint of work currently underway to develop standards for future studios. Not only does this reduce the number of signal formats that need to be supported, but also enables significant cost savings by reducing or eliminating the need to deploy people and equipment to remote venues for live productions. Mobile production and ENG teams can reduce or eliminate their dependency on mobile production trucks. This paper will describe technical details of the Stagebox system developed by BBC R&D including: – Multicamera video and audio synchronization enabled by IEEE 1588 PTP – Video and audio encapsulation – Support for ancillary services including timecode, talkback, tally, and camera control – Direct integration into live workflows, including editing, archiving, and live-to-air production – Direct Deployment on the camera back with battery power — This paper will describe several live events around the globe that have already been successfully produced using this system, including “lessons learned” along the way.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "stagebox",
                      "ip camera back",
                      "avci-100",
                      "bbc",
                      "vidovation",
                      "ieee 1588",
                      "multicamera synchronization",
                      "synchronization ethernet",
                      "ptp",
                      "precision timing protocol",
                      "typhoon"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001591"
                  }
                }
              },
              {
                "article_local_id": "59",
                "article_title": "A Psychophysical Study Exploring Judder Using Fundamental Signals and Complex Imagery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/59/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Scott daly",
                    "Ning Xu",
                    "James Crenshaw",
                    "Vikrant J. Zunjarrao"
                  ],
                  "abstract": "There are well-known observations of movie content being displayed at different frame rates. While the terms are not consistent across the industry, there are four main degradations of the signal as compared to non-sampled motion (i.e., real-world motion). These are: 1. Non-smooth motion 2. False multiple edges, 3. Flickering, and 4. Motion blur. In natural imagery, all four of these effects are generally visible at typical movie frame rates. The spatiotemporal window of visibility [1] has proved successful in describing when motion looks distorted from the real-world smooth motion. However, that model only predicts detection performance, and doesn't address the appearance or magnitude of motion distortions. In addition, there are also well-known image capture and display parameters involved with frame rate questions, such as exposure duty cycle (angle), object speed, and object contrast. There are also known interactions with brightness and contrast, which are also generally linked in the end-to-end system. For example, the Ferry-Porter law of psychophysics indicates the temporal frequency bandwidth of vision increases with increasing adapting luminance. We aimed to isolate the non-smooth motion component of judder in a psychophysical study by using fundamental test signals, such as the Gabor signal. Two interval forced choice methodology was used to generate interval scales of the magnitude of judder, or judderness. Results are presented for the viewer assessment of the magnitude of judder, or judderness, as a function of these key parameters tested in isolation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Judder",
                      "Motion Artifacts",
                      "Frame-Rate",
                      "Subjective Study"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001593"
                  }
                }
              },
              {
                "article_local_id": "60",
                "article_title": "A Quality Metric for High Dynamic Range",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/60/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "The Peak Signal to Noise Ratio (PSNR) metric has long been utilized for codec evaluation and development, and other uses. However, for High Dynamic Range (HDR), the PSNR metric is not suitable. A more appropriate characterization of coding and image quality is to split image brightness into ranges (such as factors of two), and then determine the standard deviation within each such range. Once the standard deviation (sigma) has been determined, the two sigma and above population of pixel differences is shown as percentages of pixels. This is necessary because codec pixel differences do not typically follow a normal Gaussian error distribution. The value of sigma at each brightness range, together with the percentage proportions of two sigma and above outliers, provides an appropriate quality metric system for HDR.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDR",
                      "Sigma",
                      "PSNR",
                      "Outliers"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001594"
                  }
                }
              },
              {
                "article_local_id": "58",
                "article_title": "Confidence Monitoring: Any Time, Any Way, Anywhere",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202014%20Annual%20Technical%20Conference%20&%20Exhibition/58/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Farmer"
                  ],
                  "abstract": "Audio and video confidence monitoring has progressed beyond the simple analog world with the evolution of broadcast technology into digital baseband, compressed video, and IP distribution networks. — Modern broadcasters are looking for increased operational efficiency, often by not tying down broadcast engineers to a central monitoring station. With the emergence of sophisticated data networks, Wi-Fi infrastructures, 4G mobile access and the internet, it is now possible to monitor these critical signals remotely on phones, tablets and traditional PC's. — This paper describes the technology enabling this advanced remote monitoring application and discusses related operational and financial benefits.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2014-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Remote Monitoring",
                      "MPEG Monitor",
                      "Confidence Monitoring",
                      "iON",
                      "Loudness Control"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001592"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2013",
        "conferences": [
          {
            "conference_name": "SMPTE 2013 Annual Technical Conference & Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Gamut Mapping for Digital Cinema",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/1/",
                "article_tags": [
                  "Information",
                  "Open access"
                ],
                "metadata": {
                  "authors": [
                    "Jan Frohlich",
                    "Andreas Schilling",
                    "Bernd Eberhardt"
                  ],
                  "abstract": "To ensure consistent presentation of wide gamut Digital Cinema Packages (DCPs) on standard gamut screens, a mandatory gamut mapping strategy has to be chosen. In this paper, current gamut mapping algorithms are evaluated with respect to their application in digital cinema. These algorithms include: “Simple Clip”, “Cusp Clip”, “Minimum delta E” (MindE), “Hue preserving MindE”, “Weighted MindE” and the mapping strategy which is used in current projectors. The investigated gamut mapping algorithms will be provided as 3D lookup tables for comparison. These can also be used to retrofit a more advanced gamut mapping strategy to standard gamut projectors. Therefore, the paper closes with an analysis of the losses introduced by using 3D lookup tables for gamut mapping. The intent of this paper is to initiate a discussion about gamut mapping strategies for digital cinema, which may ultimately lead to an addendum to the SMPTE standards for digital cinema.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Information"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "gamut mapping",
                      "digital cinema",
                      "digital projection"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001489"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "The Fundamentals of the All-IT Media Facility",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Al Kovalick"
                  ],
                  "abstract": "Over the past 10 years, file-based (IT) production and broadcast workflows have become mature. However, the migration of real-time AV workflows using IT has taken a back seat, until now. With the advent of Software Defined Networks/Storage, 10G Ethernet, low latency network switching, compute virtualization methods and widely available web apps (SaaS), the move to the “all-IT facility” is on the horizon. This paper will describe the enabling technologies and their role in the migration. Technical obstacles and advances to resolve them will be described. Bottom line, a clear path to the all-IT facility will be outlined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IT",
                      "Ethernet",
                      "10G",
                      "packetized",
                      "network infrastructure",
                      "SaaS",
                      "cloud",
                      "SDN",
                      "media",
                      "AVB"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001497"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Video Processing in an FPGA-Enabled Ethernet Switch",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Edwards",
                    "Warren Belkin",
                    "Andy Bechtolsheim"
                  ],
                  "abstract": "Carriage of uncompressed HD video using IP holds great potential for enhancing the flexibility of broadcast plants while reducing the number of cables required through aggregation of signals using statistical multiplexing. The broadcast industry is just beginning to determine the appropriate architectures to best utilize professional video-over-IP capabilities. The Arista 7124FX Application Switch is a 10GbE data center class Ethernet switch that also supports application acceleration through the use of an on-board FPGA (Field Programmable Gate Array) without adding network jitter. A proof-of-concept has been developed to show how an FPGA-enabled switch can perform frame accurate video stream switching of SMPTE 2022-6 RTP flows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SMPTE 2022-6",
                      "FPGA",
                      "Ethernet",
                      "SDI",
                      "RTP",
                      "10GbE"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001498"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "All-IP Video Processing of SMPTE 2022-6 Streams on an All Programmable SoC",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matt Klein",
                    "Thomas Edwards"
                  ],
                  "abstract": "Realizing the functions of routing, switching and video processing equipment while utilizing standard networking equipment for video transport provides an evolutionary step toward gaining the benefits of professional media networking in broadcast environments. This paper describes a fully networked broadcast platform based on the Xilinx Zynq-7000 All Programmable System on a Chip (SoC) that performs live video processing, similar to that of traditional broadcast equipment switchers and routers, but uses 10 GbE networking interfaces for uncompressed video transport. HD-SDI video only enters and exits a 10 GbE network through SMPTE 2022-6 bridges based on the Xilinx Kintex-7 FPGA. The demonstration platform is connected using a standard off-the-shelf 10 GbE switch showing the vision of a networked broadcast facility.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "100 GbE",
                      "10 GbE",
                      "1588",
                      "3G",
                      "400 GbE",
                      "40 GbE",
                      "4k",
                      "8k",
                      "A9",
                      "ARP",
                      "bridge",
                      "broadcast facility",
                      "compression",
                      "control",
                      "Cortex",
                      "Cortex A9",
                      "destination port",
                      "dual Cortex A9",
                      "DVB/ASI",
                      "effects",
                      "embedded processing",
                      "embedded processor",
                      "Ethernet",
                      "Ethernet switch",
                      "FPGA",
                      "FTP",
                      "Gigabit Ethernet",
                      "HD",
                      "ICMP",
                      "IGMP",
                      "integrated receiver decoder",
                      "IEEE 1588",
                      "IP",
                      "IRD",
                      "JPEG",
                      "JPEG 2000",
                      "L2",
                      "L3",
                      "mix/effects",
                      "multicast",
                      "processor",
                      "programmable logic",
                      "router",
                      "routing matrix",
                      "RS422",
                      "RTP",
                      "SD",
                      "SDI",
                      "SMPTE2022-1",
                      "SMPTE2022-2",
                      "SMPTE2022-5",
                      "SMPTE2022-6",
                      "SoC",
                      "source port",
                      "System on a Chip",
                      "transmission",
                      "UDP",
                      "UHDTV1",
                      "UHDTV2",
                      "video routing matrix",
                      "video server",
                      "Zynq"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001499"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Put IP and Media Perfectly in Tune? Running an IT Media Facility in a Predictable Way",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Luc Andries"
                  ],
                  "abstract": "Media organisations based on IP networks and IT technology systems are running in a continuous state of accepted risk. Yet this is an unknown and unquantifiable risk. The world of SDI and tapes gave us ‘guaranteed service’. The world of IP and IT promises us flexibility introducing a statistically very good but ‘best effort' approach’. A growing demand in load, usage, formats etc., increases the stress and skews the statistical behaviour. This increases the chances of underperformance and failures, which costs a lot of time and money. — To cope with this, ‘over-provisioning’ has been the sole solution given by the IT industry until now. Leading to ever increasing investments in network, storage and servers. And leading to a continuously higher inefficient usage of resources. Over-provisioning only helps to reduce or even mask part of the risk but doesn't guarantee the performance and reliability of the installations. It still falls short in providing the strict predictability that an operational solution requires when it matters. — However, it is not commonly known that technologies and solutions have been developed recently and do already exist today to make IP networks/IT systems behave in a predictable way. When applied in the right way IP networks and IT systems can deliver guaranteed predictable performance, run much more efficient, scale up linearly and be managed more easily.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ethernet switch",
                      "IP network",
                      "Quality of Service",
                      "QoS",
                      "Media IP network",
                      "SDI over IP",
                      "Software Defined Network",
                      "SDN"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001500"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Playout Automation in a Virtual Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Openshaw",
                    "Glen Sakata"
                  ],
                  "abstract": "As the consumer demand for video increases and the delivery models expand to provide more ways to consume it, today's digital media companies struggle to keep up. Computer and Storage Clouds promise to augment and eventually replace the media factory of today using persistence and elasticity. But for those implementations to be truly beneficial, the applications and solutions provided must be designed and built for a virtual environment. Virtualization is more than installing a Virtual Machine (VM) and loading software. The applications themselves must be designed for virtualization, reducing inherent complexity and be able to efficiently perform as the requirements change.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Automation",
                      "Playout",
                      "Virtualization",
                      "Cloud",
                      "Channel-in-a-Box"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001501"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "A Perspective on the Evolution of Sound-System Equalization and its Possible Impact on New Recommended Practices for B-Chain Calibration",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John A. Murray"
                  ],
                  "abstract": "SMPTE is exploring processes and technologies that might be used in calibrating the B-chain in movie theater sound systems to improve the overall sound quality and consistency that will be based only on measurements, reducing the need for the subjective judgment recommended in the appendix of SMPTE ST 202:2010. The Audio Engineering Society and InfoComm are also developing new recommended practices and standards for sound-system equalization as well. Time-windowed, 3-dimensional measurements are being considered by all three groups. — The sound-reinforcement industry has been using time-windowed-measurement systems for over 30 years. During this time, a set of measurement techniques have been developed which are very different from those specified in SMPTE's ST 202:2010. These techniques have been shown to be more efficient and accurate, when applied to time-windowed measurements, than the older techniques commonly used for Real-Time Analysis (RTA). Some techniques that have been correctly and effectively applied to RTA measurements, are still being incorrectly applied to time-windowed analysis in the field in both the cinema-sound and sound-reinforcement industries. — The authors are solely responsible for the content of this technical presentation. The technical presentation does not necessarily reflect the official position of the Society of Motion Picture and Television Engineers (SMPTE), and its printing and distribution does not constitute an endorsement of views which may be expressed. This technical presentation is subject to a formal peer-review process by the SMPTE Board of Editors, upon completion of the conference. Citation of this work should state that it is a SMPTE meeting paper. EXAMPLE: Author's Last Name, Initials. 2011. Title of Presentation, Meeting name and location.: SMPTE. For information about securing permission to reprint or reproduce a technical presentation, please contact SMPTE at jwelch@smpte.org or 914-761-1100 (3 Barker Ave., White Plains, NY 10601). — A brief history of equalization is discussed from the viewpoint of the sound-reinforcement industry. This covers some aspects of the speaker-room interface that have not been applied in the ST-202:2010 standard. This discussion will also cover the evolution of measurement techniques developed specifically for time-windowed measurement, why different techniques are necessary when considering wavelengths above and below the Schroeder Frequency, and why they are more effective than traditional RTA-based techniques when applied to time-windowed measurement. — Finally, a truncated-line-source- (line array) measurement technique will be discussed, as well as issues unique to cinema-sound systems. Hopefully, this paper's discussed techniques will prove to be useful in the development of the new SMPTE sound-system-equalization standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "equalization",
                      "room curve",
                      "ideal room curve",
                      "preferred listening curve",
                      "room resonances",
                      "neutral transfer function",
                      "time-windowed",
                      "Fast-Fourier Transform",
                      "FFT",
                      "spectrum analysis",
                      "Real-Time Analysis",
                      "RTA",
                      "time-windowing",
                      "ST 202:2010",
                      "regenerative method",
                      "room modes",
                      "room ring modes",
                      "standing waves",
                      "flat direct sound response",
                      "average response"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001502"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Advanced Storage Techniques Using Scalable Media",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Heiko Sparenberg",
                    "Siegfried Foessel"
                  ],
                  "abstract": "Data storage is still one of the major bottlenecks in today's post-production workflows. Improving the data-throughput by combining some disks in a certain RAID-configuration makes the system faster but more expensive. In contrast, scalable compression techniques can also be used to significantly increase the overall throughput of storage devices. This work gives an overview of the development of storage techniques especially designed for scalable media files such as JPEG 2000 and H.264 SVC. This paper introduces two techniques: (1) a data-relocation algorithm exploiting foreseeable access pattern to the media content. This technique, in combination with scalable media achieves an singnificant increase in I/O performance of HDDs by a factor of three and (2) a novel RAID configuration especially designed for scalable media allowing for guaranteed real-time performance of attached storage devices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "RAID",
                      "scalable media",
                      "JPEG 2000",
                      "image compression",
                      "video storage",
                      "video playback"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001504"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "French Cinema Goes IMF",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt",
                    "Benoit Fevrier",
                    "Frantz Delbecque",
                    "Xavier Brachet",
                    "Hans-Nikolas Locher",
                    "Marc Bourhis"
                  ],
                  "abstract": "The French government has recently funded a cinema digitization program to help make past and current film catalogues available in digital form. The program stipulates that the digital assets be delivered in a dedicated open file format. An ad hoc committee has been formed at the request of the Centre National du Cinema to review the issue. The “IMF application 2 extended” seems a natural for implementing the program on a practical level. The application meets the requirements of a demanding workflow while preserving the highest quality for film. It also addresses the need for interoperability and the diversity of the film sources. On the other hand the conservation of cinematographic works has some consequences on the specifications of the format. In addition to recognized extensions of options to accept larger sizes of images and extended dynamic range, other topics are to be considered. The robustness of the encoding against bit rot as well as the need to carry uncomplete or deteriorated content has been examined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "MXF Implementation",
                      "JPEG2000",
                      "lossless eoncoding",
                      "IMF",
                      "CST-RT21",
                      "bit rot",
                      "high dynamic range",
                      "CPL",
                      "wrapping"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001505"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "“It's a Retrieval Problem, Not a Storage Problem.”",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Josef Marc",
                    "Chi-Long Tsang",
                    "Victor Steinberg",
                    "Maxim Levkov"
                  ],
                  "abstract": "MXF standards SMPTE ST 377-1:2011 and ST 422:2006; SMPTE Technical Committee TC-31FS AHG ST 422 Revision (JPEG2000 in MXF); the Advanced Media Workflow Association; and related SMPTE standards all clarify MXF implementations for the most active use cases. To illustrate technical advances, this paper presents laboratory observations of MXF video clips from multivendor sources alongside mathematically generated test patterns, master- and archival-grade video content, and an MXF metadata viewer. The paper focuses especially on reformatting JPEG2000, uncompressed, AVI, and MOV master/archive files into MXF for interchange and preservation. Video clips are shown.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "JPEG2000",
                      "MXF",
                      "reformatting",
                      "transcoding",
                      "archives",
                      "master files",
                      "interchange",
                      "preservation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001506"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Media Facility Infrastructure of the Future",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric F. Pohl"
                  ],
                  "abstract": "The owners of contemporary television facilities are being faced with challenges from a number of directions. • The introduction and use of large format images in television program production creating motions images in excess of HD rates (2K and 4K) • The increasing reliance on IT storage and server technology for motion image storage and processing • The need to accept and provide content in multiple forms to multiple business partners • The need to be compatible with current large installed investment in SDI baseband infrastructures • The emergence of higher capacity IP based transport and routing as well as new standards for encapsulating HD video into IP — This paper will review the evolution of large facility infrastructures and in the context of these new trends and offer a point of view on the characteristics and requirements of the “multi-resolution infrastructure of the future”.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Infrastructure",
                      "Facility",
                      "Cloud",
                      "Encapsulation",
                      "HD-SDI",
                      "TCP/IP",
                      "Multi-resolution"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001495"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Depth/Disparity Creation for Trifocal Hybrid 3D System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ralf Tanger",
                    "Marcus Muller",
                    "Peter Kauff",
                    "Ralf Schafer"
                  ],
                  "abstract": "Fraunhofer HHI has developed a software solution to create depth and disparity maps from a Tri-Focal Rig. Computational cinematagrophy techniques can be used to determine the depth of the items in the shot by mathematically comparing the differences in the images captured from each of the motion picture cameras after the initial photography is completed. By creating a 3D geometry of the scene and then projecting the images onto that 3D geometry a Stereoscopic movie can be created after principal photography has been completed. The software adapts disparity estimation algorithms to the specific needs of the multi-camera system. This includes in particular dedicated post-processing filters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Computational cinematography",
                      "depth",
                      "disparity",
                      "trifocal",
                      "multi-camera",
                      "3D"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001493"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Analysis of PTP Locking Time on Non-PTP Networks for Genlock over IP",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nikolaus Kero",
                    "Tobias Muller",
                    "Thomas Kernen",
                    "Mickael Deniaud"
                  ],
                  "abstract": "With the integration of IP based systems into broadcast architectures genlocking devices need to be transposed in this environment. Within SMPTE 33TS, an IEEE-1588 profile suited for the production industry is under definition. PTP has been widely adopted in other industries to synchronize nodes in asynchronous networks such as Ethernet. If PTP is used for synchronizing broadcasting equipment replacing systems like color black, locking times of five seconds are required to facilitate frequent changes in the network topology offering the same availability as analog systems. — After describing ways to obtain short lock times results are presented for a three hop network. Different classes of PTP unaware components were used ranging from older generation desktop devices to current generation data-center units with line-rate switching capabilities. The lock time was measured using different PTP message rates as well as default and expedited forwarding for PTP traffic while applying various network load conditions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "PTP",
                      "Fast locking",
                      "Genlock over IP"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001490"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Depth/Disparity Interchange Representation for Post-Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peshala V. Pahalawatta",
                    "Kevin J. Stec"
                  ],
                  "abstract": "Depth/disparity information is conducive to various post-production processes, such as compositing, editing, and alternate view rendering. Therefore, this paper describes a display agnostic framework for representing depth and disparity in post-production. The paper details the requirements and constraints associated with the representation. It also shows the manner in which the interchange framework can be used during compositing, conforming and editing. The framework simplifies the exchange of depth/disparity information gathered from Live and CGI sources. Finally, the paper analyzes the robustness of the representation to depth/disparity conversion errors and provides example scenarios in which the representation can be used.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Depth",
                      "Disparity",
                      "Multi-view",
                      "Post-Production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001494"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "The Principles of Low-Latency Media Centric Network Architectures",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Kernen",
                    "Steven Posick"
                  ],
                  "abstract": "With the move to Internet Protocol (IP) networks, the desire to produce low-latency, high throughput networks has increased in recent years. But low-latency and high throughput do not necessarily go hand-in-hand. In fact there is somewhat of an inverse relationship between the two, despite the fact that latency plays a critical role in TCP/IP throughput. Microbursts, buffer/queue management, and poor software design all play significant roles in increasing latency. In this paper, we will discuss the key design principles for the creation of low-latency, high throughput IP networks for real-time media centric applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IP",
                      "low-latency",
                      "media",
                      "synchronization",
                      "multicast",
                      "network",
                      "workflows",
                      "monitoring"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001491"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Tri-Focal Rig (Practical Camera Configurations for Image and Depth Acquisition)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Johannes Steurer"
                  ],
                  "abstract": "In many VFX productions the existence of a disparity or depth map for the captured images is of the essence. This article describes two approaches for simultaneous acquisition of image and depth information. The first approach utilizes three cameras, one primary motion picture camera and two smaller auxiliary cameras. A robust and set-ready tri-focal camera rig was designed and implemented, which meets the requirements of motion picture professionals and enables precise and robust alignment of the cameras and perfect synchronization. — In the second approach a depth camera based on the principle of time-of-flight is integrated with a motion picture camera forming the so-called Motion Scene Camera. A rotating mirror shutter allows both sensors to utilize a single lens and capture the scene from the same viewing point. Both concepts have taken extensive tests, including a real production for the tri-focal approach and first field tests for the motion scene camera. Results are very encouraging and exalt the imagination of novel post production applications like hybrid 3D production and depth based masking and compositing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Computational cinematography",
                      "depth map",
                      "disparity map",
                      "hybrid 3D",
                      "motion scene camera",
                      "multi-camera array",
                      "stereo",
                      "time-of-flight",
                      "tri-focal"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001492"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Your Eyes Don't do the Math: Effect of Temporal Display Protocols on Perceived Brightness",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Zoltan Derzsi",
                    "Sindre Henriksen",
                    "Jenny Read"
                  ],
                  "abstract": "It is usually assumed that in temporally multiplexed stereoscopic displays, the perceived binocular brightness is set by the total rate at which photons enter the human visual system, with the timing of these photons being immaterial on the timescales relevant to temporal multiplexing. In order to appear as bright as a 2D system, a perfect temporally multiplexed stereo display would therefore require twice the photon flux, even if it avoided all other losses. Yet this assumption has not been tested in human observers. Here, we examine how brightness perception depends on when photons are delivered to each eye. We find that stimuli appear equally bright when light is presented in alteration to each eye as when it is presented simultaneously in both eyes. Thus, there is no brightness advantage for temporally multiplexed stereo. We do find a novel non-linearity affecting brightness perception in short impulses of light, as in a Cathode Ray Tube. Light pulses presented at low frequency appear brighter than when the same number of photons is delivered at high frequency. However, this does not apply to the longer-duration light steps found in modern displays such as Liquid Crystal Displays. — We conclude that, when evaluating such stereoscopic displays, one should measure luminance with a single photometer pointing at the screen through the same eyewear as the viewer. The recorded luminance then can be directly compared to that measured by a single photometer for 2D displays. Additionally, we point out that due to the logarithmic relation between physical luminance and perceived brightness in the human visual system, halving luminance does not halve the perceived brightness.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Stereoscopy",
                      "Shutter glass",
                      "RealD",
                      "3D",
                      "Human vision",
                      "Psychophysics",
                      "Non-linearity",
                      "CRT monitors",
                      "LEDs",
                      "Physiology",
                      "Perception"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001511"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Study on the Acceptance of Higher Frame Rate Stereoscopic 3D in Digital Cinema",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wolfgang Ruppel",
                    "Yannic Alff",
                    "Thomas Gollner"
                  ],
                  "abstract": "Frame Rates higher than the conventional 24 fps have been proposed recently, and a first movie “The Hobbit — An Unexpected Journey” has been shown in theatres in HFR 3D at 48 fps/eye. — This paper contributes to the debate whether HFR 3D is appreciated by the audiences over conventional 24 fps/eye Stereo 3D. Subjective tests have been conducted in order to evaluate the effect of the frame rate on the reception of stereoscopic content in a cinema environment. — The method used for the subjective tests is based on an ITU recommendation leading to a subjective assessment in three categories related to image perception, being smoothness of motion, sharpness of motion and overall visual impression.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HFR",
                      "Higher Frame Rates",
                      "3D Digital Cinema",
                      "Stereoscopic 3D",
                      "Subjective Tests"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001512"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Controlling Miniaturization in Stereoscopic 3D Imagery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael D. Smith",
                    "Jason Malia"
                  ],
                  "abstract": "Viewers of stereoscopic 3D imagery can perceive the absolute size of objects within a scene. On larger screens the perceptual size of objects commonly appears bigger than reality, which matches viewers' expectations for big-screen “larger than life” theatrical experiences. The geometry involved in stereoscopic imaging can cause the perceptual size of objects to appear smaller than reality (“miniaturization”). Miniaturization can be distracting for viewers and is more extreme on smaller screens like 3DTV and handheld 3D devices. — A common misconception is that miniaturization occurs only when the stereo camera separation (interaxial) is larger than the human eye separation (interocular) 2.5 inches. Counter-examples of this misconception will be provided as well as an analysis framework that allows stereo-camera-operators to accurately predict when the miniaturization effect will on any screen size. — During the presentation of this paper, example stereoscopic 3D images will be shown illustrating control of perceptual size.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "stereoscopic",
                      "3D",
                      "miniaturization",
                      "gigantism",
                      "size",
                      "perception",
                      "geometry"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001513"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Faxes, Emails, Pagers, and the Macarena – Adios to Relics of the '90s",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Lennon"
                  ],
                  "abstract": "You may laugh, but the first two items in this paper's title are still in daily use as data exchange methods in today's media organizations. How can that be? The '90s were 20 years ago. Yet, the fact remains that standard exchange of traffic instructions between ad agencies and media outlets, telling broadcasters when, where and how to air commercial advertising, remains fax and email. SMPTE's Broadcast eXchange Format (BXF) Working Group set out to change this. Automating the flow of traffic instructions from ad agencies to broadcast media is perhaps the most anticipated BXF 3.0 enhancement. Key industry players put in countless hours to create an XML schema for the exchange of this data that can be used in modern service-oriented architectures. We'll explore what has been completed, and look at the potential impact on media organizations over the coming years. We're hoping this also means we'll never hear “The Macarena” again.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Commercial Scheduling",
                      "Workflow",
                      "BXF",
                      "Advertising",
                      "Agencies",
                      "SOA",
                      "Traffic Instructions",
                      "Content"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001514"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Deploying Video Platforms in the Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Sinclair"
                  ],
                  "abstract": "The cloud is transforming IT infrastructure and much like “IT hardware” transformed broadcast equipment the next evolution is set to have a major impact on the broadcast industry. There are now many mature cloud platforms and combined with the relatively low cost of fibre optic networking within metro areas this presents a major opportunity to leverage the cloud for video workflows. This paper looks at many of the possibilities and challenges the cloud presents from production, edit, asset management, playout and distribution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "cloud",
                      "network latency",
                      "cpu usage",
                      "storage latency",
                      "platform as a service (PaaS)",
                      "infrastructure as a service (laaS)",
                      "Software as a service (SaaS)"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001515"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Private Patching in the Cloud: Offering the Media Industry a Mind of its Own: Bringing Public and Private Computing Together for All Media Needs",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Jenkins"
                  ],
                  "abstract": "This paper outlines the advantages to the media industry of building a hybrid cloud computing solution that provisions private computing resources which can be scaled to the public cloud. Such a solution can cater to a much broader range of media related computing requirements than a private or public only computing resource strategy.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001516"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "New Generation of Contribution Services Using HEVC 422 Profile",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Juan Jose Anaya",
                    "Damian Ruiz"
                  ],
                  "abstract": "This paper addresses the performance of the new Range Extensions profile of HEVC standard for professional UHDTV contribution services, where 4:2:2 color format, a bit depth of 10-bits, and high bit rates are required in order to achieve excellent video quality. — With the aim to carry out a neutral technology comparison for the 4k format, we have conducted some simulations using the HM reference software of HEVC, under the new “Main 422 10-bits” profile, and JM reference software of H.264 under the “High 422”” profile. The experiment results show that for the same objective quality obtained by H.264, HEVC can achieve a bit rate saving in the range of 30% to 50%, reaching the best performance for the most complex sequences. — We have repeated the experiment to gather the HEVC robustness in a cascaded encoding-decoding 4K contribution scenario, implementing a new HEVC simulation with two re-encoding stages. The results reveal that the average quality losses for second generation are really low, around 0.3dB, but the bit rate penalty is over 20%. These results can help network operators and broadcasters to estimate efficiently the bandwidth services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "Range Extensions",
                      "H.264",
                      "High 422 Profile",
                      "contribution services",
                      "Ultra High Definition",
                      "4k",
                      "compression efficiency"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001517"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Developing Requirements for a Visually Lossless Display Stream Coding System Open Standard",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dale Stolitzka"
                  ],
                  "abstract": "VESA (The Video Electronics Standards Association) is developing a standard for a visually lossless coding system to be used for the compression of high-bandwidth display data streams. This coding system will complement digital display interface technologies to increase pixel rates or save system power, or both. The display stream coding system is primarily being designed to meet the increased pixel rate needed in high resolution displays expected in the next few years. — This paper recounts VESA's process that led to compression requirements, the selection of a coding system baseline, and strategies to evaluate a visually lossless coding system for consumer electronics and commercial displays. Key concepts in this paper evolved from discussions and documents of VESA's Display Stream Compression Task Group that have been made available to the author with permission from VESA. The Display Stream Compression Standard is forthcoming for publication in the first quarter of 2014.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Data compression",
                      "display stream compression",
                      "open standard",
                      "image coding system",
                      "requirements"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001519"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Beyond BT.709",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Maciej Pedzisz"
                  ],
                  "abstract": "The recent High Efficiency Video Coding (HEVC) standard and current progress in the specification of HDMI 2.0 has revived discussion about video colorimetry. For years, BT.709 was successfully used to define the primary chromaticities of display devices and transformation to the Y'Cb'Cr' color space that is used for the compression of HD video. Current advances in display technologies, along with the introduction of Ultra High Definition Television (UHDTV), makes the following question more relevant than ever before: Can we do better than BT.709? — This paper tries to answer this question by highlighting methods of extending the color gamut, showing the difficulties in the transformation from one color space to another, and pointing out the different conversion methods used to represent RGB data in the Y'Cb'Cr' color space. It emphasizes the importance of Constant Luminance Transform for color perception and compares BT.709 to BT.2020 from different viewpoints. Finally, the advantages and disadvantages of switching to BT.2020 are presented from a broadcast engineering perspective.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "color",
                      "space",
                      "conversion",
                      "gamut",
                      "bt.709",
                      "bt.2020"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001507"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Towards a Hierarchy of SDI DATA Rates",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Hudson",
                    "Edward Frlan"
                  ],
                  "abstract": "Once again our ability to capture and display images has leap-frogged our ability to transport, control and monitor them. — New ultra high definition formats, and high frame rates, require increasing data rates in image transport. Payload rates approaching 200Gb/s are required in support UHDTV-2 image structures at 120Hz progressive frame rate. — Building on the concepts presented in the paper “1080p50/60, 4K and beyond: Future Proofing the Core Infrastructure to Manage the Bandwidth Explosion” presented at the UHDTV: Ultra-High Definition Imaging Session of the 2012 SMPTE Annual Technical Conference, this paper introduces a hierarchical approach to increased SDI data rates, allowing affordable steps towards extended data rates, including those needed for UHDTV-2. — It describes progress in technical standards and technology development since the 2012 conference, for single-link and multi-link SDI interfaces operating at 6Gb/s, 12Gb/s and 24Gb/s using protocols which enable easy compatibility between data rates. It shows the performance that can be expected at these data rates, over copper and optical interfaces, and introduces coding concepts to improve the reliability of serial video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHDTV",
                      "SDI",
                      "Serial Digital Interface",
                      "3Gb/s",
                      "3Gbit/Sec",
                      "3G-SDI",
                      "100Gbit/Sec",
                      "stereoscopic 3D",
                      "2K",
                      "4K",
                      "8K",
                      "SMPTE standards",
                      "SFP+",
                      "QSFP+",
                      "IEEE",
                      "OIF"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001503"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Filtering in a High Dynamic Range (HDR) Context",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "Many image processing steps involve filters or filter-like constructs (such as wavelets). Filters are used for displacement, such as flowfield displacement or block displacement within codecs. Filters are used for re-sizing, and for detail-band-splitting in resolution hierarchies. Wavelets also are applied in a manner similar to filters, and can be used for detail-band-splitting in some constructions. The Discrete Cosine Transform similarly represents image spatial frequencies in an array of coefficients for such frequencies. — When applying filters to pixels, theoretical underpinnings of filter theory often require that the pixels be represented in linear light (gamma 1.0). When extending filter and wavelet techniques to High Dynamic Range (HDR), the general assumptions about acceptability of filtering errors in many common filter uses must be revised to consider very large increases in brightness value differences. Filter errors, especially from negative filter lobes, are often greatly magnified within the intended viewing range. — This paper explores filtering practices that improve filter, wavelet, DCT, and other common filtering elements when applied to HDR. Further, we examine the precision necessary to distribute HDR, and we consider quality metrics that might be appropriate for HDR systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital Filters",
                      "HDR",
                      "Video Filtering"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001509"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "An IIF Based Post Production Infrastructure Developed for Feature Film Production and Higher Education in Iraq",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher C. Woollard"
                  ],
                  "abstract": "This paper describes a digital post production distributed environment developed in the country of Iraq in order to enable the reintroduction of effective feature film production. A joint development between the Kurdish ministry of Higher Education and the University of Greenwich, London, the system has enabled effective post production to be carried out in the cities of Sulaymaniyah, Erbil, Kirkuk and Bagdad. Initially supporting both ARRI Alexa, RED and conventional 35mm production, the unique problems of film production are presented along with techniques for combining the work of multiple crews using differing camera systems. High speed digital interchange and laboratory work is presented along with arrangements for digital grading using large Cinema systems and digital film distribution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "ACES",
                      "Iraq",
                      "Cinema",
                      "IDT",
                      "Kurdistan"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001508"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Software-Defined Network for Media Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ammar Latif",
                    "Tom Ohanian"
                  ],
                  "abstract": "Software-defined networking (SDN) is receiving considerable attention in the Broadcast and Media industry due to its potential to bring innovation to Internet Protocol (IP) and Networking approaches. This is especially relevant and timely due to the pervasiveness of IP and Ethernet as the converged medium for carrying multiple services (video, audio, data, etc.) — This paper will outline the SDN concept as it relates to Media IP workflows and broadband delivery of content. The paper will define network programmability and network application programming interfaces (APIs) and their role in achieving more granular control of network services, network analytics, and security. Finally, SDN use cases for Media IP workflows and the business benefits will be highlighted.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SDN",
                      "Software Defined Networking",
                      "Media IP Workflows",
                      "Network Programmability"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001496"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "Compact 120-fps Super Hi-Vision (8K) Camera with 35mm PL Mount Lens",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hiroshi Shimamoto",
                    "Toshio Yasue",
                    "Kazuya Kitamura",
                    "Toshihisa Watabe",
                    "Norifumi Egami",
                    "Shoji Kawahito",
                    "Tomohiko Kosugi",
                    "Takashi Watanabe",
                    "Taku Tsukamoto"
                  ],
                  "abstract": "NHK has been researching and developing Super Hi-Vision, the 8K version of UHDTV, for future broadcasting. Last year we developed a CMOS image sensor with 120 fps, 33 megapixels, and a 12-bit ADC in conformance to the highest resolution and frame frequency specified in Recommendation ITU-R BT.2020. We also developed a 120-fps three-chip color camera equipped with this image sensor. — We recently developed a 120-fps 33-megapixel single-chip color CMOS image sensor and a compact 8K camera head equipped with this image sensor. As the width, height, and depth are 125-, 125-, and 150- mm respectively and it weighs only 2 kg, it was significantly smaller and lighter than conventional 8K cameras. The optical size of the image sensor is 25 mm and the camera head is compatible with super 35-mm PL mount lenses for various cameras for digital cinema.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "8K",
                      "Super Hi-Vision",
                      "BT.2020",
                      "UHDTV",
                      "120-fps",
                      "single-chip color CMOS image sensor",
                      "35-mm PL mount lens"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001532"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "Dreams do Come True!",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rick Rothschild"
                  ],
                  "abstract": "To explore how emerging digital media technology is influencing the themed entertainment industry, specifically using FlyOver Canada, a newly opened (June 2013) attraction in Vancouver, BC Canada, as the focus. This attraction is a “flying ride” 180° dome experience employing 4K 60 fps digital capture and playback with specially designed and manufactured spherical projection lens as well as a unique 14:1 audio system. The inspiration of this new attraction was Disney's Soarin' Over California, which only 12 years ago was at the edge of display technology having employed 48 fps IMAX film for both capture and playback. Having been the creative director for both attractions, my presentation will provide unique insight into how times (and media formats/technology) are quickly changing and influencing the global themed entertainment world.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K",
                      "60 fps",
                      "hemispheric projection",
                      "Soarin'",
                      "Over California",
                      "FlyOver Canada",
                      "flying ride"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001533"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "High-Accuracy Digital Camera Color Transforms for Wide Gamut Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jon S. McElvain",
                    "Walter Gish"
                  ],
                  "abstract": "For digital camera systems, transforming from the native camera RGB signals into an intermediate working space is often required, with common examples involving transformations into ACES or XYZ. For scene-linear camera signals, by far the most common approach utilizes 3times3 matrices (formed using regression methods), which are low-complexity approximations to the exact transformation that would be obtained using a full spectral analysis. For workflows designed for Rec709 displays, matrix-based input transforms are capable of producing reasonable accuracy in this domain. However, the 3times3 matrix colorimetric errors can become significant for saturated colors in workflows involving wide-gamut primary systems such as UHDTV or ACES. To address this shortfall, a novel input color transformation method has been developed that involves separate one-dimensional and two-dimensional operations. From the native camera RGB signals, chromaticity-like coordinates are computed and these are used to index into a two-dimensional lookup table (LUT); the output of the two-dimensional LUT is then scaled according to the input signal. Because the surfaces associated with the 2D LUTs possess many degrees of freedom, highly accurate colorimetric transformations can be achieved. For several cinematic and broadcast cameras tested, this new transformation method consistently shows a modest reduction of mean deltaE errors for colors within the Rec709 primaries. The improvement in accuracy becomes much more significant for saturated colors, for which the mean deltaE errors are reduced by more than a factor of three for colors that lie between Rec709 and Rec2020.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Camera Color Correction",
                      "Academy Color Encoding Specification",
                      "ACES",
                      "Input Device Transform"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001535"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Analyzing and Optimizing Video Quality in the New H.265 (HEVC) Standard",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Advait Mogre",
                    "Bhupender Kumar",
                    "Shekhar Madnani",
                    "Muneesh Sharma",
                    "Shailesh Kumar"
                  ],
                  "abstract": "The emerging H.265 High Efficiency Video Coding (HEVC) standard for video compression is geared towards providing high quality / high resolution video at low to moderate bit rates; thus providing a significant increase in compression efficiency over existing standards like H.262/263/264. As is typically the case, increased compression results in decreased coding redundancy. Hence from a video quality perspective, of interest would be the nature of potential coding artifacts as well as the profile of video failures or dropouts arising due to uncorrected coding errors. In the latter case, the occurrence of these uncorrectable errors would depend upon external factors like the channel SNR or Eb/No profile, coupled with the source coding efficiency (or redundancy); the latter being governed by the opposing constraints of picture quality versus allowable bit rate or channel bandwidth. — The initial portion of this work is focused on dropout profiles due to randomly occurring bitstream errors. The geometries of the manifested dropout regions are quite noticeable as compared to those observed in traditional slice based video syntax for the same content, under a similar random error profile. This uniqueness impacts the spatial dropout detection algorithms to be used. — In the latter part of this work, video quality for a variety of content applications (like sports, news/talk shows, animation, etc…) and under varying encoder parameter profiles is monitored. The goal is to optimize the HEVC encoding parameters such as Transform Unit size, Coding Unit size and Maximum Partition Depth for video quality, for each chosen content application.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "H.265",
                      "HEVC",
                      "AVC",
                      "MPEG2",
                      "coding efficiency",
                      "dropout profiles",
                      "encoding parameters",
                      "PSNR",
                      "blockiness"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001525"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "HEVC, the Key to Delivering an Enhanced Television Viewing Experience “Beyond HD”",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sophie Percheron",
                    "Jerome Vieron"
                  ],
                  "abstract": "Broadcasters and operators' objectives remain the same over time: reduce transport costs, reach more customers, and improve the TV viewing experience. Ten years after the beginning of the SD to HD transition, history is about to be repeated once again. With the 50% bitrate savings promised by the new HEVC (High Efficiency Video Coding) standard, these compression gains will not only reduce the bandwidth but also allow us all to more importantly improve the viewing experience, conveying more information and emotional impact though higher spatial and temporal resolution. — 1080p60 transmission has already been demonstrated to be a better user experience than 1080i30, inspiring market leaders to commence the transition towards producing 1080p60 channels. However the required bandwidth still remains the bottleneck to complete and efficient end-to-end deployment. — This paper will demonstrate why HEVC will be the key to unlock the “progressive only” broadcast chain deployment; and why it will not lead to forcing a premature end of life to interlaced television. Finally we will discuss future (premium) services brought about by the “beyond HD” viewing experience: live events, sports, concerts, and other newly immersive experiences offered by UHDTV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "beyond HD",
                      "Ultra-HD",
                      "4K",
                      "UHDTV",
                      "enhanced viewing experience",
                      "video compression",
                      "interlaced",
                      "progressive"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001528"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "A Design Approach to Creating Scalable Beyond-4K Video Processing Systems on FPGAs",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Benjamin Cope",
                    "David Shih"
                  ],
                  "abstract": "An unquenchable end-user thirst for enhanced video quality results in an ever-scaling video frame size and frame rate requirements. As we move from 4K to 8K and 120fps to 300fps, inevitably the computational complexity of video processing systems required to consume, process and deliver video content increases. The need for solutions to support combinations of frame sizes and rates, as well as future increments, emphasizes the need for system scalability. The computational complexity and scalability requirements pose exciting challenges for FPGA implementation of video processing pipelines. This paper presents implementation techniques and methodologies to overcome these challenges. We specifically concentrate on architectures whereby the input per-pixel video sample rate exceeds the system clock rate. Novel results include classifying pixel processing orders and presenting a component-based design approach for future-proofing video processing solutions against an ever-scaling computational complexity requirement. Resource and memory bandwidth requirements of such systems are also analysed and trends presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "FPGA",
                      "video processing",
                      "4K"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001527"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "VC-5 Video Compression for Mezzanine Compression Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward Reuss"
                  ],
                  "abstract": "The new SMPTE video compression standard ST 2073 “VC-5 Mezzanine Level Compression” is a variable-bit-rate codec originally developed for video acquisition and post-production, applicable to a diverse range of image and video formats. The term “Mezzanine Level Compression” refers to a lightly compressed video format, usually compressed from one half to one twentieth the uncompressed format. Mezzanine compression is used for workflows where the image sequence will need to be decompressed and recompressed multiple times, while still minimizing the accumulated compression artifacts. There are several different video compression standards used for mezzanine-compressed workflows. Each one offers a specific set of trade-offs (compression ratio, fidelity, speed, power consumption, image formats, etc.) that makes it suitable for specific situations. This paper introduces the new VC-5 standard and describes its advantages for certain acquisition and post-production workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VC-5",
                      "video compression",
                      "image compression",
                      "file-based workflows",
                      "CineForm",
                      "wavelet transform"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001524"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Look to the Cloud: Enabling Seamless Video in a Multi-Device World",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jeff Malkin"
                  ],
                  "abstract": "The increasing complexity of successfully delivering video across a multitude of fragmented device platforms presents a significant challenge. Preparing a high volume of video content for multi-screen consumption requires massive computing resources equipped for high-speed processing. It also requires the tools and know-how to transcode and often programmatically edit or re-package video assets for error-fee, optimized delivery. Cloud computing allows content owners to deploy scalable and flexible video workflows that maximize consumption across all targeted platforms. We compare different workflow cost structures and technical options for a variety of internet delivery targets.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001521"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Enhanced Image Processing beyond Baseband: CPU/GPU Process Model Unlocks Performance Possibilities",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ernie Sanchez",
                    "Kirk Marple",
                    "Hank Frecon"
                  ],
                  "abstract": "The speed and quality of traditional baseband approaches to image enhancement is now being eclipsed by commodity enterprise computing technology, with emerging file-based solutions focused on frame-rate conversions, de-noising, resolution-scaling, and other techniques for improving image quality. This paper will examine how continually increasing CPU power combined with increasingly sophisticated GPU-based algorithms enables ever-greater performance and output quality, with the significant operational and cost benefits found only in highly automated and massively parallelized grid-based processing workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "file-based",
                      "image-enhancement",
                      "computing technology",
                      "IT",
                      "baseband",
                      "CPU",
                      "GPU",
                      "processing",
                      "parallel",
                      "grid-based",
                      "frame-rate conversion",
                      "standards conversion",
                      "image processing",
                      "algorithms",
                      "transcoding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001529"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Taking the Pixel Out of the Picture",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Philip Willis",
                    "John Patterson",
                    "Peter Balch",
                    "Jan Paxton"
                  ],
                  "abstract": "We have developed a contour-based image and movie representation which takes the pixel out of the picture. We use contours, which are scale-free and can readily be rendered back to an image at a new resolution independent of the original. They are easy to rotate and zoom by fractional amounts. They can act as a universal intermediate during post-production. They provide a single delivery mechanism, whether to mobile phone, TV screen or cinema. They are future-proof, taking HD resolution and beyond in their stride. This is not a disruptive technology: moving between pixels and contours can happen at any stage in the pipeline. Nor does it need special cameras or displays.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Codecs",
                      "image representation",
                      "image manipulation",
                      "contourisation",
                      "contour images"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001530"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "A Technical Overview of VP9 – The Latest Open-Source Video Codec",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Debargha Mukherjee",
                    "Jingning Han",
                    "Jim Bankoski",
                    "Ronald Bultje",
                    "Adrian Grange",
                    "John Koleszar",
                    "Paul Wilkins",
                    "Yaowu Xu"
                  ],
                  "abstract": "Google has recently finalized a next generation open-source video codec called VP9, as part of the libvpx repository of the WebM project (http://www.webmproject.org/). Starting from the VP8 video codec released by Google in 2010 as the baseline, various enhancements and new tools were added, resulting in the next-generation bit-stream VP9. The bit-stream was finalized with the exception of essential bug-fixes, in June 2013. Prior to the release however, all technical developments in fact were being conducted openly in the public experimental branch of the repository for many months. This paper provides a brief technical overview of the coding tools included in VP9, along with coding performance comparisons with other state-of-the-art video codecs — namely H.264/AVC and HEVC — on standard test sets. While a completely fair comparison is impossible to conduct because of the limitations of the respective encoder implementations, the tests show VP9 to be quite competitive with main-stream state-of-the-art codecs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video compression",
                      "motion-compensated prediction",
                      "transforms",
                      "quantization",
                      "entropy coding",
                      "quad-tree partitioning",
                      "DCT",
                      "ADST"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001518"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Camera Radiometric Calibration from Motion Images",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ricardo R. Figueroa",
                    "Jinwei Gu"
                  ],
                  "abstract": "We present a research study for estimating a camera's radiometric response function from a series of motion images. Current methods to estimate this function rely on multiple static images taken under different exposures or different lighting conditions, the use of measurement charts, image sets from point-and-shoot only cameras, or assume a simplistic model of the function's shape. All these become impractical when it comes to having a robust efficient method that can fit into motion picture industry post-production workflows, ACES as an example, where simplicity and accuracy are very important. In this paper we present a research methodology based on the work of Lin et al. expanding it to the use of measured color characteristics in a motion image sequence and include additional constraints during the estimation. Using footage from an ARRI D21, preliminary results are presented and discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Radiometric calibration",
                      "camera response function",
                      "high dynamic range",
                      "gamma correction",
                      "Image Interchange Framework",
                      "computational photography"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001510"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Creating an Innovative Broadcasting with Technology and Standardization",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tadaaki Yokoo"
                  ],
                  "abstract": "Radio systems in broadcasting and telecommunications, as seen in digital broadcasting and smartphones have been increasingly advanced. Today, they are essential for our economic activities and social life. The Association of Radio Industries and Businesses (ARIB) devotes itself, as a standards development organization (SDO) to foster information and communication technology (ICT) society through contribution to radio systems. The paper describes ARIB's role and activities to enrich and enlarge broadcasting services and industries by introducing its study, research and development (R&D) and standardization work on various broadcasting technologies and systems. Among them, the work on ultra high definition television (UHDTV) systems is highlighted. Also, an issue on standards and essential industrial property rights is touched upon.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "ARIB",
                      "standards development organization",
                      "radio systems",
                      "digital broadcasting",
                      "study",
                      "R&D",
                      "standardization",
                      "UHDTV systems",
                      "essential industry property rights"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001526"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "Development of a Multi-Link 10-Gbit/s Mapping Method and Interface Device for 120-fps UHDTV Signals",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takuji Soeno",
                    "Yukihiro Nishida",
                    "Takayuki Yamashita",
                    "Yuichi Kusakabe",
                    "Ryohei Funatsu",
                    "Tomohiro Nakamura"
                  ],
                  "abstract": "We are currently researching Super Hi-Vision (SHV) as a next-generation ultra high definition television (UHDTV) broadcasting system. The video parameters of UHDTV systems with 120 frames-per-second (fps) signals are specified in Recommendation ITU-R BT.2020. — In this study, we have developed a new mapping method to transmit various UHDTV signals, including 120-fps signals, and we have developed a prototype interface for connecting UHDTV video devices. — The method is to transform UHDTV signals into multi-link 10-Gbit/s streams. The number of 10-Gbit/s streams differs according to the UHDTV format (frame frequency, pixel count, and sampling lattice). To realize a compact and low-power interface, we implemented the prototype using a parallel fiber-optics transceiver with a capacity of 10-Gbit/s per channel. Finally, we verified the practicality and feasibility of the multi-link 10-Gbit/s mapping method and the prototype interface.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Super Hi-Vision (SHV)",
                      "UHDTV",
                      "interface device",
                      "mapping method"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001531"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Development of the Super Hi-Vision HEVC/H.265 Real-Time Encoder",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yasuko Sugito",
                    "Kazuhisa Iguchi",
                    "Atsuro Ichigaya",
                    "Kazuhiro Chida",
                    "Shinichi Sakaida",
                    "Yoshiaki Shishikui",
                    "Hiroharu Sakate",
                    "Takayuki Itsui",
                    "Nobuaki Motoyama",
                    "Shun-ichi Sekiguchi"
                  ],
                  "abstract": "This paper introduces the world's first Super Hi-Vision (SHV) real-time encoder incorporating the HEVC (High Efficiency Video Coding)/H.265 scheme. — A test broadcasting using the SHV HEVC codec is scheduled for 2016. HEVC is the newest video coding standard, and is capable of achieving approximately twice the level of compression of the existing AVC (Advanced Video Coding)/H.264 scheme. Its coding performance is expected to be particularly high for SHV videos, especially due to extended block partitioning. — In this paper, we describe the fundamentals of HEVC and its suitability for high-resolution videos such as SHV. We also introduce the specifications of the developed SHV encoder and its approach to achieving real-time processing. Finally, the results of image quality evaluation are presented, which confirm that the newly developed encoder can achieve a higher image quality than a conventional SHV AVC encoder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video coding",
                      "HEVC",
                      "H.265",
                      "Super Hi-Vision",
                      "8K",
                      "UHDTV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001523"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Light-Field Acquisition and Processing System for Film Productions",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Siegfried Foessel",
                    "Frederik Zilly",
                    "Michael Schoberl",
                    "Peter Schafer",
                    "Matthias Ziegler",
                    "Joachim Keinert"
                  ],
                  "abstract": "With traditional film cameras, important creative parameters such as the depth of field and the viewpoint are burned into the footage after acquisition without the possibility to change them in post-production. In consequence, special attention is required on set to frame the scene and to pull the focus. Against this background, we propose a light-field capturing and processing system, suitable to be used on set, and allowing to change the camera viewpoint and focal plane in post-production. Our approach involves a synchronized array of compact high definition cameras to capture multiple viewpoints enabling a high image quality of the resulting footage. Based on computational imaging methods virtual camera positions and synthetic apertures will be created afterwards. First scenes captured with such an array will be demonstrated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Multi-camera acquisition",
                      "free viewpoint",
                      "light-field processing",
                      "depth-of-field"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001534"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Building Real World Media in the Cloud",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Campanotti",
                    "Andy Hurt"
                  ],
                  "abstract": "“Building Real-World Media in the Cloud” examines the unique nature of managing media-centric “big data,” and how advanced, on-premises content storage management (CSM) systems make it possible but not necessarily affordable. The paper explores the idea of using a private cloud to back up, archive, protect, and manage valuable media assets in a more affordable, more effective way than an on-premises CSM system can do. Readers will learn about the concept of CSM as a Service (CSMaaS) and how it can help media organizations overcome the technical and financial barriers to employing advanced CSM in their operations. Finally, the paper describes key considerations when transitioning CSM into the cloud, and how making this transition can help media organizations with ever-tightening budgets add the necessary flexibility and agility to remain competitive and relevant.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "CSMaaS",
                      "Cloud",
                      "media",
                      "integrated workflow",
                      "storage",
                      "archive",
                      "content management",
                      "content protection",
                      "disaster recovery"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001520"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Virtualization of Television Playout",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202013%20Annual%20Technical%20Conference%20&%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Martin Holmes",
                    "Neil Maycock",
                    "John Shike"
                  ],
                  "abstract": "This paper considers how conventional broadcast operations for network, cable, and affiliate station television services (Appointment TV) can be consolidated with on-demand services into a unified “Media Factory” and how that can be virtualized in a datacenter or cloud. The virtualized Media Factory will facilitate greater agility in delivering new services, variable infrastructure costs that align with revenues, and scalable infrastructure. These benefits will enable media companies to economically meet the exploding consumer demand for new services and to address new markets where traditional television models were untenable. The diagram below is a high level summary of the concept.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2013-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001522"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2012",
        "conferences": [
          {
            "conference_name": "The 2012 Annual Technical Conference & Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/",
            "articles": [
              {
                "article_local_id": "8",
                "article_title": "Optimised IP Multicast Architectures for Real-Time Digital Workflows",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Kernen",
                    "Javed Asghar"
                  ],
                  "abstract": "Across the entire broadcast chain from production to distribution, real-time digital workflows are now commonly being distributed over Internet Protocol (IP) networks. Many deployments are leveraging IP multicast to optimise the delivery from a source to a set of diverse end points (receiver) such as video servers, mixers, quality control units, video monitoring, time & synchronisation slaves, etc. These devices require reliable and deterministic network behaviour to ensure an optimal operating environment. — Technology developments in multicast-related protocols and architectures such as Source Specific Multicast, transport virtualisation, Fast Convergence, inline video monitoring metrics, combined with multicast hardware replication improvements in routers and switches, have significantly increased the reliability of the network layer transport for digital workflows. — By preventing bandwidth duplication or centralised congestion points, reducing outage duration by using dual paths between source and receivers, combined with protocol, hardware, monitoring and security improvements, the overall reliability of IP multicast networks has dramatically increased in the last decade.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IP",
                      "multicast",
                      "security",
                      "network",
                      "workflows",
                      "monitoring",
                      "fast convergence",
                      "SDN"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001437"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Automatic Interlace or Progressive Video Discrimination",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Manish Pindoria",
                    "Tim Borer"
                  ],
                  "abstract": "Video content originates from a wide variety of sources. Even within one programme, several different video technologies may have been used during production. This paper discusses an algorithm that is able to reliably identify progressive and interlace frames. The algorithm is based on calculating a metric based on the degree of “interlacing artefacts” produced when adjacent fields from different frames are re-interleaved to reform a frame. The metrics are analysed over multiple frames to detect whether the material originates from a progressive or interlace source. This process has successfully been adapted to correct film-phase errors found in telecined archive material.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Film-mode detector",
                      "telecine"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001440"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "GPU-Based Real-Time 4K RAW Workflows",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas True",
                    "Andrew Page"
                  ],
                  "abstract": "Advances in digital imaging technology are fundamentally changing the cinema workflow and the tools artists and engineers traditionally use. Relatively inexpensive 4K resolution digital motion picture cameras capable of capturing and storing RAW sensor data with a wide dynamic range, high color gamut, and high bit depths all at frame rates that have traditionally been the domain of broadcast video are now available. Implementing a RAW workflow that provides real-time interactivity and a production path where all artistic choices are non-destructive requires a great deal of compute as every image displayed needs conversion from RAW sensor data to display oriented imagery and colorimetry. This highly parallel operation is well suited to the capabilities of modern graphics processing units (GPUs). This paper will present best practices for optimal GPU compute core and memory usage as well as efficient data transfer schemes for sensor data processing and display.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001433"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Real Time File System for Content Distribution",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Heiko Sparenberg",
                    "Siegfried Foessel"
                  ],
                  "abstract": "This presentation gives a deep view into the development of a file system, especially designed for scalable media files including JPEG 2000 and H.264 SVC. By applying specially developed techniques, including the Substitution Strategy, a real-time capable file-system can be built, even if the mass storage, or the interface to it, is too slow to deliver the data in the desired time. Rather than skipping whole files, new caching strategies will be shown that again, take advantage of the file-inherent scalability. — The presented system also comprises an advanced user-rights-management that allows for granting access-rights to certain parts of a scalable file, rather than granting rights to whole files. Users will therefore get a different version of an image or video, dependent on their current access-rights.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "real-time",
                      "virtual file system",
                      "caching for scalable media",
                      "JPEG 2000",
                      "image/video data compression",
                      "content distribution",
                      "eviction policy"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001435"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Dynamic Rate Control Technologies Enabling Priority Based Bandwidth Allocation for IP News Gathering Network",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shuhei Oda",
                    "Katsunori Aoki",
                    "Yosuke Endo"
                  ],
                  "abstract": "In this paper, we propose an IP based news gathering network where terminals share bandwidth. Seamless route connection of IP networks and dynamic bandwidth allocation enables speedy and accurate coverage. We developed a new TCP that considers transmission priority. The TCP allocates bandwidths at an appropriate utilization ratio with consideration of their priority while the conventional TCP allocates bandwidths equally among TCPs in the common path, and this protocol maintains backward compatibility with the conventional TCP. We evaluated the technology by performing transmission experiments and proved that file transferring traffic share network bandwidth reflecting the operation of bandwidth allocation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "file-based work flow",
                      "video file transmission",
                      "transmission priority",
                      "TCP",
                      "congestion control algorithm"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001434"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Compliance with FCC Rules for IP Distribution of Video Programming",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alison Greenwald Neplokh"
                  ],
                  "abstract": "In January, 2012, the Federal Communications Commission adopted rules requiring closed captioning of IP-delivered video programming that has aired on television. The rules apply to video programming owners (i.e., the entity that licenses the video for distribution), video programming distributors and providers (e.g., online video distributors), and manufacturers of apparatus designed to receive or play back video programming. These rules begin to take effect on September 30, 2012. This paper describes the rules, compliance, and the status of SMPTE Timed Text as a “safe harbor” for compliance. It will also cover the status of ongoing accessibility initiatives at the FCC.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SMPTE Timed Text",
                      "Federal Communications Commission",
                      "Closed Captioning",
                      "Accessibility"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001448"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Closed Captioning Challenges for IP Video Delivery",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jason Livingston"
                  ],
                  "abstract": "New FCC regulations require closed captions from TV broadcasts to be available when these videos are delivered by Internet Protocol (IP), such as on the web and mobile devices. This presents a number of challenges in content authoring, asset management, and delivery. To address these challenges, SMPTE created a new specification called SMPTE 2052 (SMPTE Timed Text). This paper will discuss the new regulations and best practices for the different workflows involved, such as: file-based authoring of closed captions for broadcast and IP compatibility, translating existing CEA-608 and CEA-708 broadcast closed captions data into SMPTE 2052, common pitfalls and workarounds, and current SMPTE activities to help address these challenges.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001449"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "HEVC - Enabling Commercial Opportunities through Next Generation Compression Technology",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lukasz Litwic"
                  ],
                  "abstract": "High Efficiency Video Coding (HEVC) is near completion by the ITU-T / ISO/IEC Joint Collaborative Team on Video Coding (JCT-VC). The aim of HEVC is to revolutionize the compression world with a potential 50% bitrate saving over Advanced Video Coding (AVC, or H.264 / MPEG-4 AVC) and even more dramatic bandwidth savings compared to MPEG-2 Video. — HEVC is already attracting much interest in all established TV markets, from content acquisition to distribution and delivery to the home over all networks. More interestingly, forecasts predict that 90% of all IP traffic will be video by 2015. This makes HEVC an attractive enabler for new types of video consumption, from mobile devices served over unmanaged networks to high end 4K TV to the home. — This paper compares simulation results from the JCT-VC HEVC test model against an industry-leading AVC encoder. Compression efficiency is measured by objective metrics (PNSR and JND) for several sequences over a range of operating points and resolutions. In addition, the paper examines the behavior of selected HEVC tool enhancements that facilitate the compression gains over AVC. Finally, the paper explores the significance of these compression efficiency gains for a variety of applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Efficiency Video Coding",
                      "HEVC",
                      "video compression"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001439"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "The Pipe Dream Becomes Real: Advertising Workflows Come of Age",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Lennon",
                    "Harold S Geller"
                  ],
                  "abstract": "The past year has been, quite possibly, the most eventful ever in the development of efficient advertising workflows. We can now embed a digital version of the infamous advertising slate in delivered commercials, using the Advanced Media Workflow Association's AS-12. BXF can be used to exchange not only the schedule of commercials, but instructions to move them from point A to B, as well as move the full complement of their metadata. BXF is also developing the ability to move copy rotation instructions from agency to broadcaster, filling the biggest gap existing today in the workflow. Ad-ID bridges all of this, making unique commercial identification simple. — With an ever-expanding array of delivery platforms, as well as targeted advertising, maximum efficiency for advertising workflows has gone from a nice idea to a must-have. The good news is that we now have the tools to make it all work. — We'll show how the whole thing fits together today, using industry standard approaches, making the pipe dream of automated advertising workflows a reality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ad-ID",
                      "Workflow",
                      "Advertising",
                      "BXF",
                      "MXF",
                      "Agency",
                      "Traffic"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001430"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Performance Parameters in File Based Workflows",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Karl Paulsen"
                  ],
                  "abstract": "Establishing a high system performance value for rich-media file-based workflows is tightly coupled to storage, server and network bandwidths. Configuring small scale storage solutions can be straight forward and simple. However, larger enterprise class systems that intend to grow, that must bridge other media platforms and peripherals, and need to support multiple sets of clients and associated workflows require a proper storage solution with few limitations. The hidden issues that become performance killers in a large scale storage solution are frequently misunderstood. This paper presents some of those hidden parameters; provide examples on how systems can be designed for scalability in both capacity and bandwidth; and shows that by proper planning and implementation the consequences of a poorly designed, under rated system can be alleviated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "storage",
                      "RAID",
                      "workflows",
                      "systems",
                      "performance",
                      "bandwidth",
                      "file-based",
                      "fault tolerance",
                      "scalability"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001436"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Spatial Concealment for Damaged Images Using H.264 (MPEG-4 AVC) Intra Prediction and Neighborhood Cliques",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Seyfullah Halit Oguz"
                  ],
                  "abstract": "Intra prediction methods introduced by H.264/AVC and furthered by HEVC, beyond enhancing intra coding efficiency also provide a potent tool for spatial error/loss concealment and digital film restoration e.g. restoration of scratches. In this paper, a novel H.264/AVC intra prediction based algorithm for spatial concealment is introduced. — The proposed algorithm utilizes reliable intra prediction direction information from available neighboring regions in the same image (or video frame) and synthesizes intra prediction directions most suitable for erroneous/lost/damaged image regions. The synthesized intra prediction directions are used to conceal the underlying artifacts through pixel domain interpolation. — Distinguishing features of the current work contributing to its success are its use of (a) an accuracy assessment and consequent weighting of available neighbors' information, and (b) conditional propagation of available neighbors' information based on the concept of ‘neighborhood cliques’. Both features significantly improve the reliability of interpolation results. Proposed framework enables using both causal and non-causal information.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "spatial concealment",
                      "image restoration",
                      "H.264/AVC",
                      "intra prediction"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001441"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Developments in the Realization of Practical File Based Workflow Environments",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ed Childers",
                    "David Pease",
                    "Andrew G. Setos"
                  ],
                  "abstract": "To make the transition to file-based content environments, tools are necessary to facilitate workflows and other key attributes. The LTO-5 magnetic tape system, with its high density, throughput, and fundamental reliability and the Linear Tape File System (LTFS) are two such tools. Both technologies are well documented, standardized, and multi-sourced. This paper will discuss the business and technical necessities for moving to a file-based workflow, the history and attributes of LTO tape, the features of LTFS, and how all of these pieces can come together to create a modern environment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "File based work flows",
                      "LTO",
                      "LTFS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001432"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "And the Winner is… Workflows for Judging Content Submissions at Siggraph and VES",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ben Roeder",
                    "Martin Rushworth"
                  ],
                  "abstract": "With the proliferation of formats and tools for media creation, providing a uniform arena in which to judge creative submissions for peer group recognition is a difficult and potentially labour intensive problem. This paper discusses a workflow and supporting software developed to support the uniform submission, judging, and display of content for the Visual Effects Society and ACM Siggraph Awards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001444"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Lessons Learned Implementing FIMS 1.0",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ian Hamilton",
                    "Tony Vasile"
                  ],
                  "abstract": "The Framework for Interoperable Media Services (FIMS) is a joint initiative of AMWA and the EBU. The objective of FIMS is to standardize service interface definitions for implementing media related operations in a Service Oriented Architecture (SOA). As one example of how FIMS can be used, a system that ingests and conforms content for playout and non-linear delivery can leverage FIMS to flexibly interact with media capture, transfer and transform products from multiple vendors. As one benefit of using standard interfaces, system components can easily be added, updated and removed in response to changing requirements and demand. This paper discusses lessons learned while implementing FIMS 1.0.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001431"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Perceptual Signal Coding for More Efficient Usage of Bit Codes",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Scott Miller",
                    "Mahdi Nezamabadi",
                    "Scott Daly"
                  ],
                  "abstract": "As the performance of electronic display systems continues to increase, the limitations of current signal coding methods become more and more apparent. With bit depth limitations set by industry standard interfaces, a more efficient coding system is desired to allow image quality to increase without requiring expansion of legacy infrastructure bandwidth. A good approach to this problem is to let the human visual system determine the quantization curve used to encode video signals. In this way optimal efficiency is maintained across the luminance range of interest, and the visibility of quantization artifacts is kept to a uniformly small level.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "perception",
                      "human visual system",
                      "transfer function",
                      "perceptual curve",
                      "signal",
                      "encoding",
                      "coding",
                      "bit depth",
                      "gamma",
                      "logarithmic",
                      "Barten",
                      "efficiency",
                      "EOTF"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001446"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Accurate ACES Rendering in Systems Using Small 3DLUTs",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yasuharu Iwaki",
                    "Mitsuhiro Uchida"
                  ],
                  "abstract": "The ACES color space has unlimited dynamic range, however, it is not so easy to implement ACES workflow keeping high quality on the grading systems currently in use. To this end, we proposed custom Log ACES and High Saturated Log ACES(HSLA) methods. The custom Log ACES can process negative ACES values and can handle high dynamic range. HSLA expands the ACES color space to reduce vacant area and spread real color data area in order to use 3D LUTs more effectively. These two methods drastically improve accuracy of color reproduction even if the post-production system supports less than 33 gird number of 3D LUTs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "ACES",
                      "3DLUTs"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001460"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Leveraging the Cloud for File-Based Workflows",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ron Quartararo",
                    "Mark Brown",
                    "Brian Campanotti"
                  ],
                  "abstract": "The information technology (IT) industry has, for several years, embraced the cloud as a viable means of transforming the technical infrastructures of its businesses. One of the key advantages has been the ability for cloud computing customers to migrate from a capital expense (cap-ex) funding model for IT infrastructure to a model where IT becomes an operating expense (op-ex), helping to improve their financials and mitigate risk. Moving to the cloud has allowed the Chief Information Officer's organization to operate on a “pay as you go” basis, rather than necessitating the design and build of costly infrastructure to meet peak demand. Enterprises can conduct business more effectively by getting what they need, when they need it, where they need it. Along with that benefit has come the ability to more adequately manage staffing, reduce the need for periodic technology refreshes and free up valuable real estate within their facility.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001461"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "A Cloudspotter's Guide to Migration",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Al Kovalick"
                  ],
                  "abstract": "Cloud adoption is growing at a 22% annual rate. SaaS apps revenue will reach $258 billion in 2020 (Forrester Research). This train is unstoppable. The economic and systems benefits are compelling and being leveraged by media companies worldwide. What does facility migration to the cloud involve? What low-hanging fruit can migrate now? What are the tradeoffs? This talk is a short tutorial on cloud basics with tips on migration. Aspects of architecture, application delivery, economics, open systems, and operations are considered. If you are a cloudspotter, this paper is for you.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud",
                      "migration",
                      "SaaS",
                      "IaaS",
                      "PaaS",
                      "application delivery",
                      "virtual desktop"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001462"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Trends in Wireless Display Connectivity",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "The newest generation of high-resolution digital display interfaces now has a new face: Wireless connectivity. Several systems, including generic WiFi (802.11)-based products, have already come to market. Two of them - 6 GHz wireless high-definition interface (WHDI) and 60 GHz wireless HD (WiHD) - are competing head to head in the consumer electronics space, while a wide-channel, short range implementation (ultra wideband, or UWB) is struggling to stay viable. — All of these systems support full bandwidth HDMI and DisplayPort signals (10 Gb/s) with low latency, making them attractive as well for 3G camera-to-monitor links for field video production. This paper will describe each system and explain their advantages and disadvantages, as well as the differences between them.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "WHDI",
                      "Wireless HD",
                      "UWB",
                      "ultra wideband",
                      "HDMI",
                      "DisplayPort",
                      "WiFi"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001451"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Being the Change You Wish to See: Changing Broadcast Schedules Right up to Air",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Lennon"
                  ],
                  "abstract": "Today's world is all about people getting what they want, right away. The world of media is no exception. The Internet has caused us to think about the words “dynamic” and “media” in entirely different ways. Viewers now have access to whatever they want, whenever they want. Advertising, long a mainstay of the media industry, is no exception. Advertisers expect the right ad to be shown to the right person, on the right device. This includes changing their minds about what they want to advertise, when, and where, right up to the time that the viewer sees the ad. — Sounds like a nightmare, doesn't it? Well, it used to be. Fortunately, we now have SMPTE's Broadcast Exchange Format (BXF), which is perfect for this task. We'll look at real-world cases in which BXF is enabling dynamically changing delivery of content, right up to the time the viewer sees it. — So, don't fear change, embrace it with the help of the right tools, and a new outlook on media consumption. Oh, and you can expect to not only save money doing this, but also find new revenue.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ad-ID",
                      "Workflow",
                      "Advertising",
                      "BXF",
                      "Agency",
                      "Traffic"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001438"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "High Speed Format Converter with Intelligent Quality Checker for File-Based System",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenichiro Ichikawa",
                    "Takuji Shimmi",
                    "Yasunori Iguchi",
                    "Kentaro Higashijima"
                  ],
                  "abstract": "NHK broadcasting is shifting to file-based systems for its TV production and playout systems including VTRs and editing machines. A variety of codecs and Material eXchange Format (MXF) formats for broadcast equipment have been adopted. These include MPEG-2/AVC and OP1a/OP-Atom. Video files need to be converted into the selected codec and format to operate efficiently. The quality of video and audio must be checked during this conversion process because degradation and noise may occur. — This paper describes equipment that can quickly convert files to multiple formats as well as intelligently check the quality of video and audio during the conversion. The equipment automatically adjusts thresholds to detect anomalies in the video quality check, depending on the type of codec and the spatial frequency of each area. This can be done in less time than the actual video duration by optimizing the processing software.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "file-based system",
                      "quality check",
                      "converter"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001442"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Quantitative Evaluation of Human Visual Perception for Multiple Screens and Multiple CODECs",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sean McCarthy"
                  ],
                  "abstract": "Great consumer experiences are created by a convergence of sight, sound, and story. This paper is an in-depth quantitative analysis of the neurobiology and optics of sight. More specifically, we examine how principals of vision science can be used to predict the bit rates and video quality needed to make video on everything from smartphones to Ultra HDTV a success. We present the psychophysical concepts of simple acuity, hyperacuity, and Snellen acuity to examine the visibility of compression artifacts for MPEG4/H.264. We also take a look at the newest emerging International compression standard HEVC. We investigate the how the various sizes of the new coding units in HEVC would be imaged on the retina, and what that could mean in terms of the HEVC video quality and bit rates we would likely need in order to deliver entertainment quality content to smartphones, tablets, HDTV, 4K TV, and Ultra HDTV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001445"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Human Perception & Advancements in File-Based QC",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Carson",
                    "Atul Ravindran"
                  ],
                  "abstract": "Archiving and retrieval of video picture assets has always presented an issue as to ensuring that the recovered asset contains the best quality picture possible. While current methods exist to detect (and correct) artifacts from the original camera negative, this is generally not the case with the medium available from the archive. The more common medium for retrieval is a digital video tape or film print. When retrieving video pictures from digital video tape or film prints, artifacts are generally introduced via methods that are difficult to detect without use of the human visual system, since many of these artifacts do not have a common, mathematically definable pattern to them. These artifacts can include film tearing, film dirt, analog noise, block-based digital drop outs and others. — This paper covers a newly designed metric and the implementation methods used to automatically find these types of artifacts without need of an external reference, substantially functioning and locating artifacts in the same method as the human visual system. The paper also shows the commercial viability of this metric in a system, and how this metric is useful and cost-saving for file-based content preparers compared to existing, manual processes for content review. The methods and system described herein are patent pending.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001447"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Leveraging Fiber Properties to Our Advantage",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Beatty",
                    "John Bradford",
                    "Richard Zahm",
                    "Kimberly Allen"
                  ],
                  "abstract": "A strand of optical fiber is inherently thin, flexible, and light weight. How can we leverage these properties to improve the fiber installation process and make it easier to adapt to changing facility needs? — A new infrastructure / installation technology called “Air Blown Fiber Infrastructure” facilitates this approach. Using a point-to-point network of high density tubes as a highway, 3000 ft. of 24 strand-fiber can be jetted (installed) from source to destination across a facility in just 30 minutes. Once the tube network is in place, changes can be made at a fraction of the time and cost of conventional fiber networks, without disruption to the network or the facility. — Technical Discussions include: • What is an Air Blown Fiber System • Conventional Fiber vs. Air Blown Fiber System ROI Comparisons • Design Considerations (intra-building, campus) • Tube Bundle Design Consideration and Limitations • Fiber Bundle Installation Considerations and Options • Jetting Specifications, Limitations and Testing",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Fiber Optical Cable",
                      "Fiber Optics",
                      "Air Blown Fiber",
                      "Fiber",
                      "Infrastructure Technology",
                      "Next Generation Digital Infrastructure",
                      "Wide Bandwidth Infrastructure",
                      "Evolving Technology for Broadcast Facilities",
                      "High Performance Networks"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001450"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Corralling the Chaos of Ancillary Data within Multiple File Formats",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sara Kudrle"
                  ],
                  "abstract": "The baseband Serial Digital Interface (SDI) workflows and formats were “iron clad” and well defined. These were the “good old days” when devices interconnected with ease thanks to the rigor and breadth of SMPTE standards for SDI. Nowadays, with the great flexibility of file based media workflows and the multitude of formats needed for different applications, the industry is dealing with incompatible wrappers and inconsistent or non-extendable Ancillary (ANC) data carriage. This paper will look at these evolving workflows and the resulting “Wild West” of files. More specifically, the paper explores the challenges faced with the handling of ANC data such as Active Format Descriptor (AFD), closed captions, ad insertion triggers, audio metadata, etc., within various file formats. The paper then describes the unified and extensible approach offered by SMPTE 436M for the carriage of ANC data within Material Exchange Format (MXF) wrapped files. Could SMPTE 436M be the champion the industry needs to restore order to the Wild West and corral some of the chaos?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SMPTE 436M",
                      "AFD",
                      "ANC",
                      "Ancillary Data",
                      "ad insertion",
                      "closed captions",
                      "metadata",
                      "MXF",
                      "standards",
                      "SDI",
                      "file based workflows",
                      "wrappers"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001443"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Image Enhancement Using Similarity-Based Color Matching for High-Quality Stereoscopic 3D Image Acquisition",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Younghoon Lim",
                    "Eunjung Chae",
                    "Eunsung Lee",
                    "Wonseok Kang",
                    "Joonki Paik"
                  ],
                  "abstract": "Stereoscopic three-dimensional (S3D) movies often contain inconsistencies between left and right images acquired by a stereo camera due to an unstable filming environment. This research introduces a novel image enhancement algorithm using similarity-based color matching between S3D images. The proposed algorithm first partitions both reference and target images into multiple sub-blocks, and then classifies those blocks into reflection and illumination components using retinex theory. Color correction is performed by matching histograms of a corresponding pair of blocks based on the structural similarity index measure (SSIM). The color corrected images are further enhanced by removing noise in the wavelet transform domain. We can make high-quality S3D images from imperfect input images acquired under stressful conditions including limited dynamic range, unstable calibration of stereo camera pairs, and low signal-to-noise ratio (SNR). The proposed method can be applied to high-quality panorama images, frame difference-based video tracking, and similarity-based image analysis as well as S3D films",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Stereoscopic 3D (S3D)",
                      "Retinex",
                      "Structural Similarity Index Measure (SSIM)",
                      "Color Matching",
                      "Image Enhancement"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001454"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Next-Generation Techniques for the Protection and Security of IP Transport",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chin Chye Koh"
                  ],
                  "abstract": "Few in the professional video community foresaw IP's rapid ascent to its position as a dominant (if not the dominant) video transport protocol. To many, IP lacks the control and protection so critical to video networking. While today's IP network infrastructure—driven by the speed and capacity requirements of data centers and cloud-based services—is now capable of carrying professional video in a controlled, useable manner, significant concerns remain for the best way to control, monitor and protect services in wide-area routed networks. — In any media delivery system, there is always concern on network availbity and the possibility of outages. With the flexibility of IP/Ethernet transport, advanced FPGA / memory technology, and low cost / efficient Ethernet switches and IP routers, we are now able to deliver new protection algorithms. With these new algorithms, the highest level of Quality of Service (QoS) can be delivered ensuring minimal outages, even in the case of partial network path faliures. This paper will focus on recently-developed techniques for real-time data flow protection now undergoing trials and initial deployment. These techniques make use of dual-launch of network feeds with intelligent buffering and dynamic control.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IP Content Networks",
                      "Transport",
                      "Architectures",
                      "Standards & Applications",
                      "IP Protecton"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001452"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Computational Photography for Dust and Scratch Detection on Transparent Photographic Material",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Giorgio Trumpy",
                    "Rudolf Gschwind"
                  ],
                  "abstract": "This work pertains the digital restoration of motion-picture films. — A new method for the automatic detection of blemishes on any kind of transparent photographic material (still and moving images, silver-based and dye-based material) is presented. It consists in an innovative combination of different optical techniques and computational photography. — The image layer is a random dispersion of microscopic elements (e.g. silver particles in b&w material) and its interaction with light is isotropic. Dust, scratches and other irregularities of the film surface produce shadows and reflections that are strongly dependent on the provenance of light. The acquisition of multiple images with different geometries of illumination, and the analysis of the differences between them, is found to be an effective method to emphasize irregularities in the film surface. — Moreover, the analysis with polarized light is found to improve the blemish detection. — The experiments show that the innovative method effectively detects flaws on photographic film surface.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital Restoration",
                      "Motion Picture",
                      "Computational Photography"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001457"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "Effects of Viewing Conditions on Fatigue Caused by Watching 3DTV",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Toshiya Morita",
                    "Hiroshi Ando"
                  ],
                  "abstract": "In order to enjoy a pleasant experience watching 3DTV, it is necessary to collect and analyze reliable safety assessment data. Evaluation experiments were conducted consisting of 500 adult participants watching 3D programes for approximately one hour on commercially available 46 to 50-inch 3DTVs that require the use of shutter glasses. The degree of fatigue after watching the 3DTV was evaluated under various viewing conditions based on objective and subjective indexes of fatigue. The results of objective indexes showed that there was no statistical difference between watching 3DTV and traditional TV (i.e., watching 2D programes without glasses) in degree of decline of visual and cognitive functions due to fatigue. On the other hand, the results of subjective indexes indicated that there were some differences between watching 3DTV and traditional TV in the sensation of fatigue, which may not be attributed to watching 3D programes, but to wearing the 3D shutter glasses.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3DTV",
                      "viewing conditions",
                      "visual fatigue",
                      "fatigue evaluation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001472"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "High Performance Polarization-Based 3D and 2D Presentation",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary D Sharp",
                    "Miller H Schuck",
                    "Dave Coleman",
                    "Kevin Curtis",
                    "Scott Gilman",
                    "Erik Arend"
                  ],
                  "abstract": "Each digital cinema 3D delivery system has a characteristic efficiency. The 3D-efficiency gives the relative luminance of 3D presentation compared to 2D presentation. In the absence of careful attention to design, component efficiencies, and maintenance, the result can be a peak luminance well below 4.5 fL, even on average sized screens. In addition, aspects of a 3D system can determine the quality of 2D presentation. Given the large installed base and immediate need for higher brightness images, methods for increasing brightness and image quality are sought which enhance existing projector platforms. This paper evaluates loss mechanisms in 3D projection systems and shows that high-brightness 3D is feasible using lamp-based illumination. These solutions can be implemented using single-projector sequential 3D, for conventional sized screens (averaging 40′), as well as premium large format screens in excess of 60′.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "digital cinema",
                      "projection",
                      "DLP",
                      "polarization",
                      "3D efficiency"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001473"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Production Media Data Centers: Scalable Computing, Networking, Virtualization, and Adaptive Bit Rate Encoding",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Ohanian"
                  ],
                  "abstract": "With “TV Everywhere” offerings driving the consumption of content, significant needs have developed in addressing the requirements of digital media supply chains. For content providers and service providers, architecting and implementing solutions to serve “TV Everywhere” require flexible and agile infrastructures. — A Virtualized Production Media Data Center combines scalable computing, dense networking, adaptive bit rate encoding and the virtualization of media applications to address the technology and business process change requirements for the Media & Entertainment industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Data Center",
                      "Virtualization",
                      "Scalable Computing",
                      "Adaptive Bit Rate Encoding",
                      "Cisco",
                      "TV Everywhere"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001475"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "The Unfolding Merger of Television and Movie Technology",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "Live show video rendering to Rec709 typically has used a simple in-camera rendering. Movies until about the year 2000 were predominantly made on film, and printed to film. — Movies have been predominantly 24fps, whereas live video has used higher motion rates. — The telecine, and also the digital film scanner, began to decouple the wide range film capture from the image produced for movie release or television release. — High-end digital cameras now capture a wide dynamic range, logically corresponding to the extended range captured on camera film negative. — A new system ingredient is the ACES system with a 16-bit half-float representation, a Reference Rendering Transform, followed by a device-specific Output Device Transform. This structure provides a unifying mechanism, bringing video and film technology closer together in underlying technology, and also in image appearance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital Cinema",
                      "HDTV",
                      "ACES",
                      "Mastering Formats",
                      "HDR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001463"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Unconstrained 2D to Stereoscopic 3D Image and Video Conversion Using Semi-Automatic Energy Minimization Techniques",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raymond Phan",
                    "Richard Rzeszutek",
                    "Dimitrios Androutsos"
                  ],
                  "abstract": "We present a method for semi-automatically converting unconstrained 2D images and video content into stereoscopic 3D. The user is presented with the image to convert, and brushes user-defined depth strokes in certain areas. These correspond to a rough estimate of the scene depths within these points. After, the rest of the depths are solved using this information, producing a depth map to create stereoscopic 3D content. For video, the user chooses several keyframes for brushing, and the depths for the entire video are found in a volumetric basis. Additionally for video, the user has the option of minimizing effort by employing a robust tracking algorithm, where the first frame only needs to be labeled. After, the labels are propagated throughout the entire video, ultimately increasing accuracy with more frames labeled. Our work combines the merits of two energy minimization techniques: Graph Cuts and Random Walks. The former respects boundaries, but does not have suitable depth diffusion, making the scene look like “cardboard cutouts”. The latter has good depth diffusion, but object boundaries are blurred. Therefore, combining the merits of both will lead to a higher quality result. Current efforts rely on automatic or manual conversion by rotoscopers. The former prohibits user intervention, while the latter is time consuming, prohibiting use in smaller studios. Semi-automatic is a compromise to allow for more faster and accurate conversion, decreasing the time for studios to release 3D content. The results shown in this paper generate good quality stereoscopic depth maps with minimal effort required.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "2D to 3D Image Conversion",
                      "2D to 3D Video Conversion",
                      "Random Walks",
                      "Graph Cuts",
                      "Depth Maps",
                      "Depth-Label Tracking",
                      "Stereoscopy",
                      "Semi-Automatic",
                      "Image Segmentation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001453"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "3D Sports Production at the 2012 London",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim DeFilippis"
                  ],
                  "abstract": "For the first time the Olympics were telecast in 3D. In the past, some 3D coverage was available on a closed circuit basis of limited Olympic events. The London Olympics 3D Channel covered multiple sports, both live and ENG coverage, and provided a full up 3D channel of over 275 hours of 3D programming. The core of the 3D coverage was provided with (3) OB Van remote production units as well as (6) single camera EFP production units. A variety of stereoscopic rigs were used in each of (4) venues along side the Panasonic ENG/EFP P2 3D Camcorder. Some special stereo cameras were also used including: pole cameras, rail cameras, RF cameras and underwater cameras. The paper will present the unique challenges to providing 3D coverage, from organizing the 3D channel as well as the technical challenge of covering sports in 3D while accommodating the full up 2D production. Finally, the paper will discuss what worked and what did not.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "stereoscopy",
                      "production",
                      "Olympics",
                      "sports"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001455"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Towards Higher Dimensionality in Cinema Color: Multispectral Video Systems",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Long"
                  ],
                  "abstract": "The current digital transition being experienced by the motion picture industry has afforded an effective increase in dimensionality in the domains of time and space, however, comparatively little effort has been put into expanding a rigorous treatment of color. All practical motion imaging systems continue to rely on the metamerism illusion wherein a particular integrated stimulation of the three cone types found on the human retina is sufficient to reproduce the sensation of color of any real object regardless of higher order spectral composition. Such treatments fundamentally restrict cinema color reproduction, offering limitations in absolute color accuracy and gamut, observer metamerism and consistent creative communication. — Optimized multiprimary reproduction focused on spectral reproduction accuracy or metamerism reduction may ultimately prove a better answer to enhancing the color experience in future systems. It also promises to open new color management paradigms for visual effects compositing of live action and computer-generated imagery or for virtual cinematography. Research in progress at Rochester Institute of Technology has focused on exploring essential design attributes for abridged multispectral capture and display systems for motion imaging applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Multispectral video",
                      "multispectral camera",
                      "multispectral display",
                      "observer variability",
                      "observer metamerism"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001458"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "High Performance Optics for a New 70mm Digital Cine Format",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Caldwell",
                    "Wilfried Bittner",
                    "Ip Winston",
                    "Dan Sasaki"
                  ],
                  "abstract": "This paper details technical features of the first series of high-speed prime lenses designed for a new 70mm digital format developed by Panavision. These new lenses offer full aperture (f/2.5) performance at or near the diffraction limit from near-UV to near-IR over a 48×20.25mm image area. These lenses are also designed to work properly with optical filters inserted between the lens and sensor. — Twelve focal lengths are under development, ranging from a 27mm ultrawide to a 300mm telephoto. In addition to traditional externally-geared controls, all lenses have internal motors for focus and aperture. High resolution metadata is transmitted continuously to the camera. Metadata includes focus distance, aperture, temperature, and individual lens identification. A replaceable internal filter near the aperture stop permits a variety of creative effects, including soft-focus.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Lenses",
                      "lens design",
                      "cine",
                      "cinematography",
                      "70mm",
                      "large format",
                      "digital",
                      "superachromat",
                      "superachromatic",
                      "apochromat",
                      "apochromatic",
                      "UV",
                      "IR",
                      "Panavision",
                      "metadata",
                      "gigapixel",
                      "Caldwell Photographic",
                      "iris",
                      "bokeh"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001456"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Low-Latency Transmissions for Remote Collaboration in Post-Production",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ales Friedl",
                    "Jiri Halak",
                    "Michal Krsek",
                    "Sven Ubik",
                    "Petr Zejdl"
                  ],
                  "abstract": "The post-production often involves several key parties who want to be in the control of the process — the director, the producer, the editor, and several technical experts — the colorist, the stereographer, the sound master, etc. Some decisions are more effectively done in real-time, interactively. However, the participants are often very busy, working on multiple projects in parallel and it is difficult for them to travel together for a collaborative session. We believe that future technology for low-latency high-quality transmissions of image and sound will enable remote real-time collaboration in post-production. As the capacity of optical networks is increasing, uncompressed transmissions of original content with minimal latency will be possible. We did several experiments with real-time remote collaboration in color grading and stereography to over 10000 km between Europe and West Coast US, using GLIF (Global Lambda Interchange Facility) network. We describe the key technology aspects and lessons learned.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Film postproduction",
                      "distant collaboration",
                      "video streaming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001465"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Cloud Media Collaboration, Enter Stage Right, and… Action: Bringing Compute Processing to a Media Services Ecosystem in Public Clouds",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Jenkins"
                  ],
                  "abstract": "It is the goal of this paper to outline the advantages inherent in building a cloud computing federated community (ecosystem) around the provision of scalable computing resources associated to data aggregation and on-demand processing capabilities, addressing major domains of data-intensive media services requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001467"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Delivering Multi-Camera Content to Smart Devices through Cloud Platforms",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Werner Ramaekers",
                    "Johann Schreurs",
                    "Maher Khatib"
                  ],
                  "abstract": "“Broadcasters must engage a new generation of multitasking viewers who no longer sit passively in front of their television sets but browse the internet and interact with social media while watching TV. — Rather than risk losing viewers, broadcasters can provide original premium content — including unseen camera angles and highlights — to viewers via second screen devices. The large amount of unused content that sits on live TV production servers can be used to enrich the user experience and maximize the value of already available content. — This paper will explore technology challenges in building open and scalable platforms to deliver high quality experiences on second screen devices, including: • Best practices in building near-live multi-camera replay platforms on top of standard live production environments • Overcoming challenges in cloud-based production and delivery to multiple screens • Integration with social networks, archives, stats and other third-party content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Second screen",
                      "multi-screen",
                      "mobile video",
                      "cloud",
                      "file-based workflow",
                      "HLS",
                      "transcoding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001468"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Using Name Spotting in Audio/Video Media Identification to Improve Media Discovery Service in Digital Object Architecture",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Manish Goswami",
                    "Lan Yang"
                  ],
                  "abstract": "Digital object repository, a component of digital object architecture, stores large number of audio/video files (as digital objects) and provides access and retrieval to them. Sometimes metadata for audio/video files are almost absent. Lack of enough metadata limits media discovery service from fetching the files containing little metadata. In addition, the media discovery service excludes those files from the result set. Relevant information, such as names, can be extracted from the given content of an audio/video file and appended in metadata of the same audio/video file for enhancing the media discovery service. In this research, we use a Hidden Markov Model and Viterbi algorithm based name spotting module, known as IdentiFinder to extract names. The research will help to make large number of audio/video files visible to the media discovery service with the help of name extraction. Also, it will increase the user satisfaction by improving the search result set.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media discovery service",
                      "Media Identification",
                      "metadata",
                      "Hidden Markov Model",
                      "Viterbi Algorithm",
                      "Name Spotting",
                      "Identifinder"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001470"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "The Cloud - What Does it Mean for Media Archives?",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nik Forman",
                    "Christopher H. Luther",
                    "Rajesh A. Patel",
                    "Howard Twine"
                  ],
                  "abstract": "Perhaps due to the close proximity IT companies now have to the broadcast industry the usage of the term ‘Cloud’ is becoming more and more prolific. Is this just another buzz word or are there real benefits to embracing the Cloud? This paper looks at the conventional media archive and discusses the opportunities and emerging trends for archive technology and the cloud. Some of the discussion will be about the enabling technologies like LTFS, as well as the emergence of Archiving as a Service. Additionally this paper will address the considerations to build a private ‘cloud’ archive in terms of users and growth expansion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cloud",
                      "Archive",
                      "LTFS",
                      "LTO",
                      "DR"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001466"
                  }
                }
              },
              {
                "article_local_id": "55",
                "article_title": "Scalable Format and Tools to Extend the Possibilities of Cinema Audio",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/55/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles Q Robinson",
                    "Sripal Mehta",
                    "Nicolas Tsingos"
                  ],
                  "abstract": "Surround sound has been making cinematic story telling more compelling and immersive for over 30 years. The first widely deployed surround systems used magnetic recording. Later, optical recording became standard, enabling up to 7.1 channels of audio. With the transition from film to digital distribution there is an opportunity for the next generational step forward. In this paper we describe a new surround sound format that dramatically advances the capabilities of cinema sound. The format was developed in close cooperation with industry stakeholders and was specifically designed to provide the most desired new capabilities and provide a path for future enhancements, while respecting and leveraging the strengths and know-how of the current sound format and pipeline. In particular, the new system maintains and advances the ability to deliver impeccable audio quality, and flexibly extends the creative possibilities to meet the needs and aspirations of both content creators and exhibitors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cinema",
                      "Surround",
                      "Sound",
                      "Spatial Audio"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001484"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "3D Production Edit Work Flow at the London 2012 Olympics",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James DeFilippis"
                  ],
                  "abstract": "For the first time the Olympics were telecast in 3D. In the past, some 3D coverage was available on a closed circuit basis of limited events. The London Olympics 3D Channel covered multiple sports, both live and ENG coverage, and provided a full up 3D channel of over 275 hours of 3D programming. Part of the Olympic 3D Channel every day was a (1) hour Summary program, presenting the best of the live 3D Coverage as well as the EFP single camera coverage captured that day. — This is the first time a 3D daily program was attempted, using a hybrid edit work flow. The paper will discuss the work flow, including the capture of the ENG footage using the Panasonic P2 3D camera, EVS Servers and AVID Media Composer editing. Additionally the challenge of quick turn around and the QC process to insure the materials were ‘stereo’ correct. The paper will cover the specific issues of what worked and what did not.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "Stereoscopy",
                      "Sports",
                      "Olympics",
                      "Editing",
                      "File Based Workflow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001474"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "120 Hz-frame-rate SUPER Hi-VISION Capture and Display Devices",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hiroshi Shimamoto",
                    "Kazuya Kitamura",
                    "Toshihisa Watabe",
                    "Hiroshi Ootake",
                    "Norifumi Egami",
                    "Yuichi Kusakabe",
                    "Yukihiro Nishida",
                    "Shoji Kawahito",
                    "Tomohiko Kosugi",
                    "Takashi Watanabe",
                    "Tadaaki Yanagi",
                    "Tetsuo Yoshida",
                    "Hideki Kikuchi"
                  ],
                  "abstract": "NHK has been researching and developing SUPER Hi-VISION, with 33 megapixels (7,680-pixel by 4,320-line of resolution), as the next-generation ultra-high definition television (UHDTV) broadcast system. Last year, NHK reported that it had decided to double the frame rate of SUPER Hi-VISION video to 120 Hz to improve its motion portrayal quality. This UHDTV system has been standardized as Recommendation ITU-R BT.2020. — We report on 120-Hz SUPER Hi-VISION devices that we have developed in this paper. One is a 120-Hz SUPER Hi-VISION image-capture device that uses three 120-Hz, 33-megapixel CMOS image sensors. The sensor uses 12-bit ADCs and operates at a data rate of 51.2 Gbit/s. We have also used three 8-megapixel LCOS chips and e-shift technology to develop a 120-Hz SUPER Hi-VISION projector. These 120-Hz SUPER Hi-VISION devices were exhibited at our open house in May 2012 and demonstrated superb picture quality with less motion blur.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SUPER Hi-VISION",
                      "UHDTV",
                      "full-spec",
                      "Standard",
                      "BT.2020",
                      "120 Hz",
                      "33 megapixel",
                      "CMOS image sensor",
                      "Cyclic ADC",
                      "LCOS projector",
                      "CFOSS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001477"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Development of a 70mm, 25 Megapixel Electronic Cinematography Camera with Integrated Flash Recorder",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Galt",
                    "Branko Petljanski",
                    "Stacey Campbell"
                  ],
                  "abstract": "This paper will describe the system design of the world's first 70mm, 25 megapixel, electronic-cinematography camera with an integrated flash memory recorder. — Although this camera shares many of the attributes of NHK's Ultra High Definition Television and benefits from NHK's pioneering research in the area of very high-resolution imaging, what we are about to describe is an electronic cinematography camera and recorder - not a television camera. While the unique requirements of the cinematographic process allow us to take advantage of certain processes that would not be practical in a television environment, we must also make provision for requirements that are unique to movie making. — The single CMOS sensor in the new Panavision camera has the same four times HDTV horizontal resolution of 7680 photo-sites as that proposed by NHK for UHDTV. Our sensor's vertical resolution is only three times the HDTV vertical for a resolution of 3240 photo-sites and an aspect ratio of 2.37:1 rather than UHDTV's 16 × 9, 1.78:1 aspect ratio. — Bucking the recent trend to take a lower resolution imager and interpolate to a higher resolution, the Panavision camera utilizes an oversampling technique to output a full bandwidth 19 megapixel RGB image from the available 25 million photo-sites. — The recorded frame size is 3840 × 1620 × 3 (RGB) or 18,662,400 pixels.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "4K",
                      "UHDTV",
                      "Super-70mm",
                      "oversampling",
                      "electronic cinematography"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001478"
                  }
                }
              },
              {
                "article_local_id": "53",
                "article_title": "4K TV Capture, an Early Experience Sharing",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/53/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jerome Vieron",
                    "Matthieu Parmentier"
                  ],
                  "abstract": "As the French public broadcaster, editor of 13 channels, 4 of which HD, francetélévisions studies 4KTV broadcasting scenarios for its premium programs. Enhancing the sense of realness, the viewing comfort and creating an immersive experience, such is the quest of any incumbent broadcaster looking to embrace the future of television. francetélévisions has undertaken 4K/60p production experiments to evaluate future workflows, and specifically work on adapting filming methods and materials. The Quality of Experience is evaluated taking into account the impact of compression on both 4K digital content and scanned films, with a specific attention to noise levels. After providing an early first report of available 4K cameras suitable for TV applications, the impact of compression technology on different types of 4k content will be presented, with a particular focus on HEVC (High-Efficiency Video Coding) codec as the natural compression standard for upcoming 4KTV applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HEVC",
                      "4K",
                      "UHDTV",
                      "video",
                      "compression",
                      "broadcast"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001482"
                  }
                }
              },
              {
                "article_local_id": "52",
                "article_title": "Frequency Response versus Time-of-Arrival for Typical Cinemas",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/52/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Louis D. Fielder"
                  ],
                  "abstract": "Cinema equalization is typically based on the use of 1/3-octave, minimum-phase filtering to adjust the spatial average of the steady-state magnitude response from multiple microphones to the X-curve. This paper explores one aspect of this process, namely whether the use of steady-state response is appropriate. The relationship between early-arrival and steady-state spectral characteristics for typical cinemas was examined. — The comparison between early-arrival and steady-state sounds was done via spectral analyses of impulse responses measured at multiple microphone locations within the audience seating area. The cinemas surveyed varied in size between 30–500 seats and the time-gating intervals varied from 4 ms to that equivalent to steady state. When the survey was done, front loudspeaker measurements above 500 Hz showed little spectral tilt upward toward “brightness” for early-arrival, compared to steady-state sounds, and a modest upward tilt for surround loudspeaker arrays in the largest cinemas. Larger response differences occurred below 500 Hz.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Cinema Measurement",
                      "Cinema Equalization",
                      "Cinema Acoustics",
                      "Cinema Standards",
                      "Time Frequency Analysis",
                      "B-chain"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001481"
                  }
                }
              },
              {
                "article_local_id": "54",
                "article_title": "Tutorial on Critical Listening of Multi-Channel Audio Codec Performance",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/54/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sunil Bharitkar",
                    "Grant Davidson",
                    "Louis Fielder",
                    "Poppy Crum"
                  ],
                  "abstract": "Listening for impairments introduced by multichannel audio codecs is an important task. Classical objective methods are not adequate in assessing audio coding schemes. Accordingly, the ITU-R BS.1116 & 1534 recommendations provide guidelines for subjective evaluation of codecs. This paper provides a tutorial on the proper conditions to do reliable codec testing. Several key components covered are, proper experimental design, selection of listening panel and training of listeners, developing the test methodology, selecting balanced program material, loudspeaker/room and sound-field requirements, listening for artifacts, and statistical analysis. This paper addresses these various components including the sound-field requirements since, as per the ITU: “The characteristics of the reference sound field at the listening area are most important for the subjective perception of, or the quality assessment of, auditory events and their reproducibility at other listening places or rooms. These characteristics result from the interaction of the loudspeaker(s) and the listening room”.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Audio codec evaluation",
                      "ITU-R",
                      "listening tests",
                      "BS.1116",
                      "ciritcal listening setup",
                      "subjective testing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001483"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "Further Investigations into the Interactions between Cinema Loudspeakers and Screens",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Long",
                    "Roger Schwenke",
                    "Peter Soper",
                    "Glenn Leembruggen"
                  ],
                  "abstract": "Modern-day data-acquisition techniques allow the gathering of high-resolution polar data to assess the detailed performance of loudspeakers. While these techniques are now common in laboratory and engineering laboratories, they can also be used for acoustic investigation into the in-situ performance of loudspeakers. This paper uses modern high-resolution data acquisition techniques and analysis tools to investigate the complexity of the interaction between a loudspeaker and the screen in a cinema presentation environment. A discussion is presented which explores the effects of three types of screen materials on loudspeaker frequency responses and radiation patterns. These screen effects are explored using a range of loudspeaker-screen distances found in typical cinemas. The impact of the screen on patron listening experience is examined and also in relation to the standards for system response set out in ST-202.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Loudspeaker",
                      "screen",
                      "high-resolution",
                      "radiation pattern",
                      "plane wave tube",
                      "reflection factor perforation",
                      "woven",
                      "image source"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001480"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "A Study of the Optical Distribution Costs of Multichannel Baseband Digital Broadcasts over a FTTH Network",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takeshi Kusakabe",
                    "Takuya Kurakake",
                    "Kimiyuki Oyamada",
                    "Yoshihiro Fujita"
                  ],
                  "abstract": "We have previously proposed a baseband time-division multiplexing method for the transmission of digital broadcasts over FTTH. Here, we evaluate the transmission equipment cost of the proposed method based on a simple assumed distribution network. We predict that the cost can be decreased to 11–36% of that of conventional sub-carrier multiplexing (SCM) and FM conversion transmission methods. By analysing the dominant factors affecting the cost, we show that significant savings are achieved due to the fact that an optical signal can be received at a lower power using the proposed method than for signals transmitted using conventional methods.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "digital broadcasts",
                      "cable television",
                      "time division multiplexing",
                      "FTTH"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001476"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "1080p50/60, 4K and beyond: Future Proofing the Core Infrastructure to Manage the Bandwidth Explosion",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Hudson"
                  ],
                  "abstract": "Traditional broadcast infrastructures only had to support one version each of SDTV and HDTV, plus extensions such as RGB 4:4:4 for better chroma keys. — Now we need to support 4:4:4:4 for external keys, high dynamic range (HDR) imaging, stereoscopic 3D, a 3D disparity channel, Quad-Full HD, higher frame rates etc, all of which drive real time streaming media bandwidth requirements. — How do we accommodate these new demands and stay future proof within our core broadcast infrastructure? — This paper outlines the latest developments, at the technical and standardization levels, to handle the emergence of new production formats. It examines changes to the studio infrastructure which add the flexibility needed to accommodate new production formats alongside existing formats, with maximum compatibility and minimum confusion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHDTV",
                      "SDI",
                      "Serial Digital Interface",
                      "3Gb/s",
                      "3Gbit/Sec",
                      "3G-SDI",
                      "100Gbit/Sec",
                      "stereoscopic 3D",
                      "2K",
                      "4K",
                      "8K",
                      "SMPTE standards",
                      "SFP+",
                      "QSFP+",
                      "IEEE",
                      "OIF"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001479"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Issues in Color Matching",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joel Barsotti",
                    "Derek Smith",
                    "L.A. Heberlein"
                  ],
                  "abstract": "To create a numerical description of color (e.g., X,Y,Z), one applies a Color Matching Function to spectral power distribution data acquired with an instrument such as a spectroradiometer. All the adjustments one makes to a video display or to video data depend on the accuracy of these numbers. The broadcast industry and others for whom color fidelity is crucial have long depended on the 1931 CIE Color Matching Function (CMF). Recent and continuing advances in display technology, however, have exposed serious deficiencies in this CMF. These deficiencies have long been known to academic researchers, who have in the intervening years proposed several alternative CMFs. This paper reviews the critical flaws that render the 1931 CMF no longer reliable, and surveys the strengths and weaknesses of candidates for its replacement",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Color Matching Functions",
                      "1931 CIE Standard Observer"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001459"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Theatrical Versioning in the Content Pipe - Integrating Digital Cinema into End to End Workflow",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Digital cinema compression, versioning and packaging is traditionally an isolated process within the life of a movie as content flowing through the “pipe” to different versions and delivery formats. With more integrated workflow and appropriate mezzanine files, the creation of digital cinema packages can become part of the flow of content from the creation to all downstream deliveries.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001464"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Practical Quality Assessment for Digitized Film Content",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt",
                    "Valerie La Torre"
                  ],
                  "abstract": "The European project CineXPRES is focusing on improving the digitization, preservation and restoration workflows for old film content. One very important topic in this project is an attempt to define a practical quality assessment for digitized film content. We believe that there is no absolute measure of quality but only measures dedicated to specific decision processes. To this end, we define three different image quality estimators, providing efficient tools in various situations that every archivist will have to face in the future: a multidimensional objective quality measure consisting in a collection of different degradation estimators, a conditional subjective quality estimator taking the display into account, and a conditional objective quality estimator, considering the ease to restore a content. This paper describes the computation of these estimators, and review few practical situations where they provide answers to complex decision making situations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Quality assessment",
                      "asset management",
                      "archive",
                      "image processing",
                      "preservation",
                      "restoration"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001471"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Towards Using Audio for Matching Transcoded Content",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dinkar Bhat"
                  ],
                  "abstract": "With the advent of multiple screens for viewing media, transcoding is becoming a key component of content delivery eco-systems. But transcoding implies that copies and versions of the same content can proliferate across various storage devices. It also means keeping track of content becomes a major problem both from copyright and recording/indexing perspectives. Video-based techniques for content indexing, where the aim is to extract robust signatures from video, have emerged as a major area of research. On the other hand, audio-based techniques have received less focus but audio could provide robust signatures for indexing media while it undergoes transformations. In this paper, we present an investigation of audio signatures under typical transcoding operations. Specifically, we look at Mel-Frequency Cepstral Coefficients (MFCC) as a signature, which has been widely used in audio recognition systems. Initial results indicate that the MFCC is quite robust.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Audio",
                      "Content indexing",
                      "Copy detection",
                      "Transcoding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001469"
                  }
                }
              },
              {
                "article_local_id": "57",
                "article_title": "Broadcasting Video over the Cellular Network and the Internet",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/57/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nuraj Lal Pradhan",
                    "John Wood"
                  ],
                  "abstract": "Because of the ubiquitous nature of the cellular 3G/4G network and the Internet, broadcasting video over the IP networks has gained lot of momentum. However, the lack of Quality of Service (QoS) required to stream real time video makes broadcasting over these networks very challenging. — In bandwidth constraint IP networks, such as the cellular network, video encoding techniques like H.264/AVC provides good video quality at substantially lower video bit rates. Transport protocols have been adopted to provide a complete streaming service between the end users in this packet based network. Excessive delay and bursty packet losses experienced in these networks make QoS control in real-time streaming application crucial. The widely used TCP protocol might not be efficient and its key feature, retransmission of erroneous or lost packets, applicable. UDP protocol, which is generally preferred for real-time applications, is not reliable and lacks flow control capabilities. In this paper, we will focus on the issues faced with broadcasting video stream over the cellular network and the Internet and possible solutions toward achieving low latency broadcast with a certain degree of QoS.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001486"
                  }
                }
              },
              {
                "article_local_id": "59",
                "article_title": "Here Comes Ethernet®",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/59/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen H. Lampen"
                  ],
                  "abstract": "On May 23, 1973, Robert Metcalf and David Boggs, working at the Xerox Research Center, succeeded in sending the first Ethernet(note 1) bit stream across their laboratory. Using packetized data ‘words’ with collision detection and retransmission, this was a dramatic improvement in computer network protocols. However, Xerox eventually abandoned their bid to manufacture computers and computer networks and gave Ethernet networking to the IEEE, where it became the open standard which now dominates the computer networking world. — One group of potential customers, those involved with professional audio and video, found standard Ethernet difficult or impossible to use. Many of them modified Ethernet, producing proprietary versions to carry audio and video bit streams. Recently, IEEE has released a new version of the Ethernet standard, IEEE 802.1 AVB (Audio and Video Bridging), to address the requirements for professional audio and video. This paper will outline the shortcomings of standard Ethernet and the changes and advantages in this new standard",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Ethernet",
                      "network",
                      "audio",
                      "video"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001488"
                  }
                }
              },
              {
                "article_local_id": "58",
                "article_title": "Multiformat Operation - System Implications and Solutions for Routing Switchers",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/58/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alan Smith",
                    "Kim Francis"
                  ],
                  "abstract": "This paper discusses the formats and media involved when routing simultaneous, multiple video and audio formats, on a variety of physical interconnections, the implications of operating in such an environment, proposes possible operational practices, and reviews practical solutions available. The simultaneous use of multiple video and audio formats, on a variety of physical interconnections, coupled with the demand for increased efficiency, has created new challenges for today's systems engineers and planners when specifying a routing switcher. Transitioning to various high-definition video formats and increasingly dense audio formats has increased the overall complexity of these multi-format systems—a 36,864 × 36,864 embedded audio matrix for an 1152 × 1152 video router! Simultaneously, audio and video processing requirements should be accommodated. Internal processing enables system and operational efficiencies: Control is simplified; a flexible input/output arrangement allows easy reconfiguration between uses. Finally, a glimpse into the future - will it get easier?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Routing",
                      "systems",
                      "multiformat",
                      "multichannel",
                      "hybrid",
                      "processing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001487"
                  }
                }
              },
              {
                "article_local_id": "56",
                "article_title": "Lee De Forest and the Invention of Sound Movies, 1918-1926",
                "article_url": "https://journal.smpte.org/conferences/The%202012%20Annual%20Technical%20Conference%20&%20Exhibition/56/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mike Adams"
                  ],
                  "abstract": "Lee de Forest received his Ph D in physics and electricity from Yale in 1899 and entered the 20th Century into a world of silence - the silent film of Edison and the quiet key clicks of the dots and dashes of Marconi's wireless telegraph. By 1906 he had patented his signature invention, the three-element vacuum tube he called the “Audion.” Beginning in 1918 he developed and patented a system of writing sound on motion picture film for synchronized talking pictures. Between 1920 and 1926 he worked with fellow inventor Theodore Case to develop the Phonofilm system of variable density recording. De Forest and Case ended up in court, with neither the winner. But for all subsequent systems of sound for motion pictures, the de Forest tube was the key as it allowed amplification of audio using loudspeakers which made it possible for audiences to experience talking pictures. In 1960 de Forest received an Oscar for his sound-on-film contributions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2012-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "sound-on-film",
                      "variable density",
                      "Lee de Forest",
                      "vacuum tube",
                      "Audion",
                      "arc",
                      "selenium cell",
                      "Theodore Case",
                      "Lauste",
                      "Bell",
                      "Edison",
                      "Fleming",
                      "Ruhmer",
                      "Vitaphone",
                      "Phonofilm",
                      "Dickson",
                      "Fox",
                      "SMPE",
                      "Oscar"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001485"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2011",
        "conferences": [
          {
            "conference_name": "The 2011 Annual Technical Conference & Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/",
            "articles": [
              {
                "article_local_id": "6",
                "article_title": "The Validity and Relevance of Reference Displays",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Chenery"
                  ],
                  "abstract": "In the past the ubiquity of the CRT display meant that it was reasonably easy to evaluate visually and check the color of images for public broadcast or viewing. — With the advent of new display technologies consumers are now viewing a wide array of different display technologies other than CRT including LCD (both CCFL and LED backlit), Plasma and recently OLED. While HD television has gone a long way towards unifying broadcast standards world wide under the ITU. BT.709 standard, studios are still clinging to their last CRT broadcast displays as references for how their images will look to the average consumer. Is this still a valid way to work? Should we be sticking to CRT devices as our reference, is it time for a new reference, or is the whole concept of a color reference monitor no longer valid?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Reference Display",
                      "Reference Monitor",
                      "Broadcast Monitor",
                      "color management"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001057"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Automated File-Based Quality Control: A Machine-Learning Approach",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matthias De Geyter",
                    "Nick Vercammen",
                    "Dirk Deschrijver",
                    "Tom Dhaene",
                    "Piet Demeester",
                    "Brecht Vermeulen"
                  ],
                  "abstract": "In recent years, broadcasters successfully introduced file-based workflows to improve production efficiency. However, they are increasingly dealing with a proliferation of file formats, and many of them still have large archives that need to be digitized for reuse. To guarantee trouble-free workflows and long-term preservation in this quickly evolving digital domain, it is essential that media files adhere to well-described, established standards. Furthermore, their audiovisual quality should be up to broadcast level. A variety of content analysis tools checking container and encoding formats, as well as audiovisual quality, are available but often hard to configure, and frequently provide difficult-to-interpret results. In this research, a learning algorithm takes into account the results of several sources of content analysis to perform a reliable automatic interpretation, which is communicated as a traffic light decision to an operator who can then take further action if necessary. Thus, valuable time and money can be saved.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "file-based workflows",
                      "quality control",
                      "machine-learning",
                      "automation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001058"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Tying it All Together — A Watershed Moment in the Media Industry: SDI, Video Compression, MXF, AS-02, AS-03, IMF, FIMS, SMPTE 2022 All Explained in 200 Pages or Less",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brad Gilmer"
                  ],
                  "abstract": "In July of 1998 the joint SMPTE/EBU Task Force for Harmonized Standards for the Exchange of Program Material as Bitstreams published its Final Report: Analyses and Results. Now some 13 years later, the basic framework outlined in this report is becoming a reality. But more than this, the framework allows innovative media companies and manufacturers to expand the power and possibilities of the framework well beyond what was envisioned when the report was published. — This paper connects the dots between SDI, image compression, the invention of the AAF/MXF data model, the MXF wrapper format, the subsequent development of AS-02, AS-03 and other MXF Application Specifications, developments in high-speed networking technology and network security, the SMPTE 2022 Standard for Professional Video over IP transmission, the recent activities of the Hollywood-based ETC's Interoperable Mastering Format (IMF) which has recently moved into the SMPTE, and the AMWA/EBU Task Force on the Framework for Interoperable Media Services (FIMS) concentrating on service oriented media workflows. — The author posits that we are at a watershed moment in the industry, which will create new opportunities, and even perhaps new media businesses that do not exist today.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "MXF",
                      "AS-02",
                      "AS-03",
                      "Application Specifications",
                      "IMF",
                      "Interoperable Mastering Format",
                      "FIMS",
                      "Framework for Interoperable Media Services",
                      "SMPTE 2022"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001052"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "2010 Survey of Digital Storage in Professional Media and Entertainment",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas M. Coughlin"
                  ],
                  "abstract": "Results from an on-line survey of SMPTE professionals in November and December, 2010 showed some trends for the use of digital storage in professional content capture, editing and post production, content delivery as well as archiving and digital preservation. The survey revealed the evolution of storage technology for professional video including the continued growth of flash memory in content capture, developing trends for content distribution and the growing use of “warm” disk-based archives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001066"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "The Landscape of Media Application Deployment",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Al Kovalick"
                  ],
                  "abstract": "User software applications (apps) are the lifeblood of a media professional: creating, capturing, scheduling, logging, searching, editing, reviewing, managing, publishing, and more. The common desktop installable program (.exe) is being eclipsed by new methods of application deployment. Web methods, virtualization techniques, and cloud computing are enabling new ways to develop and deploy applications with outstanding value for end users and administrators. Of special importance are advantages gained in the areas of performance, simplicity, access patterns, software distribution, upgrades, and configuration management. This paper will survey the landscape of software application methods including Rich Internet Applications using browsers or sandboxed app players, hosted desktop virtualization, application streaming, and native apps for tablets/phones",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Software applications",
                      "media apps",
                      "deployment",
                      "RIA",
                      "web apps",
                      "sandboxed apps",
                      "virtualization",
                      "VDI",
                      "hosted virtual desktop",
                      "desktop streaming",
                      "AJAX",
                      "HTML5"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001054"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Disparate Monitor Technologies and How to Calibrate Them",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Mandle"
                  ],
                  "abstract": "With the advent of so many new display technologies, it is often difficult to develop a process where two monitors may match. Understanding how the technology works, the design of the signal pat, differences in signal characteristics, and the reason for discrepancies when using probes are all part of getting the intended results. This paper talks about the technologies as they relate to alignment and considerations how to implement the best procedure.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Monitor Calibration",
                      "Monitor Alignment",
                      "Matching a CRT",
                      "BVM",
                      "CRT",
                      "Plasma",
                      "OLED",
                      "LCD",
                      "ISO",
                      "SMPTE",
                      "EBU",
                      "ITU",
                      "ARIB"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001060"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "UMID Applications in Practices",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yoshiaki Shibata",
                    "Jim Wilkinson"
                  ],
                  "abstract": "UMID is a SMPTE standard identifier that globally uniquely identifies an AV material. Because it is a core component of MXF and AAF, it has been also handled by the products claiming the MXF/AAF support. However, its originally intended use as a globally unique identifier to link AV material to its metadata has been seldom seen in practice. — This paper aims to achieve its original intention by introducing the concept “UMID Managed Domain” where all AV materials are fully managed via their UMIDs, resulting in any AV material to be unambiguously retrieved by its UMID. — Another important aspect of the UMID Managed Domain is that the domains from various products can be merged to produce a wider domain covering the entire system. To achieve this, however, the UMID resolution protocol spoken among those products needs to be standardized, for which a couple of basic proposals are presented for further discussions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UMID",
                      "Material Number",
                      "Instance Number",
                      "UMID Application Principles",
                      "UMID Managed Domain",
                      "MXF",
                      "AAF",
                      "Material Package UID",
                      "File Package UID",
                      "UMID Resolution Protocol"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001064"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Plasma Advancements as Evaluation-Grade Monitors",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James D. Noecker"
                  ],
                  "abstract": "Several fixed-pixel display technologies have been proposed to replace cathode ray tubes (CRTs) for reference monitor applications. To date, most fixed-pixel broadcast and production monitors have relied on liquid-crystal displays, but there are several limitations to LCD image quality that are challenging and expensive to overcome. A more practical alternative is the plasma display panel, which has proven to be a strong candidate for reference displays. As an emissive technology, it has wide viewing angles, high contrast, deep black levels, and excellent color saturation. It is also very affordable in large sizes and offers greater life spans than other leading reference monitor replacements, which is of great interest in today's challenging economic climate. This paper will detail the performance tests and calibrations performed on three generations of industrial plasma monitors that eventually led to the first commercial 42-inch and 50-inch reference plasma displays.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Plasma",
                      "plasma reference monitor",
                      "plasma evaluation monitor",
                      "emissive",
                      "transmissive",
                      "LCD",
                      "LED",
                      "OLED"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001056"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "File Based Workflows: Managing the Unmanageable",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John King"
                  ],
                  "abstract": "One of the largest obstacles in migrating a facility to an all file-based workflow is understanding the nature of all of the various content sources and how they will be ingested, edited and managed throughout the workflow. Facilities must take into account wide variations in the formats of file-based sources available from field cameras, national news providers and web-based sources as well as archives. In addition to the file-based sources there will always be real time content from microwave, satellite and tape-based archive material that must be encoded and placed into the workflow. In the past these various formats and real time sources were normalized by a check-in, dub-in or transcode process that added time to the process. With the advancement and adoption of standards-based content types, along with increased capabilities of commercially available non-linear editors, there are new and more efficient ways of addressing the challenges.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "file-based workflow",
                      "content sources",
                      "ingest",
                      "editing",
                      "file-based sources",
                      "web-based sources",
                      "tape-based archives",
                      "archiving",
                      "non-linear editors",
                      "standards-based content"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001059"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "A 200-Inch 3D-Glasses-Free High-Definition Projection Display",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shoichiro Iwasawa",
                    "Masahiro Kawakita",
                    "Sumio Yano",
                    "Masahisa Sakai",
                    "Yasuyuki Haino",
                    "Masahito Sato",
                    "Naomi Inoue"
                  ],
                  "abstract": "This presentation unveils the world's largest and highest-resolution 200-inch high-definition automultiscopic display. Even with the current 3D glasses methodology, some inapplicable fields remain, such as 3D advertisements and public viewing events. — Furthermore, conventional automultiscopic displays usually suffer from small screens, poor image quality, and flipping artifacts. A purpose-built rear-projection screen, featuring a unique anisotropic diffuser and a large condenser lens, and a projector array, consisting of densely aligned projectors with customized RGB LEDs, were developed as prototypes for a 200-inch screen display system. Every projected parallax image has true high-definition image quality, 57 viewpoints, and 23-mm viewpoint intervals: less than half the interocular distance. — Such life-sized objects as humans and cars can be rendered in the prototype's 16:9, 200-inch large screen display. The prototype display performs with dense and fluid horizontal motion parallax, and limited flipping appears in the observed images.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "autostereoscopy",
                      "multiview"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001062"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "‘The Set-Top-Box: A New Rendering Platform?",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mary-Luc Champel"
                  ],
                  "abstract": "Looking at the last 10 years of content production, it is clear that 3D Computer Generated Imagery (CGI) has drastically raised the bar for the quality of images we see on both TV screens and movie theatres. While originally 3D CGI became popular for animation movies, it is used today in many different kinds of movies to perform special effects. At the same time 3D CGI was used more and more frequently in live broadcast where it was mixed with real content so as to offer new experiences to the viewer: virtual studios, 3D panels with information or statistics during sport events, virtual avatars in TV shows are just examples of 3D CGI applications that are even considered as common today. — Thanks to OpenGL ES (OpenGL for Embedded Systems) which is a royalty-free cross-platform API for 2D and 3D graphics on embedded systems, new opportunities for 3D CGI applications will become possible directly on the Set-Top-Box itself. OpenGL ES 2.0 enables full programmable 3D graphics and is now available on several systems-on-chip around which Set-Top-Boxes will be built. The move has begun. — This paper aims at investigating various 3D CGI applications that will soon become a reality on Set-Top-Boxes or Home Gateways. Whether it is for 3D stereoscopic or traditional content, we will soon see new ways of enhancing, presenting or even interacting with such content thanks to the use of Graphical Processing Units (GPU) directly in the home device.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Graphical Processing Units (GPU)",
                      "Computer Graphics Imaging (CGI)",
                      "Set-Top-Box (STB)",
                      "3D",
                      "User Interface",
                      "embedded platform"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001080"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Mobile Devices — The Next Wave of 3D Display",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul D. Panabaker",
                    "Simon Sungho Cho"
                  ],
                  "abstract": "The deployment of stereoscopic 3D digital cinema has been followed closely by 3D televisions for the home. The next 3D display type expected to become widely available are autostereoscopic mobile phones and tablet devices that provide 3D viewing without glasses. This presentation explains how these autostereoscopic devices work and describes the display factors that provide for a high quality glasses free 3D viewing experience. — Specific content preparation and processing is required in order to adapt film and television content to meet the unique requirements of these autostereoscopic displays. Distribution through wireless and broadcast methods is presenting the industry with new standards and formatting issues to be solved as these 3D devices enter the consumer marketplace. Considerations and progress in mobile device 3D content preparation and distribution will be addressed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Autostereoscopic",
                      "3D"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001055"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "1080p50/60 & Beyond: Network Architectures for Wideband Video Transport",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Watford"
                  ],
                  "abstract": "The combination of traffic engineered Carrier Ethernet (e.g. IEEE 802.1ad / 802.1Qay) and 40G/100G Optical Transport Networks (OTN per ITU-T G.709) presents the underpinnings for a converged packet/optical network architecture with the flexibility to support existing SD/HD demands and the scalability to support 3G-SDI (2Kx1080p50/60), 4K and beyond in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Uncompressed HD video",
                      "HD-SDI",
                      "3G-SDI",
                      "2K",
                      "4K",
                      "UHDTV",
                      "Carrier Ethernet",
                      "POTS",
                      "OTN"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001070"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Media Hash List (MHL) Format Improving Data Integrity in Digital Cinematography",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Patrick Renner",
                    "Gregor Baumert",
                    "Michael Hackl",
                    "Jan Frohlich",
                    "Sabine Wax",
                    "Peter Hinterseer",
                    "Andreas Minuth",
                    "Alexander Sahm"
                  ],
                  "abstract": "In Digital Cinematography complete and correct backup of source media is one of the essential activities of the file-based workflow. In order to verify the completeness and correctness of a backup at any time, this paper proposes a XML-based Media Hash List (MHL) format - containing all the necessary information needed to detect possible errors during file copy and transfer. Such errors include aborted copies, bit errors, or changes in selection and contents of a backup. — A MHL file contains a list of files, cryptographic hashes for file verification, and digital signatures for data integrity of the MHL and the media files. An additional, optional section for documentation purposes is specified as well. — For a well-documented data workflow with improved integrity and simplified interchange of media files the MHL format is intended to be implemented by software for backup and media management as well as by file-based cameras and recorders.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital cinematography",
                      "cryptographic hashes",
                      "XML signature",
                      "data management",
                      "backup",
                      "information management",
                      "trust",
                      "data integrity",
                      "file-based workflow",
                      "proposal"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001065"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Mastering the Integrity of Technical Information in Tapeless Production and Long-Term Archives",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Benoit Fevrier",
                    "Valerie Popie",
                    "Ludovic Dupont"
                  ],
                  "abstract": "The main challenge for IT teams is to ensure that the media created today will not become obsolete tomorrow. Standards must remain high while, at the same time, all types of information must continue to be accessible. In workflow architecture, key decisions revolve around choosing the right audio/video codecs to guarantee maximum interoperability. However, although various layers such as VANC, VBI, SMPTE 328M and VAUX contain strategic data (timecodes, multi-channel audio descriptions, CC, aspect ratio…), they are not sufficiently taken into account in operation processes. — This valuable information often comes embedded in the input source video stream and must be directed towards the MXF essences to ensure a genuine integrity of metadata in a multi-layered bark. This document provides practical case studies on codec selection, timecode and subtitle carriage, as well as the number of audio channels, including those encoded in Dolby-E.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001067"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Theoretical and Practical Limits to Wide Color Gamut Imaging in Objects, Reproducers, and Cameras",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wayne E. Bretl"
                  ],
                  "abstract": "Available color gamut in imaging systems is discussed. Both theoretical and practical gamuts of object colors, color reproducers, and, in particular, cameras are presented. The practicalities of extended color gamut for both film and electronic capture are explored by study of a regular series of object spectra varying in both center wavelength and bandwidth.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital cinema",
                      "wide gamut capture",
                      "color cameras",
                      "color reproduction"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001074"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Dealing with Consumer Display Interfaces in a Professional World",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "For years, advances in professional video displays trickled down into the world of consumer electronics. That's all changed now, as advances in display technology now ‘trickle up’ to professional lines from the consumer world. One such feature is the High Definition Multimedia Interface, or HDMI. This copy-protected video/audio/data interface, originally intended to connect TVs to Blu-ray players and set-top boxes, is now standard on cameras, monitors, and other professional equipment and has created a myriad of switching and distribution headaches. Other display interfaces, such as DisplayPort, are now evolving into ‘multifunction’ ports that carry video, audio, data, Ethernet, serial device control, and even high speed serial data. Alternately, all of these functions are being combined with HDMI into structured wire interfaces (HDBaseT).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001061"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "An Improvement to Media Discovery Service Using Image Identification Technique",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yen Chieh Fu",
                    "Lan Yang"
                  ],
                  "abstract": "The media discovery service is an important element in managing and discovering media objects based on the metadata in Digital Object Architecture. However, types of metadata used today often lack some of the basic requirements for compatibility, such as standard definitions and unique identification. The media discovery service searches for media objects based on the metadata information. Therefore, it is not able to discover those media data with incomplete or missing metadata information. — In this research we propose to the media discovery service for identifying images with missing or incomplete metadata information. The image identification technique by integrating the image identification technique into the service will find the information of identical images from databases when the service discovers any media object without complete metadata information. In the image identification technique the SURF (Speeded Up Robust Features) algorithm is used to extract the interest points and feature descriptions for image comparison and then produce the similarity. In this way the media discovery service may recognize an image without metadata information associated with it. In general, the media discovery service treats two identical images with different metadata as two distinct files. In the improved media discovery service we verify the metadata first before the system registers the homological data into the storage system. This improvement adds to the media discovery service the ability to search for unknown media objects and the advantage to save storage space from avoiding the homological media objects registered into it. Thus, it makes the media discovery service more powerful and more space efficient.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Media discovery service",
                      "reverse image search",
                      "image processing",
                      "surf",
                      "image identification",
                      "image metadata",
                      "image database"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001068"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Physiological and Psycho-Acoustic Basis for Multi-Resolution Frequency Response Analysis",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roger Schwenke",
                    "Brian Long"
                  ],
                  "abstract": "Perceived pitch is proportional to the percentage change in frequency, not the absolute change. The perceived loudness of a tone is proportional to its duration, until a saturation time is reached. The higher the frequency, the shorter the duration needed to achieve saturation. These perceptions can be correlated with measurements of nerve impulses from the auditory hair cells. — This paper reviews the physiological and psycho-acoustic factors that influence the choice of analysis time and bandwidth for cinema sound system measurements. — In order to have a high resolution in frequency, one must use a long analysis time. In order to have a high resolution in time, one must analyze a wide frequency bandwidth. To measure perceptually relevant phenomena, a multi-resolution approach is needed. At low frequencies, constant fractional bandwidth and longer loudness integration time means a high resolution in frequency and long analysis time is appropriate. At high frequencies, constant fractional bandwidth and shorter loudness integration time means a lower frequency resolution and shorter analysis time is appropriate.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Audio",
                      "Frequency Response",
                      "Time Frequency Analysis",
                      "Physiological Acoustics",
                      "Psycho-Acoustics",
                      "B-Chain",
                      "Sound System",
                      "Loudspeaker",
                      "Microphone",
                      "Measurement"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001072"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Editing and Managing Multi-Channel Video — A Light Field Approach",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shailendra Mathur",
                    "Stephen McNeill"
                  ],
                  "abstract": "A strong trend in the media industry is acquisition of higher data resolutions and broader ranges in color, spatial and temporal domains. The data can be in the form of multiple views over these domains. Media may be captured from multiple devices, a single device with high resolution/range capabilities or, a synthetic source such as a CGI scene. Video productions are evolving from working with one view at a time to capturing as much information as possible i.e., “super-sample the world!” and extracting only the views needed for mastering. The role of traditional story telling tools becomes challenging. Well known editorial and data management techniques have to be applied to multiple media samples of the same scene for different ranges and resolutions in the temporal, color and spatial domains. This paper presents concepts from the area of Light Fields to propose an editorial and data management system to work with these multi-view sources. A proposed data model and run-time system shows how media from various views can be grouped in a way that they appear as a single light field source to the editing and data management functions. By defining the interrelationship between the multiple sources with metadata and output view requirements, transformations can be applied on various input view samples to create novel output views of the scene. The use of range information is shown to be important as it extends common editing and data management techniques to the multi-view case.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Multi-channel editing",
                      "data management",
                      "light field",
                      "multi-view",
                      "output context",
                      "spatial",
                      "temporal",
                      "color",
                      "high dynamic range",
                      "resolutions",
                      "range",
                      "reference coordinate",
                      "synchronization",
                      "registration",
                      "alignment",
                      "relational meta-data",
                      "consolidate",
                      "transcode",
                      "optimized delete",
                      "log",
                      "stereo",
                      "3D",
                      "S3D",
                      "multi-channel video",
                      "quality matching",
                      "group ID",
                      "channel ID"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001073"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Leveraging Video Services Management to Enhance Video Transport",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jan Helgesen"
                  ],
                  "abstract": "The nature of video and audio transport for contribution is changing as users are demanding more flexibility and efficient use of wide-area network resources. We are moving from the static, point-to-point reality of the past to a highly dynamic world where set up and tear down of contribution services on demand is required to meet contribution needs that can change within minutes. A new approach is required to deliver managed video and audio services across fiber, SDH/SONET or IP networks for this new reality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001069"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "New Imaging, Storage and Workflow Technologies for 4K Digital Cinematography Applications",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hugo Gaggioni",
                    "Yasuhiko Mikami",
                    "Kazuo Endo",
                    "Satoshi Kanemura",
                    "Peter Crithary"
                  ],
                  "abstract": "This presentation details several new technologies to support 4K acquisition as it becomes the norm in high-end cinema production applications. Technical details will be given on a novel 8K camera sensor, a high-speed digital memory architecture with associated storage and processing devices, a very high-quality compression codec and a RAW file-based Digital Intermediate workflow for motion picture and episodic TV productions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001076"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Digital Workflow Efficiency",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Murphy"
                  ],
                  "abstract": "In today's evolving market, the consumer is watching programming on countless consumer devices. As a content creator, distributor and local broadcaster, how do you deliver programming to all of these new consumer devices? More importantly, how do you deliver content while adding little operational overhead cost to your organization? Fortunately, the new world of tapeless workflows combined with a sophisticated layer of media asset management, the user now has access to tools that create a streamlined factory line approach to the creation and distribution of these packages. Our belief is to push the manual operational or highly repetitive tasks as far upstream in a workflow as possible, and then use the metadata to automate downstream processes, such as automated transcodes for an operator's multiple delivery formats.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "workflow",
                      "file based",
                      "Media Asset Management"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001063"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Development of Binaural Headphone Processor for 22.2 Multichannel Sound",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kentaro Matsui",
                    "Yasushige Nakayama",
                    "Kimio Hamasaki"
                  ],
                  "abstract": "A 22.2 multichannel sound system for an ultra-high definition TV is being developed. The system consists of three layers of loudspeakers and provides three-dimensional spatial sound. At program productions outside the studio, especially those performed in outdoor broadcasting vans, it is difficult to place loudspeakers for all channels. Consequently a feasible monitoring system for the 22.2 multichannel sound is required. — To meet this requirement, a headphone processor for monitoring multichannel sound productions was developed. It can be used with ordinary headphones and reconstruct the three-dimensional spatial sound by processing the audio signal in each channel of 22.2 multichannel sound with the help of head-related impulse responses (HRIRs). A key feature of the processor is its adjustability to individual variations in HRIRs. Sound engineers can modify measured their own HRIRs to fit their sensation of hearing. Together with this “binauralization,” it also has the function of generating reflections and reverberation to simulate artificial environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "22.2 multichannel sound",
                      "HRIR",
                      "binaural processing",
                      "individual variation",
                      "reverberation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001077"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Optimum Image Codec and Digital Enhancement Techniques for VDSLR-Based Filmmaking",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Younghoon Lim",
                    "Chulhyun Kim",
                    "Jaehyun im",
                    "Jaehwan Jeon",
                    "Joonki Paik"
                  ],
                  "abstract": "Digital filmmaking allows extended variations in every stage, such as development, pre-production, production, post-production, and distribution. Because of the advanced editing tools and devices, it becomes easy to make high quality movies at low cost. Recently, as video-capable digital single lens reflected (VDSLR) cameras are widespread, many people are interested in filmmaking using VDSLR cameras. However, digital filmmaking using VDSLR cameras exhibits two fundamental problems in shooting and editing stages. This paper deals with the use of a VDSLR camera in the production stage and digital enhancement algorithms in the post-production stage for compensating distortions made by the DSLR camera. More specifically, we will provide an optimum use of video codec by analyzing two different editing approaches with and without image compression. We also present digital image restoration algorithms for compensating jello and aliasing artifacts of DSLR video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VDSLR",
                      "Post Production",
                      "Optimum Image Codec",
                      "Digital Enhancement Techniques"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001075"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Direct Display of Integer ACES Content for Post-Production Environments",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jon S. Mcelvain",
                    "David Ruhoff",
                    "Glenn Woodruff",
                    "Walter Gish",
                    "David Schnuelle"
                  ],
                  "abstract": "The Image Interchange Framework (IIF), created by AMPAS with the goal of providing a unified post-production workflow, has seen increased interest in recent years. Central to the IIF is the RGB wide-gamut color space defined by the Academy Color Encoding Specification (ACES). For output device viewing, the ACES data must first be rendered through the Reference Rendering Transform (RRT) and the Output Device Transform (ODT). Recently a quasi-logarithmic 12 bit integer ACES encoding scheme was proposed, and we present initial results on the direct display of integer ACES content on a Dolby PRM-4200 monitor. Frames were delivered directly to the monitor across a 12 bit dual link SDI interface, and the decoding, as well as the RRT and device ODT were computed via 1D and 3D LUTs resident on the monitor. Several different LUT designs were considered, and the limitations of each including failure modes will be discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Image Interchange Framework",
                      "Academy Color Encoding Specification",
                      "ACES",
                      "Integer ACES"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001089"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "A Broadcasting Schedule Scheme for Both 2D and 3D Video on Demand",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yan Xu"
                  ],
                  "abstract": "A multicast scheduling scheme is proposed for 3D VoD (Video on Demand) service, with the objective of lessening the bandwidth requirement and minimizing the startup delay of 3D video. The format of 3D video adopts 2D plus metadata. A heuristic scheduling scheme is applied. First, determine the minimum startup delay through a first scheduling try; then rearrange the schedule in order to guarantee the maximum data sharing. The scheme consists of 3 main steps: initial schedule, minimum startup delay determination based on bandwidth detection, and schedule rearrangement. The emphasis is put on the bandwidth detection and rearrangement. This scheme can also be applied to a platform providing both 2D and 3D VoD. — Experiment has been made with assumption of requests' arrival being Poisson process and regular arrival. Some factors' effect on the startup delay is also investigated. These factors include arrival interval, bandwidth limit, and the ratio of 2D user to 3D user. Results show the average startup delay decreases greatly with bandwidth limit increasing and keeps a slight variation as arrival interval varies; the average delay of only 3D users existing is usually less than that of 3D users and 2D users coexisting. When the requests arrives regularly, our multicast scheme degenerates to a broadcast scheme. Results show that average startup delay using our scheme is close to the delay bound of a broadcast scheme under the same bandwidth.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Scheduling",
                      "3D Video",
                      "Streaming",
                      "Multicast"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001092"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "Active Pulfrich Spectacles",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth Jacobs",
                    "Ronald Karpf"
                  ],
                  "abstract": "While many Pulfrich 3-D movies have been produced, the movie and TV industries have correctly concluded that 3-D viewing with passive Pulfrich spectacles imposes such severe limitations that it is not a suitable 3-D technique. Active Pulfrich Spectacles (APS) is a new implementation of Pulfrich 3-D that addresses these limitations. APS allows every scene with motion in any 2-D movie to be viewed in 3-D. — APS works on a different principle than other methods for 3-D. 3-D movies typically use the asymmetry of dual images to produce stereopsis. In contrast, APS is a single image system. All APS requires to view any 2-D movies in depth is an illumination asymmetry — a controlled difference in optical density between the lenses. — APS uses microprocessor controlled optoelectronic lenses. APS only needs the motion vectors already calculated during digital image-processing of the video to calculate the correct adjustment to the lens optical density so that the viewing spectacles always produce realistic 3-D. — APS is an intermittent 3-D enhancement to 2-D viewing. Only those scenes that can be converted are shown to the viewer in 3-D. All other scenes appear in 2-D. A viewer can put on APS for intermittent 3-D viewing, or remove them and continue viewing in 2-D. — APS has substantial benefits to the motion picture and television industries. APS displays 2-D movies in 3-D without change to the video architecture and infrastructure. This is achieved without additional production or exhibition cost and no requirement for 3-D cameras, 3-D digital formats, or 3-D projectors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Active Pulfrich Spectacles",
                      "optoelectronics",
                      "Pulfrich effect"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001094"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Development of Super Hi-Vision Eight-Channel Live Switcher: For Production of a Variety of Ultra-High-Definition Video Content",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kentaro Higashijima",
                    "Kazuyuki Arai",
                    "Daisuke Ito",
                    "Mayumi Abe",
                    "Toshiya Kikkawa",
                    "Hayato Fujinuma",
                    "Koji Nishida",
                    "Koji Mitani",
                    "Yuichi Watanabe",
                    "Hideki Kouno",
                    "Yoshihito Saito"
                  ],
                  "abstract": "The authors will present the development of a new live switcher for Super Hi-Vision (SHV, 7680 × 4320-pixel video with 60 fps), which delivers a realistic viewing experience through live broadcasting with multiple SHV cameras and a live slow-motion system. — This equipment has eight SHV inputs and four SHV outputs, capability to output down-converted 4K and HD images for monitoring, wipe/mix, superimposition, and digital video effects. A new signal processing device which divides an SHV image into 16 HD-sized partial images by pixels and simultaneously composites these images to achieve real time SHV video effects was developed. With this equipment, real-time, sophisticated composition of high-resolution large-screen video is possible. This is useful, not only for SHV live events, but also for program production, and it can reduce time and costs for post-production. These developments open up a new world of high-resolution, large-screen video effects.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Super Hi-Vision",
                      "real time SHV video effects",
                      "SHV live events",
                      "high-resolution large-screen video effects"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001079"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Service Oriented Architecture & Cloud Computing in Media Industry",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Footen"
                  ],
                  "abstract": "This paper will introduce the core concepts associated with the modern integration of the software systems used in media facilities. The principles of Service-Oriented Architecture (SOA) and associated technologies will be described in an introductory and accessible form. This session will also provide a tutorial on the basics of cloud technology. Public and Private clouds, SaaS, PaaS, BPaaS, and other related topics will be covered. Advantages and disadvantages in taking a cloud based approach will be examined. The application of these technologies in the Media industry will be interlaced throughout the presentation. It is intended that this presentation would provide the introduction to a session of papers around the Cloud and SOA.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Service Oriented Architecture",
                      "Cloud Services",
                      "Business Process Management",
                      "Enterprise Service Bus",
                      "Service",
                      "SaaS",
                      "PaaS",
                      "IaaS"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001082"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Story-Centric Workflows in the Cloud",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Defreyne",
                    "Luk Overmeire",
                    "Matthias De Geyter",
                    "Rik Van de Walle",
                    "Wim Van Lancker"
                  ],
                  "abstract": "After the transition to file-based workflows broadcasters and production companies are facing new technological challenges. New business opportunities encourage programme makers to tell their stories on multiple distribution platforms, but typically lack tools and platforms to do so efficiently. Furthermore, production platforms should embrace the flexibility offered by consumerization and cloud paradigms. VRT-medialab proposes a cloud hosted autonomous media production platform (CHAMP) that brings innovative production workflows to the cloud. CHAMP is a technology platform on which software and media infrastructure can be offered as a service. For programme makers the platform provides fit-for-purpose cloud webapps to collaborate on a multi-platform story, using consumer devices such as the tablet. In this paper a set of innovative platform webapps are discussed that support a real-life documentary use case. To provide interoperability a flexible story-centric data model is defined. Also public and private cloud concepts are applied to enable high resolution workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "story",
                      "cloud",
                      "transmedia",
                      "consumerization",
                      "collaboration",
                      "production",
                      "multi-platform"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001083"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Potential LTFS Enhancements and the Relationships between LTFS and other Media Types",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Zents"
                  ],
                  "abstract": "This paper will demonstrate how LTFS could be enhanced if tape media had more than two partitions. Multi-level partitioning would improve access time as different metadata partitions could be placed close to the beginning of the tape. In addition, because media utilizing LTFS is designed to be removable, it needs CRC checking to ensure data integrity as it moves across storage landscapes, regardless of whether the movement is during importing and exporting or as content is archived. Checking should occur in-line with ANSI standards. Finally, the paper briefly describe potential relationship(s) between LTFS, and AXF.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "LTFS",
                      "tape",
                      "storage",
                      "AXF",
                      "partitions",
                      "partitioning",
                      "CRC-check",
                      "LTO",
                      "T10000C",
                      "ANSI X3.139"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001053"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "3Gb/s SDI for Transport of 3D, 4k and Beyond",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nigel Seth-Smith"
                  ],
                  "abstract": "The latest generation of the Serial Digital Interface, 3Gb/s SDI, or 3G, has been in use in the broadcast industry for 5 years. But what exactly is 3G SDI? The basic data rate is capable of carrying many different video and audio formats, so we need additional metadata to achieve interoperability. SMPTE has standards to describe the different formats, and the EBU has produced a Technical Report to help its members on this subject. — For higher data rates, multiple 3G SDI links can be combined, and SMPTE is standardising the transport of formats up to 4K, using 2 or 4 links to provide up to 11.88Gb/s. — This paper describes 3G SDI systems, including the different formats available and how they are flagged for identification. The paper includes updates on SMPTE standardisation work and the EBU technical report. — It also informs the system designer on the reliable use of 3Gb/s SDI, including optimum selection of coax copper cable vs optical fiber.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SDI",
                      "Serial Digital Interface",
                      "3Gb/s",
                      "3Gbits/s",
                      "EBU",
                      "3D",
                      "2k",
                      "4k",
                      "SMPTE standards",
                      "Level A",
                      "Level B",
                      "cable reach"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001071"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Mobile TV Services in Sports Arenas — A New Business Model for New Mobile TV Services",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gustavo Marra"
                  ],
                  "abstract": "Driven by the newest digital terrestrial television standards deployed all around the world like ATSC-MH, DVB-T2, DMB and ISDB -Tb, mobile TV is one of the hottest topics in the broadcast industry nowadays. But while engineers and content producers demonstrates a great excitement regarding mobile TV, a new and creative business model is not emerging at the same speed as the service is being offered. — This paper suggests a new business model to explore the power of mobile TV, focusing a targeted audience, based on broadcasting live sport events inside stadiums or arenas where the event is happening, targeting the audience present in the venue, taking advantage of the existing digital terrestrial television standards available nowadays in combination with wireless broadband networks. — It will be presented the technical approach of the suggested model and the cross-media opportunity to broadcast valuable content to a known audience with a common interest.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Mobile TV",
                      "Mobile Broadcasting",
                      "Multi-screen",
                      "Cross-Media",
                      "Digital Terrestrial Television",
                      "ATSC-MH",
                      "DVB-T2",
                      "DMB",
                      "ISDB-T",
                      "ISDB-Tb",
                      "1-SEG"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001084"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Contrasting Software Systems Integration Strategies for Large Scale Media Architectures",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Hinton",
                    "Dan Shockley",
                    "Michael Koetter"
                  ],
                  "abstract": "The prevailing method for media systems integration is trending towards orchestration of a number of loosely coupled services via process automation frameworks. And who can blame anyone for wanting to avoid point to point integrations that are difficult to re-purpose, costly to maintain & lacking flexibility as business needs change? Yet, as the key ingredients for these loosely coupled “orchestration” frameworks have evolved, so have the web-driven frameworks to support lightweight “choreographed” interactions between networked service endpoints. — This paper compares and contrasts these strategies. We explore techniques for bridging heterogeneous integration techniques, ultimately arguing that a hybrid model provides the optimal mix of flexibility, performance, reliability, rapid integration & maintainability.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001086"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Divergence: Where Broadcast and Streaming Headends Differ",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ian Trow"
                  ],
                  "abstract": "With the development of video compression headends catering to broadcast, mobile and web, care is needed to architect solutions that play to the strengths of the distribution media. Traditional linear broadcasting over satellite, terrestrial and cable utilises bandwidth which is both constant and guaranteed. Mobile and web based platforms rely on networks which cannot offer the same service guarantees. Consequently streaming techniques have been developed to overcome the limitations of a network where packet loss is common and latency variable. — With the recent advances in algorithms, processing and memory density, a source can be encoded in one pass for the various bit-rates required for both broadcast and streaming applications. The prospects for multi-stream and profile handling will be explained in the context of combined broadcast, mobile and web headends. The advent of such a highly integrated headend has appeal to broadcasters keen to adopt a more streamlined workflow than the current separation of compression solutions addressing broadcast, mobile and web needs. — Producing a range of compressed profiles is only part of the solution when it comes to streaming. Adaptation of these streams to the needs of the client devices will be a significant aspect of future headends. A number of rival streaming technologies now exist which utilise the Internet's basic HTTP protocol. Adopting such a web friendly approached has enhanced the performance of video in a web environment, but little is understood on how this approach can be scaled for large channel bouquets. It is also quite likely that rival streaming technologies will have to co-exist in a headend if adequate coverage of client devices is to be achieved. The different streaming approaches will be explained and contrasted to demonstrate how multiple profiles can be handled for a wide range of channels on client devices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001081"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Advanced Workflows through Metadata Capture and Immediate Content Availability",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Trepess",
                    "Russell Stanley",
                    "Kevin Whiting",
                    "Kazuo Endo"
                  ],
                  "abstract": "This paper introduces technology that allows for existing and newly-created metadata to be assigned to content as it is captured resulting in enhanced workflows with minimal impact on existing operations. Content becomes more accessible to people working on the production, using a local network that links cameras, laptops and mobile devices. This is achieved by providing role-specific web applications for navigating content using the metadata that has been assigned to it. The result is improved access to content during production and more efficient post production. — This technology has been developed following comprehensive studies of broadcasters' operational workflows. This includes an understanding of the activities of production staff and areas where the use of metadata technology can enhance file-based workflows. Results and feedback from initial trials of this technology with production companies are described in the paper and we demonstrate that significant time savings can be achieved.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Metadata",
                      "file-based workflows",
                      "human factors. contextual inquiry",
                      "(The SMPTE disclaimer is on a footer on this page and will show in Print Preview or Page Layout view"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001085"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Smooth Asset Workflows, Bigfoot, and UFOs",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "We all have a nagging feeling all three could exist. Many would like to believe they could be real. All we need is some proof. Hard evidence. Something that could tangibly demonstrate that their existence is at least possible.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001087"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "“Super Hi-Vision” Video Parameters for Next-Generation Television",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takayuki Yamashita",
                    "Ken'Ichiro Masaoka",
                    "Kohei Ohmura",
                    "Masaki Emoto",
                    "Yukihiro Nishida",
                    "Masayuki Sugawara"
                  ],
                  "abstract": "The crux of the move to UHDTV is to simply deliver a wider field of view, which only requires an increase in pixel count to 3840 × 2160 or 7680 × 4320 pixels, which are well accepted standards. However, this overlooks important factors such as color/tone rendition and motion portrayal, which could be crucial to delivering an enhanced visual experience with next-generation television (next-gen TV) systems. To this end, we propose system parameters including colorimetry and frame frequency for next-gen TV. The proposed colorimetry system is based on the real RGB color system and has a color gamut covering 99.9% of real surface colors while using physically realizable RGB primaries. Further, a frame frequency of 120 Hz is proposed on the basis of subjective assessments of motion picture quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "UHDTV",
                      "system parameters",
                      "colorimetry",
                      "high frame rate",
                      "specification",
                      "Super Hi-Vision"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001078"
                  }
                }
              },
              {
                "article_local_id": "52",
                "article_title": "Video Scaling — Time to Banish Bilinear!",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/52/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward Callway"
                  ],
                  "abstract": "Video is always being scaled and resampled, whether to change its size or as part of a more complex algorithm such as frame rate conversion. — Linear interpolation, and its 2D equivalent bilinear, are used extensively because they are easy to understand and implement. But bilinear scaling never produces a satisfying image, combining a fuzzy overall look with jagged edges and motion artefacts. It is possible to show analytically why bilinear looks bad, mapping it back to well understood video parameters such as step, frequency and phase response. This information can be used to pick a visually better scaling kernel, instead of the opaque “this window function has a wider lobe”. — As image processing moves to GPUs that include a tempting free bilinear scale in the texture fetch pipeline, it is important to ensure it is not used for video, and to show better alternatives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Scaling",
                      "resampling",
                      "bilinear",
                      "polyphase",
                      "GPU",
                      "texture fetch",
                      "OpenCL"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001103"
                  }
                }
              },
              {
                "article_local_id": "53",
                "article_title": "Direct to GPU Video Transfers",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/53/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas True",
                    "Ashley Reid",
                    "James Jones"
                  ],
                  "abstract": "Modern graphics processing units (GPUs) are high-performance parallel floating point processors ideal for the image and video processing operations required for broadcast and digital film applications. Historically, image data transfer to the GPU required that the data pass through a staging buffer prior to upload to or download from the GPU as the buffers utilized by the video I/O device could not be used directly by the GPU. This memory copy operation created a performance bottleneck. Direct to GPU Video Transfer enables the sharing of a lockable system memory buffer between a video I/O device and the GPU eliminating the latency incurred by the memory copy. Results demonstrate transfer times for SD, HD, 2K and 4K frames approaching realized PCI Express 2.0 limits. Overall system latency can be further reduced by overlapping sub-frame transfers with the video device capture and scanout.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "GPU",
                      "Video I/O"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001104"
                  }
                }
              },
              {
                "article_local_id": "54",
                "article_title": "Broadcast Convergence — Bringing Efficiency to a New Platform",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/54/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark A. Aitken"
                  ],
                  "abstract": "Television Broadcasters have entered a new competitive era. The inherent efficiency of broadcast technology's ‘one-to-many’ platform has become widely understood. Mobile Network Operators (MNOs) are exploring use of LTE Evolved Multicast Broadcast Multimedia Service (eMBMS). I will briefly explore several technologies that tie together and compliment what could become a “Next Generation Broadcast Television” (Next Gen) standard with a Physical/Mac Layer in a new topology that supports multiple broadcast services in a spectrum efficient manner. The paper's main focus will be on a new IP-centric “Broadcast Convergence Gateway” node and the interrelated infrastructure components that could enable intelligent and collaborative use of broadcast television spectrum for a wide variety of future Fixed, Portable, Mobile and converged services in the USA. The coordination needs associated with convergence of what could be a new / future Next Gen broadcast standard and 3GPP LTE-Advanced will be an example explored. This paper will convey an understanding of the ‘value added’ by such an approach to the participants (MNOs, Broadcasters and others) in a more efficient ‘shared spectrum’ capability that can be leveraged to deal with bandwidth constraints of today's wireless providers competing for spectrum. The nature of the infrastructure interconnect and shared resources will be laid-out and a new understanding of what is possible in such a combined ‘Intelligent Broadcast Overlay’ will be discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Broadcast Overlay",
                      "LTE",
                      "eMBMS",
                      "3GPP",
                      "Mobile",
                      "Convergence"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001105"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "A Grading System for the Integration of Differing Camera Technologies",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher C. Woollard"
                  ],
                  "abstract": "Managing the look from different acquisition camera technologies and grading these for a single production is a challenge. Productions may use a number of camera technologies, with different sensor characteristics (resolution, color space, latitude) and require these to be successfully cut together and graded, including of course 35mm negative. — This paper presents such a system developed with the lower budget filmmaker especially in mind. Examples such as Alexa, RED, and 35mm negative are considered along with lower cost digital camera technologies such as the 8-bit DLSR camera systems, where possible codec's are an important aspect. An important new development, IIF, is also central to this system. — Support is provided to help the Cinematographer predict what is possible with the given choices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Grading",
                      "color space",
                      "latitude",
                      "compression",
                      "education",
                      "IIF",
                      "Education"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001090"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Combined Editing and VFX Process Using Metadata for Efficient Post Production",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Younghoon Lim",
                    "Chulhyun Kim",
                    "Joonki Paik"
                  ],
                  "abstract": "Advanced imaging devices and the related production environment necessitate high-resolution image processing techniques. In this context, optimization of processing time and amount of data in the workflow attracts increasing attention in both large-scale commercial film production using 4K and stereoscopic three-dimensional (S3D) cameras and small-scale independent film production using digital single lens reflected (DSLR) cameras for full HD outputs. — Digital picture exchange (DPX), which is a common standard file format for digital intermediate (DI) and visual effects (VFX), requires greater amount of data than the original image without compression. — This paper presents an efficient method that can minimize processing time and amount of data between editing and VFX processes using metadata. The proposed method can significantly increase productivity in both large and small production studios.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Post Production",
                      "Metadata",
                      "DPX",
                      "Workflow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001088"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "High Efficiency Video Coding (HEVC) — The Next Generation Compression Technology",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matthew S. Goldman"
                  ],
                  "abstract": "High Efficiency Video Coding (HEVC) is in development and aims to revolutionize the compression world with a potential 50% bitrate saving over Advanced Video Coding (AVC, or H.264 / MPEG-4 AVC). Is history repeating itself? There was a 10 year gap between the standardization of MPEG-2 Video and AVC, with AVC eventually maturing to deliver a 50% bitrate saving over MPEG-2 Video. The ITU-T|ISO/IEC Joint Collaborative Team on Video Coding (JCT-VC) is aggressively aiming for a 2013 distribution date for the HEVC standard. Early investigations indicate there is scope for a 30–50% bitrate saving over AVC. Some may argue this is a technology without a home, but potential applications lie in IPTV over DSL where HEVC would increase service reach, or point-to-point links for newsgathering where bandwidth is at a premium. But the most applicable usages will be delivering the emerging 4Kx2K video format in the same channel capacity as HD AVC today and eventually more power-efficient coding for handheld devices. This paper explores the HEVC tool set enhancements that facilitate the compression gains over AVC, with example sequences compressed in the HM test model, and an exploration into the commercial opportunities which HEVC opens up in the television industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High Efficiency Video Coding",
                      "HEVC",
                      "H.265",
                      "next generation video coding"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001098"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Perceptual Effects When Scaling Screen Size of Stereo 3D Presentations",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jonathan R. Thorpe",
                    "Mark J. Russell"
                  ],
                  "abstract": "Stereo 3D content that is shot for the cinema may go on to be displayed on a number of different types of display device, from domestic televisions to mobile devices. Stereo 3D content is scaled appropriately for the display device, but this scaling process alters the stereo 3D properties of the scene. For instance, when scaling cinema screen content to be shown on a domestic television screen, disparities are reduced and the perceived depth of objects in the scene are affected in a nonlinear way. — This paper explores the case of displaying stereo 3D cinema content on screens of a different size, both larger and smaller. It explores in more detail the issues of showing cinema content on a domestic television which leads to non-linear scaling of depth. — Experiments are presented which show that the effects of this depth distortion are mitigated by 2D perspective cues within the 3D scene, thus limiting the perceived distortion. — The effect can be further mitigated by introducing a positive planar shift (of around 1%) which also improves comfort by keeping the depth range in the centre of the comfort zone, reducing the vergence-accommodation conflict.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Stereo 3D Display",
                      "3D Cinema",
                      "Image Scaling",
                      "Depth Distortion",
                      "Perception Experiments"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001093"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "Development of a High-Quality Low Latency Wireless HDTV Camera Using the Millimeter-Wave Band Using Bidirectional Wireless Transmission for High Operability",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shinichi Suzuki",
                    "Takayuki Nakagawa",
                    "Tetsuomi Ikeda"
                  ],
                  "abstract": "We have developed a 42-GHz wireless HDTV camera that has bi-directional wireless transmission in the main and return links. We implemented a main link using a millimeter-wave wideband and Multiple-Input Multiple-Output (MIMO) technology with two transmit and four receive antennas to transmit high quality (data rate of 320 Mbps) and low latency (less than 1 picture frame) high definition television (HDTV) video. In addition, we also implemented a return link using a millimeter-wave wideband and a Space Time Block Coding (STBC) technique with four transmit and one receive antennas to transmit return high link reliability and low delay HDTV video. We also achieved camera functions equivalent to those of cable-connected cameras, such as precise camera control, genlock and intercom communication, using the bi-directional transmission. — These performances make it possible to switch seamlessly between pictures from cable-connected cameras and this camera with the same operability as cable-connected cameras. This wireless camera has been used in several productions without any interruption while moving freely within a range of several hundred meters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Millimeter-wave",
                      "HDTV Wireless Camera",
                      "main link",
                      "bi-directional transmission",
                      "OFDM",
                      "MIMO",
                      "STBC"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001101"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "Application of DVB-S2 for DVB-T & DVB-T2 Transport",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gerard Faria",
                    "Philippe Hostiou"
                  ],
                  "abstract": "DVB-S2 is the second-generation standard for satellite broadcasting produced by the DVB project. Using state-of-the-art FEC (LDPC) for channel encoding in association with various modulations as QPSK, 8PSK, 16APSK and 32APSK, it achieves quasi-Shannon-capacity transmission performance. When compared to its predecessor DVB-S, DVB-S2 requires a reduced C/N margin for an equivalent error protection overhead and accordingly even operated using a smaller receiving antennas and a smaller transmission power, DVB-S2 performs as efficiently as DVB-S. — Beyond the intrinsic performance of its physical layer, DVB-S2 provides enhanced flexibility with regard to the organisation of the payload: with DVB-S2, several multiplex streams (MPTS) can be carried on a single transponder. This novel feature is of particular interest for the distribution of several DVB-T (or DVT-T2) multiplexes to transmitter sites using a single transponder but preserving the synchronisation required to operate terrestrial Single Frequency Networks (SFN). The DVB-S2 link, in this case, is 100% transparent to the terrestrial SFN synchronisation constraints. — For contribution and distribution networks, upgrading the satellite link to DVB-S2 is clearly the right choice to save money: whatever the number of receiving sites, the Return-On-Investment (RoI) is immediate, thanks to the DVB-S2 overall performances!",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "DVB-S",
                      "DVB-S2",
                      "DVB-T",
                      "DVB-T2",
                      "Digital Terrestrial TV",
                      "DTTV distribution"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001099"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Best Practices for Using Fiber in a Broadcast Facility",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Timothy Walker"
                  ],
                  "abstract": "This paper will highlight best practices for using fiber optics for signal distribution in broadcast facilities and production trucks. It will be relevant to engineers who are planning to install or expand fiber optics within their broadcast facility. — The accompanying presentation will review all the core elements, including transmitters, receivers, splitters, and mux/demux, and it will explain the essential differences between coax and fiber optics from a broadcast perspective. — It will also address frequently used connector types, active and passive fiber components, and sources of optical signal degradation. Additionally, the paper will explain how to calculate a power budget for fiber.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Fiber",
                      "Fiber Optics",
                      "Tutorial",
                      "Sfp",
                      "Production Trucks",
                      "Broadcast Facilities",
                      "Power Budget",
                      "Laser",
                      "CWDM",
                      "DWDM",
                      "Optical Mux",
                      "Optical Demux",
                      "Optical Transmitter",
                      "Optical Receiver"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001100"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Interactive Decoding Enabled Using a File/Folder Layered Compressed Structure",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "Compressed moving image data has heretofore taken the form of a “multiplex” in which header, image, and audio data are intermixed. Whether conveyed in files or sent in “streams”, such a multiplex does not naturally support multiple layers nor random access. A file/folder structure can alternatively be utilized wherein layers are contained in folders, and data for each frame for that layer are in files within each such folder. Using SATA or USB Flash memory there is no seek time penalty, unlike rotating disks. Computer networks and local memory access will naturally only access data needed for the layers currently being decoded. Thus, media and network bandwidth automatically matches the compressed data rates at those layers. Compressed layer files can further have index list headers so that regions of interest can be selectively accessed within moving frames using file pointer movement. The resulting file/folder compressed structure becomes an enabler for high quality random access of layered moving images, with layers all the way up to bit-exact lossless reproduction of the original image. Such high quality layered lossy and bit-exact lossless reproduction can be applied to integer pixels as well as to half-float IIF ACES pixels. The resulting coded representation is therefore suitable for movie masters, video masters, surveillance, networked remote video access, post-production servers, and many other moving-image applications that can benefit from layering and random access.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Compressed Video",
                      "Surveillance",
                      "Video Masters",
                      "Video Archive Library Access",
                      "Digital Movie Masters",
                      "Video Networking"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001097"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "AVC-I: Yet Another Intra Codec for Broadcast Contribution?",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre Larbier"
                  ],
                  "abstract": "Large availability of fiber and high-speed IP networks now enable the use of intra video codecs in a wide range of contribution application. Such formats permit low end-to-end delays and are easily editable. In addition, their reduced complexity allows a significant equipment cost reduction over Long GOP equivalents. These well-known advantages have paved the way for a variety of proprietary and standardized solutions like VC-2, VC-3 or JPEG-2K. — AVC-I is simply an MPEG-4 AVC / H.264 profile obtained by capping complexity and removing encoding tools from the standard's broadcast contribution profiles. This simple conception is the promise of a straight-forward compatibility between equipments from various vendors. But it remains to be seen, beyond academic research, if actual AVC-I products are able to meet and exceed the quality levels and the operational advantages of intra codecs currently in use.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "AVC-I",
                      "H.264",
                      "AVC",
                      "video",
                      "compression",
                      "intra"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001102"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "Matching the Human Visual System, Balancing Bit Depth, High Dynamic Range and Coding Efficiency",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt"
                  ],
                  "abstract": "The human visual system sensitivity is not linear: it requires much more detail in the low values. This phenomenon has been generally modelled by a logarithmic relation between magnitude and sensation. — This aspect of the visual sensation has always been implemented in various ways in high quality imaging systems, from the 2.2 gamma in legacy video to logarithmic coding for film scanned content and 2.6 coding for Digital Cinema. — As a result, we have multiple domains with complicated exchange, specific computations with ad hoc parameters, rounding errors and degradation arising from multiple coding decoding concatenations. — It is possible to avoid these complications and have a unified system by using “Unsigned floating point” which is a simple extension to floating point “half” format. The additional benefits are a very high dynamic range, a built-in logarithmic law and an efficient use of codes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Human Visual System",
                      "dynamic range",
                      "coding efficiency",
                      "perception",
                      "floating point",
                      "pixel format"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001096"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "The “Sense of Depth” of a Stereoscopic 3D Capture and Display System",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael A. Weissman"
                  ],
                  "abstract": "Stereoscopic 3D imaging systems try to mimic the binocular vision of our eyes. However, there are many examples of 3D photography and video where the stereo camera does not have the same separation as our eyes and the display does not show the same field of view as our normal vision. Examples include stereo microscopy and endoscopy and 3D telephoto sports photography. Unaided vision never sees scenes such as these, yet very comfortable and effective 3D images can be displayed in an electronic system. How do we compare the 3D “experience” of one camera/display configuration to another? — We all know that camera separation is an important factor for providing a stereoscopic depth effect, but so is the convergence distance of the cameras and their magnification. Other important factors are the size of the screen, the viewer's distance from the screen, and his or her eye separation. How do all these parameters work together? And, in turn, how can we use them to provide the viewer a good viewing experience? — This paper will parameterize the overall stereoscopic sense of depth as the product of a camera contribution (CDE = MC*CRC) and a display contribution (DDE = MD/CRV). (MC and MD are camera and display magnification factors and CRC and CRV are camera and viewer Convergence Ratios. “Convergence Ratio” is stereo baseline divided by convergence distance.) We will use these parameters to compare the depth effect produced by various stereo camera systems, including our unaided and aided eyesight, and we will see how the depth effect of normal vision can be used to evaluate the sense of depth produced by a pair of telescopic cameras zoomed into the quarterback in a football game!",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Stereoscopic",
                      "3D",
                      "Stereo 3D",
                      "Depth Effect",
                      "Parallax",
                      "Stereo Base",
                      "IPD",
                      "Stereo Cameras",
                      "Stereo Displays",
                      "Stereo Imaging",
                      "3D Imaging",
                      "Stereoscopic Computer Vision"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001095"
                  }
                }
              },
              {
                "article_local_id": "55",
                "article_title": "Control Systems: Conducting the Symphony",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/55/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sara Kudrle",
                    "Kieran Lyons",
                    "Charles Meyer"
                  ],
                  "abstract": "As television stations continually tighten their belts to survive amidst higher channel counts and more competition from internet and cable, the importance of lowering operating expenses while maintaining or improving workflow efficiency becomes paramount to their success. By condensing multiple functions within a router, thereby reducing power and cooling costs; operational expenses are lowered, but the complexity of the system is increased. — As routers become larger and more complex, the issue of control and the functionality of control systems becomes a greater consideration with regards to designing or upgrading a facility. Historically, a router was just a glorified patch panel and control allowed a user to operate it without having to manually move connectors. However, routers have grown both in size and functionality, moving beyond handling a few crosspoints or connections to handling thousands of crosspoints and allowing traditionally external processing to occur internally, thereby streamlining the overall workflow while reducing operational costs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Control systems",
                      "hybrid router",
                      "reduce operational costs",
                      "streamlining workflow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001106"
                  }
                }
              },
              {
                "article_local_id": "56",
                "article_title": "Remote and Mobile Monitoring of On-Air Signals for Centralcasters",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/56/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Patrick Daly",
                    "Michael Wright"
                  ],
                  "abstract": "Local television stations continue to aggressively centralize their operations in a quest to operate more efficiently and to meet financial targets. Remote monitoring of on-air signals has emerged as a primary area of importance for station group managers. This paper will explore a nationwide monitoring solution that was created to allow NBC managers in New York and Los Angeles to monitor (remote and mobile) on-air signals in their eleven flagship markets across the United States.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "master control",
                      "automation",
                      "remote",
                      "monitoring",
                      "centralcasting",
                      "centralized",
                      "local television station"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001107"
                  }
                }
              },
              {
                "article_local_id": "60",
                "article_title": "3D Point of View Videography for Sporting Activities",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/60/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mike Finegan"
                  ],
                  "abstract": "Part of the excitement of sports and adventure programming is seeing things from the point of view (POV) of an athlete or enthusiast. Accomplishing this at a Prosumer level is ad hoc. — This paper details POV stereo videography rigs leveraging OEM components as applied to short-form programming of adventure sports. Comparisons, guidelines, lessons learned and future direction are provided. The requirements for an HMCD (head mounted capture display) are presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Adventure Sports",
                      "Helmet Camera",
                      "Point of View",
                      "POV",
                      "HMD",
                      "HMCD",
                      "3D",
                      "Stereo Video"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001111"
                  }
                }
              },
              {
                "article_local_id": "57",
                "article_title": "New Video Coding Technologies and its Effects on Next Generation Plant Infrastructures",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/57/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yasser F. Syed",
                    "Chuck Wester",
                    "Paul D. Egenhofer",
                    "Austin Vrbas"
                  ],
                  "abstract": "This paper examines some of the plant changes happening today required by the introduction of new high density video transcoder solutions for broadcast service providers in the cable/satellite/telco industries. It will cover signal workflows, distribution, density, and monitoring. Video & audio codecs are briefly touched upon, but the majority of this paper deals with how new video technologies and how increased density can affect plant, network, signal, and device infrastructures. The paper will investigate the impacts from increased signal density due to adaptive streaming, and processor density resulting from improvements in CPUs, GPUs, ASICs, and DSPs as well as the changes to device rack footprint. From the distribution perspective, the paper will describe how multicast, non-baseband distribution is becoming more commonplace, which allows for addressing multiple devices at the same time. In terms of routers, it will examine management of traffic flows onto subnets with multiple source devices. Lastly, this paper will examine the effects of monitoring in this new environment without being too prohibitive.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001108"
                  }
                }
              },
              {
                "article_local_id": "59",
                "article_title": "IP-Based Monitoring within the Broadcast Environment",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/59/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Martin Jolicoeur"
                  ],
                  "abstract": "Emerging IP video infrastructures in the broadcast environment are changing the requirements for monitoring of television signals. This paper explains the latest developments in audio/video monitoring for broadcasters, and how they can streamline operations and improve the Quality of Experience for the audience. — Aimed at broadcast engineers, this paper reviews key applications for IP-based monitoring, such as its use in multi-channel playout centers, centralization of regional television stations, and monitoring across multiple distribution platforms such as cable and internet. For each of these applications, the key monitoring challenges are described and solutions are proposed. — The following topics will be covered: the transition to IP video within the playout center; metadata monitoring including ad insertion cues; the use of IP video in TV station centralization; and the use of media fingerprinting for higher volume returns monitoring.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "IPTV",
                      "IP Video",
                      "Monitoring",
                      "Metadata",
                      "Media Fingerprinting",
                      "Digital Program Insertion"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001110"
                  }
                }
              },
              {
                "article_local_id": "58",
                "article_title": "A Statistical Approach for VBR Video Streaming in Wireless Networks",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/58/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "R. Laraspata",
                    "D. Striccoli",
                    "P. Camarda"
                  ],
                  "abstract": "Nowadays mobile multimedia applications are foundamental services brought to people by Universal Mobile Telecommunication System (UMTS). Multimedia services represent an ongoing challenge for every mobile operator. Nevertheless, a good business strategy involves a high Quality of Service (QoS) concerning data services, as well as optimal classic voice services. This work proposes an optimal scheduling algorithm to improve QoS of the video streaming service on UMTS network. We consider a statistical approach to avoid client buffer overflow and underflow resulting from the external user actions. The algorithm is particularly suitable for real-time interactive multimedia transmission of VBR streams. It takes into account the feedback of the real available buffer size periodically coming from client terminals. The aim of the algorithm is the minimization of losses due to user interaction.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Statistical Approach",
                      "Adaptive Scheduling",
                      "QoS",
                      "RTCP feedback",
                      "User Interactivity"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001109"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Nielsen Watermarking",
                "article_url": "https://journal.smpte.org/conferences/The%202011%20Annual%20Technical%20Conference%20&%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Mears",
                    "Scott Brown"
                  ],
                  "abstract": "Nielsen measures television usage through the use of discreet digital audio watermarks (or codes) embedded within content by the programming community (networks, cable networks, syndicators and stations) for purposes of content identification. Nielsen also utilizes a vast reference array of signature matching technology as an additional content identification mechanism; one that is an equally vital and important approach. The audio watermark payload identifies the source or origin of the distribution feed via a SID (source identifier) assigned to the distribution outlet, date, and time stamp payload structure that is repeated at 2 second intervals. Application of watermarks in a broadcast center is achieved through use of rack mounted hardware encoders. The encoders by design are intended to be positioned on each broadcast feed along with backups positioned as near to the satellite uplink or transmitter as possible. A typical broadcast network may employ 12-15 encoders to support all live feeds as well as backup or emergency feeds. The task of the encoder is to simply and continuously apply watermarks to all content passing though the encoder on a 24×7 basis.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001091"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "SMPTE 2nd Annual International Conference on Stereoscopic 3D for Media and Entertainment",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/",
            "articles": [
              {
                "article_local_id": "6",
                "article_title": "Photo-Realistic 3D Model Extraction from Camera Array Capture",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John R. Naylor",
                    "Callum Rex Reid"
                  ],
                  "abstract": "In which the authors describe a process of capturing photo-realistic 3D computer models using purely passive methods based on subject capture with arrays of cameras, and image analysis to permit the instant capture of both form and texture of the subject or talent. — The key performance characteristics of the array are discussed, particularly the challenges of triggering, and the limits imposed on the content created by the native resolution of the cameras used in the array. — Details of the rig design and camera layout and configuration for efficient and effective subject capture are presented. — The process by which multiple still photographs are processed to produce a point cloud which in turn becomes the model mesh are presented, together with examples of the current state of the art of this approach. — Tradeoffs such as the decision to eschew the use of active techniques such as laser scanning, structured light projection, or time-of-flight techniques are discussed, together with their benefits.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D scanning",
                      "Full Body",
                      "Camera array",
                      "Photometrics",
                      "Passive scanning",
                      "Sculptural Photography",
                      "Free Viewpoint Media"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001423"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Effect of Scene, Camera and Viewing Parameters on the Perception of 3D Imagery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael D. Smith",
                    "Bradley T. Collar"
                  ],
                  "abstract": "This paper explores the mathematical relationships between the scene geometry, camera parameters, and viewing environment and their influence on the viewer's perception of 3D. The current practice of using horizontal image translation to set convergence has an effect on the shape ratio and 3D magnification factor of the resulting images and is not well understood by the industry. This paper examines the gap between the creative processes used by stereographers and the mathematical relationships affected by those creative processes. Examples images varying the aforementioned parameters will be demonstrated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "camera parameters",
                      "shape ratio",
                      "horizontal image translation",
                      "viewing distance",
                      "screen size",
                      "width magnification"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001424"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Stereoscopy and the Human Visual System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Martin S. Banks",
                    "Jenny R. Read",
                    "Robert S. Allison",
                    "Simon J. Watt"
                  ],
                  "abstract": "Stereoscopic displays have become very important for many applications, including operation of remote devices, medical imaging, surgery, scientific visualization, computer-assisted design, and more. But the most significant and exciting development is the incorporation of stereo technology into entertainment: specifically, cinema, television, and video games. It is important in these applications for stereo 3D imagery to create a faithful impression of the 3D structure of the scene being portrayed. It is also important that the viewer is comfortable and does not leave the experience with eye fatigue or a headache. And that the presentation of the stereo images does not create temporal artifacts like flicker or motion judder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001418"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "New Techniques to Compensate Mis-Tracking within Stereoscopic Acquisition Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurence J. Thorpe",
                    "Hitoshi Yoshida",
                    "Nicolas Chauret",
                    "Louis Lapeyer",
                    "David Fayollet"
                  ],
                  "abstract": "When a lens is mounted to a camera there is an inevitable mechanical tolerance associated with the lens optical center, and another associated with the camera optical center. These separate tolerances can be additive or subtractive for a given lens-camera combination (both tolerances entail unpredictable +/− limits). This aberration poses the greatest challenge to the imaging alignment of stereoscopic rigs. Lens operational dynamics add another variable differential in terms of small mis-tracking between angle of view over the focal range of a zoom lens pair, mis-tracking between their optical focus, and mis-tracking between their aperture settings. Many workers in the field of 3D are diligently seeking practical and cost-effective solutions to these disparities. — This paper will describe recent developments that entail automatic and dynamic corrections for these differential tolerances. New software in the digital servo systems that operate lens zoom, iris, and focus control allows entry of compensation data that corrects for mis-tracking errors in these three operational functions. Separately, a novel development by 3D rig designer Microfilms of France, utilizes the technology of optical image stabilization built into an HDTV lens to implement automatic real time correction of both the fixed and the dynamic optical miscentering errors between two lenses. A different image stabilization technology - built-into the lenses of integrated HD lens-camcorders (increasingly popular for small handheld 3D rigs) - allows corrections for the fixed optical mis-centering between any two such systems at specific focal length settings.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001419"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Distortions of Space in Stereoscopic 3D Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Karim Benzeroual",
                    "Robert S. Allison",
                    "Laurie M. Wilcox"
                  ],
                  "abstract": "In S3D film, many factors affect the relationship between the depth in the acquired scene and depth eventually produced by the stereoscopic display. Many are geometric including camera interaxial, camera convergence, lens properties, viewing distance and angle, screen/projector properties and anatomy (interocular). Spatial distortions follow at least in part from geometry (including the cardboard cut-out effect, miniaturization/gigantism, space-size distortion, and object-speed distortion), and can cause a poor S3D experience. However, it is naïve to expect spatial distortion to be specified only by geometry — visual experience is heavily influenced by perceptual and cognitive factors. This paper will review geometrical predictions and present the results of experiments which assess S3D distortions in the context of content, cognitive and perceptual influences, and individual differences. We will suggest ways to assess the influence of acquisition and display parameters and to mitigate unwanted perceptual phenomena.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "S3D",
                      "stereoscopic depth perception",
                      "stereoscopic distortions"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001420"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "A Perception Based System for Depth Metadata",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Welsh",
                    "Christian Ralph"
                  ],
                  "abstract": "With the proliferation of three dimensional content across various media platforms, metadata that supports the generation and display of this content has become increasingly significant. Many examples of 3D metadata generation and use exist, but they have so far been application specific in their description of the depth component. When measuring or rendering objects in 3D space with relation to a viewing plane (see fig. 1), the depth value (taken to be the z axis here) is usually absolute in relation to the volume of the image space. Depth values (z) are usually expressed using an arbitrarily decided unit of measurement, but do not take into account how objects at depth (z) will appear when viewed on displays of different sizes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001425"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "High Efficient Computational Integral Imaging Reconstruction Based on Parallel-Group Projection (PGP) Method",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shasha Shi",
                    "Patrick Gioia",
                    "Gerard Madec"
                  ],
                  "abstract": "Integral imaging is an auto-stereoscopic 3D technique presenting remarkable advantages over classical stereo. In this paper we propose a new computational integral imaging reconstruction (CIIR) technique based on Parallel-Group Projection (PGP) method to improve the performance of CIIR. Different from previous CIIR techniques which project each point of integral image (II) to the reconstructed plane pixel by pixel, the proposed method reconstruct the 3D image by mapping a series of sub image (SI) onto the reconstructed plane successively, where each SI records pixels from parallel light rays with identical viewing angle. According to experimental results, this approach is able to simplify the calculation of reconstruction process and improve the quality of reconstructed 3D image.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "integral imaging",
                      "computational reconstruction",
                      "parallel-group projection",
                      "sub image"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001429"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Live Holographic TV: From Misconceptions to Engineering",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "V. Michael Bove"
                  ],
                  "abstract": "Futurists have recently proposed that “holographic telepresence” will be one of the life-changing technologies of the next few years. But what exactly do we mean by holographic TV? Did Al Gore really appear as a hologram at Live Earth Tokyo? What technologies and processes would it require to display live holograms of real scenes? Do we have to capture directly and transmit actual holographic diffraction patterns or can we use a camera array or a rangefinding camera (like a Kinect) and compute the hologram from that? And what does holographic TV have to do with standardization efforts for other sorts of 3-D TV? In this presentation I answer these questions and more.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3-D",
                      "stereoscopic television",
                      "holographic television",
                      "holograms",
                      "visual perception",
                      "displays",
                      "telepresence"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001428"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "The Use of a Dense Disparity Map to Enhance Quality of Experience in Stereoscopic 3D Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Doyen Didier",
                    "Blonde Laurent",
                    "Borel Thierry"
                  ],
                  "abstract": "What stereoscopic 3D content brings to the viewer is essentially a binocular cue to better understand the depth of a scene. A disparity map associated to the stereoscopic content is a key data to ensure that the 3D effect will be well accepted by the user. Limitation of the human vision system in term of binocular cue acceptance will be presented. It will explain when specific video processing can improve the quality of experience. Several uses cases either in post-production or on the end-user side will be presented. All of them will use the dense disparity map as additional input data. Means to generate this disparity map will be introduced. Then technical details of disparity-based algorithms will be presented as well as their positioning in the global 3D workflow. Some standardization challenges will also be addressed",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "Dense disparity map",
                      "Stereo vision",
                      "Displays",
                      "Human factors",
                      "3DTV",
                      "Video signal processing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001426"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "I can See Clearly Now — In 3D",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Norm Hurst"
                  ],
                  "abstract": "The emergence of stereoscopic 3D video brings with it a need for convenient tools for rapid verification and evaluation of displays and signal chains. 3D signal chains have all the usual 2D issues with the addition of left-right matching of timing and tone scale as well as special subsampling and compression issues. 3D displays also have issues of timing, tone scale, and subsampling and add viewing angle and left/right crosstalk. This paper will examine measurement techniques that use test sequences to quickly evaluate these 3D system and display parameters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001427"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Stereoscopic Volume Perception",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniele Siragusano"
                  ],
                  "abstract": "In the past five years technology improvements made it possible to capture, modify and present technically good stereoscopic images. With devices able to capture high-resolution digital pictures and robust computer vision algorithms in postproduction, today we are able to produce high quality live action stereoscopic content - from a technical point of view. — This paper is an analytical engagement tackling a question living in the art domain of stereoscopic cinema: When does a ball look flat like a frisbee disk and when does it appear elongated like an egg? — To analyze volume perception we introduce a simple but powerful basic concept: A 1×1×1 meter cube is used to virtually sweep through space away from the observer's eyes to infinity. For each distance we measure the angles of width and depth on the observer's retina, which causes the retinal disparity that elicits stereopsis. This ratio leads to a width to depth «chirp» through space (width to depth ratio vs. distance). The same test setup is then duplicated. Instead of the eyes we have two cameras connected to a virtual cinema where our observer sits. Again we sweep our cube through space and measure the width and depth angles. — Having established this basic concept we then modify the parameters focal length and interaxial distance and see how they affect the «width to depth» ratio. During evaluation we find new dependencies between all parameters. — Moreover new measurement parameters will be presented, which simplify the usage of depth volume in stereoscopic photography.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001421"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "A Unified Trifocal System for Advanced Depth-Based 3D Capture",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%202nd%20Annual%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Brune",
                    "Nicola M. Gutberlet",
                    "Ralf Tanger",
                    "Dirk Gandolph"
                  ],
                  "abstract": "While benefits of depth-maps for content creation and 3D post-production for multi-view displays are already widely known, their usage as an alternative stereo 3D (S3D) production workflow is just starting to become visible. In addition the generation of reliable depth-maps is still an active research topic. — The paper describes a comprehensive 3D capture infrastructure approach comprising a trifocal camera system entirely based on Ethernet interface technology, a dedicated field recording solution realized with solid state technology capable of recording up to seven uncompressed ‘high frame rate’ camera streams in parallel, and algorithms for trifocal depth estimation enabling real-time depth preview on-set as well as high-quality depth extraction offline. The new interface approach harmonizes and consolidates image data, depth information and general metadata. The system provides a new 3D production workflow with no need of scene dependent adjustments but the possibility to calculate a virtual view with any favored baseline during post.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2011-06"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D Cameras",
                      "depth maps",
                      "Ethernet",
                      "10Gbps",
                      "real-time networks",
                      "trifocal",
                      "3D capture",
                      "reliable disparities",
                      "field recorder",
                      "Flash memory"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001422"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2010",
        "conferences": [
          {
            "conference_name": "SMPTE International Conference on Stereoscopic 3D for Media and Entertainment",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/",
            "articles": [
              {
                "article_local_id": "5",
                "article_title": "ASC's 3D Flash LIDAR™ Camera: The Science behind ASC's 3D Depth Imaging Video Camera",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Laux"
                  ],
                  "abstract": "Based on unique patented technologies, ASC's 3D Flash LIDAR enables each pixel in the camera's focal plane to measure the range (r) and intensity (i) of every point and object in the camera's 3D field of view without scanning. Capturing 16,384 pixels per eye-safe laser pulse up to 30 frames per second, ASC's 3D Flash LIDAR Cameras create video streams of 128 × 128 3D point clouds of the scene in front of the non-mechanical, solid state camera. The short capture time (typically ½ a microsecond or less) emphasizes the camera's ability to capture 3D images without motion distortion. Additionally, the camera provides geometrically accurate 3D point cloud data (x,y,r) with the added benefit of co-registered intensity (i) on each pixel in the scene, from which velocity and position vectors of various objects can be calculated in real-time. The camera can image through obscuration (e.g. dust, smoke, fog), is very light and compact and has an effective capture range from 5cm to 1km. The TigerEye 3D Flash LIDAR Camera can be found in unmanned ground and air vehicles, is used for Automated Rendezvous & Docking for space applications, is useful for aviation and helicopter brownout and automotive applications. With a a number of lens and laser options, the Ethernet enabled TigerEye is finding a wide range of new applications arenas including the Entertainment industry. We will discuss ASC's disruptive technology and the implications to content creators who have relied on prior generations of technologies such as scanning ladar, 2D stereoscopy and other sensing technologies and methodologies to create 3D content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001404"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Sensitivity to Monocular Occlusions in Stereoscopic Imagery: Implications for S3D Content Creation, Distribution and Exhibition",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurie M. Wilcox",
                    "Inna Tsirlin",
                    "Robert S. Allison"
                  ],
                  "abstract": "Since S3D requires two views of a scene, one for each eye, transformations such as reseating, 2D to S3D conversion, synthesis of multiview displays, coding and ADAT communications efficiency require generation of new views from 2D images. One of the main challenges to this process is the identification and treatment of monocularly occluded regions. In natural environments, monocular occlusions occur whenever objects are partially obstructed by other objects in a scene, giving rise to a region that is visible to only one eye. Experiments have shown that these regions influence depth percepts. Importantly, if monocular occlusion regions are presented with texture that is inconsistent with the surrounding regions, or with inappropriate geometry, depth is degraded. This paper will review the geometric basis of monocular occlusions and their role in natural depth perception. The analysis will be framed in the context of the reconstruction of novel and appropriate viewpoints from sequences of 2D images from one or more vantage points.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "S3D",
                      "monocular occlusions",
                      "2D to 3D conversion",
                      "stereoscopic depth perception"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001406"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Research on 3DTV at NHK STRL",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jun Arai",
                    "Takayuki Ito"
                  ],
                  "abstract": "Three human factors, namely, visual naturalness, comfort/discomfort, and visual fatigue, play key roles during viewing of stereoscopic 3DTV. Current stereoscopic 3DTV systems mainly use vergence and binocular disparity as depth cues. Accordingly, the relations between these factors and shooting and display parameters were clarified. It was experimentally shown that discrepancy between vergence and accommodation causes visual fatigue. In addition, two spatial-imaging systems, namely, an integral 3DTV system and holographic 3DTV have been developed as prototypes. The Integral 3DTV system is based on integral photography. With this system, the processes from shooting to displaying 3D images are done in real-time. An experimental setup for spatial imaging was developed and used to display a 3D image without the need for 3D glasses.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Stereoscopic image",
                      "Human factors",
                      "Visual naturalness",
                      "Visual comfort/discomfort",
                      "Visual fatigue",
                      "Spatial image",
                      "Integral 3DTV",
                      "Holographic 3DTV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001408"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Simplicity vs. Flexibility; an Integrated System Approach to Stereography",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael A Bergeron"
                  ],
                  "abstract": "Over the years stereoscopic image acquisition requirements have hardly changed. One must acquire two views; imperfect images must be matched; and parallax must be managed within known parameters to avoid viewer discomfort. Currently popular HD stereo rigs accomplish these goals admirably and have the flexibility to take high performance 2D lenses and cameras off the shelf and re-utilize them for stereoscopic shooting. The price of this flexibility includes: an arguably cumbersome system and potentially time consuming configuration each time the system is built; moreover downstream processing is nearly always necessary. To broaden the field of stereo video production to broadcast and even industrial applications, compromises and innovations are required to reduce rig sizes and production costs. New tools are needed to simplify the operation of stereo systems and expand the availability of professional shooters and crew. This paper will examine all of these needs and propose a fully integrated dual camera and lens system to address these issues.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001401"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "3D Shooting with a Single Digital Camera with the Use of 3D Lenses of the Stereoscopic System “Stereo-70”",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alexander Melkumov"
                  ],
                  "abstract": "The Russian stereoscopic system is one of the oldest in the world. This system was used for production of 3D movies for more than 40 years. The important principle of this system is the use of a single camera, single lens and a single film. — The interaxial distance between the left and right lenses should not exceed 30 mm for live 3D shooting if we want to shoot the people and animals without effect of miniaturization and should have a sufficient distance of comfortably reproduced space between the front and background without large parallaxes. — For this reason in the majority of 3D stereoscopic rigs professional digital cameras must be placed not in parallel but at an angle of 90 degrees with the use of a translucent mirror. — The 3D lenses of the Stereo-70 cameras were designed specifically for 3D shooting of the live nature. The small size of optical blocks allows for interaxial distance of 26.4 mm. It is enough to have two 35 mm side by side standard frames on one 65-mm film negative. — The optical axis of each lens can be adjusted to a film when we want to change the distance of the point zero parallax. Remote control of the 3D lens allows cameramen to work without special computing tables. — Recently we have found the way to use the same optical system in digital format with the use of camera “Phantom-65” with a sensor similar to the 65-mm cinema frame. — The choice of single system allows solving the problem of synchronization of the left and right images automatically.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Stereoscopic system",
                      "3D lens",
                      "65-mm film",
                      "interaxial distance (basis of the shooting)",
                      "“Stereo-70”",
                      "“Phantom-65”",
                      "3D camera"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001400"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Spatial Phase Imaging",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Blair Barbour",
                    "Himanshu Vajaria"
                  ],
                  "abstract": "The quest for high-resolution, accurate 3D geometry at real-time speeds has led to the evolution of various 3D sensing mechanisms - from biologically motivated methods such as shape from motion and stereo, time-delay based methods such as LIDAR and RADAR, and structured light systems. Practitioners of 3D (range) imaging are well aware of the shortcomings of these methods such as sparse 3D points, low Z resolution, and bulky setups. — In this paper we describe a revolutionary 3D imaging technology that Photon-X has pioneered over the last ten years to surmount these shortcomings. The resulting Spatial Phase Imaging (SPI) technology measures both, the color and phase response from the scene with a modified focal plane array. This results in extremely high-resolution, accurate 3D geometry on a uniform grid using a single camera. Furthermore, this technology can be made to work with any existing sensor-optics combination, making it amenable to a plethora of applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001402"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Stereo Image Acquisition Using Camera Arrays",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Macmillan",
                    "John R. Naylor"
                  ],
                  "abstract": "“Simultaneity” was one of the central concepts of the Cubist movement in early 20th century art, in which an object or scene is recorded from multiple angles to create an artwork that synthesises time and space. The instigators of Cubism (Picasso, and Braque) took some of their inspiration from the work of Eadweard Muybridge, who though rightly regarded as the father of motion pictures, was also the first person to record “frozen time” sequences with camera arrays. Today, such sequences can be produced at high resolution within 30s of a telegenic event by using arrays of digital stills or video cameras. They can also produce content in stereo; simultaneity indeed!",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001403"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Novel Stereoscopic Content Production Tools",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alexander Hornung",
                    "Aljoscha Smolic",
                    "Markus Gross"
                  ],
                  "abstract": "Stereoscopic 3D is on the cusp of becoming a mass consumer product. But despite the recent rise of stereoscopic movies and technological advances in the industry, many challenges regarding 3D content creation and display remain unsolved. A fundamental issue is control and modification of the stereoscopic depth of live-action content after it has been recorded, since changing depth effectively amounts to changing the baseline and vergence of the capture rig. — With existing post-production tools, the modification of these parameters involves cumbersome and expensive segmentation, dense depth reconstruction, and inpainting. In our paper, we provide an overview on existing technologies for stereoscopic content editing, identify current challenges, and present a number of recent research results which provide novel solutions to problems such as disparity correction and depth authoring, display adaptation, and 2D-to-3D conversion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Stereoscopic 3D content generation",
                      "post-production",
                      "depth editing"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001411"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Visual Fatigue in Three-Dimensional Subtitle Projections",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Angel Garcia-Crespo",
                    "Fernando Paniagua-Martin",
                    "Ricardo Colomo-Palacios",
                    "Juan Miguel Gomez-Berbis"
                  ],
                  "abstract": "Entertainment is becoming multimedia and audiovisual. Hearing impaired people are unable to access a particular type of entertainment if an appropriate action is not taken. For a hearing impaired person to fully enjoy the audiovisual entertainment is vital using closed captioning. There are rules and recommendations for the proper inclusion of subtitles in films, but when it comes to a movie in 3D, it is necessary to perform an extra research work. Not only must position, font, font size and color must be set together with the subtitles, but also the focal length which has been making that subtitle must be chosen. This article presents a study relating to visual fatigue which means the viewer's eye three-dimensional projection of subtitles.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "visual fatigue",
                      "accessibility",
                      "closed-caption",
                      "stereoscopic"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001405"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Development of Tools and Workflow for “Run-and-Gun” Video Production in Stereoscopic 3D",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "George Joblove"
                  ],
                  "abstract": "Stereoscopic 3D production for motion pictures and much television is able to use beamsplitter mirror rigs, in which a half-silvered mirror allows an arbitrarily-small interaxial separation between two conventional cameras. While the size and weight of such systems are manageable for many productions, they are unwieldy for so-called “run-and-gun” shooting. This type of production, which includes much “reality,” nature, and other documentary and unscripted work, tends to be done on modest budgets, and is characterized by quick set-ups; no blocking, rehearsals, or reshoots; frequent handheld operation; and lack of a stereographer or other camera assistant to handle stereo-specific adjustments. These characteristics favor a highly-portable camera which is compact, lightweight, and simple to operate.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001410"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Blu-Ray 3D™",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Zink"
                  ],
                  "abstract": "The Blu-ray 3D™ specification allows the home entertainment industry to bring 3D movies directly into living rooms. While this new standard leverages the technical features of the existing Blu-ray Disc™ format, it also provides a number of enhancements to support a high quality Full HD 3D viewing experience. — This paper will aim to provide an overview of the new features for Blu-ray 3D such as the new compression scheme called Multiview Video Coding (MVC), which enables a disc to contain a Full HD 1080p resolution per eye and at the same time allows for full 2D backwards compatibility. — In addition, to the support for the new codec, Blu-ray 3D also allows for enhanced 3D interactivity and subtitles. There are a number of different ways to implement 3D graphical elements and interactivity - from leveraging 2D elements positioned in z-space all the way to real 3D elements. All of these options have a different impact on production and the user experience. — A key challenge for any 3D format is to creatively manage the various objects positioned in z-space. Since video objects and various graphical overlays all have a depth associated to them, it is important to ensure they don't interfere with each other by creating conflicting visual impressions. — This presentation will address the possibilities to efficiently manage this third dimension in a production environment and also discusses the required changes to the production processes to release titles in this new format.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Blu-ray 3D",
                      "Multiview Video Coding",
                      "MPEG-4 MVC",
                      "Base view",
                      "Dependent View",
                      "Offset Metadata",
                      "BD-Java",
                      "BD-J",
                      "3D graphics",
                      "3D Subtitling",
                      "Disparity Map"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001412"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "What is Holographic Television, and will it Ever Be in My Living Room?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "V. Michael Bove"
                  ],
                  "abstract": "For a 3-D television viewing experience to be maximally realistic, it needs to be autostereoscopic (requiring no glasses), and present not just two-view stereopsis but continuous parallax and other perceptual cues to depth such as visual accommodation (focusing). The display technology most likely to able to offer these features to consumers is holographic television. In this presentation I describe the principles behind diffractive 3-D displays, review the history of holo-video, examine relevant developments in standards and technology (in particular the application of off-the-shelf graphics processors for holographic displays), and connect these with work at the MIT Media Laboratory in developing a holo-video display suitable for consumer use.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3-D",
                      "stereoscopic television",
                      "holographic television",
                      "holograms",
                      "visual perception",
                      "displays"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001413"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "MOBILE3DTV: Content Delivery Optimization over DVB-H System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gozde B. Akar",
                    "Atanas Gotchev"
                  ],
                  "abstract": "Mobile TV has recently received a lot of attention worldwide with the advances in technologies such as Digital Multimedia Broadcasting (DMB), Digital Video Broadcasting - Handheld (DVB-H) and MediaFLO. On the other hand 3DTV is a new approach to watching TV, introducing the third dimension for a more realistic and interactive experience. With the merge of these two technologies it will be possible to have 3DTV products and services based on portable platforms with switchable 2D/3D autostereoscopic displays. The paper presents the European Mobile3DTV project approach toward achieving such a merge. The project specifically addresses the mobile 3DTV delivery over DVB-H system. It develops a technology demonstration system comprising suitable stereo-video content-creation techniques; efficient, scalable and flexible stereo-video encoders with error resilience and error-concealment capabilities, tailored for robust transmission over DVB-H; and also the corresponding stereo-video decoders and players working on a portable terminal device equipped with an autostereoscopic display.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Mobile3DTV",
                      "error resilient transmission",
                      "DVB-H"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001417"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Visibility of Digital Video Artifacts in Stereoscopic 3D and Comparison to 2D",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniel Howard",
                    "Michael Green",
                    "Ramanathan Palaniappan",
                    "Nikil Jayant"
                  ],
                  "abstract": "Georgia Tech has developed at testbed to explore new encoding techniques and other enhancements to stereoscopic 3DTV. A methodical subjective testing program is important in evaluating new approaches, so the testbed has been designed to explore issues such as 1) whether typical compression and network artifacts are more or less visible in stereoscopic 3DTV and under what conditions, 2) what new artifacts specific to stereoscopic 3DTV exist and what the taxonomy of these artifacts should be relative to the tolerance of humans to them, and 3) how stereoscopic 3DTV artifacts vary in visibility depending on the codec used, the bit rate, the transport method (e.g., Frame Compatible transport), and any enhancements applied to stereoscopic 3DTV. This presentation will outline the program overall, provide initial results of subjective testing using artifacted stereoscopic 3DTV video using both active shutter and passive polarization displays, and discuss next steps in the research program. — Initial subjective results from the work thus far show that 1) compared to passive polarization, the active shutter display gave a better experience in full 3D, more visibility of artifacts, and better viewing of two independent channels by multiple viewers, 2) subjects did not see a significant difference in Frame Compatible format vs. full 3D format; 3) subjects were evenly split on whether compression and network artifacts were more or less visible in 3D vs 2D, and 4) the isolation between left and right eye in both active shutter and passive polarization glasses is currently insufficient to support independent channel viewing using 3D technology.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "stereoscopic 3D television",
                      "digital video",
                      "compression artifacts",
                      "network artifacts",
                      "subjective testing",
                      "active shutter",
                      "circularly polarized"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001407"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "3D: How Video Compression Technology can Contribute",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre Larbier"
                  ],
                  "abstract": "Transmission of 3D TV content has become a reality in 2010 with DTH services operators committing to commercial deployments. To avoid video encoders and set-top boxes modifications, high definition content is constructed by packing two views onto a single video stream. — For contribution, removing information from the original views could introduce dramatic degradation to the edited and distributed 3D video. This can be avoided by transmitting independently the two views (simulcast) with standard contribution encoders and decoders. — This paper will present the quality tradeoffs of the most popular 3D packing schemes from a video compression perspective with particular attention paid to the specific AVC/H.264 artifacts that they might cause. — We will also present deployed innovative AVC/H.264 4:2:2 10-bit compression solutions that overcome quality degradation in the 3D contribution space with special attention paid to simulcast synchronization issues.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "H.264",
                      "AVC",
                      "contribution",
                      "sub-sampling"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001416"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Quality Autostereoscopic Displays",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul D. Panabaker",
                    "Simon Sungho Cho"
                  ],
                  "abstract": "The categorical success of digital 3D cinema coupled with the introduction of 3D flat panel screens for the home have raised the questions of what is next, and when can I watch 3D without glasses? Autostereoscopic 3D is considered by some industry leaders to be the key to widespread 3D adoption in consumer electronics. The marketplace for Autostereoscopic 3D devices displaying entertainment and special-purpose 3D content is immense. — This paper examines various methods and commercial technologies currently employed to present Autostereoscopic images. Specific attention will be given to the development and optical requirements of a unique, cell matrix/parallax barrier technique that is currently providing high quality, glasses-free 3D in personal display applications. Content preparation requirements for this display will be reviewed along with future 3D content delivery approaches. The paper concludes with analysis of the challenges and potential posed by Autostereoscopic 3D technology, going forward.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Autostereoscopic",
                      "parallax barrier",
                      "3D"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001415"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Target Screensize for Stereoscopic Feature Film",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniele Siragusano"
                  ],
                  "abstract": "For stereoscopic pictures the geometric dimension on set and the geometric situation at the screening interact with each other. The combination of both produces the final depth perception at the observer. The screen size is believed to be a central variable in the process of creating a stereoscopic picture. The information of the screen size must be known during shooting. But different screen sizes at different theaters raise the question: What is the target screen size for stereoscopic feature film? This paper tries to examine this question.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Screen size",
                      "target screen size",
                      "disparity",
                      "relative parallax",
                      "absolute parallax",
                      "divergence",
                      "binocular rivalry",
                      "panum's fusion areal"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001409"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Display Technologies for Consumer 3D TV Viewing Compared and Contrasted",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20International%20Conference%20on%20Stereoscopic%203D%20for%20Media%20and%20Entertainment/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "3D is coming to the home, and there are several ways it can be viewed. For direct view flatscreen TV displays, there are two competing technologies available (LCD and plasma), with a third (OLEDs) waiting in the wings. Each of these display technologies has its strengths and weaknesses when showing 3D images. — LCD technology, which is widely used for consumer TV designs, provides bright pictures under normal room lighting, but has difficulties with fast motion and 3D crosstalk. Optimum viewing angles are restricted for 3D LCD TVs. TV manufacturers are moving away from traditional CCFL backlighting to light-emitting diodes to provide local area dimming, higher contrast, and faster switching speeds. — Plasma displays are well-suited to 3D because of their inherently wide viewing angles, high contrast, and deep black levels. They are largely immune to crosstalk. However, 3D plasma TVs must use different phosphor formulations for active shutter 3D viewing. Plasma technology also uses more power than same-size LCD TVs. — Organic light emitting diodes have been in development since 1987, and may be best suited for 3D TV applications. However, there are still issues with brightness and color uniformity and organic color material lifetime that will be challenging to overcome if OLED TVs are to come to market.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001414"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "SMPTE Annual Tech Conference & Expo, 2010",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/",
            "articles": [
              {
                "article_local_id": "8",
                "article_title": "Quality Metrics in Long-Term Preservation and Restoration Paradigms",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt"
                  ],
                  "abstract": "Increasing term of preservation for audio-visual digitized content as well as digital restoration requires a change in the measure of content quality. As soon as digital content is to be preserved for a long time it will become the only quality reference material. This is especially true because the traditional analog display technology will no longer be in use. As a consequence, monitoring the quality of content, estimating quality gain or loss after a restoration work and evaluating the expected quality for a given (possibly currently unknown) target display requires a new approach to quality evaluation. — Most audio-visual quality measurement experiments used to be done by comparing an original version and a present version. However new technical paradigms imply a possible loss of reference to the original content hence the need for reference free quality measure. — It is equally necessary to go beyond the traditional signal processing measures inherited from the video technology. All the technical processes applied to the analog content up to its digitization bring their own degradation and are modifying the quality of the content. — A two stage strategy is proposed. — A first set of metrics is derived from traditional signal and image processing and weighted considering the technical work-flow used to obtain the digital copy. — Then a second metrics is built from the first one taking into account the intended restitution channel. — Such a method is designed to allow a better estimation of quality when comparing two versions of the same preserved content or the gain of quality of a restored content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital preservation",
                      "digital restoration",
                      "quality measure",
                      "quality estimator",
                      "quality assessment",
                      "audio-visual quality"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001358"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Delivering 3D Programming: A Snapshot into Realistic Technical Solutions",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matthew Goldman"
                  ],
                  "abstract": "• The delivery of 3D programming to home viewers is a technical challenge that has many possible solutions. Whether 3D is viewed as a checklist item for live sporting events and concerts, a tiered bundle of channels or as a set of revenue generating services which may include on demand programming, every operator needs to have a plan to deliver 3D to its subscribers. • This paper will provide a snapshot into delivering 3D TV today and a course of action for the future. It will provide an overview of key 3D concepts, details of the various distribution-to-the-home methods, a description of the unique challenges of delivering separate left eye and right eye streams, and a look at the standards as they evolve. Suggestions will be offered on how to deliver and implement 3D services to consumers, today and tomorrow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001353"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Enhancing Motion Picture Lens Performance by Digital Calibration and Correction",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher C. Woollard"
                  ],
                  "abstract": "To some degree, all lenses used by the motion picture industry exhibit certain distortions which can detract from the ideal viewing experience. This paper presents a lens calibration and correction system which enables these problems to be resolved digitally in post production. — For some time lenses such as the Cook 4i and now 5i provide the necessary metadata on focus and aperture settings to enable digital post corrections to be applied. Cameras such the Alexa and RED are capable of capturing this metadata. Many other lenses however may be adapted to provide the necessary metadata by means of a simple encoder. The paper presents how this is achieved followed by a presentation of the digital correction system for enhancing such scenarios as extreme focus pulls. Using digital high definition camera systems the calibration of each individual lens is presented along with the automatic derivation of the required lens database. The full post production work flow through to final image generation is presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Lens distortions",
                      "Lens breathing",
                      "Barrel distortion",
                      "Focus pull",
                      "Lens correction",
                      "Digital correction",
                      "Metadata"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001356"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "File-Based Workflows: Key Challenges in Real-World Facilities",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matthias De Geyter",
                    "Luk Overmeire"
                  ],
                  "abstract": "In past years, broadcasters have adopted file-based workflows to enable faster than realtime and concurrent media processing, hereby improving production efficiency. This introduction turned out to be highly challenging, in particular with respect to the integration of different file-based islands into an optimized end-to-end workflow. Now that most issues are solved, time is ripe to assess the accomplishments of current implementations and to identify the key future challenges. — From a distant perspective, the main promises of working file-based seem to be fulfilled, but taking a closer look reveals that the majority of the implemented workflows is still very linear. System integrations could be taken to a higher level, especially concerning metadata, multiple-level format exchangeability and truly collaborative production workflows. Additionally, recent trends such as the consumerization of media production require adapted or novel workflows to handle the proliferation of formats and to provide a less strict, collaborative way of working.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "File-based workflows",
                      "system integrations",
                      "consumerization",
                      "metadata",
                      "quality control"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001354"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Petabytes in Motion: Ultra High Speed Transport of Media Files: A Theoretical Study and its Engineering Practice of Aspera fasp",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Xingzhe Fan",
                    "Michelle Munson"
                  ],
                  "abstract": "With the explosive growth of file-based entertainment content, fast movement of massive digital data over global distances is vital to business success. The Transmission Control Protocol (TCP) that provides reliable data movement has inherent bottlenecks in performance, especially for WANs with large bandwidth, high round-trip time and packet loss. Network file systems (NFS, CIFS) and wide area block based storage protocols (iSCSI) that utilize TCP have severe performance bottlenecks over such WANs. Block-based protocols such as fibre channel provide a high-speed data pathway in the LAN but are impractical over the WAN. This paper introduces fasp (fast and secure protocol), which overcomes the network bottleneck, only to expose other bottlenecks in the end systems, such as in the disk I/O and network file systems. This “last foot” of data movement is our focus. We cover multi-Gigabit per second transfer benchmarks with major storage vendors, across SAN, LAN, and WAN, and explain the key engineering practices learned to maximize the transmission speed and efficiency.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "High-speed file transfer",
                      "wide area networks",
                      "Aspera",
                      "fasp",
                      "protocol",
                      "TCP",
                      "10 Gbps",
                      "storage",
                      "I/O",
                      "NFS",
                      "CIFS",
                      "iSCSI",
                      "FTP",
                      "congestion control",
                      "rate control"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001352"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "The Influence of the 3D Technology on the Film Esthetics and the Changed Film Experience of the Audience",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Plas"
                  ],
                  "abstract": "If the 3D technology is to survive the sensational effect and the new 3D boom, a certain motivation is required concerning its content. This paper tries to prove that there is more need for reconciliation between the technological possibilities of 3D and the newly acquired esthetics by referring to the pragmatic concept of dispositif of the French philosopher Jean-Louis Baudry. The 3D technology is part of a triangular relationship with the film experience and the (new) different textual modes or film esthetics. We study the relationship between those interactors and how these relationships are problematic for generally made assumptions about 3D. We especially try to focus on the question in what possible ways the 3D technology can change the film experience and how this affects the cognitive relation with the content. We focus here on our own small conducted audience research and complete and compare our findings with other relevant studies. We lay out a connection between different platforms in which 3D is used and point to their importance. Next, we try to search all the ways in which 3D can serve and influence the cognitive process of a story and a film in a useful way. With the help of a numerical genre analysis of all 3D films ever made until now, we can see that 3D was mainly used to support a more ‘realistic’ vision. However this kind of 3D use has not yet proved to have a perceivable psychological impact on the content. Finally, we summarize the three main sorts of dispositifs or configurations in which 3D can take place to clear up for once and for all the misconceptions about the universal remedy that 3D appears to be. You just do not simply add stereoscopy to an image without changing (slightly) the context of the overall functioning of the cinema experience and the cognitive process.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "stereoscopy",
                      "content",
                      "3D technology",
                      "3D film experience",
                      "3D film esthetics",
                      "dispositif",
                      "added value of 3D",
                      "3D and realism",
                      "uses of 3D",
                      "story involvement in 3D",
                      "suspension of disbelief",
                      "3D genres",
                      "3D audience study",
                      "changed film experience",
                      "new film esthetics"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001361"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Visionary Archive - Archiving Color Images to Single Strip B&W 35mm Film",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sean McKee",
                    "Victor Panov"
                  ],
                  "abstract": "For decades, color motion pictures have been archived for long-term preservation storage by separating the three primary color components that when combined make a full color image, yellow, cyan and magenta, known as YCM separations, and recorded each color channel on to a black and white strip of film, also known as ‘3-strip’. Black and white film stock is known to have a longer shelf life with less degradation than color film stock. This archival process is the same whether the movie was shot on film, or with modern digital cinema cameras. In the case of stereoscopic 3D movies that contain left-eye and right-eye content, a total of six strips (three for each eye) would have to be made for archival purposes. Ultimately, a future generation would be able to take these strips, recombine them (called registration), and view a full color movie.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001360"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Colour Correction and Matching between Scenes Using 3D LUT",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jin-Seo Kim",
                    "Maeng-Sub Cho",
                    "Soon-Young Kwon"
                  ],
                  "abstract": "Correct colour reproduction is an important factor in digital cinema. To do that, this paper proposes methods of colour correction by means of look-up-table (LUT) interpolations. Reference colour patches are taken by movie camera like taking a clapperboard shot which is generally used for sound synchronisation. Once the shooting is completed, device characterisation is performed to generate the 3D LUT for correct colour reproduction. By using the LUTs, any colours taken from camera under any illumination conditions can be converted to the colours under any preferred illumination conditions by means of a tri-linear interpolation. Finally, the real scenes can be colour changed to any illumination conditions without visual discrepancies. This paper also presents another 3D LUT type in which input RGB colours can be directly converted to output RGB colours without device characterisation. This LUT can be easily adapted to the stereoscopic cameras so that pairs of stereo images may match each other",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Colour reproduction",
                      "Look up table",
                      "Digital cinema",
                      "Colour correction"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001359"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Designing a Film for Multiple Recorder Capability",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anabisdally Castro",
                    "John C. Rutter"
                  ],
                  "abstract": "Digital Intermediate use is fairly widespread nowadays. The recorder technology that allows the creation of DI's has been escalating as well. Recorders can be categorized by their illumination source into three main groups: Laser, CRT and LED recorders. They have varying speeds, exposure latitudes and optical power capability. In addition, the different light sources have unique spectral output characteristics, none of which are an ideal match to the sensitivity of current intermediate films that were designed to work in an optical system. This paper will describe the technology incorporated, as well as the criteria and analysis taken into consideration for designing and optimizing KODAK VISION3 Color Digital Intermediate Film 5254/2254, an intermediate film for recorder applications. This new film, launched earlier this summer, provides optimum image quality and system performance independent of the recorder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "DI",
                      "Digital Intermediate",
                      "Recorder film",
                      "CRTs",
                      "LED",
                      "Lasers",
                      "Spectral Sensitivity",
                      "recorders"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001357"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "BXF Integration to an IT Based Automation System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ben Halsted"
                  ],
                  "abstract": "Underlying BXF is a rich schema that can accommodate many different broadcast scenarios. This schema provides a standard syntax for the exchange of data but requires independent semantic mapping of that data between systems and vendors. — The application of BXF in traffic to automation system interfacing requires the use of transport mechanisms not explicitly defined within the standard. File and web service-based transport mechanisms are frequently encountered in the interfacing of traffic and automation systems. — This paper examines practical aspects of using BXF for traffic to automation interfacing and provides real world examples of solutions to both the configuration and transport issues. In addition the unique attributes of an IT based automation system are discussed as they apply to the application of BXF.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "BXF",
                      "IT",
                      "Automation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001351"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Interoperable AV SYNC Systems in SMPTE 22TV LIP SYNC AHG (Content-Fingerprinting Based Audio-Video Synchronization)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mihailo Stojancic",
                    "Daniel Eakins"
                  ],
                  "abstract": "An end to end interoperable content fingerprint based audio-video synchronization system is described, including audio-video fingerprinting technology overview and current status of the standardization process in SMPTE' 22TV Lip Sync AHG. The system is based on the audio-video fingerprinting technology currently submitted to the SMPTE 22TV Lip Sync AHG by Miranda Corporation. The particular type of signatures are implemented and imbedded in Zeitera Corporation' file based workflow, and in Miranda' real-time SDI-based audio/video synchronization equipment, showing signatures being captured by either vendor's system, and providing results through either vendors application management flow. The example of successful collaboration on an interoperable, mixed vendor solution that can handle both compressed audio/video files and real-time SDI audio/video input is highlighted.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001364"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "3D Standardization - A Status Report and Survey",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. Patrick Waddell"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001374"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "You Want that 3D Channel on Air When?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Lennon"
                  ],
                  "abstract": "There's no denying that 3D has been generating a lot of buzz of late. What to do when your boss announces that you'll be launching a 3D channel? What equipment do I need? Will what I already have work? Do I have enough crosspoints on my routing switcher? These are among a litany of questions you could be faced with some day. We'll simplify the whole situation for you. We'll take a holistic view of the entire broadcast TV ecosystem, and examine 3D's impacts. When you're done, you won't fear that day when the boss comes by with his big surprise!",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D",
                      "3DTV",
                      "ecosystem",
                      "Harris",
                      "equipment",
                      "graphics",
                      "router",
                      "fiber optic",
                      "server",
                      "multiviewer",
                      "editing",
                      "video networking",
                      "switcher",
                      "master control",
                      "channel branding",
                      "test and measurement"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001375"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Advanced Monitoring Techniques for Data Centers Using Virtual Reality",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jurgen P. Schulze"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001376"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "A Codec for Content Masters",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "Codecs continue to improve in efficiency and capability. It is now possible to compress original digital negative film (as printing density data), camera original linear data (gamma 1.0 scene-referred), and output-referred (distribution, with gamma 2.22 or 2.6) moving images in a common codec. The two key ingredients which enable this are 1) the ability to automatically adapt to the increased dynamic range and varying gamma, and 2) the ability to emulate the process of print emulation to yield output referred images for any presentation media from a wide variety of original image formats. Print emulation can further include modest alteration to gamma and gamut for output-referred (high gamma) images. The automatic adaptation to a variety of material types and gamma is enabled via the use of a high dynamic range regional quantization scale. The print emulation process is easily accomplished with current computation, and is a natural task for graphics processing units (GPU's). The use of layering in resolution and signal-to-noise (SNR), including up to bit-exact, further improves the integrity and range of usefulness of the codec.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001355"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Non-Linear Video: A Cross-Platform Interactive Video System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Seeliger",
                    "Christian Rack",
                    "Stefan Arbanowksi"
                  ],
                  "abstract": "Non-linear video is an approach, which makes video content an interactive experience. Non-linear video gives the viewer the opportunity to interact with objects that are part of the video and access supplemental information. On demand, multimedia content is linked with related information. Interactive, time independent navigation opens a new ways to experience video content. This paper shows how such an system could be built upon IPTV and web technology in a cross platform manner.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Interactive video",
                      "non-linear content",
                      "user interaction",
                      "object description",
                      "personalization",
                      "IPTV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001362"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Live/File-Based Workflows Convergence for Multi-Screen Delivery Strategy",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Remi Beaudouin",
                    "Howard Barouxis"
                  ],
                  "abstract": "This white paper deals with the revolution occurring in the content delivery industry, new ways for consuming video anytime and everywhere. This paper also addresses how this impacts live and file based workflows. In the first section, this paper provides a status on multiple screen delivery strategies now being adopted by Operators and Broadcasters to monetize content value. The trends driven by successful multimedia devices such as iPhone, iPad or Over-the-Top TV deployments leads viewers to consume video of their choice on any type of screens, whether it is; Television, Mobile or PC- at any moment. Content viewers now require watching a live asset on their mobile phone while commuting, and on their Full HD plasma with a pristine Blue-ray quality when at home. Consequently, customer's expectations increase from both a quality and timing perspective. In a second part, this white paper details the necessary technical innovations brought to workflows to enable this content revolution. This section especially deals with how TV channels can be processed to allow the production of multiple flavors of the same asset in live, near-live or offline schedules. Due to all of this, content workflows are now being turned from isolated file production islands and live video head ends to fully optimized systems in which live and file-based work flows are converging. Lastly, this white paper points out some challenges that the industry will have to face to in the near future. The trends outlined in this section will cover cloud computing and ad insertion among other topics.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "VOD",
                      "Over-The-Top TV",
                      "transcoding",
                      "Video Everywhere",
                      "ad insertion",
                      "Cloud Computing",
                      "Convergence"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001367"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Editing on Generic Storage over IT Networks",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Defreyne",
                    "Luc Andries"
                  ],
                  "abstract": "At present, broadcast companies are increasingly implementing and optimizing file-based workflows for standard and high definition media production. In this respect, the Flemish public broadcaster in Belgium, VRT, has built the Digital Media Factory (DMF) for news production and generic programs in 2007. The DMF is based on the concept of a centralized generic storage platform. Often media services require their own dedicated storage platform. This results in many file transfers over the network. Performance and cost efficiency could be improved if media services could be integrated with the central storage platform. This paper describes the integration for post production environments, also referred to as in-place editing. It will be shown that the design of the IT network will have a profound impact of the performance. Traditional best practices for IT network design are no longer valid. This paper presents new insights on designing reliable IT networks in high performance media environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Post production",
                      "editing",
                      "edit",
                      "storage",
                      "network",
                      "IT",
                      "Avid",
                      "Apple",
                      "Adobe"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001368"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Stereoscopic 3D Contents Editing Workflow Using Depth Measurement and Compensation",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chulhyun Kim",
                    "Joonki Paik"
                  ],
                  "abstract": "This paper presents an efficient method for creating depth perception for editing stereoscopic three-dimensional (S3D) contents. Unlike two-dimensional (2D) contents, S3D contents require a production of depth perception from the pre-production step. The storyboard and depth chart for each cut should first be established, based on which the shooting and editing work will be done. Most existing methods for editing S3D contents are completed at the expensive DI step of the final editing process, in which the stereoscopic imagery has been viewable. For this reason the depth perception of S3D contents is currently achievable only at the DI step and not at the non-linear editing (NLE) steps. The editing based on storytelling however creates primarily at the NLE (Non Linear Editing) process. This paper proposes a more effective method for confirming the depth perception of each cuts using a depth map, as an editor creates shots of sequences. The experimental results demonstrate that an editor can more efficiently identify the not-good (NG) sequences using the depth map using generated by the proposed method",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Stereoscopic",
                      "Workflow",
                      "S3D"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001366"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "High Density Interconnect Standards for Next Generation Broadcast Networks",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Owen Barthelmes",
                    "David Weinstein"
                  ],
                  "abstract": "HD-BNC is a high density interconnect standard which satisfies space constraints in next generation system architectures. The configuration maintains expectations relative to user experience, mechanical robustness and low loss at extended frequencies to support higher data rates. BNC connectors per IEC 169–8, having been deployed in systems for over 50 years, offers robust performance and user friendly quarter turn bayonet style coupling. HD-BNC is therefore proposed as an open standard solution preserving all of the benefits of BNC with a fourfold footprint reduction. HD-BNC was developed from inception as a 75 Ohm interface with extensive simulation and test validation to optimize signal transmission per SMPTE-292M and 424M standards in both analog and digital video and audio signals. This paper will detail the development process and contrast this interconnect solution to others in the industry in key areas such as mechanical robustness and electrical performance of real world applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "high density",
                      "interconnect",
                      "analog video",
                      "digital video",
                      "high bandwidth",
                      "connector"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001371"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "The New Connectivity - Is the BNC Connector Dead?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Randy Conrod"
                  ],
                  "abstract": "The New Connectivity — Is the BNC Connector Dead? No, not quite yet. The BNC connector has been utilized for many decades in the television industry. It is common knowledge that the density leaves a lot to be desired in modern television equipment because of the real estate required on back panels for external connections. A move to smaller connectors has taken place recently. This paper describes the process that Harris went through in analyzing all of the available connectors and choosing the best candidate with which to move forward.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "BNC",
                      "HD-BNC",
                      "DIN 1.0/2.3",
                      "Mini BNC",
                      "Slimline BNC",
                      "Micro BNC"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001372"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "System Monitoring: An Overview",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joey Faust"
                  ],
                  "abstract": "Increased complexity in media facilities means an increased need for better monitoring and management tools. Today, the workflows and technologies of general-purpose IT hardware and software are relevant to air-chain media environments and fast turnaround production. But, in many media facilities, these capabilities—already “baked in” to the servers and networks supporting operations—are misunderstood or under-utilized. — This paper presents an overview of the technologies and architectures of IT system monitoring with a focus on how these are applicable to media systems. Standards such as SNMP, WBEM and EMS are useful for enabling both active and passive system monitoring architectures. A “system of systems” approach to system monitoring is a best-practice methodology for monitoring complex media environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "System monitoring",
                      "system management",
                      "SNMP",
                      "IT monitoring"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001369"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Workflows for Embedding Content Protection Watermarks in Theatrical Soundtracks",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dean Angelico",
                    "James Baggerly",
                    "David Chiang"
                  ],
                  "abstract": "The motion picture industry's adoption of a standard audio watermark technology for content protection has generated interest within the professional sound post-production community to better understand the tools and processes for incorporating watermark embedding and verification within existing workflow environments as well as the proper handling and use of the resulting watermarked content. Content protection watermarks differ from forensic watermarks by providing active content protection rather than passive post-theft tracking and are applied during post-production rather than during exhibition. — This paper describes the tools and workflows developed for theatrical sound mastering to embed an audio watermark using Cinavia™, the new cross-industry standard for the protection of filmed entertainment content developed by Verance Corporation. Cinavia has been adopted as a required element of the Advanced Access Content System (AACS) that is used to protect high-value content on Blu-ray Discs. Cinavia can stop the playback of unauthorized copies in compliant Blu-ray Disc players. The paper presents an overview of the Cinavia technology, its protection benefits throughout different content release windows, and the tools used for embedding and verifying the correct copy protection payloads. It addresses issues including time spent on the soundstage, interfaces to existing equipment and software, content labeling and archiving, and preserving audio quality. The paper focuses on the deployment of these tools and processes in audio mastering workflows for theatrical film release and concludes with a summary of Cinavia adoption in the marketplace.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "AACS",
                      "audio watermark",
                      "Cinavia",
                      "content protection",
                      "embedding",
                      "film print mastering",
                      "theatrical post-production workflows"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001365"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Fingerprinting for Solving A/V Synchronization Issues within Broadcast Environments",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sara Kudrle",
                    "Michel Proulx",
                    "Pascal Carrieres",
                    "Marco Lopez"
                  ],
                  "abstract": "With ever increasing complexity in the distribution and delivery systems, how can providers manage content, without modifying it, while keeping costs low? — Media Fingerprinting is an emerging technology that is gaining momentum and has far reaching benefits for content creators, providers and distributors alike. What is Media Fingerprinting and what are its current applications? How could standardization help promote this useful technology? This paper will address all of these issues and provide some answers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Fingerprinting",
                      "A/V synchronization",
                      "Lip sync",
                      "Asynchrony",
                      "watermark"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001370"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "GPU Accelerated H.264 Video Compression for Broadcast",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dmitri Klimov",
                    "Jan Weigner"
                  ],
                  "abstract": "In recent years the ability to perform massive parallel computations has become readily available on every desktop due to improved graphic processors and new programming tools like CUDA. The standard CPUs are also evolving rapidly in the same direction, making this technology even more accessible. Video compression is an illustrative example of an area where the speed / computation power trade off is especially steep. To render all the features of the modern H.264 compression standard a super-computing level of power might be necessary. The modern GPU and the next generation of the CPU could deliver the required computation power. We investigate what can be done to exploit the features of the modern GPUs for H.264 compression and how the new video compression standards like H.265 might be adopted in the future of massive parallel processing",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video encoding",
                      "H.264",
                      "H.265",
                      "MPEG-2",
                      "GPU",
                      "massive parallel computing",
                      "CUDA",
                      "OpenCL",
                      "codec"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001388"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "Integrating New Technology and Conventional Playout Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Wadle"
                  ],
                  "abstract": "The availability of IT/software-based playout systems can dramatically lower the cost and complexity of deploying and operating broadcast channels. However, few broadcasters can deploy this new technology in a “greenfield” site, even if adding new channels. Rather, these new systems must be integrated into an existing operation and interoperate with conventional broadcast hardware supporting existing channels — hardware that will be retained through some or all of its remaining useful life. Doing this efficiently means planning integrated workflows that utilize both conventional and new solution components, as well as the critical ability to share content libraries - and the storage that hosts them - between existing and new channels — These objectives can be met, but require flexibility within the new technology solution to accommodate existing ingest methods and content file formats. In addition, the communication of scheduling and program management systems with both conventional and IT/software-based systems for ingest and playout requires the selective application of the new IT methods such as web services and data exchange standards like BXF, along with the retention of legacy communication methods where necessary. — This objectives of this paper are to explore several approaches to the efficient integration of IT/software-based and conventional playout systems, and the ingest and content preparation processes that support them. To do this, we will identify the required and potential touch points of these systems to each other, to shared resources such as content storage, and to adjacent planning systems such as traffic and program management. At each such touch point, we can examine available solutions and identify the benefits of each approach.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "automation",
                      "IT",
                      "file-based",
                      "workflow",
                      "playout",
                      "transmission",
                      "software",
                      "OmniBus",
                      "iTX",
                      "Wadle",
                      "Miranda"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001393"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Development of Super Hi-Vision Compact Cameras and Recording System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mayumi Abe",
                    "Kazuyuki Arai",
                    "Daisuke Ito",
                    "Hayato Fujinuma",
                    "Toshiya Kikkawa",
                    "Taku Tsukamoto",
                    "Shinichi Takahashi",
                    "Hideaki Mita"
                  ],
                  "abstract": "NHK is developing Super Hi-Vision (defined as UHDTV-2 in SMPTE2036–1; SHV), a new television system capable of providing a highly realistic viewing experience. We recently developed a new SHV camera and SHV recorder/player, both with greater compactness and mobility than the previous prototype. — The camera was miniaturized as a compact 10G-SDI-based optical transmission unit and high-integration signal processing unit. With 16 H.264/AVC compression units operating in parallel, the compact recorder/player can hold up to two hours worth of content on 16 semiconductor memory cards (P2 cards). The camera and the recorder/player are less than half the sizes of the previous prototypes. — Moreover, superimposing control and status data on the ancillary data area of 1.5G-SDI ensures improved operability and efficient editing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001380"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Improving Workflow Efficiency - The Challenges of True End-to-End Control and Monitoring",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Maurice Snell"
                  ],
                  "abstract": "The traditional way for broadcasters to achieve an integrated system covering their entire workflow was to invest heavily in customized development. Only the wealthiest broadcasters could afford to do this, and therefore benefit from the workflow efficiencies that such an integrated system brings - giving operators a user-friendly view and control of all aspects of the operation. Today's financial environment drives all broadcasters, large and small, to maximize the efficient use of their assets, giving their staff the tools to do more with less. This increases the requirement for off-the-shelf packages that can approach the level of integration that previously necessitated custom development. This presentation will discuss the technical challenges involved in using a combination of generic protocols such as SNMP, and vendor-specific protocols, to provide cost-effective user-configurable end-to-end control and monitoring systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Control",
                      "Monitoring",
                      "SNMP",
                      "Infrastructure",
                      "Modular",
                      "Efficiency",
                      "Workflow",
                      "End-to-end",
                      "Systems",
                      "Integration",
                      "GUI"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001381"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Next Generation Multichannel Television Station Monitoring",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Wright",
                    "Patrick Daly"
                  ],
                  "abstract": "The modern local television station faces many challenges - most significantly the national decline of advertising revenues. Individual and group-owned stations are searching aggressively for new, more efficient and cost-effective operational models. For many, some type of centralized content ingest and play out facility is an attractive alternative. With the promise of cost savings and central command comes the challenge of a monitoring system that will allow visibility into the movement of media, the health of remote systems and the signals themselves. — Media Movement — Many centralized operations employ an “ingest once, use many” philosophy. Local television stations present a different set of challenges than those of networks. Specifically a generous portion of the broadcast day is devoted to content that arrives close to air. — Health of Remote Systems — With physical and media assets in diverse geographic locations, a proper network and set of tools for remote monitoring and control of hardware and software is essential. — Signal Monitoring — When remotely operating local television stations one of the significant challenges is the development of a video and audio monitoring environment that is space-friendly and easy to navigate while retaining a complete view of the various critical signals. The choice of what signals to monitor is eclipsed only by the various technical challenges that await the designer when planning and implementing the system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "master control",
                      "automation",
                      "monitoring",
                      "centralcasting",
                      "centralized",
                      "local television station",
                      "ingest",
                      "syndicated",
                      "feeds"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001377"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Digital Image Processing Techniques for Restoring Old Damaged Films and Their Applications to Korean Film Restoration",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chulhyun Kim",
                    "Sangjin Kim",
                    "Joonki Paik"
                  ],
                  "abstract": "This paper presents a set of digital image processing techniques for restoring old damaged Korean films. This project was initiated last year by joint efforts of Chung-Ang University, HFR, and Seoul National University supported by Korea Creative Content Agency(KOCCA). The characteristics and types of damages in old Korean films are quite different from those of the Hollywood films that have been properly stored and maintained. Therefore the need to develop a restoration solution for old damaged Korean films has become an issue of great interest. The set of image processing algorithms in the solution include; image stabilization, auto-focusing, and frame interpolation. This paper presents the characteristics of old Korean films and experimental results of the restoration using the proposed image processing solution. From the experimental results, it is evident that the visually acceptable level. The auto-focusing and the stabilization can improve the quality of damaged films up to.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Restoration",
                      "Classic film"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001383"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "A Camera System Using Three 33-M-pixel CMOS Image Sensors for UHDTV2",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takayuki Yamashita",
                    "Ryohei Funatsu",
                    "Tadaaki Yanagi",
                    "Kohji Mitani",
                    "Yuji Nojiri",
                    "Tetsuo Yoshida"
                  ],
                  "abstract": "We describe a world's-first camera system that can capture images complying with the highest-level image format specified in SMPTE 2036-1— i.e. UHDTV2 (7680 ×4320/59.94p, R/G/B 4:4:4). For this camera system, we developed a 33-million-pixel CMOS image sensor, an ultra-high-resolution lens, and a signal-processing function for correcting lens chromatic aberration in real time. As a result, the limiting resolution of captured images was achieved over 4,000 TV lines. Moreover, WDM optical interface with nine 10G-SDI modules was developed. Using this technology, the camera head and camera-control unit can be connected by an SMPTE 311 camera cable. In addition, the camera system's configuration and performance are also described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Camera",
                      "Ultra-high definition",
                      "CMOS image sensor",
                      "Chromatic aberration",
                      "Super Hi-Vision"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001379"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "An End-to-End Managed Media Archive Workflow for Scalability, Interoperability and Data Longevity",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lee Hu",
                    "Sam Sun",
                    "Lan Yang"
                  ],
                  "abstract": "The media data set is growing exponentially due to digital revolution and ubiquitous deployment (e.g. cell phone video). Current patch solution with storage, archive, workflow and networking is not scalable and costly from long term perspective. We propose a set of principles and implementation schemes for a scalable, interoperable and long-lasting architecture for enterprise. We pursue technology virtualization, storage virtualization, location virtualization and device virtualization and emphasize at data supply and consumption perspective. The important goal is to work with today's existing and heterogeneous infrastructure and gradually phase in a mechanism to manage the data and its access while providing an open framework for future technology.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Archive",
                      "scalability",
                      "interoperability",
                      "data longevity",
                      "managed media",
                      "archive workflow",
                      "media cloud"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001363"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Hybrid Routers: A New Era of Routing",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sara Kudrle",
                    "Charles Meyer"
                  ],
                  "abstract": "As television facilities seek ways to lower costs and improve efficiencies, routers have risen to the challenge by doing more than just routing. These Hybrid Routers, which handle multiple formats within a frame, are capable of internally managing functions such as embedding and disembedding audio, handling mismatched audio channels, audio shuffling and audio breakaways. This ability coupled with intelligent software control allows the router to do this seamlessly and automatically when needed. — With the inclusion of hybrid routers, facilities will no longer need to rely on separate dedicated video and audio routers, external signal processing equipment and complicated management software overlays to overcome their signal processing challenges. The integration of audio processing within the router significantly reduces costs while saving power and space and simplifies signal management by handling the logic internally. — This paper will explore the many ways that the audio-video hybrid router confronts signal management challenges that facilities face and provides an in-depth look at the internal router logic needed to achieve a successful result.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Router",
                      "audio signal processing",
                      "multichannel audio",
                      "disembedder",
                      "embedder",
                      "mux",
                      "demux",
                      "cost reduction",
                      "flexible"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001382"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Ultra-Low-Delay H.264 Based Wireless HDTV Camera",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takashi Tsuyuguchi"
                  ],
                  "abstract": "For existing MPEG-2 based wireless HDTV camera, latency and picture quality is a major issue, and swift improvement is strongly required. Therefore, NHK developed a wireless HDTV camera integrated with ultra-low delay H.264 encoder, as for this solution. By installing board-type ultra-low delay H.264 encoder to compact-type OFDM (Orthogonal Frequency Division Multiplexing) microwave transmitter, 10msec latency and twice of compression efficiency was achieved. As a result, operation of wireless HDTV camera will become the same as any other wired HDTV camera, and no special treatment will be needed. Contribution to various HDTV program is greatly expected for this ultra-low delay H.264 based wireless HDTV camera. In the presentation, a detailed technology and operation image of this camera will be shown.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "“Ultra-low-delay”",
                      "“H.264”",
                      "“HDTV Codec”",
                      "“Wireless Camera”"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001373"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Optical SDI Networks: Evaluating Robustness, Performance and Reliability in Your SDI Network",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alex Bond",
                    "Sam Pirritano"
                  ],
                  "abstract": "The continued transition to HDTV, the advent of 1080p50/60 production, 3D TV production, D-Cinema production and higher resolution / bit depth formats, are all factors driving the build out of 3G SDI capable broadcast infrastructure and the increased prevalence of optical fiber interfaces. — Though optical networking provides a number of advantages, the technology is new to the broadcast industry and not yet well understood by many broadcasters and equipment suppliers. As a result, optical SDI networks are being specified and deployed without a proper understanding of the robustness of those optical links, leading to the selection of marginal optical technology, putting mission-critical links at risk. — This presentation will outline some best practices on how robustness of an optical link can be evaluated. Presented will be best practices in optical transmitter, receiver and system testing, as well as a case study contrasting results from a robust and marginal optical transmit/receive pair.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Optical Networking",
                      "Fiber",
                      "SMPTE 297",
                      "Fiber Optic Interfaces",
                      "robust optical links",
                      "Optical Receivers",
                      "Optical Transmitters"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001378"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "A New Programming Methodology for Rapid Deployment of Computationally Intensive Broadcast Codecs",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael W. Bruns",
                    "Martin A. Hunt",
                    "Lin Tong",
                    "Keith Bindloss"
                  ],
                  "abstract": "Higher quality video encode is only one of many requirements in an industry increasingly interested in lower power consumption, upgradable standards flexibility, and lower cost. To date, meeting all needs at the same time has been unachievable, limited by inefficiencies in underlying silicon architectures and traditional programming methodologies. Legacy processing solutions using arrays of FPGAs, DSPs, GPPs or inflexible ASICs have forced designers to make feature set tradeoffs and solutions that do not scale well with increasing pixel rates. A new approach using a dataflow programming methodology and a massively parallel processor array introduces a technical discontinuity in meeting tomorrow's equipment requirement with respect to computationally intensive algorithms such as H.264 Hi10P, Level 4.1 or greater. This development flow allows for 1) rapid deployment 2) software defined implementation that is upgradable for new features or algorithm enhancements, 3) high quality/low power video encode at the point of capture. We present two key components of a H.264 encoder, CABAC and motion estimation, and demonstrate the application of the dataflow methodology on a massively parallel processor.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Dataflow programming",
                      "massively parallel architecture",
                      "H.264 codec",
                      "low power"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001387"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "System Monitoring: An Overview",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joey Faust"
                  ],
                  "abstract": "Increased complexity in media facilities means an increased need for better monitoring and management tools. Today, the workflows and technologies of general-purpose IT hardware and software are relevant to air-chain media environments and fast turnaround production. But, in many media facilities, these capabilities—already “baked in” to the servers and networks supporting operations—are misunderstood or under-utilized. — This paper presents an overview of the technologies and architectures of IT system monitoring with a focus on how these are applicable to media systems. Standards such as SNMP, WBEM and EMS are useful for enabling both active and passive system monitoring architectures. A “system of systems” approach to system monitoring is a best-practice methodology for monitoring complex media environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "System monitoring",
                      "system management",
                      "SNMP",
                      "IT monitoring"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001384"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "New Compute Components for Video Equipment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward G. Callway"
                  ],
                  "abstract": "Traditional video processing equipment is a mix of real time circuits for simple effects, and offline software running more difficult algorithms on a general purpose processor (CPU). The PC industry has developed extremely powerful graphics processing units (GPUs) with teraflops of rendering power. These are well known for gaming or workstations running a large OS in a large box. Driven by silicon advances, there are now APUs (Accelerated Processing Units) that integrate multicore CPUs with GPU parallel pixel processing in a single low power package. Combined with the OpenCL parallel programming language, and small software platforms such as Linux or Win7 Embedded, it is now possible to do many offline or dedicated hardware effects in real time software on portable equipment. This will be important for applications such as 3D stereo ENG cameras that need to correct lens and sensor aberrations in real time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "GPU",
                      "CPU",
                      "GPGPU",
                      "APU",
                      "DisplayPort",
                      "Shader",
                      "x86",
                      "VGA",
                      "HDMI"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001389"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Technology for Grade 1 LCDs",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Goran Stojmenovik"
                  ],
                  "abstract": "For decades, color-critical video monitoring for broadcast and post-production applications was performed on a reference (grade 1 *) CRT monitor, or a reference projector for cinema applications. Flat panel displays, although having clear advantages in terms of depth, longevity and insensitivity to magnetic fields, have until recently failed to produce accurate and stable pictures as required for true grade 1 monitoring. Various LCD artifacts stood in the way of accepting LCD as the next technology for color critical applications: insufficient viewing angle causing a drop in contrast, a color shift or even a color inversion; crushed dark levels and clipped highlights; over-saturated colors, skin tone errors and color cast errors; motion blurring, deinterlacing problems, jaggies, and motion judder; unstable colors and unstable brightness.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001396"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Migrating from MPEG-2 Video to MPEG-4 AVC",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matthew S. Goldman"
                  ],
                  "abstract": "Due to the large savings in bandwidth that MPEG-4 AVC compression provides over MPEG-2 Video, content providers are now, or soon will be, migrating to MPEG-4 AVC for distribution to local broadcasters and service providers, as well as for contribution backhauls. MPEG-4 AVC enables improved picture quality of existing services or additional services to be provided, or a combination of both. Migrating to MPEG-4 AVC introduces many changes to the programmer's infrastructure. The “HD challenge” is discussed, along with a review of how MPEG-4 AVC compression improves upon MPEG-2 Video. DVB-S2 modulation is overviewed and the bandwidth efficiency gains one obtains when it is combined with MPEG-4 AVC compression is explained. Migration issues to consider are discussed including the support of legacy MPEG-2 Video receive sites and the impact of multiple decode/encode stages (concatenation).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Migrating from MPEG-2 to MPEG-4 AVC",
                      "bandwidth efficiency",
                      "DVB-S2",
                      "MPEG-4 AVC",
                      "transcoding receiver",
                      "transcoder",
                      "compression concatenation effects"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001391"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "OLED; What is it and How Does it Work?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Mandle"
                  ],
                  "abstract": "In the early days of television, things were simple. The primary display technology was the CRT. Other technologies are now available, and all claim to fit within the performance parameters offered by CRT technology. Of these, OLED may be closer to CRT performance, and in fact may exceed the CRT on several levels.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "OLED",
                      "Light Emitting Diode",
                      "electroluminescence",
                      "organic materials",
                      "electrons and holes",
                      "guest molecules",
                      "emission layer",
                      "electron injection",
                      "hole transport",
                      "bottom emission",
                      "top emission",
                      "microcavities",
                      "TOLED",
                      "SOLED",
                      "P-LED",
                      "AMOLED",
                      "XEL-1",
                      "PVM-740"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001395"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Introducing New Profiles for Broadcast Applications in the JPEG 2000 International Recommendation | Standard",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dale Stolitzka",
                    "Walt Husak",
                    "Siegfried Foessel"
                  ],
                  "abstract": "The ITU recently added new profiles to the JPEG 2000 standard for broadcast video contribution and distribution within the production flow published ITU-T Rec. T.800 (08/2002)/Amd.4 (2010E), an amendment to JPEG 2000 core coding system. This amendment represents a major step toward a transport system for studio contribution allowing equipment from different manufacturers to interoperate. The process relies on both existing standards and new amendments from three international standard organizations JPEG, MPEG and SMPTE developed in cooperation with studios, broadcasters and equipment vendors. — The new amendment specifies a selection of encoding parameters and newly defines rate limits over seven operating levels for video encoded with JPEG 2000. The operating levels create a basis for compliance test points to ensure equipment interoperability. The paper also reviews a proposed transport mechanism for the codestream over SDI and IP.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "JPEG 2000",
                      "Broadcast Applications",
                      "contribution video",
                      "MPEG-2 Systems",
                      "transport stream",
                      "packetized elementary stream",
                      "video transport",
                      "lossy",
                      "lossless",
                      "reversible",
                      "irreversible compression"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001390"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Inside the Jokes: TV Search Technology Yields Creative, Comedic Screenwriting",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rakesh Agrawal"
                  ],
                  "abstract": "Problem Statement: — “We need a better, less expensive way to monitor TV.” Those were the very words expressed by the writers and producers at The Daily Show with Jon Stewart and The Colbert Report to summarize the pain points of archiving and finding clips in television shows. — The two popular Comedy Central programs began airing in HD on January 4, 2010, one year after the launch of Comedy Central HD. The conversion to HD achieved a significant broadcast milestone but also brought new workflow challenges for the engineering teams. — A vital part of this new workflow would be inventing a new way to record, archive, and search traditional television for clips, clips which serve both shows' media commentary and witticisms. The shows had previously relied on analog consumer-grade DVRs and low-quality and expensive outside clipping services for their TV clips. After a rigorous evaluation process, The Daily Show and The Colbert Report formed a partnership with SnapStream to meet their TV recording and search needs. — Objectives & Methods: • Recording traditional TV in HD using a custom in-house QAM plant • Enabling keyword search over TV shows, using closed-captioned and program guide data. • Integration with Avid and Final Cut Pro, using both file-based and SDI-playout workflows. • Archiving of TV recordings for potentially multiple years using petabyte-scale storage — Quantitative Results: • Implemented possibly the world's largest high-definition DVR, with the ability to record a total of 30 channels of TV, split between The Daily Show and The Colbert Report • Each show has its own SnapStream storage to save two to three weeks of most recent television recordings. • Integrated with HP's storage solution to create a single video library, currently using 500 terabytes with room to grow into the petabytes. — Findings Significance: — Archiving a large body of searchable, indexed television, The Daily Show and The Colbert Report have carved a new benchmark in the process of creating high-quality, responsive-style entertainment programming. The pioneering architecture and technical workflow created with SnapStream has greatly reduced post-production time and optimized creative collaboration.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "television search technology",
                      "media monitoring",
                      "TV monitoring",
                      "DVR",
                      "enterprise DVR",
                      "closed captioning",
                      "clipping television",
                      "news monitoring",
                      "clipping service",
                      "QAM recording",
                      "digital video archive",
                      "TV Aircheck",
                      "TV editing",
                      "software",
                      "media server",
                      "storage",
                      "streaming"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001392"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "The Establishment of Adaptive LUT for Digital Cinema Projectors Based on ICC Profile",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ju-Yeon You",
                    "Soon-Young Kwon",
                    "Jin-Seo Kim",
                    "Maeng-Sub Cho"
                  ],
                  "abstract": "Every digital cinema projector has different color characteristics, thus the color of each projector can be seen differently. To solve this problem, LUT (Look-up-Table) should be differently made for each target device during DI(Digital Intermediate) process. Also, 8-bit images, used in general display devices, should be expanded to 10-bit images which are generally used in digital cinema in Korea. However, ICC (International Color Consortium) profile of 10-bit 3D LUT is difficult to handle because of its large size and long transfer time. In this paper, we propose the method of expanding 8-bit 3D LUT for each target device using ICC profile with private tag to 10-bit 3D LUT by using geometric interpolation. By using (use of) the resulting 10-bit LUT, scene images are transformed to be suited for target digital cinema projector in the process between DI and mastering. The proposed method can reduce the time to transfer 10-bit full 3D LUT and give interoperability between devices based on ICC profiles as achieving color consistency between digital cinema projectors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital cinema",
                      "Color consistency",
                      "ICC profile",
                      "Private tag",
                      "Geometric interpolation",
                      "10-bit color depth"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001397"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "A Non-Conventional Approach to the Conversion of 2D Video and Film Content to Stereoscopic 3D",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Carlos Vazquez",
                    "Wa James Tam"
                  ],
                  "abstract": "We will present a non-conventional approach and method for converting naturalistic (non-computer-generated) 2D video and film material to Stereoscopic 3D. We will present experimental evidence to show the efficacy of colour-based surrogate depth maps for automatic 2D-to-3D conversion aimed at small screen applications. We will then present a semi-automatic 2D-to-3D conversion system (CRC-DMEG), also based on surrogate depth maps, for the conversion of video and film contents for commercial projection on large cinema screens. A major advantage of CRC-DMEG is that it exploits the correlation between the 2D colour images and the surrogate depth maps to allow for direct manipulation of the depth of objects in a scene. Another major advantage is that it allows for the instant realization of depth details, such as raindrops, foliage and the textures found in carpets. Our approach and method, minimizes the labor-intensive work associated with the conventional method of rotoscoping. Moreover, the manual task of filling in disoccluded regions is also significantly reduced.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "3D-TV",
                      "2D-to-3D conversion",
                      "3D cinema"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001385"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "Method and Good Estimators for Projection Uniformity Measurement",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt"
                  ],
                  "abstract": "An improved method for screen luminance uniformity measurement was proposed in a previous paper using a calibrated digital camera to capture a complete view of the screen in one shot. — As large screen projection exhibits vignetting, a model of the vignetting phenomenon is used in this paper to characterize the distribution of luminance values over the screen. The specific geometry of the projection is taken into account in the model by integrating the throw ratio as a parameter of the model. — The results give more detailed information and can be used to store and track the history of measures of multiple screens. — A similar approach has been explained for flat panel uniformity measurements for the broadcast industry. Once the vignetting of the given projection is compensated for, the process of computing a quality estimator is equivalent for both display systems. — Traditional point-wise measurements can be computed from both methods, but it is also worth trying to give more informative measurements and associated tolerances to obtain a useful measurement system. This was left open at the end of the last paper; we will explain how quality measures can be computed and justified. — The above mentioned broadcast paper proposes a quality estimator called the “uniformity score”. It is computed from the statistics of small patches evenly distributed all over the screen. It is based on standard deviation and scaled; questions arise about the scaling. — Deviations from a perfectly uniform projection may have multiple causes. Any uniformity measure must somehow be related to human perception of uniformity. Random deviations are less visible than structured luminance patterns. It is then logical to complement the standard deviation measure by a statistical measure which may indicate a biased error distribution. One such measure is proposed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Uniformity",
                      "screen's measurement",
                      "vignetting"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001398"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Written for Presentation at the SMPTE 2010 Technical Conference & Expo",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "The adoption of digital projection in the cinema is gaining momentum. The challenge for the adoption of digital cinema has been system cost. Even with the promise of incremental revenue from 3D and cost sharing with motion picture studios, overall cost of ownership remains an obstacle for many theater owners. Today, digital cinema projectors using Xenon light sources have become the dominant design. However dramatic improvements in the price/performance of high-power lasers in recent years create great opportunities for both reducing operating costs and improving the quality of digital cinema projection. Both the potential and the pitfalls of 2D and 3D digital projection based on laser light sources will be discussed. System impacts on contrast, efficiency, brightness, color gamut, and laser speckle will be considered. — Kodak has built a fully functional, DCI ready 2D and 3D laser projector prototype demonstrating a unique optical architecture that takes advantage of the best attributes of lasers. Enhanced image performance is delivered in a cost-conscious design. The challenges of lasers, such as speckle, are addressed throughout the system, providing excellent performance on the large screen.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Kodak",
                      "TI",
                      "DLP",
                      "3D",
                      "Digital Cinema",
                      "Laser",
                      "“Cost of Ownership”",
                      "contrast",
                      "brightness",
                      "color gamut",
                      "laser speckle",
                      "projector"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001399"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Identifying Good & Bad 2D to 3D Conversion",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matthew DeJohn"
                  ],
                  "abstract": "2D to 3D conversions vary greatly in terms of quality. Understanding what causes bad conversion and how to identify those issues is an essential skill to critique 3D and manage a conversion project. A bad conversion is usually the result of a cost cutting measure. Usually 1 or more of the 3 main artistic phases (depth, roto/matte, and paint) is shortchanged. — Inaccurate or conflicting depth cues and the “card-board cutout” effect arises when the depth process is shortchanged. Poor or low detail models, used to drive the depth of the scene, are the usual culprits. — The “rubber sheet” effect, “watery, stretched, or messy” edges, or lack of transparency is the result of shortchanging the paint process. To avoid painting occluded surfaces, the “rubber sheet” approach creates a sense of depth with no distinct separation between elements. Automated paint process often lead to “Watery, stretched of messy edges”. A transparency, such as smoke, is often allowed to play against a wall instead of in mid-air because that could require paint to remove and replace the smoke. — A “composited” looking shot can arise when the roto/matte process is shortchanged. Flyaway hair may be removed or matte edges may be overtly apparent because they are too hard or soft. This makes the shot look composited, even if it was captured practically. — Uncomfortable or fatiguing conversion arises if there is poor QC or stereography. Vertical alignment, too much positive parallax, and poor stereo continuity are likely causes of uncomfortable of fatiguing conversion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Conversion",
                      "2d to 3d",
                      "depth cues",
                      "monoscopic",
                      "stereoscopic",
                      "card-board cutout",
                      "rubber-sheet",
                      "cost cutting",
                      "eye fatigue",
                      "winking method"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001386"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "European Broadcasters' Requirements for Production Video Monitors",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202010/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Salmon"
                  ],
                  "abstract": "Video monitoring in the production of TV programmes is important since it is essential that the visual appearance within a single programme is consistent, and that consumers do not need to adjust settings on their TV sets for each programme or when switching channels. Standards are also important to facilitate the exchange of material between broadcasters, and they must be stable in the long term to ensure that material from the archive can be broadcast along-side more recent productions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2010-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001394"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2009",
        "conferences": [
          {
            "conference_name": "SMPTE Annual Tech Conference & Expo, 2009",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/",
            "articles": [
              {
                "article_local_id": "7",
                "article_title": "Audio/Video Synchronization in Compressed Systems - A Status Report",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. Patrick Waddell"
                  ],
                  "abstract": "Audio/Video synchronization (“Lip-sync”) is an ongoing problem in digital multimedia broadcasting. This paper will review some of the sources of the problem (end to end in the system), as well as current work towards resolving it being undertaken by different organizations (SMPTE, IEC, EBU, ATSC, CEA, …) worldwide. A new CEA “CEB-20” which provides detailed decoder implementation guidance will be reviewed in detail. The work of the current SMPTE Study Group will also be reviewed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001300"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Detection and Correction of Lip-Sync Errors Using Audio and Video Fingerprints",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kent Terry",
                    "Regunathan Radhakrishnan"
                  ],
                  "abstract": "A method for measuring and maintaining time synchronization between an audio and video stream is described. Audio and video fingerprints are used to create a combined audio/video synchronization signature (A/V Sync Signature) at a known reference point. This signature is used at later points to measure audio/video timing synchronization relative to the reference point. This method may be used, for example, to automatically detect and correct audio/video synchronization (i.e. lip-sync) errors in broadcast systems and other applications. — Advantages of the method described over other existing methods include that it does not require modification of the audio or video signals, it can respond to dynamically changing synchronization errors, and it is designed to be robust to modifications of the audio/video signals. — While the system requires data to be conveyed to the detection point, this data does not need to be synchronized with, or directly attached to, the audio or video streams. As this method uses fingerprints it also enables other fingerprinting applications within systems, such as content identification and verification. In addition, it may be used to maintain synchronization of other metadata associated with audio/video streams.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001302"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "On How Metadata Enables Enriched File-Based Production Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dieter Van Rijsselbergen",
                    "Erik Mannens",
                    "Maarten Verwaest",
                    "Rik Van de Walle"
                  ],
                  "abstract": "As file-based production technology gains industry understanding and commercial products are becoming common-place, many broadcasting and production facilities are commencing re-engineering processes towards file-based production workflows. — Sufficient attention should however also be spent on the development and incorporation of standardized metadata in order to reach the full potential of such file-based production environments. In addition to its initial meaning, metadata and underlying data models can represent much more than just some meta-information about audiovisual media assets. In fact, properly modeled metadata can provide the structure that holds various media assets together and that guides creative people through production workflows and complex media production tasks. Metadata should hence become a first-class citizen in tomorrow's file-based production facilities — The aim of our paper is to show how standardized metadata standards and data models, complemented by custom metadata developments, can be employed practically in a file-based media production environment in order to construct a coherently integrated production platform. We discuss the types of metadata that are exchanged between different parts of the system, which enables the implementation of an entire production workflow and provides seamless integration between different components.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001299"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Decomposing Media Operations Leveraging Advanced Content and Metadata Storage Management Solutions",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Campanotti"
                  ],
                  "abstract": "As the paradigm for media operations continues to morph in this ever-changing economic and technological environment, content owners face increasing challenges with respect to improving operational efficiencies, preserving content and effectively monetizing their valuable assets. Add to these challenges the changing expectations of the viewer and the multitude of new content delivery mechanisms, and the complexity of the situation rises exponentially. — Although it is not necessarily a convenient perspective to take, a high-level view that deconstructs the media organization into its component workflow entities, or its macro-blocks, not only provides a clearer picture of information and content flow throughout the facility, but also illuminates possible efficiency gains and ROI opportunities. If done correctly, this decomposition can also be used to remove dependencies between these organizational macro-blocks adding operational flexibility to the list of potential benefits which can be realized. — This paper takes a macro-level view of the media organization and shows that technical blocks focusing on content storage management (CSM) and metadata storage management (MSM) are fundamental to the future agility and growth of such an organization. Armed with a clear understanding of the workflow components that comprise a media operation and of technological enablers such as MSM and CSM solutions, content owners can quickly recognize advanced business opportunities with little added investment and little or no human involvement.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001298"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "What will Replace the CRT for Professional Video Monitors?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "Cathode-ray tubes (CRTs) have all but disappeared from the marketplace, and new display technologies are rushing in to take their place. Today, consumer TV sales now drive the market for displays, not professional applications. Are these new display technologies suitable for reference-grade monitor applications? The answer is yes, although the two most common technologies (LCD and plasma) both have advantages and disadvantages, while other technologies (OLEDs and FEDs) - while promising - are still waiting in the wings.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001310"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Ultra High-Definition TV (UHDTV): Development of Next-Generation TV Video Equipment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "T. Kudo",
                    "D. Ito",
                    "K. Arai",
                    "T. Tsukamoto",
                    "T. Higaki",
                    "S. Yahagi"
                  ],
                  "abstract": "Ultra High-Definition TV (hereinafter referred to as “UHDTV”), featuring 33 megapixels with 22.2 multichannel sound, adds a new sense of reality to TV programs. We are currently developing new video equipment for a UHDTV system, enabling us to shoot and record immersive scenes for sports, nature and art coverage for UHDTV program production. NHK's UHDTV system, generates images with 16 times the spatial sampling of current HDTV, consists of 4layers (G1, G2, B, R) of the Gch diagonal pixel offset structure and each layer is 3840×2160. A new, compact down converter exclusive to UHDTV program production converts 8K (7680×4320) images to 4K (3840×2160) or HDTV images; it's also equipped with an HDTV image cut-out function, a color correction function, and an energy-saving function. Because a second-dimension digital filter process is applied for converting Dual Green UHDTV signals to UHDTV signals, it can excerpt high quality HDTV images smoothly from arbitrary UHDTV images on a live feed, which make a single source effectively multipurpose. This converter is expected to be used for HDTV sport programs such as football games, to pick up specific players from UHDTV images. New lenses are also being developed for UHDTV cameras. New wide-angle and portable zoom lens have been specifically designed for UHDTV imaging. The view field of the wide lens is 100 degrees, the angle at which the sensation of reality becomes saturated. Zoom ratio is 10:1 (18–180mm focal range), while the maximum focal length is triple that of existing lenses and the resolutional power at the center is more than 250 line pairs per millimeter (LP/mm). In addition, a compact camera and recording and playback equipment for UHDTV have been developed. This report provides a UHDTV video equipment development, starting with a consideration of the signal processing of the down converter, and the lenses.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001311"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "2009 Survey of Digital Storage in Professional Media and Entertainment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas M. Coughlin"
                  ],
                  "abstract": "Results from an on-line survey of SMPTE professionals in February and March, 2009 showed some trends for the use of digital storage in professional content capture, editing and post production, content delivery as well as archiving and digital preservation. The survey revealed the evolution of storage technology for professional video including the growth of flash hard disk drives in content capture, developing trends for content distribution and the growing use of “warm” disk-based archives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001313"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "The Importance of Media Verification for Effective Content Management Workflow",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Harry Aine",
                    "Kirk Marple"
                  ],
                  "abstract": "The value of a media asset lies in the owner's ability to access and use that content when needed. For this reason, media verification is a critical element of effective content asset management. This paper will explore three major phases that are necessary to fully implement and attain the benefits of both disk and tape file-based content management workflows, in the process examining the obstacles encountered throughout these three phases, strategies for eliminating those obstacles, and ways in which content producers and owners can use media verification to ensure that all of the media required for production (or delivery) has been verified off the archive. It will also examine how, as a seamless part of the asset management workflow, media verification and indexing allow media organizations to federate storage archives and use a central database to search media assets, in turn maximizing use of their archives. — Media verification can be implemented in three tiers addressing wrapper data, basic metadata, and content verification. By providing deep QC (evaluating the media at the physical level) and ensuring the presence and integrity of all pieces on ingest, the media verification system provides immediate confidence and a baseline for indexing and later verification. The ability to configure the scanning and indexing process, as well as the rules and settings governing it, allows the content owner to target and maximize performance according to the company's business needs. By exchanging rich metadata with other content management systems and feeding a centralized metadata repository, the media verification solution facilitates specific verification tasks through the user's preferred MAM interface and provides powerful search capabilities across the enterprise. — This paper also incorporates three interviews with content producers/owners, not only to discuss the obstacles they faced in fully realizing the benefits of file-based content management workflows, but also to gain their insight into related processes. Finally, this paper will discuss techniques for adopting media verification systems within a highly automated and easily managed content asset management workflow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001315"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Beijing TV Station SOA Based Network Production System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bi Jiang",
                    "Yu Jun"
                  ],
                  "abstract": "The BJTV New Station Network System was designed starting in May of 2005, with installation completed by August 2008. On-Air operations commenced on April 1st, 2009. The design of whole network system is HD and SD compatible, and features a fully file-based production workflow. The system includes backbone platform system, News system, Sports system, Normal post production system, Deep post production system, Station Promo editing system, Ingesting system, Studio room sharing network system, MAM system, Program planning (Chief-Editor) system and production management system. The total storage capacity is: on-line 500TB, near-line 100PB. The total number of servers is 500, and the total number of terminals is over 1,200. — The system is constructed by adopting SOA concept, and utilizing backbone platform to facilitate integration and connection of every business system. Based on the requirements of broadcasting and TV industry, the system utilizes EMB (Enterprise Media Bus) concept. Enhancements to standard ESB technology were used to manage the different types of distributed storage in the system, to realize transferring of media files among system, and for format conversion. The backbone platform created by the adopting ESB+EMB structure makes the new BTV production network system easy to manage. It also provides secure operation with high efficiency. In the future, a new business system could be integrated based on this platform. Since the technical concept of network production system is relatively matured, the article intends not to describe further on construction technologies of the BTV network production system. The article, rather, focus on how to construct a large size network production system by utilizing SOA technology to integrate multiple network production systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SOA",
                      "ESB",
                      "EMB",
                      "BPM",
                      "network production system",
                      "TV station total solution"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001296"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Workflow-Driven Design in File-Based Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joey Faust"
                  ],
                  "abstract": "Successful file-based television production, post-production and distribution requires an understanding of and adherence to a well-documented workflow. Technology selection should be secondary to this workflow, because the way in which the system is to be used must drive its design. A major challenge for designers of these systems is to completely understand the workflow and translate that understanding into architecture, technology, and configuration. — The dependence of technology on workflow has made it increasingly worthwhile for systems integrators, technology vendors, and engineering departments alike to take a workflow focus in their design. Such a focus can be achieved through various methods, and by using different design tools, templates, and metrics.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001294"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Selecting Production Parameters to Ensure that Picture Quality Accommodates the Intended and Possible Future Imaging Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Corley",
                    "Moss Scott",
                    "David Adams"
                  ],
                  "abstract": "For many years there has been an emphasis on increasing dynamic range and color saturation in television and, to an even greater extent, in digital cinema. This begs the question; just how much data do we really need to record and store? An epic motion picture to be shown on a 20 m screen at 3000:1 contrast ratio could justify the ultimate image quality, but this could be overkill for a daily breakfast show typically viewed in a kitchen. This paper discusses aspects of studio production and image quality with regard to present day imagers and current market trends.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001307"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "File Based Sports Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Bergeron"
                  ],
                  "abstract": "File-based workflows have revolutionized news production, even migrating from the on-air server to the camera. NLE features taking advantage of this trend, found to be as powerful in dramatic production and electronic cinematography, continue to claim more production credits. Additional file based tools have emerged, as higher quality file based imaging and post production has become commonplace. Live sports production has appeared to remain a bastion of streaming AV, where the skill sets necessary for real time media have taken precedence over the ability to re-create a compelling narrative from a collection of raw media. — Daily twenty four hour sports highlight coverage and retrospective sports production has grown in parallel with the live broadcast, and the repackaging of gripping game footage day by day or season by season has become an integral part of the sports broadcasting. Here the advantages of file based production have already been realized. As broadcast and dramatic production tools have merged and the speed of data networks have even surpassed that of streaming media; the distinctions between broadcast and dramatic production have become more logistical than technical. — This paper will examine the innovations and possibilities of file based sports production. We will look at the concepts and implications of moving from real-time to faster than real-time content transfer. As broadcasters seek to offer viewers with ever more viewing options, ready availability of alternate content is always a tempting proposition.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001306"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Case Study: File Based Workflow from Acquisition to Air",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Foti"
                  ],
                  "abstract": "WGBH is one of the largest Public Television operations in the US producing more than one third of the programs seen nationally on PBS. Program distribution platforms include; over the air broadcast channels, Cable TV, Satellite, DVD and web streaming. On the horizon is broadcast to mobile handheld devices through ATSC M/H. Over the years technological advancements moved the facility infrastructure from analog to digital but the production workflow was essentially the same as it had been for many years, a linear process involving movement of physical media from one step to the next toward the final deliverable. In late 2008 an analysis of the current production practices was undertaken with an eye toward moving to a file based workflow. In early 2009 the first phase of a transition from a largely tape based linear production workflow to a file based process took place. This paper describes the system as implemented, which is based on a SAN (Storage Area Network) architecture that ties studio ingest, edit and final packaging for air.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001303"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "On-Set Generation of Color Corrected Dailies in Digital Cinema Production",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert B. Currier",
                    "Yuri Neyman"
                  ],
                  "abstract": "The amount of time between shooting a scene and being able to view dailies to evaluate the results has decreased from a matter of days on film productions to almost instantaneous on video productions. However, with the introduction of file-based workflows, this time has once again increased due to the need for post-processing of the raw image data. New developments in file-based workflows now allow for the creation of dailies on the set during production—rather than overnight at a post-production facility— providing rapid feedback for the cinematographer and director. Creating dailies becomes an integral part of a file-based workflow including data management and backup, color correction, dailies production, editorial proxy generation, and color metadata creation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001308"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Program Loudness and Loudness Management",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth Hunold"
                  ],
                  "abstract": "Television programs are typically delivered without a specification for loudness. As a result, the loudness of television programs can vary significantly. Some broadcast networks have asked for programs to be delivered at a specified loudness. Have program producers been meeting the delivery specification? For programs delivered where loudness has not been specified, how much does loudness vary program-to-program? Approximately 80 prime-time television programs were recorded for analysis to determine their loudness. Loudness was measured using the ITU-R BS.17701 standard. The analysis will show how consistent loudness is for a network. For networks that specify a target loudness, the analysis will show how well the target is being met.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001301"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Virtual File Systems for Dynamic Content in Digital Production Workflows: A Novel Approach to Integration of Video Applications and MAM Based Archives",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dmitry Klimov",
                    "Jan Weigner"
                  ],
                  "abstract": "IT-based television workflows have matured significantly over the last few years. The new, completely IT-based approach to TV production and broadcast has proven to be highly scalable and extremely cost-effective. Despite all the advances in technology it till takes a lot of work to integrate the wide range of different applications, such as non-linear editors (NLE), video servers, web portals, and legacy video archives. This document introduces a novel, open and transparent approach to dynamic content exchange between Media Asset Management (MAM) system based video archives and various video applications. The ultimate goal is providing each video application with the video format it wants in which ever codec it prefers regardless of which physical format it is stored in and where it is really physically located. This paper will describe the ideas in detail and also how far we have come implementing them.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001305"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Automation of Coordination: Business Process Management for Media Companies",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tobias Soppa",
                    "Felix Froede"
                  ],
                  "abstract": "This paper dissects the problems and challenges that the typical media company faces in aligning their fast changing technology and business requirements with their increasingly complex production processes and shows how Workflow Management Systems (WfMS) can leverage a Service Oriented Architecture (SOA) and the concept of Business Process Management (BPM) to streamline production. With a Workflow Management system, automated handoffs between functions, notifications and status updates replace inefficient manual coordination efforts. Scheduling can also be automated to assign tasks to human or machine resources. Included are examples of how Workflow Management Systems are used in media companies such as SONY, the First German Television ARD and Warner Bros., to manage their processes holistically and to integrate and optimize these processes on a global scale.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001295"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Proposal for Practical Screen Luminance Uniformity Measurement",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Francois Helt"
                  ],
                  "abstract": "The traditional way to measure screen uniformity in Cinema is by pointing manually a measuring device at a few locations on the screen. This method is subject to operational errors and not foolproof. — As an increased quality control is required by Digital Cinema a better method is needed. It is also worth noting that luminance variations are also affecting color measurements. — Large screen projection is always subject to vignetting. A set of practical vignetting models is proposed to help define a typical vignetting effect for cinema projection. — From these models one can devise a method and apparatus that may give practical luminance uniformity measurements. A proposal for specifications with tolerances is given.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001309"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Taking File-Based Workflows to the Next Level: Project and Timeline Based Integrations",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ilja Strobbe",
                    "Matthias De Geyter",
                    "Luk Overmeire"
                  ],
                  "abstract": "Broadcasters are rapidly adopting file-based media production workflows in their back-end facilities. To a considerable extent, the application of file formats such as MXF for media exchange and AAF for representing edit decisions brings about unprecedented advantages by providing the essential “glue” between different system components. The integration between a central asset management (MAM) system and craft editing suites is a typical, meanwhile widespread practice that reconciles pre- and post-production functional steps based on dedicated MXF rewrapping, EDL to AAF timeline conversion and metadata transformations. By imposing additional constraints on the applied file formats by means of MXF Application Specifications and the AAF Edit Protocol, the baseline for a successful media file and edit interchange between products of different vendors has been established. Concurrently, similar integration solutions based on QuickTime and FCP XML have emerged. — The time is ripe to stretch the outlined paradigm to its next level: the exchange of multiple edit timelines, composite bin structures and other project information between different systems. This extension would clearly accommodate more complex integrated workflows than established to date such as a better structured programme pre-production, temporary archiving of editing projects, mixed craft editing on central storage using different applications and even automatic forwarding of search results to appropriate user bins. — This paper explores state-of-the-art techniques for exchanging project and timeline information with and between major post production suites and pinpoints the present shortcomings and bottlenecks. It reflects on different approaches and candidate formats for bin structure exchange and also discusses the possible role of application interfaces. Finally, the business need is taken into account and considered against the implied complexity. The reflections presented in this paper are valuable for all technical practitioners dealing with the implementation of file-based production workflows.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "AAF",
                      "MXF",
                      "file-based integrations",
                      "post production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001304"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Keeping Video Quality Pristine throughout the Production Process: Introducing 10-bit 4:2:2 AVC/H.264 Encoding",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yasser F. Syed",
                    "Pierre Larbier"
                  ],
                  "abstract": "This paper discusses how using the 10-bit 4:2:2 AVC/H.264 encoding profile for transmission can maintain quality throughout the production process workflow. Upto now an MPEG-2 4:2:2 8-bit profile was used, the new AVC/H.264 encoding profile will allow for significantly lower transmission bandwidth or higher quality for the same transmission links. The profile is also compatible with pre-existing native SDI signal infrastructures used already in production processes. Furthermore 4:2:2 10-bit processing can help to preserve quality during multi-generation encodes/decodes that can happen often in the production process. This paper presents empirical results using real-time implementations to demonstrate the advantages of using this profile. Examples are also presented where this new technology can assist in production workflows ranging from remote uplinks of live broadcasts, non-collocated collaboration of dailies, support of playout-to-tape infrastructures, to international distribution & editing of content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001323"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Balancing New and Old, Multi-Channel Encoders Delivering MPEG-2 and MPEG-4 AVC Workflow Efficiencies",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ian Trow"
                  ],
                  "abstract": "Compression encoding is in a state of transition, MPEG-2 is the dominant incumbent for standard definition whereas MPEG-4 AVC is the promising upstart, catering for both handheld and high definition applications. — MPEG-2 has been written off by many as being a standard that has been fully developed leaving no room for improvement. However, broadcasters have forced the issue of further MPEG-2 improvements to protect the significant infrastructure investment and seek more revenue from existing platforms. Technology advances have allowed new theoretical algorithms to be applied to MPEG-2 and MPEG-4 AVC encoders resulting in a range of new and unfamiliar techniques being deployed. Look-ahead, adaptive pre-processing, rate-distortion optimisation, hierarchical B frames, sub pixel motion estimation, variable block size and high profile support are all terms used to justify the improvements implemented on the latest generation of encoders. But what do these terms mean, which compression standard do they apply to and, most importantly, what efficiencies can these techniques deliver? The first part of the paper will explain these techniques and outline the potential benefits. — The second part of this paper will compare and contrast the options for multi-stream encoding. Streaming is now becoming a serious issue for broadcasters seeing their audiences fragment in terms of viewing preferences and play-out platforms. Catering for live and offline content consumption on a range of devices use to imply further workflow steps. Cost conscious broadcasters are now looking to source encoders to produce multiple streams to improve workflow and reduce overheads.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001324"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "The Rollout of 3 Gb/s Infrastructures",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Randy Conrod"
                  ],
                  "abstract": "This paper will review the evolution of digital infrastructures for broadcast television, explain how data is organized in the 3 Gb/s serial digital domain, and explore the possibilities that exist for this new infrastructure. An explanation of how the video/audio/data essence and metadata are organized in the serial data stream is provided for standard definition and high definition, including 1080p, as well as for 2× formats (left eye, right eye) for 3D television and “dual-link” production formats. The new 3 Gb/s infrastructure not only brings 3D television into the realm of possibility for broadcasters, but also includes 32 channels of embedded audio, a higher bit depth (12-bit) for video, an alpha or key channel with the program signal and the utilization of RGB color space for video production in television.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001326"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "ABC's Bandwidth Independent Fiber Optic HD Central Switching Center",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Bauer"
                  ],
                  "abstract": "This paper presents the design and construction concepts for ABC's new HD Central Switching Center, which is the first 3 Gig HD-SDI television switching and transmission plant capable of support 1080p/60 and the emerging 3D TV standards implemented on a fully-fiber based infrastructure. The paper focuses on key decision processes, technology choices and, the desire to implement a future proof format and bandwidth independent television broadcast facility and illustrates the challenges that were faced in designing a completely fiber based plant including the analysis of technical limitations and constraints to a traditional coax-based plant. The paper will also address the novel methods needed to design the fiber cable infrastructure and the new terminal equipment needed to satisfy TV operations. A discussion is included on the implementation of an alternative routing methodology that utilizes advanced tie-line management to essentially create a signal routing cloud that permits users from any destination to access any source on any router within the ABC campus. Finally, an improved approach to transmission operations will be discussed. This approach employs universal routing control, integrated monitor control and alarming, and a single work-surface panel to improve workflow efficiency.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001327"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Increasing Efficiency in Digital Distribution of Media - Concurrency and Conforming",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Stevenson",
                    "Mike Nann"
                  ],
                  "abstract": "The demand for wider distribution and syndication of content brings with it the need for more efficient mechanisms to deliver content to distribution points. Fully digital distribution via terrestrial IP-based networks or satellite offers many advantages over traditional physical delivery, but technical and workflow obstacles must be overcome for these benefits to be fully realized. The challenges are compounded by the expanding and varying nature of distribution partners, with a scope much greater than earlier broadcast affiliate models. New approaches to distribution systems and workflows can overcome these challenges and greatly increase digital distribution efficiency.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001328"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Error Concealment Methods for Improving HD Video Quality in Internet Transport",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Benny Bing",
                    "Camille Mazataud"
                  ],
                  "abstract": "This paper presents some error concealment (EC) schemes for high-definition (HD) videos encoded using the H.264 and VC-1 codecs. These schemes enhance HD video quality in online Internet transmission without relying on feedback mechanisms. We propose and implement an EC method, and show that the peak signal-to-noise ratio (PSNR) improvement can be substantial (17 to 24 dB for a variety of HD videos under a packet loss rate of 20% and 25%). Although the schemes are not dependent on the use of error resilience methods such as flexible macroblock ordering (FMO), the best performance is usually achieved when FMO is employed. We will compare the performance of these schemes and evaluated the overheads associated with FMO. Finally, we will provide demos that clearly illustrate the benefits of the EC methods.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001329"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "The Evolution of Watermarking and Fingerprinting Technologies: From Protection to Monetization",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jaap Haitsma"
                  ],
                  "abstract": "The introduction of new technologies has caused the broadcast industry to experience rapid and often drastic transformation. We are now entering a new digital TV, broadband and mobile age where the classic distribution model of platform operator to consumer is dissolving. People are now able, using an array of digital tools, to create, distribute and consume content, anytime, anywhere. — Content providers and marketers tap into a vast arsenal of new technologies and services at their disposal to reach an ever-more sophisticated audience. Today they are testing a myriad of different content on multi-platforms to differentiate their brands and content offerings. In such context, measuring success has become paramount to ensure they are wisely allocating their resources and budget. — In an ever expanding universe of choice and availability of media content, broadcast and internet tracking solutions are becoming critical tools for maximizing content value throughout its life cycle. The new wave of content identification technologies will transform the way content is distributed, consumed and paid for.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001330"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Approaches to Non-Glasses-Based 3D Displays",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas G. Edwards"
                  ],
                  "abstract": "Recent interest in delivering 3D content to the home has been tempered by some reluctance of viewers to wearing stereoscopic selection devices (“glasses”). In addition, the geometry of in-home 3D viewing may enhance accommodation/convergence mismatch of stereoscopic displays that could cause some viewers visual fatigue. Both of these issues motivate the desire for “non-glasses-based” 3D (NG3D) displays, also known as “autostereoscopic” displays. This paper will address the general theory of the light field, a function that describes the amount of light traveling in every direction through every point in space. It will then discus how this light field could be generated to allow for NG3D displays. These mechanisms include integral photography, lenticular displays, parallax barriers, computer generated holography (CGH), and time multiplexed image steering.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001316"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "D-ILA® Full Resolution 8K Projector",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Furuya",
                    "R. Sterling",
                    "W. Bleha",
                    "Y. Inoue"
                  ],
                  "abstract": "JVC has developed a D-ILA™ projector for Super Hi-Vision (8Kx4K) that NHK of Japan has proposed as a standard for an ultra-high-resolution display system format. In previous demonstrations, the Super Hi-Vision image was created using two 4K2K D-ILA projectors in a vertical stacked configuration. This method could not reproduce the pixel definition of 8Kx4K precisely. A three- chip D-ILA projector has been realized using the new 8K by 4K (33Mpixel) 1.75-inch diagonal D-ILA device developed by JVC. This prototype is the world first full 8K × 4K resolution projector. The LCOS backplane required advancement in LSI technology. JVC developed new high voltage transistors and MIM capacitors for the small pixel size. A pixel pitch of 4.8 μm was achieved. A new optical engine was developed to meet the increased brightness and contrast ratio required for Super Hi-Vision. 10,000 lumens with a 5500:1 sequential contrast ratio were demonstrated. A D-ILA projector interface for the high data transfer rate required for real time 8K by 4K images was developed. In addition the system connectivity and ease of installation were improved. The projector will be used for the development of Super Hi-Vision by NHK and establishment of a new standard. The projector will provide high image realism and brightness for demanding applications in visualization, simulation and entertainment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001312"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Emerging Digital Post-Production File-Based Infrastructure, Workflow, and Process Enhancements for Theatrical and Episodic Television Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David W. Carroll",
                    "Jim Farney"
                  ],
                  "abstract": "For the past 20 years, technology for digital editing, processing and storage of film, video tape and digital file originated content has continued to advance until today it is the norm. However, many problems still affect digital post-production including required storage size and performance, access speed, storage and network bandwidth, copying and transport of many large files, tracking metadata, and managing files and versions. — By optimizing the digital infrastructure and storage fabric network design, incorporating lossless compression, and leveraging media-specific SOA workflow driven processes and services, most tasks can be orchestrated and significant portions of workflows can be automated, resulting in lower costs and higher quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001297"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Building and Managing a File Based Wireless ENG Infrastructure",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "George Maier"
                  ],
                  "abstract": "The development of microwave and wireless video file transfer technology, as it applies to ENG, is an on going endeavor. For the last few years, we have focused on tools that will enable the transport of files from the field to the studio. Now that these tools are becoming available, the time has come to focus on what is needed at the studio to provide a scalable hybrid workflow that can support live news as well as file based news. — As more of the broadcast infrastructure moves toward IT techniques for managing file based media, more emphasis is placed on building a service oriented architecture (SOA) that will support broadcast operations from end to end. The integration of news into the SOA requires support for multiple secure simultaneous IP connections to and from field resources that will transport news content over a variety of disparate networks to insure reliability. — More than ever, Electronic News Gathering requires greater levels of efficiency, operational transparency and an easily measureable ROI. This paper will review progress in the field, and explore the use of purpose built studio gateways and servers that effectively integrate a field news fleet into the SOA as a transparent extension of studio operations. We will examine a solution that offers newsroom and field workflow management, field asset management, and looks at new ways to leverage metadata support.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001318"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Getting HD Files from the Scene to Air in Record Time",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fred Fourcher"
                  ],
                  "abstract": "Getting HD content from the field to air is a challenge because the resolution is up to 6 times greater than SD. Increasing the submission time is not an option, so we will discuss methods to keep the quality and time of HD contribution comparable to SD.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001319"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Move to HD without Bandwidth Penalty; Perfecting HD Streaming",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Pelkey",
                    "Melanie Charles"
                  ],
                  "abstract": "Converting satellite-enabled video networks to MPEG-4 compression and DVB-S2 modulation allows operators to realize significant bandwidth savings and subsequent revenue generation - making new HD programming more feasible. But do the bandwidth savings and increased revenue offset the cost of launching a HD channel for a private network? This paper explores strategies to move to HD without expending exorbitant bandwidth costs and compare the different media distribution options. — Among the ideas presented will be: (1) Moving to MPEG-4 HD codecs from MPEG-2 (2) Transitioning to HD content creation (3) Maximizing the DVB-S2 modulation spec (4) Converting to a file-based broadcasting platform (5) Simulcasts to legacy TV monitors at the receive sites",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001322"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Field-to-Air-to-Online-to-Mobile: Cross-Platform Integration and New Technology Approaches to News & Sports System Design",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Walter Raps",
                    "Jim OBrien"
                  ],
                  "abstract": "In recent years there has been considerable progress in remote-to-central-site news and sports feeds via IP networks of various types, using a variety of codec's. There's been good progress in how to handle the vast amount of incoming media with workflow automation. With viewership extending to Internet-and-mobile, and with the dawn of Addressable TV via project Canoe and similar Internet TV architectures, there are compelling reasons to review how we design TV networks for on-air, online and on-mobile operations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001320"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Stereo Coding with MVC",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Walter Gish",
                    "Christopher Vogt"
                  ],
                  "abstract": "This paper presents an investigation into the coding efficiency of the MVC (multi-view video coding) extension of MPEG-4 AVC/H.264. MVC adds prediction among multiple views to the temporal motion compensation and prediction known as inter-coding. Here we consider the case of only two views or stereo coding. How much coding gain should we expect from the addition of inter-view coding to the motion-only coding of left- and right-eye images? To answer this question we examine fundamental qualitative and quantitative differences between temporal motion vectors and stereo disparity vectors. These differences are related to simple properties of the images themselves and they affect the entire prediction stage and hence overall coding efficiency. Our results suggest that the differences between the statistics of motion vectors compared to disparity vectors along with the statistics of the resulting residuals offers insight into the overall coding efficiencies currently observed in stereo coding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001317"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Super-Performance 3 Gb/s in a Practical Application",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Hoffmann"
                  ],
                  "abstract": "Signal routing infrastructure that is installed today must be ready for 3 Gb/s transport even if there are no immediate plans to exploit it for rates above HD-SDI. However, the data rate increase from 1,5 Gb/s to 3 Gb/s has created some technical challenges that must be overcome for signal infrastructure investments to retain their value over the long term. This paper demonstrates that it is possible to build products today, that overcome the technical hurdles to offer superb signal performance at 3 Gb/s and thus assuring your upgrade to 3 Gb/s does not result in a down grade in performance. It discusses how long cable lengths – approaching 200 m - with 3 Gb/s signals are possible. It describes techniques that are used to obtain very low jitter specifications. It also outlines that the added benefit of this super-performance approach results in signals that are more robust. It concludes that investing in 3 Gb/s infrastructure today is entirely practical even desirable as to be ready and capable when you are ready to make the transition to the higher data rate.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001321"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Is There a Future for Digital Terrestrial Television Broadcasting? One Observer's View",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "The decade-long transition from analog to digital terrestrial television broadcasting (DTTB) has finally been completed, but the future of DTTB is now in question. The economic recession and cultural shifts in the way viewers watch television programming have had a severe impact on both advertising revenue and audience shares. — This has led some industry analysts to ask, was the digital TV transition even necessary? Or, has it enabled new ways for TV broadcasters to communicate with viewers and not only survive, but also even thrive in the 21st century?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001339"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "A Systematic and Flexible Architecture for IP-Based Media Services: Broadcast Technical Research Institute, KBS (Korean Broadcasting System), Republic of Korea",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Byunghee Jung",
                    "Myunghwan Ha",
                    "Moonsik Lee",
                    "Yeonhee Oh",
                    "Sungchoon Park"
                  ],
                  "abstract": "Recently, the Internet is regarded as an important medium for media services owing to its popularity and profitability. Major broadcasting companies have been developing and refining their websites to deliver their programs individually. To satisfy user's continuous and rapid requests for novel services, broadcasting companies should renovate their systems with service-ready architecture. In this paper, we describe a systematic and flexible architecture which collects contents (e.g. essence and metadata) automatically from production systems and serves the contents to various services properly. Employing standardized metadata and a program ID in exchanging contents between systems, the proposed architecture could collect contents systematically. KBS standard of metadata and a program ID have been achieved after two years of work. For a flexible supplying of contents to various services, we utilize open API. Open API which we define can be easily applied to websites, since it is designed over HTTP. Furthermore, users can generate novel services by mashing several service concepts using our open API. We developed a prototype system, called OASIS (Open Architecture for Systematic IP-based Service) system, realizing the proposed architecture. The system collects contents from KBS programming and playout systems and supplies them to our prototype web-based contents browser implemented with our open API. Since the open API is easily applicable to web-based applications, it could be applied to mobile devices and Internet-connected TVs. Also, the prototype browser can easily expand its service functions by adding functions of the open API. The OASIS system shows the usefulness of the proposed architecture.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001340"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "A New Single Camera System for Stereoscopic Image Acquisition",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Zoran Perisic"
                  ],
                  "abstract": "Three key elements determine the ability of a Stereoscopic System to capture a realistic 3D image: Wide angle of view, Inter-ocular distance and Convergence. Z3D achieves all three of these, in a compact, format-independent unit, that works with both film and digital cameras. It is a single camera and single lens system that includes an optical 3D viewfinder and a video 3D viewfinder which take the guesswork out of setting the convergence. It is compatible with existing 3D projection methods but can also be used for live 3D Video projection.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001341"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "2D to 3D Conversion for Post Production, Advertizing and Legacy Titles",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yusuf Broachwala"
                  ],
                  "abstract": "The paper will present advantages of using the 2D to 3D conversion in post production, 3D commercials and converting legacy libraries to 3D. The paper will also briefly discuss the methodology and process used for 2D to 3D conversion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001342"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "Centralized Multi-Station Operation - Take 2",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Wadle"
                  ],
                  "abstract": "About ten years ago, following the widespread deployment of master control automation systems in the U.S. station market, the concept of centralized operation of multiple stations under common ownership was evaluated and in a several cases deployed. The results of these initial multi-station centralizations were mixed, and a primary objective of significantly lower operating costs was not always achieved since the resultant savings in manpower proved inadequate to offset the cost of the required communications links at 1990s rates. Nevertheless, several of these centralized projects continue in operation today, and a few have been expanded or upgraded with newer technology. Overall, however, the anticipated substantial benefits of station group centralization have not been fully realized, and broadcasters continue to look for new models to improve their bottom line through reduced costs. — Today in the midst of a stark outlook for local TV station profitability - exacerbated by the recent economic crisis - station group owners are taking a second look at centralization. Specifically, this renewed interest is being fueled by technology and market advances that promise lower costs and simplified deployments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001344"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Backhaul of Live Television Using JPEG2000 in MXF over RTP",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Helge Stephansen"
                  ],
                  "abstract": "Wavelet-based compression technology, such as JPEG2000, is emerging as an alternative to DCT-based solutions such as MPEG-2 and AVC. Benefits including picture by picture compression, 10 bit resolution, and uniform compression for all pixels, provide an improved starting point for post-production provided that sufficient bitrate is allocated in the IP transport network. — MXF is gaining ground in post-production as a generic format for exchange of video and for program delivery, the paper will give offer a focused discussion of the implementation and encapsulation of JPEG2000 in MXF over IP. — There are several different protocols in use for the JPEG2000 contribution. This paper will provide an overview of JPEG2000 encoder / decoder implementations with regard to MXF wrapping for transport over IP. This provides real time ingest directly on video servers in parallel to using the live signal for direct broadcasting. The solution allows for combining synchronized transport of television and metadata, A comparison to alternative wrapping solutions with respect to key features such as packet loss, forward error correction, latency and synchronization issues.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001325"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Architecture for Embedding Audiovisual Feature Extraction Tools in Archives",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robbie De Sutter",
                    "Karel Braeckman"
                  ],
                  "abstract": "In the near future, it will no longer be sufficient that only archivists annotate audiovisual material. Not only is the number of archivists limited, the time they can spend on annotating one item is insufficient to create time-based and detailed descriptions about the content to make fully optimized video search possible. Furthermore, we observe an accelerated increase in newly created audiovisual material that must be described due to introduction of file-based production methods. — Fortunately, more and more high-quality feature extraction tools are being developed by research institutes. These tools examine the audiovisual essence and return particular information about the analyzed video and/or audio streams. For example, tools can automatically detect shot boundaries, detect and recognize faces and objects, segment audio streams, etc. As a result, they quickly and cheaply generate metadata that can be used for indexing and searching. On top of that, it relieves archivists of performing tedious and repetitive, but necessary low-added value tasks, for example identifying within an audio stream the speech and music segments. Although most tools are currently not yet commercially offered, it is to be expected that these solutions soon will become available for broadcasters and media companies alike. — In this paper, we describe a solution on how to integrate such feature extraction tools within the annotation workflow of a media company. This solution, in the form of an architecture and workflow, is scalable, extensible, loosely coupled, and has clear and easy to implement interfaces. As such, our architecture allows one to plug in additional tools irrespective of the software and hardware used by the media company. — By integrating feature extraction tools within the workflow of annotating audiovisual essence, more and better metadata can be created allowing other tools to improve indexing, search and retrieval of media material within audiovisual archives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Feature Extraction Tools",
                      "File-based Production",
                      "Media Asset Management",
                      "Annotation",
                      "Archives",
                      "Architecture",
                      "Integrated Workflow"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001332"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Automatic Flicker Removal by Digital Restoration Techniques",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Li Zhi-Yong",
                    "Du Kun"
                  ],
                  "abstract": "To rescue the precious archival films, China Archival Film Digital Restoration Project was approved in 2004. To carry out the project with numerous films, the automatic restoration methods are now urgently needed than ever. The aim of this paper is to report our recent related work. First, flicker in Chinese archival films was analyzed and classified into two categories: global flicker and local flicker. On the basis of the survey for the algorithms reported in literature, two techniques were devised for two kinds of flicker. The computational experiments show that the methods work well. The processing is fully automatic. This is important for the reduction of man-power cost in massive processing application.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital Restoration of old films",
                      "Intensity Flicker",
                      "Regularization"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001333"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Restoration of Damaged Korean Films by Using Various Image Processing Techniques",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chulhyun Kim",
                    "Vivek Maik",
                    "Sangjin Kim",
                    "Jaehwan Jeon",
                    "Joonki Paik"
                  ],
                  "abstract": "Recently, the digital cinema distribution chain takes an additional path for old, damaged films with proper restoration. Old films, which are acquired by a low-quality camera and stored in harsh condition, tend to have lot of defects compared with modern digital cinemas. This paper presents a set of image processing algorithms for enhancing and restoring old films severely degraded by camera jitters, film scratches, grain noise and poor contrast, to name a few. In 2005, Korean Film Council re-ran 30 years old animated films in digital, high standard quality. In this work we briefly introduce the restoration of the animation film, and provide additional, ongoing restoration works for old Korean film with consideration of the bottleneck between the main workflow and the intermediate equipment compatibility. Experimental results will be presented for restored samples of old movies and animations followed by the workflow pipeline of the proposed restoration module.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001334"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "Dealing with IP for Mobile in an MPEG World",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rich Chernock"
                  ],
                  "abstract": "Until recently, MPEG-2 Transport Streams have been the only means used to carry Digital Television (DTV). MPEG-2 provides the necessary underpinnings for broadcast quality delivery of DTV content, including a well-established timing and buffer model. The new ATSC Mobile DTV standard has chosen to instead use IP transport for both streaming and file content. Compatibility with other emerging mobile systems was one of the reasons for this choice. — This paper explains the use of IP transport in ATSC Mobile DTV for both streaming and file content. The protocol stack will be explained, as well as the mechanisms adopted to allow “broadcast quality” to be achieved. Additionally, considerations for differences in the component interconnections will be discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001336"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Latest Developments in Content Management Standardization: The Content Management Interoperability Services (CMIS) Standard Proposal by OASIS",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ugo Corda"
                  ],
                  "abstract": "This paper is an introduction to the OASIS content management standardization effort, still under way, called Content Management Interoperability Services. — After describing the rationale, history, goals and scope of the standardization project, the paper presents the basic architecture and technology components of the standard, including the abstract Domain Model (composed of a Data Model and a set of Services operating on the Data Model) and two concrete instantiations of that abstract model - i.e., the Web Services Binding and the RESTful AtomPub Binding. — Following a brief review of currently available implementations, the paper concludes with a discussion of how well the standard meets the needs of a typical content management system targeting the Media & Entertainment industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001314"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "A Bigger-Picture Perspective on the Small Screen and ATSC-Mobile Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glenn Reitmeier",
                    "Rajan Mehta",
                    "Greg Depriest",
                    "Sheau Ng"
                  ],
                  "abstract": "The launch of ATSC Mobile broadcasting will bring live television to consumers on new personal devices. But mobile broadcasting can be seen as part of a bigger trend towards making all forms of content widely available to consumers on any screen, anytime and anywhere. This paper will examine these major trends, provide some commercial examples of their impact and discuss important future considerations for new technologies and standards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001337"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Basic Elements of ATSC Mobile DTV",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wayne E. Bretl"
                  ],
                  "abstract": "An overview of the layered structure of the ATSC Mobile DTV system is presented. This paper is intended to be introductory only. Detailed explanations are in other sources. However, all of the system elements are mentioned, both existing protocols that have been adopted, and new features that are unique to the system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001335"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "U.S. Broadcaster Plans for Provision of ATSC Mobile DTV",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sterling Davis"
                  ],
                  "abstract": "As the U.S. broadcast industry gears up to provide ATSC Mobile DTV service to consumers throughout 2010, this paper describes the technical parameters of that service. It will include basic consumer use cases and system requirements necessary to implement mobile DTV. Services envisioned range from basic linear simulcast to interactive and location-based services, with a variety of premium and advertising-supported subscription plans. The primary value proposition for mobile DTV is live transmission of content identical to local television stations transmitted in full-motion digital format to a variety of consumer devices. This paper will summarize expected broadcaster launch plans, future use cases envisioned by broadcasters and station requirements to realize those plans.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001338"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "Proposed New RGB Gamut Display with True Color Saturation and Value Scales",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dan Baker"
                  ],
                  "abstract": "In the days of composite signals, the Vector display was used for precise video synchronization and timing due to the sensitivity of the color sub-carrier phase and resulting Hue to genlock and timing jitter. With component distribution and production, the Hue is not so sensitive to timing errors and other methods are used for relative component timing assessment. However, the Vector display remains a popular analysis tool for assessing the artistic color characteristics such as Saturation and sometimes the signal range or gamut of a video signal. However, the Vector display does not allow the determination of the actual color Saturation or color Value (vividness) as is often believed nor does it provide a useful indication of a valid RGB signal gamut. In fact, there is no commonly available real-time Waveform or Vector type XY display that directly indicates the color Saturation or color Value of the signal along with conformance to valid RGB signal limits. There is a need then for a new display tool that clearly shows the artistic metrics of color Saturation and color Value or Lightness combined with RGB gamut limits allowing a colorist to adjust live video signals into a valid signal gamut range such that the desired image quality is maintained throughout distribution. Similarly, there is a need to determine the impact on the artistic color quality of any gamma/matrix conversion or signal limiting during distribution due to various format conversions and legalizer processing. Therefore, this paper proposes and describes the application of a new real-time display technology in the format of a simple, 2-dimensional, triangular color space bounded by the so called “valid” color gamut RGB signal limits.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001343"
                  }
                }
              },
              {
                "article_local_id": "56",
                "article_title": "The Use of Flowfield Motion Compensation for 3-D Stereoscopic Moving Image Compression",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/56/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "Using flowfield motion compensation, it is possible to efficiently code 3-D stereo pair moving images. The displacement fields between left and right eye images have a different character than frame-to-frame flowfield motion compensation, since motion blur, edge coverage, and other properties are inherently and fundamentally different. However, the general construction can be applied effectively using the flowfield coding method based upon a floating point codec (using windowed-sinc and wavelet hybrids, as described in the Jan/Feb 2009 SMPTE Journal). Both the inter-ocular displacement as well as the frame-to-frame motion can be built into a related flowfield set. For example, a motion compensation spine can be coded, with an inter-ocular displacement coded as a displacement to the left and right eye motion compensation fields. — Another useful approach is to code flowfields both forward and backward, as well as in relation to inter-ocular displacement fields. Such an approach requires resolving holes and confounds which appear during reverse flowfield traversal. However, this technique allows multi-reference motion compensation while needing to convey less flowfields. Additionally, flowfields can be delta coded, since they tend to have coherence between frames. Also, inter-ocular displacement fields are similarly coherent, and can similarly be delta coded. Further the flowfield and displacement flowfields and deltas are highly correlated. — The result is an efficient method of coding 3-D stereoscopic moving images.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001349"
                  }
                }
              },
              {
                "article_local_id": "55",
                "article_title": "Pitch Blue™: A Real Time HDTV Store and Forward Program Delivery System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/55/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert P. Seidel"
                  ],
                  "abstract": "CBS and Ascent Media and Warner Bros. are some of the largest distributors of syndicated programming with a distribution footprint to over 1,350 television stations or 800 hub locations. This paper will describe the system developed by the joint venture between CBS/Warner Bros./Ascent Media for end-to-end origination, distribution, reception, storage, and play-to-air of high definition content. The system will employ MPEG-4 video compression and will allow for both 5.1 surround sound and stereo audio, as well as a variety of vertical ancillary data services. The “catch server” at each station will be capable of receiving signals from two separate satellite transmissions. The server will contain three Terabytes of storage and be able to play high definition HD/SDI signals or down converted SDI signals directly to air. The server will also respond to standard VDCP automation control commands. The paper will detail the command and control system for conveying record and program schedules to the 800 catch servers. It will review the error correction protocol and retransmission methods for replacing error packets. Also discussed will be the insertion process for splicing triggers using the SCTE 35 protocol. The paper will also detail the bit budget and RF link budget required to ensure the reliability factor of 99.96%.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001348"
                  }
                }
              },
              {
                "article_local_id": "52",
                "article_title": "I can See Clearly Now: A New Test Pattern for the Digital Age",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/52/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Norman Hurst"
                  ],
                  "abstract": "The colorbar test pattern was developed in the 50's to test analog television systems. It revealed many things that went wrong with analog video. Yet even though the problems it revealed no longer exist in today's digital video world, we still use it. Yet there are many things that can go wrong with digital video that “bars and tone” won't reveal. — This paper describes a new test pattern sequence that visually reveals many issues with digital video systems, including compression fidelity, colorspace mismatch, chroma downsampling, field-dominance reversal and lip-sync.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001345"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Using LED Backlight Display Technology to Provide Passive Forensic Marking for High Value Content",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Sterling"
                  ],
                  "abstract": "One of most effective and least technologically challenging ways to pirate content is to point a camcorder at a display screen. As compact and inexpensive HD solid state memory camcorders are becoming readily available, this presents a threat to those content holders attempting to protect high value content throughout the production and post-production process. — Forensic marking techniques are not new and watermarking technology exists to provide an audit trail for digital exhibition but can new technologies in home displays be leveraged to provide an effective system to protect content in post production environments? — We examine several ways in which this can be implemented and discuss the potential benefits of integrating a passive forensic marking system as part of a display device.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001331"
                  }
                }
              },
              {
                "article_local_id": "54",
                "article_title": "Broadcast Service Quality Monitoring Strategies",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/54/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rich Chernock"
                  ],
                  "abstract": "Today's digital television broadcast systems are quite complex. The systems range from single station operations to large, centralized station groups. The ultimate goal of the broadcaster is to provide a quality viewing experience for the customer. Monitoring service quality throughout the broadcast system is therefore a necessary activity. — For DTV content, video packets must be delivered on time, in-order and compliant with MPEG and ATSC standards. The “correctness” of a broadcast DTV “flow” is critical to ensure that all viewers will be able to watch the content. Unfortunately, these standards are quite complex and at times impossible to completely adhere to. Without the appropriate care, monitoring systems can result in an overwhelming number of alarms (most for unimportant non-compliance), which tend to obscure any real problems that exist. — The ATSC Recommended Practice on Bitstream Verification (A/78) has provided a methodology for filtering these alarms. Significant emphasis was placed on practical considerations that might impact the use of MPEG monitoring equipment, including suitable categorization of error conditions to avoid operator fatigue and placing more emphasis on errors that would directly impact the viewer. The resulting RP gives a common methodology that has been designed with real-world use considerations, which can significantly reduce the time required to address faults. — To match the complexities of centralized broadcast operations, distributed monitoring systems have emerged that allow monitoring of various points within the distribution system and consolidation of the metrics in meaningful forms. Approaches and strategies for applying distributed monitoring to the broadcast architectures will be discussed - using Tiling as an example. — Digital terrestrial broadcast signals are often cross-carried into other infrastructures, for example Cable. Often, there are business or contractual agreements on what modifications may be made to the signal, in terms of quality, services and components. Auditing compliance with these agreements in an automated fashion has been quite difficult in the past. New techniques for carriage auditing will be discussed in this presentation which will allow a broadcaster to understand what (if any) modifications have been made to their signal as it is incorporated into another system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001347"
                  }
                }
              },
              {
                "article_local_id": "57",
                "article_title": "Multi-Format Hybrid Transcoding Platform",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/57/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ali Etezadi-Amoli",
                    "Hugo Gaggioni",
                    "Shigeru Ohwada",
                    "Andrey Nikolov"
                  ],
                  "abstract": "As content producers adopt file-based workflows, and viewers demand a wider variety of delivery formats, the need for faster and more efficient ways to encode and transcode video files and metadata has greatly increased. This paper describes a new multi-format transcoding platform based on Intel and Cell/BE hybrid architecture to provide improved performance and high efficiency for post-production image processing tasks and customer content management workflows. — The proposed prototype system can support a variety of codec formats including proxy, J2K, MPEG2, AVC/H.264, DNxHD, for resolution independent video data contained in a wide variety of file wrappers. In addition to high-performance transcoding, the system can also be used to perform complex processing and multi-tasking operations in faster than real-time, due to its aggregate computational power of 3.2 TFLOPS. — The new platform has been designed around a flexible, scalable, open architecture concept that incorporates Java applications, consistent metadata management, and a SOAP-based interface to enable seamless integration with a variety of workflows and third-party components. This paper describes the technical details of the processing architecture, the benefits it provides to the users, and example workflows that the platform supports.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001350"
                  }
                }
              },
              {
                "article_local_id": "53",
                "article_title": "Automatic Content Based Video Quality Analysis for Media Production and Delivery Processes",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Annual%20Tech%20Conference%20&%20Expo,%202009/53/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Schallauer",
                    "Hannes Fassold",
                    "Martin Winter",
                    "Werner Bailer",
                    "Georg Thallinger",
                    "Werner Haas"
                  ],
                  "abstract": "Automatic quality control for audiovisual media is an important tool in several steps of the media production, delivery and archiving processes. Today, mainly technical properties of the material are checked, e.g. stream compliance, playtime, aspect ratio, and resolution or MXF compliance. Only some content properties can be checked automatically, e.g. blocking or luma/chroma violation. Other relevant content properties and impairments like noise level, sharpness, large dropouts, flickering or instability are checked by manually exploring the audiovisual content. In this work we focus on challenges and recent results in automatic content based visual quality analysis of video. We first give an overview on which visual impairments are relevant in which stages of the media production, archiving and delivery process. A set of requirements for impairment detection algorithms, tools and systems is presented. We show how impairment detection algorithms need to be designed in order to meet these requirements. Furthermore we show our recent algorithmic research results for two content based impairment detectors (freeze frame and video breakup detection). In order to facilitate interoperability and exchange of impairment metadata between different tools and systems, a standardized way of description is needed. We give an overview on our framework proposed for the description of visual impairments based on MPEG-7. In order to enable efficient human interaction with quality analysis results we present the “Quality Summary Viewer” application which allows a user to quickly grasp the frequency and strengths of visual impairments in the content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2009-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001346"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2008",
        "conferences": [
          {
            "conference_name": "SMPTE Technical Conference & Exhibition, 2008",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Computer Vision Technologies for Repurposing Multi-Distribution Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Claire-Helene Demarty",
                    "Siwar Baghdadi"
                  ],
                  "abstract": "Content creators are looking forward to spreading their offer of services, by repurposing their original content, usually first dedicated to broadcast, to other distribution channels. But multiplying the distribution channels does not and cannot mean multiplying the production cost: one really wants to “produce once, and repurpose many”. Moreover, “the faster the content production the better the workflow” remains a key aspect even for new distribution channels. To answer this need while taking into account the above constraints, innovative repurposing solutions are introduced from the initial stages of the broadcast production workflow. These solutions enable to speed up the process of high quality content creation, while generating new revenue. Simultaneous production of content for the Internet, mobile and IPTV is then achieved through a suite of automated tools, grouped together in a single workflow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Multi-distribution systems",
                      "repurposing",
                      "computer vision",
                      "HMM",
                      "BN",
                      "DBN",
                      "metadata"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001020"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "1080P, What Does this Mean for Broadcasters in the Short-Term?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ian Trow",
                    "Jean-Louis Diascorn"
                  ],
                  "abstract": "The drive towards progressive High Definition delivery is well underway. Many broadcasters are already contemplating bridging the technology gap between existing interlaced services to deliver 1080p. Blu Ray has now established itself as a global production standard based around 1080 / 24p and set picture quality expectations amongst viewers eager to see the picture quality replicated in their Terrestrial, Satellite and IPTV services. There is no doubt consumer demand exists, with viewers eager to transfer from being HD ready to 1080p deployed. — This puts broadcasters and service providers under pressure to meet viewer's 1080p HD expectations. — What technical strategies are viable to allow existing High Definition Interlace services to co-exist alongside 1080p transmissions? Will Scalable Video Coding be able to cross the gap between interlace and progressive, to allow seamless delivery of the most deployed HD standard, 1080i, and the new 1080p challenger? — With 1080p production equipment being scarce, often not scheduled to be available until 2010, how do broadcasters factor for future 1080p demands with limited scope to put in place an evolution towards 1080p today? Does 720p represent a half-way house towards full 1080p? — 1080p offers the promise of greatly improved HD service quality, but the steps towards this improvement are key to offering commercial services that allow linear and non-broadcast content to be high quality and profitable ventures. — This paper will focus on the short-term technical decisions broadcasters need to be making to realize their 1080p ambitions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001022"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "New Consumer Displays: The Challenge of Providing Content to Take Advantage of Them",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael A. Sterling"
                  ],
                  "abstract": "The cathode ray tube has been a key enabling technology for television since Vladimir Zworykin successfully demonstrated a small, primitive image display in 1929. Zworykin's invention, the Kinescope, was used in 1931 when the first all-electronic television receiver was offered for sale to the public.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001025"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "The Impact of Technology upon Metadata Costs: Courvoisier or Cold Duck?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Potter"
                  ],
                  "abstract": "The cost of collecting and organizing metadata for media assets remains high, although technological advances do - and will continue to - reduce these costs. As these costs continue to decline, media organizations will modify their practices to exploit opportunities that were previous uneconomical. — This paper examines the various components of cost associated with metadata, the impact that technology has had upon those costs, and how media enterprises have reacted to new opportunities as they have appeared. It further explores the potential impact of emerging technologies upon metadata costs and what effect they may have on the media and entertainment industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001034"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Building the Next-Generation Asset Management Solution",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric DuFosse"
                  ],
                  "abstract": "The introduction of high-speed hard disk drives progressively changed the industry. With such innovations as non-linear editing, video servers, and data tape libraries that use direct-access medium for tapeless workflows, technology has not only provided powerful and reliable tools but created new requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001035"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "CBS Television Network HDTV Satellite News Gathering Requirements",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gregory M. Coppa",
                    "Robert P. Seidel"
                  ],
                  "abstract": "This document describes a proof of performance test CBS Engineering conducted to validate the technical specifications and requirements for High Definition Satellite News Gathering (HDSNG). The test results indicate that HDSNG is now possible using much of the existing satellite infrastructure and is due to the evolution of two new technologies that use bandwidth more efficiently; specifically, DVB-S2 [1] modulation and AVC/MPEG-4 [2] video compression.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001039"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "AVC-Intra 100 Mbps Compression in a File Based Master Archive",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Bergeron"
                  ],
                  "abstract": "File based workflows are gaining popularity for HD post production. Uncompressed files offer maximum quality but file sizes can become so unwieldy that file based workflow advantages are lost. Small file sizes can be created using low bandwidth HD distribution quality compression, but content then lacks the robustness necessary for post production and generation of various deliverables. — In the wake of the standard definition DV production revolution, independent productions have likewise embraced the efficiency of 100 Mbps DVCPRO HD, operating natively on IT platforms through the post process, balancing efficiency with broadcast quality performance, but not approaching master quality. — Master level compression, for archiving and generation of multiple format deliverables has traditionally achieved robustness and quality with high data rates. Mezzanine level compression proposals have suggested even higher bit rate “visually lossless” compression working in an IT environment. As real world applications and budgets change, these definitions might need reconsideration, and perhaps advances in compression technology and available processing power can close the gap between needed performance and file size.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001030"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Efficient Lossless to Lossy Transcoding of JPEG2000 Codestreams for D-Cinema",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takahiro Fukuhara",
                    "Katsutoshi Ando",
                    "Hitoshi Kiya"
                  ],
                  "abstract": "In this paper, a method of lossless to lossy transcoding of images is presented by taking advantage of bitplane coding of JPEG2000. In the case of decoding of JPEG2000 lossless codestream's and subsequent JPEG2000 lossy encoding of the decoded image, lots of computational time is consumed especially during JPEG2000 lossless decoding. In order to reduce the time, partial decoding of the lossless codestream is proposed. In addition, by employing a unique rate control, the degradation of image quality caused by partial decoding is reduced. Experimental results show that the computational complexity is dramatically reduced, while the subjective image quality is almost the same as one by full-decoding of lossless codestream.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001027"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Considerations When Designing for the 3Gbps SDI Interface",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Sauerwald"
                  ],
                  "abstract": "When SMPTE 424M came out with the standard for a 3 Gbps Serial Digital Interface, much of what was standardized was similar to the HD SDI interface that is so well established and understood. The assumption of many early adopters of this standard was that you could use the same architectures to build 3 Gbps equipment as what had been used for HD SDI, and then build studios with this equipment in order to support the higher definition formats. Unfortunately when SMPTE 424M was approved, it included a relaxed jitter specification, allowing up to 0.3UI of alignment jitter rather than the 0.2UI which is permitted in SMPTE 292M - the HD SDI specification. This paper explores the consequences of this relaxed specification on system performance and looks at new architectures for studio equipment which are able to better tolerate the increased jitter, as well as discussing the fact that studio designers may want to look more closely at some performance measures of 3 Gbps equipment rather than just looking for ‘SMPTE 424M Compliant’",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001023"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Secure Content Distribution on P2P Networks",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mary-Luc Champel",
                    "Nicolas Prigent"
                  ],
                  "abstract": "Peer-to-Peer exchanges represent more than 50% of the exchanges over Internet today. If it were not mainly for illegal sharing of copyrighted content, there is very little doubt that those technologies would be considered differently and that content owners, in particular, would change their current opinion about P2P. Indeed, with the addition of dedicated security and management capabilities, we believe P2P can actually offer a new distribution mean that would ensure not only the protection of the content but also the privacy of its users and the integrity of its system. — Unlike what can be mostly observed today on Internet, P2P is not only about illegal file sharing and the same technologies can actually be enhanced so as to deliver Video-on-Demand and even LiveTV to the home via Internet. This paper will first explain how P2P technologies can be used so as to provide content owners with a new distribution media for both their popular and long-tail content for only a fraction of the cost of other distribution platform. In a second step, this paper will focus specifically on security issues and introduce several concepts that can be used so as to ensure that legal content distributed on P2P platforms can actually be protected against thievery and not be mixed with illegal content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001024"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Navigating the DTV Transition: How Broadcasters are Using AFD to Maintain Formatting Control of their Programming",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Clarence Hau"
                  ],
                  "abstract": "The 2009 Analog Shutdown is quickly approaching and television broadcasters have been preparing throughout this year. As programming content will continue to originate in both SD and HD for many years, broadcasters have been forced to find ways to maintain the presentation quality for each home viewer after the February 17, 2009 deadline.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001021"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Defining the Future Consumer Video Format",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ingo Doser",
                    "Carlos Correa",
                    "Rainer Zwing",
                    "Laurent Blonde",
                    "Juergen Stauder",
                    "Cristina Gomila",
                    "Jiancong Luo"
                  ],
                  "abstract": "The current display model, and with that, the consumer video format itself as the connecting element between the motion picture content creation world and the consumer display world are currently being challenged! • Consumer displays are offering new features, such as Wide Color Gamut and High Dynamic Range, to the audience, and there is yet no content that is capable of supporting these features. • The CRT-based display model currently used in content creation can no longer be seen to be a representative for new consumer displays. • The consumer displays themselves have no common reference, and due to the emergence of new display technologies it is not to be expected that display capabilities will converge in the future. • Content Creators like to use newest technologies but are confused about the approach, and about how to achieve best results for the consumer. • The current video format, which relies on the CRT model, can therefore no longer stand, and is to be revised. At the same time, the appropriateness of current coding schemes for delivery has to be revisited as well. — This paper describes challenges for the imaging chain in perspective to the changing and volatile landscape of display technologies; the question of how display evolution will impact — or better, can be exploited for — content creation. • This paper proposes two possible solutions, among which is a change of doctrines by abandoning the CRT display model for content mastering, and ultimately allow the content creators to utilize the full spectrum of capabilities of the new display technologies.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001026"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Mscope – Anamorphic Capture with Dual CIF HD",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Milan Krsljanin"
                  ],
                  "abstract": "Mscope facilitates the conversion of generic 4×3 aspect ratio originated pictures into the 16×9 aspect ratio frame format by maintaining optimal resolution and picture quality of the original images.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001048"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Rich Metadata Description for Interactivity and Dynamic User-Generated Information",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shaiwal Priyadarshi",
                    "Kourosh Soroushian",
                    "John Villasenor"
                  ],
                  "abstract": "Typical multimedia container formats offer practical and efficient methods of encapsulating standard multimedia data types such as audio, video and subtitles. The same efficiency, however, does not typically extend to metadata, especially in most consumer targeted multimedia container formats. Often the descriptive and interactive metadata associated with content is collectively placed in a distinct section of the same file, or stored in secondary files using proprietary formats. To date, practical implementations of metadata have been limited to simple descriptions of the video title, rarely extending to any direct associations with the actual scenes in the video. Moreover, in systems where secondary metadata files are employed, many challenges come to light when delivery occurs over the Internet due to factors such as the re-naming and re-grouping of files by caches between the publisher and the consumer. In this paper, we introduce a rich metadata format aimed at increasing the scope of metadata tags and fundamentally enhancing the capabilities of media-managers and players on both personal computer and consumer electronic (CE) platforms.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001033"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Rendering of Scene Data in Digital Cinema Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gabriel Fielding",
                    "Thomas O. Maier"
                  ],
                  "abstract": "Several years ago, the Academy of Motion Picture Arts and Sciences formed a committee to study the use of a scene-referred image format for image encoding. The goal was to offer an alternative to the widely used printing density encoding usually stored in the DPX file format. There were many factors motivating people to examine a scene-referred encoding including: making compositing real images with computer graphics easier to accomplish, fulfilling a desire for increased dynamic range to facilitate higher-quality manipulation of images in post-production, and adopting an encoding that is better suited for material originated on digital cameras. Since the inception of this committee, Kodak has been an active supporter of the authors' participation, allowing us to make significant contributions to the underlying design considerations for workflows using a scene encoding. One of the central elements of the Academy's workflow is the concept of a “reference rendering” transform that takes scene image data and prepares it for the anticipated digital cinema viewing environment. The concept of a reference rendering is controversial because the final “look” of most movie and television productions is often considered to be central to the creative aspect of each production. But as we shall show, defining a reference rendering transform can offer several advantages to creating a scene referred image encoding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001037"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Content ID: The Elephant in the Room",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Lennon",
                    "Karen Broome",
                    "Harold Geller"
                  ],
                  "abstract": "The identification of audiovisual content. While the topic is nothing new, increasingly complex user demands across global application interfaces and user languages are making new demands on content identification.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001032"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Stereoscopic Broadcasting and the Art of Motorcycle Maintenance",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Horton"
                  ],
                  "abstract": "The 30 second commercial used to be the engine that drove the Broadcast business, funding both Broadcasters and their suppliers, especially Post houses. That engine started misfiring some years ago and there is no sign that it is going to work in the same way ever again.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001042"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Multimedia Semantics from MPEG-7 Metadata to Semantic Web Ontologies",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ugo Corda"
                  ],
                  "abstract": "This paper reviews various industry efforts to formalize the semantics of multimedia metadata and develop tools for the automatic extraction of semantic metadata from media assets. — These efforts are particularly relevant to today's media industry because of the commonly recognized importance of semantic metadata in effectively supporting various media-related activities (e.g. multimedia data management, intelligent search and retrieval, Web access, personalization, etc.), and because of the high cost usually associated with the manual creation of such metadata. — This paper aims to provide a taste of some major research trends in this area, and to illustrate these trends via concrete examples of relevant projects. The focus is on MPEG-7 and Semantic Web technologies, for reasons described in the Introduction. This paper is not intended to be a comprehensive survey of academic and industrial efforts currently addressing the subject of multimedia semantics, which are too numerous and varied in scope to be discussed in a single paper. — After a brief presentation of the semantic description features of MPEG-7, the paper discusses current work intended to leverage Semantic Web technologies to address multimedia semantics. Work to translate MPEG-7 semantic constructs into machine-processable ontologies and work attempting to automatically populate MPEG-7-based semantic annotations of multimedia content are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001036"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Bringing Stereoscopic 3D into the Connected Home",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Now that High Definition Television (HDTV) has established itself in the marketplace, what is on the horizon for the next big technological innovation with television (TV)? One potential new technology is stereoscopic three dimensional (S3D) TV. Whereas S3D has been primarily targeted to the theaters in the past, delivering and displaying it into the home brings a whole new set of challenges. In the connected home of today is a plethora of (audio/video) AV media devices. Along with these devices, there have been a large number of new applications that have become commonplace in the home. Some examples include true video-on-demand (VOD), iTunes, social networking (MySpace), video sharing (YouTube), and multiplayer gaming.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001043"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Draft Document: The Impact of Ubiquitous IP Connectivity on Electronic News Gathering and Remote Broadcast Infrastructure",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "George Maier"
                  ],
                  "abstract": "The convergence of IP technology within the broadcast infrastructure has caused permanent changes in every process and workflow. In news, it has had a profound impact on video capture, editing, storage, play-out, and transmission of recorded content. Non-linear editing tools have been a factor in video production for over three decades, but the true extent of their capability is only now being reached. In the 1990's, tape based digital field cameras became available, and had an immediate impact on ENG in that the benefits of studio quality non-linear editing were now directly applicable to digital tape shot in the field. Early adopters of digital video for ENG found themselves in a familiar situation, as the new field cameras recorded compressed digital files on video tape, and the workflow process was essentially similar to analog tape. Cameras based on DV formats had the advantage of an IEEE 1394 link from the recording deck to simplify and speed up the transfer of recorded clips to a computer. Purpose built mobile editing platforms soon became available, followed by editing software for generic laptop computers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001041"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Business Continuity Planning for Disaster Recovery",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John E. Wadle"
                  ],
                  "abstract": "One of the major challenges facing broadcasters today is preparing for the continuity of their business following a possible catastrophic event that disables the operation of their transmission facility.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001044"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "The Fundamental Elements of Media Workflows",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Al Kovalick"
                  ],
                  "abstract": "Since the advent of file-based technologies, innovative and powerful implementation strategies are being used for broadcast, news, post and DI workflows. This paper covers four key features of these workflows, namely; system design considerations, process orchestration, operational aspects (what, how, when, where, who) and workflow agility factors. Several fundamental flow models are developed that become components in other more elaborate systems. Select examples are given including; high availability concepts, documenting workflow using UML diagrams, file transfer advantages, loosely coupled design ideas, SOA integration and more. Best practice guidelines are offered for several scenarios.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001045"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Automating HD Workflows: Future Challenges for MXF",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Matthias De Geyter",
                    "Dieter Van Rijsselbergen",
                    "Luk Overmeire",
                    "Steven Van Assche",
                    "Rik Van de Walle"
                  ],
                  "abstract": "Nowadays, broadcasters are rapidly adopting integrated, file-based media production architectures for their back-end facilities, while simultaneously facing the transition from Standard Definition (SD) to High Definition (HD) Television. Broadcasters take full advantage of file-based workflows when they apply the standard file formats MXF and AAF to bring about the essential glue for the integration of production systems. Indeed, the use of MXF for the exchange of media materials in SD-TV production is widely accepted, but only because of continued efforts to keep the file format complexity low and because of rigorous testing procedures. In order to deal with interoperability issues, broadcaster-specific MXF Application Specifications have materialized that strictly define the rules of MXF usage in the broadcaster's production environment. These rules can differ per application (production, editing, play-out, archive) and quality level (compression format), and may evolve in due course. — Based on the lessons learned for SD, this paper discusses MXF and AAF's far-reaching, future challenges for mixed SD/HD media production, taking into account the expected impact of HD on the technical architecture. In particular, the forthcoming adoption of the Service Oriented Architecture (SOA) paradigm will increasingly enable the automation of broadcaster-specific workflows based on central, reusable services and human interactions. — Firstly, HD-specific MXF requirements, such as surround sound and time labeling are elaborated. The use of additional metadata in MXF for further automating production workflows is mooted and a number of useful applications are suggested: media tracking, quality control and preservation, efficient repurposing based on audio-visual information, etc. Then, refinement of the current MXF strategy and the pros and cons of applying higher MXF operational patterns in order to improve efficiency in multi-platform production scenarios are contemplated on a per-application basis. Finally, an effective strategy is presented for automating the laborious MXF validation processes based on Application Specifications, and subsequent corrective updates, all realized in a service oriented way. — The reflections presented in this paper are valuable for all technical practitioners facing the introduction of file-based workflows for SD and HD production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "MXF",
                      "SOA",
                      "workflow automation",
                      "Application Specification",
                      "HD production"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001047"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "H.264 Parameter Optimizations for Internet Based Distribution of High Quality Video",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kourosh Soroushian",
                    "Shaiwal Priyadarshi",
                    "John Villasenor"
                  ],
                  "abstract": "The digital video revolution is evolving from a physical-media distribution model to electronic-media distribution models that utilize Content Delivery Networks (CDNs) and Consumer Grade Networks (CGNs – such as residential Internet and in home networks) for delivery of content to devices. The utilization of the Advanced Video Coding (AVC/H.264) standard is prevalent in today's optical and broadcast industries, but the adoption of this standard at bit-rates suitable for CDN/CGN distribution has not yet materialized in a unified and open specification for resolutions including full-HD (1080p) video. In this paper we present a set of empirical and scientific measurements (PSNR and SSIM) which have been collected through over 6,500 H.264 encodings of a set of content samples in order to determine the optimal compression settings for delivering a high-quality viewing experience across CDNs/CGNs. Based on this research, a specific set of operating points have been devised in order to maximize compatibility across both personal computer (PC) and consumer electronics (CE) platforms, resulting in high quality video at data rates that are encoded at up to 40% lower rates than those of the H.264 Level 4 data rates, while still maintaining a good visual quality level.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001029"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "The “Esmeralda” Stage: An Analytical Test Laboratory for Image Acquisition",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jonathan Erland"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001051"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Supporting the March to 8K with Dirac and Dirac Pro (SMPTE VC2): The Dirac Family",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Borer",
                    "Thomas Davies",
                    "Seiichi Gohshi",
                    "Yasutaka Matsuo",
                    "Peter Wilson"
                  ],
                  "abstract": "I am often asked why did the BBC embark on the design of yet another Codec?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001031"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Service-Oriented Architecture (SOA) in Media Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Footen"
                  ],
                  "abstract": "The precepts associate with Service-Oriented Architecture (SOA), Web Services, and Business Process Management (BPM) provide an excellent approach to systems integration in the Media and Entertainment industry. Current problems of integration complexity and rapid business changes can be addressed through the agility, visibility, and productivity benefits provided by these approaches and technologies. While SOA, BPM, and Web Services are currently only beginning to be used within the M&E industry, they are well-established IT methods and backed by accepted standards. — SOA, with its use of middleware and wrappers, is an excellent architectural choice for systems in the M&E industry. When implemented using Web Services, it can enhance and simplify software integration within a facility. When combined with BPM to streamline business processes, SOA provides additional benefits to any media enterprise that adopts its fundamental principles. These “Service-Oriented Media Enterprises” will be able to react to changes in requirements more efficiently in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001046"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Compatibility of 48 and 24Hz Motion Images: A Problem and a Solution",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Richards"
                  ],
                  "abstract": "Shortly after a soundtrack was added to 35mm film in the late 1920s, 24Hz was established as the standard frame rate for sound films. However almost since the ink was dry on that standard, many people on both the technical and creative sides of the industry have lamented that selection as being barely adequate to depict motion properly. As part of their training, cinematographers have to learn how quickly they can move the camera without destroying the illusion of motion1. Frequently directors have to limit how fast a person or an object moves within a scene for the same reason. It has almost become standard practice for any extremely fast action to be represented in slow motion. For example an explosion will invariably be shown slowed down, likewise a car crash, or even a boxer's punch. This has become part of the standard “cinematic language” such that moviegoers don't question or even notice the practice. But the reason it's done is more rooted in the technology and human psychophysics than the storytelling art – a frame rate of 24Hz isn't really adequate to properly display anything beyond minimal movement. 24Hz is fine for a scene with people simply talking to each other, however almost any kind of “action” scene must either be presented in slow motion, or be carefully staged so the successive movement of objects within the scene from one frame to the next isn't so great that the illusion of motion breaks down.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001050"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Getting the Shot: Advanced MPEG-4 AVC Encoding and Robust COFDM Modulation Deliver HD-ENG",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John L. Pittas"
                  ],
                  "abstract": "The primary goal of any television news production team is to deliver an audio/visual narrative that engages the audience. Often this is accomplished under ideal conditions of time and environment. But just as often this must be accomplished as a live news event is underway or in a challenging physical and Radio Frequency (RF) environment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001040"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Digital Film Archival Using JPEG 2000 and MXF – Formats and Practical Applications",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. Nowak",
                    "S. Fobel"
                  ],
                  "abstract": "Digital technologies have entered movie production and distribution and become more and more important for archives. Key factors in digital film archiving are the data formats that are used to store images, sound and metadata. These formats have to be carefully chosen to ensure that future generations will be able to view the movies of today. This article describes the formats that are used by the digital film archive system concept and prototype implementation that is under development in the European EDCine project. The most important properties of the chosen format JPEG 2000 and the profiles for use in film archiving that have been proposed for standardization are described. In the second part of the article the practical application of JPEG 2000 and workflows to encode image data to these profiles and back to distribution formats are explained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001028"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Implementation of the Academy Image Interchange Framework",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gabriel Fielding",
                    "Thomas O. Maier"
                  ],
                  "abstract": "Several years ago, the Academy of Motion Picture Arts and Sciences formed a committee to study the use of a scene-referred image format for image encoding. The goal was to offer an alternative to the widely used printing density encoding. There were many factors motivating people to examine a scene-referred encoding including: making the compositing of real images with computer graphics easier to accomplish, a desire for increased dynamic range to facilitate higher-quality manipulation of images in post-production, and adopting an encoding that is better suited for material originated on digital cameras. In this presentation we will show that we have been able to successfully manipulate images in both the Academy system and the conventional Printing Density system. Conversion between the systems is relatively easy with the proper transforms. We will show that the same result can be achieved in either system. Thus people can work in whichever system is more convenient for the work that needs to be done.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001038"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Capturing Lunar Footage and Utilization of Image Data: The HDTV Camera System Onboard the Lunar Explorer Kaguya (SELENE)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20Technical%20Conference%20&%20Exhibition,%202008/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. Mitsuhashi",
                    "J. Yamazaki",
                    "J. Tachino",
                    "M. Yamauchi",
                    "K. Tanimoto",
                    "R. Honda",
                    "M. Shirao",
                    "Y. Iijima",
                    "H. Maejima",
                    "H. Otake",
                    "S. Sobue"
                  ],
                  "abstract": "The high-definition television (HDTV) camera onboard the Japanese lunar explorer Kaguya (SELENE), launched from JAXA's Tanegashima Space Center on September 14, 2007, succeeded in taking the first high-definition moving image of the “receding Earth” at a distance of 110,000 km from the Earth.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2008-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001049"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2006",
        "conferences": [
          {
            "conference_name": "39th SMPTE Advanced Motion Imaging and VSF VidTrans Joint Conference",
            "conference_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/",
            "articles": [
              {
                "article_local_id": "6",
                "article_title": "Maintaining QoS of Video over IP Services",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Like all new technology deployments, the delivery of Video over IP presents its own, entirely new, set of challenges, of which many people are entirely un-aware. Because the delivery of e-mail and other data is assured, it is often presumed that video will also be delivered cleanly over an IP networks. The reality is that, video is reliant on constant rate lossless transmission and can display many different quality issues, including loss of video and in extreme, decoder lock ups, or failure to locate the correct channel.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00371"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "3G: The Evolution of SDI",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Sauerwald",
                    "John Hudson",
                    "Vasilis Papanikolaou",
                    "Rakesh Patel"
                  ],
                  "abstract": "Currently there are proposals before both SMPTE and the ITU for a 2.97Gb/s SDI interface using 75Ω coax cable and BNC connectors. The interest in these interfaces is driven by a desire to be able to transport 1080 line progressive formats video over a single link, rather than the dual link interfaces currently used. — The implementation of this interface with existing infrastructure components such as patch panels, connectors, coax cable types, etc. has been studied, and key components have been realized in silicon. The results of this work will be discussed in this paper.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00372"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "JPEG2000 Rate Control for Digital Cinema",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael D. Smith",
                    "John Villasenor"
                  ],
                  "abstract": "Recent industry developments have made it clear that although digital cinema signals are image sequences, they will almost certainly be compressed using an intra-frame image compression method such as JPEG2000 that operates on one frame at a time. This is in contrast to traditional inter-frame video standards such as MPEG that operate on multiple frames at once. Furthermore, recent research has shown that the coding efficiency advantages of inter-frame coding are significantly reduced for 4K digitized film content at the data rates and quality levels associated with digital cinema. This raises a number of important issues related to rate control methods, which have the goal of maximizing quality while also ensuring that the overall post-compression bit rate maintains average and peak values within the limits of the delivery and decoding systems. While rate control in general has received significant attention in the academic and commercial communities, with a few notable exceptions there has been almost no formal research aimed at addressing the problem when a still image coding method such as JPEG2000 is applied to successive frames in an image sequence. — We introduce a new framework for rate control that enables a JPEG2000 encoder to achieve a user-specified quality, and therefore makes it possible to produce constant quality from frame-to-frame. The new method makes direct use of the same JPEG2000 coding pass data as the traditional approaches, and thus can easily be adopted at the back end of JPEG2000 encoding engines. We compare the proposed method with two other common rate-control techniques for JPEG2000.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00373"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Don't Believe Everything You See on (IP)TV: The Challenges of IPTV Today",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Danny Wilson"
                  ],
                  "abstract": "IPTV is the undoubtedly the future of broadcasting. Expert estimates of IPTV penetration range from 20 million households to 72 million households worldwide by 2010. China alone is expected to have between 3.6 million and 16 million households on IPTV by 2009. — However, while there is no question that IPTV represents the future, exactly what that future will look like is still uncertain. The vastly different estimates by different analysts is one indication of this lack of clarity. — This uncertainty is due to the fact that the technology is still in a relatively early stage. Worldwide IPTV penetration is currently about 1.5 million households. The interaction of video, voice and data on the scale that companies hope for has not been tested at all, making test cases of all IPTV projects now. Scaling up will bring its own set of problems. How existing networks and systems will handle 72 million households is completely unknown.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00375"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "File-Based News Acquisition",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rick Young"
                  ],
                  "abstract": "File-based news and content acquisition has arrived. Once dominated by linear feeds via satellite, fiber and microwave trucks, today reporters, producers and photographers are finding alternative ways to get video back from the field. When no ENG truck is available, crews are no longer required to make the mad, deadline-driven, dash back to the station, bureau or closest uplink to prep video for air.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00376"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Wide Dynamic Range, High Precision, Lossless Layered Coding Method",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "The author's previous paper “High Quality, Wide Dynamic Range, Compression System”, which was presented at SMPTE Pasadena in Oct 2004, described a highly layered precision lossy coding system. That paper introduced the concept that “visually lossless” lossy coding could be achieved by ensuring that the amplitude of quantization coding errors is always less than the inherent original image noise floor. In general, the original image noise floor is a function of brightness and color, and is sometimes a function of regions within a frame. This noise floor will also usually vary between shots and scenes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00367"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "10 Gigabit Networking for Audio and Video Applications",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Lampen"
                  ],
                  "abstract": "On May 23, 1973, Robert Metcalf and David Boggs succeeded in sending low collision data packets down a cable. This occurred at the Xerox Palo Alto Research Center. Metcalf had gotten the inspiration while working on the ‘AlohaNet’ radio network linking the Hawaiian Islands built by data pioneer Norman Abramson. Since these data packets traveled through the ‘ether’ (i.e. wireless), this inspired the term Ethernet®. Metcalf was interested that packet collisions made such a system about 17% efficient. He applied advanced math theory that would eventually increase efficiency to almost 90%.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00369"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Next Generation Transport for Broadcasters",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bob Collmus"
                  ],
                  "abstract": "Broadcaster Contribution Networks are undergoing some significant changes as bandwidth and functionality requirements increase and fiber becomes more readily available. The purpose of this paper is to highlight some of the considerations associated with these changing requirements and make recommendations about the ideal platform technology and overall capabilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00366"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Utilizing HDTV as Data for Space Flight",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rodney Grubbs",
                    "Walt Lindblom"
                  ],
                  "abstract": "In the aftermath of the Space Shuttle Columbia accident February 1, 2003, the Columbia Accident Investigation Board recognized the need for better video data from launch, on-orbit, and landing to assess the status and safety of the Shuttle orbiter fleet. The board called on NASA to improve its imagery assets and update the Agency's methods for analyzing video. — This paper will feature details of several projects implemented prior to the return to flight of the Space Shuttle, including an airborne HDTV imaging system called the WB–57 Ascent Video Experiment, use of true 60-Hz, progressive scan HDTV for ground and airborne HDTV camera systems, and the decision to utilize a wavelet compression system for recording. — Compression test results will be included, along with imagery from the launch of STS–114, and details of how commercial components were utilized to image the Shuttle launch from an aircraft flying at 400 knots at 60,000 ft altitude. The paper will conclude with a review of future plans to expand on the upgrades made prior to return to flight.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00368"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Conference Proceedings",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Within the two folders on this CD ROM are the submitted papers and PowerPoints to the VidTrans/SMPTE Joint Conference 2006. The papers and PowerPoints appear with the corresponding name of the presenter/author (see program below). At the time of production, several papers and/or PowerPoints had not been submitted, and so if a Paper or PowerPoint were submitted after this CD-ROM had gone into production, you can download them from the conference's secured Proceedings Website. The papers/PowerPoints will be uploaded within a week or so after the conference.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00370"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Experience with SDI Contribution over IP Network",
                "article_url": "https://journal.smpte.org/conferences/39th%20SMPTE%20Advanced%20Motion%20Imaging%20and%20VSF%20VidTrans%20Joint%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Helge Stephansen",
                    "Tom Erik Krognes"
                  ],
                  "abstract": "The growth of IP based service in the national and international market has been tremendous, and the traffic volume is comparable to ordinary voice. At the same time the cost of IP technology is considerably less than that of ATM and SDH. The consequence is that telecom operators are constructing new IP networks with the intent of converging all services to IP. The result for the broadcaster is that it will be more economical to base new contribution and distribution networks on IP. The Pro-MPEG Forum has proposed two standards for transport of video over IP. Code of Practice 3 (CoP 3) covers compressed video in the form of MPEG-2 Transport Streams. This standard is well advanced and equipment is available from several vendors, as being demonstrated at this event. Code-of-Practice 4 is similar to CoP 3 and concerns transport of uncompressed video - SDI. This paper describes the experience with using CoP 4 for contribution. Moreover, the paper includes a description of the standard and configuration trade-off for SDI transport.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2006-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00374"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2005",
        "conferences": [
          {
            "conference_name": "VidTrans and SMPTE Advanced Motion Imaging 2005",
            "conference_url": "https://journal.smpte.org/conferences/VidTrans%20and%20SMPTE%20Advanced%20Motion%20Imaging%202005/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "JPEG2000 for Digital Cinema",
                "article_url": "https://journal.smpte.org/conferences/VidTrans%20and%20SMPTE%20Advanced%20Motion%20Imaging%202005/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael W. Marcellin",
                    "Ali Bilgin"
                  ],
                  "abstract": "JPEG2000 is the latest international standard for image compression. It combines state of the art image compression performance with a rich feature set. JPEG2000 codestreams are highly scalable. Many different image products can be extracted from a JPEG2000 codestream without decompression. For instance, lower resolution and/or lower quality imagery maybe extracted from a compressed codestream of higher resolution and/or higher quality. Digital Cinema Initiatives (DCI) has selected JPEG2000 for future distribution of motion pictures. This selection was based in part on the fact that JPEG2000 is an open international standard that can support both 2K and 4K resolution projectors from a single codestream. The JPEG2000 feature set is discussed, followed by a high level description of the JPEG2000 algorithm.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001112"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Network and Advanced Compression: Systems Testing",
                "article_url": "https://journal.smpte.org/conferences/VidTrans%20and%20SMPTE%20Advanced%20Motion%20Imaging%202005/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C.R. Purdy"
                  ],
                  "abstract": "The parameters involved in the transmission of digital television have now become too numerous to list. The secret of maintaining reliable, high quality services over the different distribution, compression and transmission systems, is to focus on those factors that are most critical. — With the addition of new challenges and compression technologies like MPEG4, H.264/AVC, VC-1 and WMV9, MPEG test & monitoring systems must be equipped to ensure safe delivery of these new services with high integrity and good quality. — With the added complexity, substantial new engineering issues become critical:- • Standards-compliance must be good: to ensure the equipment interoperates with that of other vendors, so that the video will play properly for the consumer • Visual quality: getting the best quality out of the available bandwidth • Real-time performance: making it all work in real-time without expensive decoders. — Different strategies for monitoring these critical parameters are described, and especially how to achieve cost-effective results by applying the correct tests & equipment to appropriate points within the distribution chain. This approach, using appropriate test and analysis tools, can make the development and implementation of these new compression standards a far easier and quicker process, minimizing costs and maximizing revenues.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001113"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Essential Elements of Triple Play: Classification and QoS at Full Strength",
                "article_url": "https://journal.smpte.org/conferences/VidTrans%20and%20SMPTE%20Advanced%20Motion%20Imaging%202005/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Olaf Nielsen"
                  ],
                  "abstract": "This paper discusses the implementation of Triple Play by telecommunication service providers and how to manage some of the key challenges and issues that they face.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001114"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Delivering Clean Broadcast Video Over Converged IP Infrastructures",
                "article_url": "https://journal.smpte.org/conferences/VidTrans%20and%20SMPTE%20Advanced%20Motion%20Imaging%202005/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jeffrey K. Jensen"
                  ],
                  "abstract": "Delivering high quality full motion video images in the home over broadband has for decades seemed a futuristic dream. Historically, this was more the realm of World Fair displays, science fiction novels and movies than reality. As networking technologies, protocols, and video compression advances have evolved, they have made it possible to deploy broadcast quality video services over converged network infrastructures; these futuristic visions have moved into the real world. These technologies are now mature enough for the “other” VoIP – Video over IP – to take its place in the world of IP networks. But beyond these foundation technologies, what are the performance requirements and enabling technologies for offering such services?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001115"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Managed IT Services for Television News",
                "article_url": "https://journal.smpte.org/conferences/VidTrans%20and%20SMPTE%20Advanced%20Motion%20Imaging%202005/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Karlin"
                  ],
                  "abstract": "In order to save cost and increase efficiency, as well as gain competitive advantage, television news operations are seeking technology solutions to today's business problems. Like all enterprises, they need to do more with less than ever before. This means streamlining and consolidating their operations to reduce expenses. They need to extract maximum value from the content that they produce.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001117"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Securing Video Contribution & Primary Distribution Over IP Networks",
                "article_url": "https://journal.smpte.org/conferences/VidTrans%20and%20SMPTE%20Advanced%20Motion%20Imaging%202005/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurent Marie",
                    "Philippe Lemonnier"
                  ],
                  "abstract": "The rapid growth of the Internet technology and high-speed IP networks offer new alternatives to bring any audiovisual content to any place.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001116"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "147th SMPTE Technical Conference and Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "Managing the High Definition (HD) Transition Bandwidth Requirements for ENG: Microwave Links from the Field",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Payne"
                  ],
                  "abstract": "The migration from standard definition (SDTV) to high definition (HDTV) program content in news, sports and special events coverage has forced broadcast news and field production managers to find transmission technology that can support higher bit rates for HD-ENG transport streams, with the same signal margins, in the new 12 MHz channel plan of the 2 GHz BAS or the existing 7 GHz band. — This paper will examine terrestrial microwave radio transmission techniques that allow contribution bit rates in excess of 80 Mbps in field production applications. It will describe the tradeoffs in radio performance associated with specific applications in regard to bit rate versus bandwidth versus C/N threshold and how they relate to maximum microwave path distances.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00378"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Building and End to End Workflow for HD News",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Schleifer"
                  ],
                  "abstract": "It has taken the industry longer than expected to build non-linear workflows for news in SD, and while a lot of the technology, workflow and experience developed for SD can be leveraged for HD, building an HD solution is not as easy at it would seem at first glance. Not only is HD a bigger challenge, but the target keeps moving. Broadcasters are now looking to publish to many different devices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00379"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "HD Graphics – What's the Big Deal?",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Caren Anhder"
                  ],
                  "abstract": "Since HDTV has become more of a reality, you, as broadcasters, are facing many important decisions. One area of concern is broadcast graphics. This area is of vital importance because it is the provider of your station's brand or identity. Do you have to compromise your branding to provide HD? Are technologies ready for the realtime environment of a live newsroom?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00380"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Shared Metadata in the Broadcast Environment",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jamie Meyer"
                  ],
                  "abstract": "The transition from an analog to a digital world is everywhere around us. It impacts every aspect of our lives, from the time the digital alarm clock wakes us precisely at 6:04 a.m., until the sleep timer on our HDTV monitor in the bedroom clicks the unit off as we collapse at the end of the day.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00381"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Schedule Metadata Flow – The Times They are a Changin'",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Lennon"
                  ],
                  "abstract": "There is no question that we are currently experiencing one of the most dramatic periods of change in the broadcast industry. The move from analog to digital has had impacts far beyond what many would have anticipated. Facilities are changing, systems are evolving, and perhaps most significantly, entire workflows are emerging that have the potential to completely change the way the broadcasting business is run. — The whole area of schedule and as run metadata, or as it is often referred to in aggregate, event-related metadata, is in the process of undergoing the most significant improvement it has undergone since the manual entry of events into automation gave way to batch file transfers. — The evolution currently underway involves improvements on several fronts. Proprietary approaches are giving way to standardization. Batch transfers of data are being complemented by dynamic, interactive integration of systems. Flat files are being replaced by XML files and messages. As a result, new workflows and business models are being enabled that are resulting in a better way of doing business in broadcast facilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00382"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "What Grass Valley Learned from GXF and How it can Help Everyone",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bob Edge"
                  ],
                  "abstract": "About 10 years ago Grass Valley developed a file format (GXF) for professional TV archives and data network transfers. This file format is in use in hundreds of facilities around the world. About 5 years ago the Pro-MPEG Forum and SMPTE started work on MXF and the resulting standards are now supported by most of the TV equipment vendors. Grass Valley learned a great deal from the GXF experience. Some of this knowledge improved MXF and other ideas can help end-users who are starting to deploy MXF based systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00383"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "MPEG2 Long GOP Mapping for MXF File Storage Applications",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Wilkinson"
                  ],
                  "abstract": "MXF is a comprehensive file format being widely introduced into the broadcast world. The primary MXF standard is SMPTE 377M and this defines the file structure and metadata. In order to accommodate all currently used audio-visual stream formats and to provide for future developments, a generic essence container was developed (SMPTE 379M) that complied with SMPTE 377M and could be used to encapsulate many essence types. To date, many essence mappings have been written. Amongst these are a generic mapping of MPEG compressed data and a mapping of AES3 audio. — This paper will identify those areas of MXF where constraints are applied to certain file components in order to encourage interoperability between various kinds of storage devices using both linear and non-linear storage media. The paper will consider constraints at the following two layers: (1) Constraints on the use of the MXF file format structure (2) Constraints on the essence data mappings. — The file constraints include the operational pattern, the use of partitions, the placement of index table segments in the file partitions, the use of index table segments and use of the KLV Fill item.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00384"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Advanced MXF Practice and Future Directions",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Golson",
                    "Kees Vos",
                    "Frederic Guiot"
                  ],
                  "abstract": "The Material eXchange Format (MXF) standards give the promise to broadcasters and production facilities that file interchange and other operational efficiencies can be achieved through interoperability between manufacturers' products. SGI has long been a supporter of MXF, participating in the collaborative development effort of the format within the Pro-MPEG Forum and through the design of products and architecture of solutions to support the MXF standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00385"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Magnetic Tape Developments for HDV Recording w/MPEG-2 Compression",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wayne Desmond",
                    "Hideki Kikuchi",
                    "Steve Tice"
                  ],
                  "abstract": "As digital video acquisition storage requirements grow, the form factor of the storage media tends to remain the same. How is it that the same mini-sized DV cassette that stores 60 minutes of standard definition can also store 60 minutes of high definition in HDV? The answer lies in compression, MPEG-2 compression employed with the HDV format. Unfortunately this type of compression puts greater demands on the media for lower error and dropout rates. This paper will explain developments made in metal evaporated technology that raise the performance level of the media to a level where the added benefits of HDV recording can be more consistently realized.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00386"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "HDV Meets HDCam “In the Heart of Music” Documenting the 2005 Van Cliburn Piano Competition",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Molly McBride"
                  ],
                  "abstract": "Every four years since 1961 the streets of down town Fort Worth, Texas swell with an influx of pianists, piano enthusiasts, journalists and filmmakers; all present to participate, in their own way, in the Van Cliburn International Piano Competition. The competition actually begins months earlier with auditions in the Netherlands, Russia, Italy, New York and Fort Worth. During the auditions this year, 147 pianists, under 30 years of age, vied to become one of the 35 contestants in the 12th Van Cliburn International Piano Competition.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00388"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "High Speed Holographic Data Storage at 100 Gbit/in2",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Anderson",
                    "Edeline Fotheringham",
                    "Adrian Hill",
                    "Bradley Sissom",
                    "Kevin Curtis"
                  ],
                  "abstract": "We present a holographic system and experimental results that demonstrate data densities of 100 Gbit/in2 with a write user rate of 235 Mbit/s and a read user rate of 117 Mbit/s.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00390"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Architecting Digital Content Storage Systems and Archives",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Inglefield"
                  ],
                  "abstract": "The media and entertainment industry is quickly adopting digital technologies to create, produce and distribute content. Driven by the need to produce more revenue from media, programming and production facilities while reducing the cost of business, digital technologies are enabling many new opportunities for content use and delivery to customers and consumers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00391"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "High Definition Does Not Equal Two Times Standard Definition!",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dave Guerrero",
                    "Mike Richardson"
                  ],
                  "abstract": "High Definition video really is not a new concept. The NHK began working on a highresolution analog television system in 1968 and by 1980 had a working implementation. This system's technical standards included 1125 lines per frame, 20 MHz luminance bandwidth, 60 Hz field rate, and 5:3 aspect ratio. As with subsequent HD production systems, the NHK system addressed the need to present a wide screen image to the viewer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00392"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "XDCAM™ Professional Disc System for SD/HD Broadcast and Professional Applications",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Toru Suzuki"
                  ],
                  "abstract": "In the world of professional television barriers between traditional Audio/Video and IT industries are diminishing. The A/V world, which is associated with terms such as video, audio, time codes, synchronous, linear, and tape is merging with the IT world's files, networks, asynchronous, nonlinear, and disc. This merger is key to improved workflows leading to less time to produce a final product, resulting in lower operating costs and contributing to the customer's “bottom line.” — Today a new medium, the Professional Disc, is being introduced to further transform the broadcast industry making workflows better, faster, and more cost-effective. The XDCAM™ Professional Disc series of products utilize optical media with state-of-the art blue-violet laser technology to achieve high data transfer rates and long recording times for practical day-to-day professional applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00377"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Advanced Research in Ultra-High Density Non-magnetic On-Camera Storage",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Oakley",
                    "Robert McGriff"
                  ],
                  "abstract": "A novel high speed, high capacity electron-beam recording technique is described in this paper. The electron beam is generated with carbon nanotube technology. The key parameters for generating the recording beam are described followed by a discussion of a strawman design. The technique provides higher recording densities and higher data rates than possible with conventional magnetic-recording hard drives. The design parameters were in part selected to satisfy the data rate and recording capacity requirements of digital film cameras. This project is a joint effort between Lockheed Martin and NanoScale Storage Systems, Inc.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00399"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "CEA and Home Entertainment Networking Filling in the Gaps",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bill Rose"
                  ],
                  "abstract": "Entertainment networks present more challenges than do data networks, and consumers have higher expectations for them as well. Many of the issues have been solved but there is more to do to complete the job. CEA's Home Networking Committee (R7) is defining, among other things, Remote User Interfaces and how they allow consumers to access content on remote devices using IP over Ethernet and 1394, how Electronic Program Guide (EPG) metadata will be delivered, and how to connect UPnP devices on an Ethernet network to legacy 1394 devices. This paper will explain what CEA is doing to fill in the gaps to enable networked A/V products to enter the living room and connect to others throughout the home and beyond.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00400"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "The Latest Technologies of Motion-Picture Color Negative Film",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tetsuo Kikuchi",
                    "Kouichi Yokota",
                    "Ryoji Nishimura",
                    "Hironori Hiyoshi",
                    "Sadayuki Yamaryo"
                  ],
                  "abstract": "Fuji Photo Film Co., Ltd. has made substantial improvements to its Super F Series, the motion-picture color negative films offering the highest sensitivity available, and in the process has developed the ETERNA Series for dramatically enhanced image quality. — In 2004 Fuji Film introduced ETERNA500—the first offering in the ETERNA Series—a product offering the highest sensitivity of E.I.500. Fuji Film has subsequently expanded the series with the release of new films of sensitivities ranging from medium to high, including E.I.250, E.I.250D and E.I.400. The ETERNA Series has successfully achieved our development goal of providing motion-picture color negative films that offer not only high image quality for traditional analog filming but also significantly improved adaptability to telecine, film scanning and other digital processes for which there is growing demand. — This innovation has been made possible through the implementation of three new technologies that have heretofore been unavailable in motion-picture color negative film. — The first technology is called “Super Nano-Structured • Grain Technology,” which ensures high sensitivity by controlling the microstructure of the silver-halide grain down to the nanoscale. — The second technology is “Super-Efficient DIR-Coupler Technology,” which provides dramatically improved sharpness and color reproducibility while reducing the orange mask density. — The third technology is “Super-Efficient Coupler Technology,” which enhances sharpness by improving the color-formation efficiency of couplers, thereby reducing the thickness of the photosensitive layer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00401"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Aliasing and Reconstruction Distortion in Digital Intermediates",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gabriel Fielding",
                    "Ryan Hsu",
                    "Paul Jones",
                    "Chris DuMont"
                  ],
                  "abstract": "In this paper we address two types of artifacts associated with the image sampling and reconstruction process, namely, aliasing and reconstruction distortion. Aliasing is an artifact that results from sampling a continuous signal at too low a spatial rate relative to the input frequency content. Shannon's sampling theorem states that discrete sampling of a signal at a uniform rate higher than twice the highest frequency in the signal, called the Nyquist rate, will allow a perfect reconstruction of the original continuous signal. However, image displays do not reconstruct images according the ideal reconstruction equation, and in many cases, the display uses nothing more than a sample-and-hold reconstruction. It has long been known that non-ideal reconstruction can lead to distortion of the image data at frequencies below the Nyquist rate. Proper recognition of the distinction between aliasing and reconstruction errors can mean the difference between accepting and avoiding artifacts. With more and more film passing through the digital intermediate process, maintaining image quality is a high priority for artists and engineers alike. This paper discusses the causes of aliasing and reconstruction distortion and how to distinguish between them. We also discuss the implications for digital intermediate scanning and recording as well as the implications for digital cinema projection.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00402"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Designing Camera Origination Films for Scan-Only Applications in Television and Digital Intermediate",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David L. Long",
                    "Thomas O. Maier"
                  ],
                  "abstract": "With the growing popularity of digital intermediate in the feature film market and the continuing development of improved telecine technologies for television, the notion of traditional camera origination film design optimized around optical printing is radically challenged. In scan-only film systems, a very different approach is taken to sensitometric curve design. Rather than focusing on tonal characteristics which yield acceptable and preferred results for overall contrast, grayscale neutrality, and shadow and highlight detail in an optical printing paradigm, the film curves must instead be drawn to optimize the quality of signal provided to the digitization step in the film scanner. Further, standard constructs of color reproduction are also open for modification as the film's spectral sensitivity and color-enhancing chemistries are modified to better mesh with digital color processing capabilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00403"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Motion Compensated Spatial-Temporal Reduction of Film Grain Noise in the Wavelet Domain",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stefan Eichner",
                    "Gunter Scheller",
                    "Uwe Wessely",
                    "Holger Ruckert",
                    "Rolf Hedtke"
                  ],
                  "abstract": "The worldwide spread of new display technologies and the advent of HDTV increase the demand for high-resolution image sources. Film is particularly suitable to fit these requirements and is most commonly used for high quality film and video productions. But film and video sequences are often visually distorted by noise resulting from the process of image acquisition, storage and transmission. Film grain noise may reduce the visual quality and becomes visible especially for light-sensitive films, short viewing distances or large screens. The reasons for film grain noise are versatile, e.g. film material, light exposure and development. It differs from other types of noise due to its origin and particular properties. Film grain noise is non-pixel-based and depends on the image content. Therefore common mathematical noise models can only be used restrictedly to describe film grain noise. We propose a new adaptive noise reduction scheme for film grain noise. The algorithm combines spatial and wavelet domain techniques and performs temporal and spatial filtering. The proposed algorithm utilizes five successive images for each noise-reduced film image. In order to get a temporal and spatial signal-noise separation, the algorithm uses bidirectional motion compensation with adaptive image adjustment. Next a three-dimensional wavelet transform is computed and the detail bands are adaptively modified. A motion adaptive three-dimensional median is used in spatial domain for further noise reduction and suppression of local color as well as brightness variations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00404"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "DRMs and High Value Video Content Business Models",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David P. Beddow"
                  ],
                  "abstract": "The focus in this paper is specifically on the delivery of high value content, i.e. motion pictures and television programs using secure broadband Internet transmission to home PCs and Media Centers and the transfer of such content to television sets and portable media devices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00405"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Content Protection Interoperability Challenges and Opportunities in the Home Environment",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Florian Pestoni"
                  ],
                  "abstract": "The increasing use of digital media and home networks is creating among consumers the expectation that content should be able to move seamlessly around the home. For the PC and consumer electronics industries, this represents a unique opportunity to create the next generation of devices and software that will deliver a unique user experience. For content producers and distributors, this convergence creates opportunities for new business models and increased sales. — However, there are significant technical and business challenges, including making it easier for consumers to set up these complex systems and addressing interoperability issues. Perhaps the most critical area is content protection, for without appropriate safeguards premium commercial content will not be widely available on these emerging systems. — In this paper, I cover some of these trends as well as ongoing efforts to improve interoperability of devices and content to create a compelling digital media ecosystem. The focus is on content protection and digital rights management (DRM) aspects.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00407"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "No Turning Back – IT & IP in the Broadcast Environment",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "The march of progress has made IP an inevitability in the broadcasting environment. However, while this brings many possibilities, it brings its own set of challenges as well. IP is still new to many, and companies will need to understand how putting IP on their network will affect their ability to deliver the services and the service quality their customers and their contracts demand.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00408"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Video Quality Monitoring over IP Networks",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Henry Sariowan"
                  ],
                  "abstract": "Accurate measurement of network characteristics is critical to ensure that networks are operating optimally as designed and configured. Present network measurement metrics, such as packet loss ratio and average latency, were designed to assess the impact of network impairments on data applications. However, as IP networks are increasingly used to carry multimedia traffic such as voice-over-IP and video-over-IP, which are much more sensitive to errors than file transfer, e-mail or web traffic, these data-centric network measurement metrics have become insufficient. — For example, highly-compressed MPEG video traffic exhibits a strong content correlation from one packet to the next packet, and thus, the loss of one packet may render a large number of perfectly received packets useless. One study (see [1]) shows that for a given MPEG-compressed stream, a packet loss rate as low as 3% may be translated into a video frame error rate as high as 30%. Therefore, the packet loss rate does not accurately reflect the severity of a network impairment's effect on video quality. — Furthermore, as video carriers increasingly use Forward Error Correction (FEC) techniques to recover packet loss, measurement metrics designed to optimally configure the FEC operating parameters to match the network condition become highly desirable. In this paper, we review a set of traditional network measurement metrics that are commonly used for data applications and discuss the deficiencies of these metrics for providing an accurate picture of video quality. We then discuss how video quality metrics can be derived from network performance metrics using simple equations and propose video-centric network metrics to compute such quality metrics. We also show how these video-centric metrics can be used to derive a probabilistic loss model which in turn can be used to evaluate the performance of a FEC algorithm.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00409"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Development of a Compact Motion Control Camera System for HD Digital Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hiroyasu Masuda",
                    "Akira Akahoshi",
                    "Tetsuaki Nakazawa",
                    "Keita Kataoka",
                    "Daiichiro Kato",
                    "Tsuyoshi Ueyama",
                    "Yoichirou Ito"
                  ],
                  "abstract": "A motion control camera is one with a system for repeating camera operations identically by computer control. It is often used in cinema and other productions that require complex multiple compositions. NHK have applied state-of-the-art Japanese industrial robotic technologies to develop a motion control camera based on a new concept for use in HDTV production. It is compact thanks to the use of a small HD camera and has a convenient user interface. Compatibility of the camera data with the popular MAYA CG software makes shooting more efficient by enabling advance simulation of the robotic motion. The ease of reproducing identical camera operations reduces the time required for the multiple and CG compositions of VFX productions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00394"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Development of a Three CMOS 1080/300p HDTV High Speed Camera",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Gotoh",
                    "Y. Hashimoto",
                    "T. Ogasawara",
                    "J. Yamazaki",
                    "H. Cho",
                    "S. Kanayama"
                  ],
                  "abstract": "We have developed an HDTV high speed camera that uses three CMOS (Complementary Metal Oxide Semiconductor) image devices. The camera can shoot at maximum speed of 300 fps (frames/second) and the images are stored directly to the semiconductor memories in the camera head. Slow motion playback is available with a high picture quality as the image sequence is stored with progressive scan and without compression (R:G:B=4:4:4). The compact, lightweight, handheld camera can be controlled from a CCU (Camera Control Unit) with a single standard HDTV hybrid fiber-optic camera cable.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00393"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "The Optics of Small-Format HD Acquisition",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Schubin"
                  ],
                  "abstract": "Tiny HD imagers raise issues of acceptance angles, sensitivity, depth of field, diffraction-limited resolution, and lens quality. For some of those issues, there may be technological solutions. Others require an awareness of apparently unavoidable differences between small-format and large-format HD imagers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00387"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "The X-Curve, its Origins and History",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ioan Allen"
                  ],
                  "abstract": "This paper traces the beginnings of the X-Curve in work carried out in the early 1970s, and follows the various developments since that time. This electroacoustic characteristic is now employed in most theatres throughout the world. The “X” stood for “experimental,” an epithet that now seems inappropriate for something that's been a national and international standard for 30 years!",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00395"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Storage I/O Acceleration for Real-Time Digital Media Production Environments",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ji Zhang"
                  ],
                  "abstract": "With the rapid rate of innovation in the last 30 years, particularly in the areas of semiconductors, networks and storage, comes a sense of invincibility. Creative minds have generated wave after wave of dazzling new technologies that continue to surprise everyone. This is particularly true in digital electronics, high speed computing and high speed networking. The constant pace of technological innovation has become an accepted expectation: if the CPU is not fast enough for a task, it will be in a year or two.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00389"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "The Introduction of Large Sensors for Digital Cine Acquisition Cameras",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William A. Hill",
                    "Steve Persall",
                    "Robert McGriff"
                  ],
                  "abstract": "35mm format digital motion picture cameras have become available and their accepted use is increasing. Most notably, the three instruments are the Arri® D20™, the Dalsa™ Origin®, and Panavision®/Sony® Genesis™. The Arri® camera is based upon complimentary-metal-oxide-semiconductor (CMOS) integrated circuit (IC) sensor technology with a color filter matrix and the Dalsa™ and Panavision® cameras are based upon charge-coupled-device (CCD) sensor technology, the former with a color filter matrix and the latter without (separate RGB channels). These cameras are intended to greatly surpass the performance of HDTV acquisition systems and, at a minimum become a useful adjunct to film acquisition, if not replacing film altogether. — These systems are typically close to the 35mm motion picture film format of 24mm (H) x 16mm (V) and on the order of 10 mega-pixels. An important capability for these new sensors is compatibility with existing cine lens families, as opposed to custom and unique lens requirements. — Although affordable multi-mega-pixel still cameras have been available for several years, motion picture acquisition cameras demand much more performance from the sensors and ancillary electronics. For many reasons the appearance of electro-optic sensors of this size and utility for cinematography have only recently become available outside of the scientific and defense communities. Certainly sensors that operate at much higher frame rates than 24P have been available and sensors much larger than 10 mega-pixels have been available for years. Charge coupled devices have been in use for more than 30 years and CMOS IC sensors started to appear approximately 10 years ago, stemming from read-out IC (ROIC) multiplexers from the infra-red focal plane array community. It wasn't until 2000 when an experimental 12 mega-pixel CCD, 24P camera was reported3. This paper discusses the convergence of technological achievements that have made multi-mega-pixel fast framing sensors available today and what may be forthcoming for EO sensors in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00398"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "DC-PCM: An Audio Packaging Proposal for D-Cinema",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stan Cossette",
                    "Pierre Lemieux"
                  ],
                  "abstract": "An effort to standardize the packaging of D-Cinema content for distribution is well underway within the SMPTE DC28 Technical Committee. Some work remains however, and the draft specifications currently do not meet some important criteria for the flexible and reliable distribution of D-Cinema sound essence. In this paper, we discuss these limitations and propose a method to address them.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00397"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Cinema Sound Quality Redux",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomlinson Holman"
                  ],
                  "abstract": "Multiple, closely similar, stadium-seating cinemas equipped with a variety of state-of-the-art sound systems from various manufacturers were thoroughly characterized for sound quality. All the auditoriums were acoustically similar, and meet all contemporary standards. — Findings include those about acoustical issues remaining after the standard reverberation time, background noise level, and isolation have been addressed. New or extended findings were made particularly related to the effects of auditorium features such as stadium seating, regularly spaced rows of seats, the low wall(s) that separate the lead-in ramp area from the stairs up to seating, and back wall absorption. Traditional problems such as screen loss and reflections between the screen and horns were investigated. — Sound system design elements were also investigated. The principal findings involve a new method of mapping the coverage of the sound system, with individual response curves for both the long-term steady-state and the first arrival sound mapped on a grid of typically ten points in the auditorium. Thus problems arising from directional effects in the loudspeaker output or screen modification of the output in coverage, and room acoustics, are well documented. Also included are subwoofer placement effects, the differences between compression drivers equipped with titanium and those beryllium diaphragms, and others.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00396"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "D-Cinema Content Protection: A Brief Overview",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pierre-Anthony Lemieux"
                  ],
                  "abstract": "D-Cinema content is extremely valuable – it is high quality, available in digital form and released in the earliest window. To thwart theft and unauthorized manipulation, a combination of proactive cryptographic and physical security, supplemented by authenticated log reporting and forensic marking, is necessary. Specifically, D-Cinema content needs to remain encrypted throughout the theatrical distribution chain, from the time it is encoded during content preparation to the time it is projected on a theatre screen. Only trusted devices – deployed in secure environments or implementing physical protection – should be given access to the cryptographic keys necessary to encrypt and decrypt content. Trusted devices may also be required to maintain a log record of security-related events and, in the case of devices performing content decryption, add a forensic mark to the decrypted content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00406"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "An Overview of TFT LCD Display Technology",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter H. Putman"
                  ],
                  "abstract": "Thin-film transistor liquid-crystal display (TFT LCD) technology is increasing in popularity for professional and consumer video display applications. With numerous companies engaged in the worldwide manufacturing and marketing of LCD modules and finished television products, prices continue to drop while screen sizes increase dramatically.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00410"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Full HD 1920 × 1080 Pixel Digital D-ILA™ Microdisplay Projector Technology",
                "article_url": "https://journal.smpte.org/conferences/147th%20SMPTE%20Technical%20Conference%20and%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. Shimizu",
                    "S. Nakagaki",
                    "K. Doi",
                    "W.P. Bleha"
                  ],
                  "abstract": "JVC1 has developed a fully digital drive D-ILA LCOS microdisplay device, which has a native resolution of full HD (1920 times 1080 pixels) and contrast ratio greater than 5000:1. The new devices have been combined in 3 device RGB configuration with advanced video processing circuitry for consumer rear projection TV applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2005-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00411"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2004",
        "conferences": [
          {
            "conference_name": "38th SMPTE Advanced Motion Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Will 1-Imager Cameras Ever Be Good Enough",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Centen"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001009"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Development Status of CMOS 1920×1080 Imaging System-on-Chip for 60p HDTV",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lester Kozlowski",
                    "M. Loose",
                    "G. Rossi",
                    "Y. Huang",
                    "P. Kulkarni",
                    "G. Chow"
                  ],
                  "abstract": "High-performance charge-coupled device imagers (CCD) having 2 million pixels in 1920×1080 format have been commercially available for over ten years1. Nevertheless, today's HDTV cameras still do not simultaneously provide sufficient resolution and electronic film speed at the minimum progressive frame rates (≥60p) needed for creative motion imaging production. Overcranking, for example, is only available at ∼1 million pixel (1280 by 720) resolution. The maximum frame rate of today's 1920×1080 progressive cameras is 30 Hz. To truly offer a compelling alternative to motion imaging film, electronic HD cameras must provide higher progressive frame rate along with additional bit depth to maximize production quality and creativity. Leveraging a key architectural advantage and ongoing improvements in CMOS technology driven by a robust semiconductor industry that produces multi-GHz microprocessors at consumer prices, CMOS-based image sensors are now more capable than CCDs of meeting this challenge. We discuss the technical background for the shift in technology from CCD imaging to CMOS imaging system-on-chip. Specifically, we compare the sensor architectures and explain why CCD noise consistently increases with video frequency at about 3 dB/octave. Managing noise consequently forces more video outputs per CCD. High-end CCD-based camera manufacturers are consequently building larger, more expensive and more power hungry cameras. We conclude by briefly reporting the development status for a CMOS 1920×1080 image sensor for next-generation, affordable and compact HD cameras to support progressive frame rates at 60 Hz and beyond.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001010"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "HD-TRIAX: Pushing the Limits of Technology",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Centen",
                    "Ruud Koppe",
                    "Joost UijtdeHaag"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001011"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "The Evolution of Non-Linear Acquisition - One Perspective",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Noriaki Ugo"
                  ],
                  "abstract": "Since the advent of electronic news gathering some 40 years ago, outside acquisition has changed little when compared to the revolution caused by full resolution non-linear editing. The pervasiveness of computer technology and products, both hardware and software, has extended PC-based video to every level and for almost every application. Having experienced NLE for production, users could easily imagine the benefits of non-linear acquisition, and some “early-adopters” and creative manufacturers have used hard drives with limited acceptance. When recordable DVDs appeared it was thought to be a solution, but many issues precluded its adoption. Nevertheless, the idea of an optical disk camcorder was definitely appealing, as was the entire notion of non-linear acquisition. — Last year 2 major manufacturers introduced two very different solutions for non-linear field acquisition - one optical disk based, and one solid-state memory based. This paper describes the background and rationale for the selection of memory for acquisition, the trade-offs and benefits, and a brief overview of the components that comprise the system. Central to the system and to the presentation are the use of Information Technology (IT) elements to transform the workflow, especially for newsgathering, and the derivation of the memory elements from the ever-increasing use of storage elements now found in consumer devices like cell phones, PDAs and still cameras. The central theme of the concept is to use the most appropriate storage element for each phase of the process, and there is a role for memory cards, hard disk drives, and optical disks wherein each plays on its own strengths.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001012"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Development of the Precision Focus Assistance System for the HDTV Zoom Lens",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Masao Wada"
                  ],
                  "abstract": "In this focusing system, a TV zoom lens has a contrast-type auto-focus function incorporated which utilizes differences in optical path length and assists a camera operator in getting his or her focused images precisely in focus. This system, by utilizing the characteristic of the image surface contrast getting maximized when the lens gets focused on an object, controls the focusing lens group so that the high frequency ingredient of the video signals, or the contrast, may be maximized. In order to achieve an auto-focus function that satisfies our requirements for large-size zoom lenses, we have invented a device called the “Precision Focusing System” which has both the contrast-type function and the function which utilizes differences in optical path length. With this system, we have developed an interchangeable lens that incorporates a CCD for focus evaluation and an imaging circuit.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001013"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Six-Gigahertz Coaxial Cable",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Lampen"
                  ],
                  "abstract": "Digital video systems require testing and performance verification at high frequencies. What frequencies should be used for testing? Up to this point a de facto bandwidth limit has been set at 3 GHz. Advances in transfer of wide-screen film formats, high-pixel rate cameras and projectors, and other applications seem to indicate that a 3 GHz bandwidth may be insufficient for many emerging applications. This paper will present a short history of bandwidth, with examples of high-bandwidth applications, and discuss some approaches to designing coaxial cable for these applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001014"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "MPEG-1, MPEG-2 and Windows Media Video Codec Comparisons Using MSE Analysis",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Praveen K. Aeluri",
                    "Vinodh Bojan",
                    "Samuel Richie",
                    "Arthur Weeks"
                  ],
                  "abstract": "Digital video faces the intrinsic problem of huge files sizes, which puts a strain on the available bandwidth in a communication system. Correspondingly, the video files need to be compressed in some manner before transmission. The inherent properties of lossy encoding algorithms can cause artifacts in the decompressed video sequences. In this paper, the effects of encoding and decoding using three different video formats (MPEG1, MPEG2 and Windows Media Video) has been analyzed at different frame rates (15fps and 30fps), frame sizes (320×240 and 640×480) and bit rates (48k, 100k and 300k). These parameters were selected by observing that they are the most commonly used for viewing video transferred over the Internet. In order to analyze the performance of codecs over a broad range of video content, sequences of 30 seconds in length were selected from various sources including movie clippings, television footage and generic video material, depending upon the range of motion of the objects in the video. The four video sequences chosen are from sources that are described as follows: animation, still frames, “talking head”, and a slide presentation. The measurement metric used by this paper, MSE (Mean Square Error), gives the cumulative mean square error of each frame's color components, averaged for the entire video sequence. The determination of how much each codec alters the frame is the goal of this paper, which will aid in the selection of the appropriate codec for a particular application.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001015"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Image Optimization in Digital Cinema, HD, SD and NTSC Engineering and Production Perspectives",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David F.E. Corley",
                    "Shirley Li"
                  ],
                  "abstract": "Two recent events, the advent of high definition television and of film crews joining the digital world, have demonstrated the need for engineers, technicians and DPs to have a better knowledge and understanding of each others' requirements and operating procedures. This paper attempts to provide practical image control solutions and to identify often overlooked issues.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001016"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Broadcast System Monitoring and Troubleshooting Using a Graphical User Interface",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dave Guerrero"
                  ],
                  "abstract": "The technology of Broadcast Test and Measurement equipment has evolved to include automated signal monitoring and verification. The desire to automate signal monitoring is a result of a need by many engineering departments to increase efficiencies of engineering resources in modern broadcast facilities. In many instances, broadcast operators are charged with monitoring the quality of an increasing amount of program content both entering (ingest) and exiting (broadcast) their system. This paper will discuss current technology applied to monitoring information describing the quality of program content using graphical user interfaces. In the broadcast world, integration of a local area network as another physical layer for control and monitoring of the existing audio and video signal paths, has become vital and routine. Development of new tools, based upon utilization of network technology, to monitor the health and quality of a centralized broadcast system is in its infancy.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001017"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Film Image Perception and Simulation",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Faber"
                  ],
                  "abstract": "Ever since the development of television, comparisons have been made between the image characteristics of film and the image characteristics of television in perception, as well as technology. This paper will delve into the reasons why moving film imagery is perceived so differently, why it seems to be frequently preferred over video, even if it's High Definition and how electronic imagery can imitate it. The paper briefly addresses the history of motion picture film, the history of television and the influence that one had upon the other. Then the differences and the technical reasons why moving images have always been perceived the way they are is explored. Elements such as resolution, gray scale, grain, depth of field and aspect ratio are investigated as to how they differ and why they alter perception. The psychological aspect of “suspension of disbelief” and its relationship to frame rate are cited as the most significant aspect of ‘film-image’ perception. The past and present methods of film image simulation are described and their relative success or failure explained. The nature of electronic imaging and the evolution of video cameras including past attempts to simulate film imagery are described. Methods of film image simulation within post-production and methods of simulation within the acquisition process (the camera) are compared. The film imagery of 24P HD video cameras are cited and compared to their predecessors (60 interlace only).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001018"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Definition, Design and Analysis of Digital Intermediate Systems",
                "article_url": "https://journal.smpte.org/conferences/38th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roger Morton",
                    "Kathleen R. C. Gisser",
                    "David Long",
                    "Michelle Maurer",
                    "Chris DuMont",
                    "Kevin Wheatley",
                    "Aviv Yaron"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2004-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001019"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2003",
        "conferences": [
          {
            "conference_name": "37th SMPTE Advanced Motion Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/37th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "High-Definition Video Coax beyond 3 GHz",
                "article_url": "https://journal.smpte.org/conferences/37th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Lampen"
                  ],
                  "abstract": "Coaxial cable has been with us since 1929. Originally envisioned as high-frequency cable for telephone applications, it has filled many uses since then, including analog and digital video applications. Coaxial cable is now being designed for use with high-definition video transmission. These high-frequency high-definition applications are approaching the self-imposed bandwidth limit of 3 GHz. — This paper will look at many existing and proposed signal formats with emphasis on the uncompressed bandwidth of these signals. The question is how high do we want to go? And how far can we go on a coaxial cable in these formats?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2003-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001003"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Storage Helps the Broadcast Industry Advance with New Technology",
                "article_url": "https://journal.smpte.org/conferences/37th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Inglefield"
                  ],
                  "abstract": "It is no longer news to anyone, not even outside the industry, that television and motion pictures have entered the digital domain. What might be news, even to insiders, is the variety of issues associated with implementing digital technologies. Does digital transmission also require digital storage? What storage technologies will be used? How will digital technologies change storage distribution models? How will long-term storage archiving work? What is the cost impact? How reliable will these storage technologies be? What storage media will be used? This paper aims at addressing the above questions and will focus on the management and storage of digital assets as well as the benefits of a digital archive.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2003-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001006"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Color Subpixel Rendering Projectors and Flat Panel Displays",
                "article_url": "https://journal.smpte.org/conferences/37th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Candice H. Brown Elliott",
                    "Paul Higgins",
                    "Michael F. Higgins",
                    "Thomas L. Credelle",
                    "Seokjin Han",
                    "Moon H. Im",
                    "M. Baek",
                    "Megan Arnold"
                  ],
                  "abstract": "Recent advances in color subpixel rendering theory have enabled the economical manufacture of very high resolution flat panels for full color natural image display. The theory has been extended to projectors using displaced color imaging light modulators, enabling higher resolution image reconstruction with no increase in modulator pixel elements. Displacing the projected pixel locations for each color allows additional degrees of freedom with which to reconstruct the image. The resulting increase in ‘addressable points’ allows high spatial frequencies at and just below the traditional Nyquist Limit to be reconstructed over the full positional phase space, without aliasing or phase error, increasing observable image quality. The Modulation Transfer Function Limit is extended, adding image detail. Examples of color subpixel rendering algorithms for both flat panel & projector displays, and resulting performance improvement are examined. Implications for Electronic Digital Cinema and HDTV are explored.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2003-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001004"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Local Storage Changes Everything",
                "article_url": "https://journal.smpte.org/conferences/37th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stuart English",
                    "Philip Livingston",
                    "Jeffrey Merritt",
                    "Neil Ugo"
                  ],
                  "abstract": "Those in the television industry tend to think of audio and video as always being real time. In part this is due to the need for the listener / viewer to see and hear the content in real time, and in part due to the legacy of the traditional devices the industry has had at its disposal to store and manipulate images. One area where real time treatment of television persists is in transmission, and it appears that this may be ripe for change. The reason is a combination of digital content that can be treated as a file, and the ever-increasing pervasiveness of local storage. This advent of local storage ever closer “changes everything.” — One only need look at the home PC to see the impact of 60, 80, and 160 GB drives and the ubiquitous presence of CD-ROMs and MP-3 music storage. All this local storage has transformed home computer use. For the Internet, companies like Akamai and Digital Island have transformed the speed and accessibility by placing literally thousands of servers at the edge of the 'net. Within TV stations the introduction of servers has transformed the infrastructure, workflow and maintenance requirements, much to the dismay of VTR manufacturers. Now, the ability to trickle or send content at non-realtime speeds to “local” storage that is close to the point of use has the potential to revolutionize distribution methodology. — This paper focuses on delivery of content for applications that can be grouped as “Narrowcasting” and that offer opportunities to both the traditional content delivery entities as well as to nontraditional new entities. The use of Narrowcasting to provide a new advertising venue, to create a consumer retail “environment” or to supply a corporate communications network for things like employee training will all hinge on the cost-effectiveness and control brought about by a nontraditional delivery and storage model. While it remains largely to others to talk about how this might affect the delivery of television programming from a television Network to affiliates or commercials to stations, one should recognize that such work is underway at least by PBS and perhaps by others. This could form the basis of a transformation of the infrastructure of network broadcasting as we know it, wherein program delivery need not be done in “lock-step real time” but rather delivered as a file to be executed by the local affiliate at the appropriate time. This holds the potential to get better quality to the affiliates at lower cost, eliminate the need for largely redundant multiple time zone feeds, and improve the security of prime time program content as well.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2003-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001008"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "A Layered Image Delivery Architecture for Digital Cinema",
                "article_url": "https://journal.smpte.org/conferences/37th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Richards"
                  ],
                  "abstract": "There has been much discussion in the cinema industry about what constitutes an acceptable quality level for Digital Cinema. The display technology is still in its infancy, which has prevented objective testing of every aspect of digital display systems. This has led to speculation about the pixel count that will ultimately be required for the application. Pixel counts have been proposed that far exceed the requirements of the human visual system under typical theatre viewing conditions, and also exceed the capability of known interfaces. This paper presents an examination of the issues surrounding the selection of a pixel count, and presents a workable approach for supporting the delivery of multiple quality levels to the theatre, without the need for new interfaces.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2003-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001005"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Techniques for Managing Variable Frame Rate Images",
                "article_url": "https://journal.smpte.org/conferences/37th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stuart English",
                    "Philip Livingston",
                    "Michael Brinkman",
                    "Stephen Mahrer",
                    "Jan Crittenden",
                    "Neil Ugo"
                  ],
                  "abstract": "Much has been presented regarding the history of the selection of frame rates for film and television, and the technical necessity for the television rate and the artistic merits of a slower rate for film have also been widely discussed. Given that film formed the traditional source for much of the high quality content for television, conversion via the classic 2:3 pull-down technique is well understood. Recently, however, cinematographers have increasingly looked to video acquisition as a cost effective option for the making of films as well as television programming, and an increasing number of films being shown at the major film festivals were acquired on video. While some of these were shot at traditional 60 field interlace (60i), many cinematographers resorted to the use of 25 frame 625 line (nominally PAL) equipment to attempt to answer their requirements. Neither 60i nor 25P convert seamlessly to 24P. The 60i material suffers from several short-comings (e.g. interlace artifacts, to name just one issue), and the 25/24 (a not insignificant 4% difference) between the speeds brings no end of complications (e.g. audio pitch and timing difficulties, to name just one issue). To satisfy these users video equipment operating at a native 24 frame progressive rate has been developed in both high definition and standard definition formats, giving the filmmaker accurate and immediate feedback about what a scene will look and sound like when finished. — This has allowed a significant portion of episodic television program production to adopt a 24 frame progressively scanned video format wherein the production process virtually replicates film. Two factors have evolved from this: a desire on the part of the production community for a variable frame rate camcorder to more fully mimic the flexibility of film cameras, and a desire on the part of a larger market for access to 24 frame standard definition video acquisition. Numerous presentations have been given on a variable frame rate production camcorder that has been well received and widely adopted, and a very compact and cost effective 60i/30p/24p frame DV camcorder has been brought to market that uniquely carries 24 frame progressive information in a 60i format. Now, as more main-stream DVCPRO50 professional equipment enters the marketplace and spans the gamut of equipment levels needed by the industry, it is increasingly important for users to understand how these devices actually process the video frames, store them in standard television frame rate video formats, and enable post production recovery and manipulation in the “native” frame rate. This paper describes and compares “standard” 2:3 pull-down, a new advanced 2:3:3:2 pull down that allows full recovery of the original progressive material when stored in an easily viewable interlaced format, as well as the techniques within the variable frame rate process that isolate the recording mechanism and its fixed frame rate from the image capture section and its user selectable frame rate with a kind of n:60 pull down. Many users have had difficulty understanding how complete the analogy is between an image on film and an image recorded using these techniques, and this is explained in some detail. In addition, one can extrapolate that future products can use techniques like increased memory to further isolate the respective frame rates.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2003-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001007"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2002",
        "conferences": [
          {
            "conference_name": "36th SMPTE Annual Advanced Motion Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "NASA Imaging for Safety, Science, and History",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rodney Grubbs",
                    "Walt Lindblom"
                  ],
                  "abstract": "Since it's creation in 1958 the National Aeronautics and Space Administration (NASA) has been making and document history, both on Earth and in space. To complete it's missions NASA has long relied on still and motion imagery to document space craft performance, see what can't be seen by the naked eye, and enhance the safety of astronauts and expensive equipment. Today, NASA is working to take advantage of new digital imagery technologies and techniques to make its missions more safe and efficient. — An HDTV camera was on-board the International Space Station from early August, to mid-December, 2001. HDTV cameras previously flown have had degradation in the CCD during the short duration of a Space Shuttle flight. Initial performance assessment of the CCD during the first-ever long duration space flight of a HDTV camera and earlier flights is discussed. — Recent Space Shuttle launches have been documented with HDTV cameras and new long lenses giving clarity never before seen with video. Examples and comparisons will be illustrated between HD, highspeed film, and analog video of these launches and other NASA tests. Other uses of HDTV where image quality is of crucial importance will also be featured.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00220"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Image Transport Quality? No Problem",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jack Heneghan"
                  ],
                  "abstract": "In the process of creating quality digital motion images, there is a need to move these images around as part of the creation process. The digital aspect of these images directly implies non-physical media as a transport option, such as broadband wired or wireless networks. The definition of ‘quality image delivery’ will be that the digital bits sent are identical to the bits received. ‘Live’ digital streaming images that are being played or stored sequentially and that cannot be resent in the event of an error have a different set of requirements than content that is image files. The quality transport of content files is addressed with reliable file transfer protocols. There are a number of protocols available that address different transport networks and environments. Terrestrial networks will allow for standard IP transport protocols. Satellite and wireless networks require different types of protocols. It will be shown how transport networks can reliably and safely deliver quality digital images everywhere, at a price.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00228"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Data Transport and Processing in a Digital Cinema Theatre System",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jesse Hose",
                    "Mark Winchell",
                    "Kent Walker",
                    "John Ratzel"
                  ],
                  "abstract": "This paper gives an operational overview of a Digital Cinema Theatre System currently in commercial deployment. Storage, transport, encryption, and compression aspects are discussed, along with architectural tradeoffs and design choices made in the development.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00230"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "DLP Cinema™ Color Management",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Greg Pettitt",
                    "Brad Walker"
                  ],
                  "abstract": "In June 1999, Texas Instruments partnered with Lucasfilm to premier the first fully digital release of a major motion picture. “Star Wars: Episode 1 - The Phantom Menace” was shown at two theaters with DLP Cinema™ projection technology. Subsequently, field trials of DLP Cinema™ prototype projectors have been conducted in over 45 theaters in the U.S., Canada, Europe and Japan, with an audience of over 4.0 million. Results of these field trials are currently being incorporated into designs for volume production. — Key to the performance of DLP Cinema™ projection systems is the linearity and stability of the DMD. The DMD's method of accurate digital data display is described and in-theater measurement data is presented. The system stability and linearity are then utilized in the development of a color management methodology for the distribution and playback of content. This paper provides an overview of DLP Cinema™ projection technology, with emphasis on color management and signal processing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00231"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "A 1920×1080 60P System that is Compatible with a 1920×1080 30I Format",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Glenn"
                  ],
                  "abstract": "The human visual system has better acuity for vertical and horizontal detail than it does for diago nal detail. Scenes statistically have less detail on the diagonal. For these reasons diagonal sampling produces a sharper perceived image than a cardinally sampled image for the same number of pixels. If the sampling pattern of a 720 line 60P image is rotated 45 degrees with the same number of pixels it will look sharper then either the 720 line 60P image or a 1080 line 30I image. This rotated pattern produces a diagonally sampled 1810×1018 60P image. A slight increase in the number of pixels and lines produces a diagonally sampled 1920×1080 60P image. A diagonally sampled 1920×1080 60P image has the same bit rate as 1920×1080 30I image with higher perceived sharpness. This pattern has 960 pixels per line. Two lines can be transmitted dot sequentially (One line on the odd pixels and the other on the even pixels) to give 1920 samples per line. A transmission in this format is compatible with 1920×1080 30I displays. However, progressive display must be used to avoid interlace artifacts. By using synchronous spot wobble, an interlaced display can display a diagonally sampled image progressively without changing the horizontal scan rate.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00219"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Objective Image Quality Metrics for DCT-Based Video Compression",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Seyfullah Halit Oguz",
                    "Avri Faibish",
                    "Sorin Faibish",
                    "Gerald Cotter"
                  ],
                  "abstract": "Image quality assessment on compressed digital video is an indispensable task in tuning compression algorithms for different applications as well as evaluating different encoding algorithms, implementations and encoder/decoder products. Since in most compressed video communication applications the ultimate viewers are human beings, it is desirable that the results of an image quality assessment procedure be consistent with the quality perceived by a typical viewer. The design of truly human visual system (HVS) compatible objective image quality metrics, consequently becomes a task of extreme importance. Block based application of the Discrete Cosine Transform (DCT) became the data compression tool of choice in many international video and image compression standards (MPEG-1, MPEG-2 (H.262), MPEG-4, H.261, H.263, H.263+, H.263++, JPEG) owing to its many desirable features. Nevertheless, the manner block based DCT is applied as well as information quantization in the transform domain lead to undesirable compression artifacts. In this paper, three objective image quality metrics are introduced. These metrics are designed to quantify the severity of the three major types of artifacts associated with block DCT based image/video compression schemes, in a manner compatible with HVS. In a vendor transparent manner, experimental results from some commercially available encoding applications are reported to illustrate the practical usefulness of the proposed metrics to assess compressed image quality aside from their theoretical significance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00222"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Noise Reduction Preprocessing for MPEG-2 Encoding",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. Patrick Waddell",
                    "Neil Brydon"
                  ],
                  "abstract": "In the real world, all video content contains some noise. Even modern facilities equipped with the latest digital production equipment will inevitably import some noisy content. Content such as archive material, film, and news feeds are likely to contain high levels of noise. Noise reduction (NR) and filtering can substantially improve the image quality received by the viewer if the appropriate techniques are gracefully applied to remove the noise prior to compression. Selectively removing noise is a challenge because the noise shares the same bandwidth as valuable picture detail. An ideal noise reduction process will allow suppression of all types of noise while preserving clean video content. An advanced noise reduction system will use sophisticated techniques that offer powerful abilities to remove noise without introducing side effects such as motion blur or ghosting. — Harmonic introduced its latest MPEG-2 encoder at NAB 2001, which features third generation embedded advanced noise reduction capabilities. The architecture is unusual for MPEG-2 encoders, so the design background is discussed in some detail. This encoder has permitted users to push encoding rates for video below 2 Mbps with good results.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00225"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "A Real Time Single Ended Algorithm for Objective Quality Monitoring of Compressed Video Signals",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alexander K.G. Worner"
                  ],
                  "abstract": "Digital compression methods based on MPEG2 are now in widespread use for broadcasting of video content. Multiple television and radio programs can be multiplexed and transmitted altogether within the same bandwidth where formerly only one analog program fit. With the analog television video quality was very much a matter of the transmission chain and all the elements along the line. Once a sufficiently high video quality level was achieved, it was nearly independent from the content. In using digital compression and transmission techniques the video quality is now strongly content and compression dependent. The changes in video quality can be very abrupt from scene to scene. A method that is capable of following all these changes in real time and displaying the picture quality, as a function of time, is required for continuous video quality monitoring. — This paper describes a single ended method that does not require a reference signal and is capable of processing the video in real time concerning picture deficiencies of a compressed video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Video Compression",
                      "DCT",
                      "MPEG2",
                      "SSCQE",
                      "Quality of Service"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00224"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Retaining Image Quality in Archives and Implementing Related Tools for the Retrieval",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Juergen K.R. Heitmann",
                    "Rainer A. Kellerhals"
                  ],
                  "abstract": "To capture and process moving images costs money. To do it with a better image quality means even higher investments. To recover these investments takes time. To preserve the content over that time period is a prerequisite for recovering the investments made. Image quality means nothing without appropriate archiving systems and tools to access and retrieve high quality content. — Part of the information given is based on the work of the Project Group P/FTA “Future Television Archives”, which was installed 1998 by the Production Management Committee of the European Broadcasting Union (EBU). The project group was charged with: • Providing an overview of the options available for the technical realization of future television archives, taking into account existing technology. • Proposing ways of migrating from the current conservative and static “legacy” based Content production to new production architectures that could accommodate continuous adaptation to the rapid pace of technological development. — Unfortunately, all physical storage media have a limited lifetime. But not only storage media are transitory, the same applies for the necessary hardware and software. Technological progress will always make hardware and software obsolete which is used to preserve content. Library systems should make content available despite technological progress. The paper will outline a concept of migration, which was formulated to solve this conflict. — The implementation of an Enterprise Content Management (ECM) is the prerequisite for minimizing the cost of content preservation & content re-use through • increased efficiency • new business opportunities and • an integrated Migration Management to master the unavoidable technological changes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00227"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Interaction of Image Quality Metrics",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roger R. A. Morton",
                    "Michelle A. Maurer",
                    "Christopher L. DuMont"
                  ],
                  "abstract": "Many image quality characteristics interact. Consequently, improving one characteristic may either enhance or degrade another. As we strive to improve cinema image quality these interactions become more important, especially if new robust cinema delivery systems are to be realized.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00221"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Mapping KLV Packets into Synchronous MPEG-2 Program Streams",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Winnie H. Liang"
                  ],
                  "abstract": "This paper proposes a method for synchronously mapping digital metadata encoded in the SMPTE Key-Length-Value (KLV) protocol (SMPTE 336M-2001) into an MPEG-2 Program Stream. In this study, our goal is to archive low- level, detailed, frame-by-frame syntactic metadata together with the associated video stream. We developed an algorithm specifically for MPEG-2 program streams that packetize MPEG-2 video elementary stream and KLV encoded metadata into packetized elementary stream (PES) packets. The group of pictures (GOP) time codes and the picture temporal reference are used to create time-stamps to place into the PES header's presentation time-stamps (PTSs) for synchronization. When a KLV inserted MPEG-2 program stream is played, an MPEG-2 splitter filter “splits” the video PES packets and KLV PES packets, retrieves the PTSs from those PES packets, and delivers the video and KLV PES packets to the appropriate decoders. The PTSs for each PES packet are kept with the decoded data. The video and metadata displayer synchronize with each other using the PTSs, so that decoded data with the same PTS time-stamp are displayed at the same time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00226"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Image Quality in FootageQuest, an Online Footage Archive",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Carl Watts",
                    "Robert Bender",
                    "Sharon Flank"
                  ],
                  "abstract": "Image quality considerations played a major role in the design of FootageQuest, a portal for on- line sales and delivery of footage. Multiple suppliers with various source material required us to create a single standard so end users would receive consistent quality. Since many customers selected clips from various sources and wanted them all delivered together in one order, we needed to optimize to support these composite orders. We decided that it was easier to build these compilation tapes from a digital server than to use multiple tapes to build a single fulfillment tape to send to the customer. Our goal was to determine what bit rate, digitally compressed, would give the same results as tape. Extensive testing led us to this result: 50 megabits per second, using the PQA200 Picture Quality Analyzer from Tektronix, ga ve the best results.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00223"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Issues in Transporting MPEG over IP",
                "article_url": "https://journal.smpte.org/conferences/36th%20SMPTE%20Annual%20Advanced%20Motion%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ciro Aloisio Noronha"
                  ],
                  "abstract": "Transporting MPEG over traditional IP networks (or packet-switched networks) involves a number of issues related to the required Quality of Service the network must provide to ensure proper playback of the content. This paper presents a discussion of these issues. We start by analyzing the MPEG requirements on the network, from a stream playback point of view. We then discuss how the IP network can satisfy these requirements, both from an infrastructure point of view and from a protocol support point of view.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2002-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00229"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2001",
        "conferences": [
          {
            "conference_name": "35th SMPTE Advanced Motion Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "5",
                "article_title": "Balancing Bandwidth and Bytes: Managing Storage and Transmission across a Datacast Network",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pete Lude",
                    "Dan Radke"
                  ],
                  "abstract": "The conversion of the nation's broadcast television stations to ATSC digital transmission affords the opportunity for the distribution of rich media content by means of data broadcasting. In a data broadcasting network, content objects such as digitally encoded video, audio, still photos, graphics, e-books, games and software applications are interleaved with television programs in the television station's MPEG transport stream.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00354"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Designing Data Models for Asset Metadata",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniel Hurtubise"
                  ],
                  "abstract": "The Media Asset Management System (MAMS) stores digital data and metadata used to support the mission of a company. In essence, the MAMS is similar to a traditional database with its entities and attributes but with added features such as media streaming, media transfers, and workflow dynamics. In fact, some vendors' MAMS solutions use commercial databases to store the metadata and provide the ability to optimize the database to increase the MAMS search performance. They may also provide basic data models for assets that can be used immediately in the design or enhanced to meet specific needs. However, in almost all cases there may be a need for the creation of new data models that will require skills in some form of data modeling. This paper presents an overview of how data models can be used to define asset metadata and ultimately support a company's mission. This paper is not intended to present the complex theories of data modeling, but rather uses basic data modeling techniques to show how data models can be designed for asset metadata.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00365"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "i-DHSM: Dynamic Hierarchical Storage Manager: Media Management for Audiovisual Digital Archiving",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. D'Alessio",
                    "A. Bertini",
                    "F. Ciferri",
                    "G. Ferrari",
                    "M. Strambini"
                  ],
                  "abstract": "Description of an integrated solution for the management and migration of heterogeneous data (HSM - Hierarchical Storage Management), by presenting an innovative software/hardware architecture, specifically developed for the digital archiving of audiovisual mass content; i-DHSM—Dynamic Hierarchical Storage Management - is a highly scalable and configurable solution for a wide range of applications, as it provides full performances on both SMP (Symmetric Multiprocessor) and “Cluster systems.” — Easily managing audiovisual files and moving clips over high-speed connections to high-performance devices is what today Broadcasters, DOT com companies and TLC operators most recommend and request whenever they plan to set up a digital archive. — Audio/video clips for large digital storage nevertheless require specific management of ingestion and migration procedures when moving files from server to backup devices (i.e. automated tape libraries, etc.) and vice versa, no matter which quality or application is required (Media Asset Management and Archive Management, for example).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00355"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "The Role of a DTV Edge Server in Support of Data Broadcasting Applications",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James P. Janniello",
                    "Christopher Ward"
                  ],
                  "abstract": "With a bandwidth of 19.4 Mbps, the DTV channel has the potential to be an extremely valuable broadcast resource, yet television's traditional use of distributing video programs to viewers does not sufficiently exploit this capability. In order to realize DTV's true potential, the DTV channel should be considered more generically as a network resource, and the potential services and applications explored. In this paper, we present a basic Data Broadcast application for automatically augmenting video news programs with auxiliary information, and then discuss a general architecture of creating a broadcast edge server. Like its Internet counterpart, the broadcast edge server provides an edge located storage system for efficiently delivering applications and content to DTV receivers while allowing the real-time pass-thru of Internet and Broadcast content as required.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00359"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Abstract: Managing and Monitoring a Data Broadcast Network Presented by Sheila Joyce, Geocast Network Systems",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "A successful data broadcast network is highly reliant on a network management system that offers effective failure prevention and immediate detection and resolution. Achieving this efficiency in a network of diverse servers and broadcast devices, each with its own operating and event reporting systems, presents a challenge. The challenge is compounded by the need to provide a centralized monitoring and control station. — This presentation will review our network design and explain how we selected and integrated the components of our network management system to achieve a 99.99% network reliability goal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00356"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Content Processing for Data Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ed Casaccia"
                  ],
                  "abstract": "The emerging business of data broadcasting is creating new requirements for content processing tools and techniques. Just as data broadcasting combines traditional broadcast technology with packetized data transmission usually associated with computer networks, these new content processing requirements combine elements of video production with technologies developed to delivery the huge mass of information available via the World Wide Web. The following is a description of how one data-broadcasting venture, Geocast Network System, Inc. of Menlo Park, California has created new technologies, adapted existing technologies, and developed operational procedures to address these needs. — Although many variations exist among the various content types, the entire endeavor can be broadly characterized in three main steps, euphemistically referred to as “Grab, Bag, and Tag.” “Grab” refers to acquiring the source material that is to be delivered via data broadcasting and, if necessary, converting that material into digital form. “Bag” refers to aggregating material from disparate sources into a single topical grouping, or disaggregating (segmenting) long form material into smaller units defined by topic, source, or any other appropriate delineation. “Tag” refers to the creation, either through human effort or in automated fashion, or a set of metatdata describing the content material.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00350"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Continuity Monitoring of Audio, Video and Data in a Multi-Channel Facility",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Strachan"
                  ],
                  "abstract": "Much has been written on the subject of maintaining video quality in a modern television facility. But with often as many as a hundred or more television channels to monitor, we must be concerned not only with signal quality, but also with the continuity of the video, multiple audio channels, closed captioning, V-Chip parental guidance and other VBI data associated with each channel. The task of monitoring so many channels, often involves employing a plethora of gadgets specifically designed to check each function. But even with the best equipment, it is difficult to watch up to a hundred picture monitors and impossible to monitor the levels and phases of hundreds of audio channels. And then what do we do about the closed captions, XDS and other data on every channel? — This paper describes a system using in-line video and audio converters, to automatically monitor signal continuity, at the same time as reporting video errors (including EDH, frozen video and black), audio levels and phases, closed captions, V-Chip parental guidance, source identification and time information. Any errors discovered, are automatically flagged over a TCI/IP network and may be logged in a database. A remote monitoring and control system, based on the common SNMP protocol, is described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00358"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "An Object Server Supporting Metadata for Video Intensive Internet-Based Access",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher C. Woollard"
                  ],
                  "abstract": "The use of video and other media type objects is now not the sole concern of the film and television industries. The construction industry in particular is now making use of these objects in various ways from project proposal and planning through approval to final completion of contracts. The requirements for such industries may be generalised and a distributed architecture built, primarily using the Internet, to serve the needs of these projects. This architecture must enable potentially very large collections of objects to be managed in a secure environment with distributed responsibilities held by many sub-contractors. — Various system management requirements arise. It is necessary do dynamically select the appropriate networking technologies and incorporate these transparently. The users should receive from the system the information they require in order to ensure a given quality of service for their needs. — Metadata must be managed in a way that enables its instantiation to evolve as standardisation occurs. Its use must however be immediately possible. A robust and tight binding mechanism is provided. — A replication service is provided. User objects may use this in addition to its use by the system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00357"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Data Broadcasting to a Trusted Client",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bhavan Shah",
                    "Marc Duvivier"
                  ],
                  "abstract": "The Internet has had enormous growth in the 1990s, analogous to the broadcast industry in the 1950s [television], 1970s [cable], and 1980s [satellite]. It has suffered from seven challenges that need to be addressed in the next stage of its development.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00353"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Transport B for Broadcasters: Boon or Bane?",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jacobs Bruce"
                  ],
                  "abstract": "Delivery of enhanced television content via DTV data broadcasting offers significant advantages. However, implementation within networks and stations presents major problems. Two distinct solutions are described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00361"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Datacasting Applications: Real World Experience",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frederic Grenier",
                    "Brett Jenkins"
                  ],
                  "abstract": "It is now a cliché to say that everything is becoming digital. This is particularly true for all broadcast media: satellite, cable and terrestrial. At the present time 75% of all satellite TV transponders are digital, and this ratio will soon reach 98%. The predominant, if not the only, standard for digital TV is MPEG-2. It was initially designed to carry video, audio and related data. But typically in an MPEG-2 Transport Stream, between 1 and 3 Mbps are unused and filled with empty or “null” packets. This represents a loss of at least $150,000 a year for a satellite transponder. As a consequence, MPEG-2 is more and more frequently being used to carry all kinds of value-added data. Internet Protocol (IP) is by far the most common way of carrying data; thus, the most sensible way of broadcasting data is to encapsulate IP frames into MPEG-2 packets. — So far, because of an early standardization process, most existing data casting applications are based in Europe. In this region “datacasters” can be classified in 3 categories: (1) Satellite operators (Astra, Eutelsat) who provide turnkey solutions to service providers, (2) Telecom operators (Belgacom, British Telecom, Deutsche Telekom, France Telecom, Telia) who provide professional services like corporate communications, distance learning, etc., (3) Broadcasters (Canal Satellite, Teracom, TPS) who inject add-value data as a complement to their digital TV programs. — Some use whole transport streams to carry their data, some use a constant part only and some others use the remaining bandwidth, injecting the data in an opportunistic way. Thomcast is by far the major supplier of IP to MPEG-2 gateways, thanks to its multiple award-winning product, Opal, based on OpenMux® technology. These experiences taught us several things: what are the most profitable applications, what pieces of equipment and software are needed in each case, and what functionality should an IP to MPEG-2 gateway and injection system provide. — This paper presents several European datacasting applications, the features that are important for our customers and gives an overview of how this can apply to the UNITED STATES terrestrial broadcast market.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00352"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "An SNMP Agent for a DTV Data Server",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dinkar Bhat",
                    "David Catapano",
                    "James Kenealy",
                    "Gomer Thomas"
                  ],
                  "abstract": "This paper presents a framework for remote control and monitoring of a DTV data server using the Simple Network Management Protocol (SNMP). This standards-based framework consists of a remote manager, agent(s) that access the properties of the data server, and a management protocol that specifies the format of transfer of information between agents and the manager. The information to be accessed by the agent is provided in the form of a Management Information Base (MIB). We describe the process of developing a MIB for a generic DTV data server. The SNMP framework clearly separates management of the data server from the function of data serving, and also facilitates a consistent user interface to monitor and control diverse sub-systems in a broadcast plant, possibly provided by different vendors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00362"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "“Streaming Metadata, Applications and Challenges”",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robin Rowe"
                  ],
                  "abstract": "Metadata is data about data. Streaming metadata can be embedded in a television transport protocol such as MPEG to enable new types of viewer experiences such as interactive television. SMPTE Working Group W25, Metadata and Wrapper Technology, is defining standards for digital streaming metadata. New standards are needed because without them new forms of data or even existing analog data like closed-captioning (which is standardized in VBI for analog television) is encoded in proprietary ways in otherwise standard digital video streams (such as MPEG-2). — We will explain why metadata is necessary, how it works, and why it is different from conventional databases. We will describe some of the features that make the metadata approach taken by SMPTE more powerful and flexible. We will discuss some lessons learned from creating BigScreen, a Windows software video player that supports metadata.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00363"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Broadband Services Using Databroadcasting and Point-to-Point Networks",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hans-Jorg Vogel",
                    "Peter Krummenacher",
                    "Erik Troelsen"
                  ],
                  "abstract": "An ever-growing demand for rich multimedia services puts enormous strain on servers and transport network under the current centralized delivery paradigms of the Internet. Consequently, they often fail to deliver a broadband user experience. Delivery models based on digital broadcast transport mechanisms can effectively bypass these bottlenecks. Broadcast networks are able to efficiently convey large volumes of data, delivering it either directly to end-consumers or replicating it across servers and caching engines, which are deployed at the network's edge for the scalable delivery of this content. Such a combination of broadcast services and point-to-point access to information residing in entities on the network edge is considered the ideal environment for the definition and delivery of new service offerings, effectively combining push- and pull- models for the delivery of a rich multimedia user experience, including live-streaming events and on-demand services. — This paper defines broadband services and then describes the enabling technologies involved in realizing that experience. We continue discussing the aspects involved in broadcast and point-to-point delivery models, raging from transport issues, to functionalities required in the aggregation, playout and caching/storage domain. Broadcasting requires scheduling and bandwidth management mechanisms. Subscriber management, protection and billing functionalities are required for broadcasting services as well as for point-to-point delivery services. We conclude by describing a fully converged network with the IP protocol as the central layer of convergence and describe its applications in a special realization of the Multimedia Car Platform project of the European commission.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00351"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "“Infrastructure for an NTSC/ATSC-Supported Nationwide Data Broadcasting Service: Present and Future”",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Boroughs"
                  ],
                  "abstract": "This paper reviews the implementation and operation considerations to support a nationwide data broadcasting transmission architecture for non-program related data. It reviews architectures utilized by PBS National Datacast: VBI, dNTSC and migration to DTV. The network management requirements to support the data delivery are also discussed. For over ten years, PBS National Datacast (NDI) has been embedding data streams into existing PBS analog broadcast signals through the use of the Vertical Blanking Interval (VBI), and has been datacasting a variety of multimedia services. Currently NDI delivers data via 260 of the total 348 TV transmitters in the PBS system. While VBI has provided a viable option in the past and continues to provide a niche for certain applications, the data environment today demands more bandwidth, and savvy users utilize multiple applications requiring varied types of data. The next step for PBS National Datacast (NDI) is the implementation of the Dotcast dNTSC (data in NTSC video) technology. The Dotcast system uses patent-pending technologies that can inject a 4.5 Mbps digitally encoded data stream into an NTSC broadcast television signal without degrading the signal or interfering with regular TV reception. The dNTSC system can make valuable use of existing NTSC assets, and provide a smooth transition path to DTV data broadcasting. This paper lays the framework for a data broadcasting architecture where multiple data services are vying for a piece of the transport stream, and local data broadcasting opportunities at the station will be competing with national opportunities for bandwidth.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00360"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Metadata for the Long Term: The Universality of Language vs. Fixed Processes",
                "article_url": "https://journal.smpte.org/conferences/35th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sharon Flank",
                    "David Forbes"
                  ],
                  "abstract": "Effective digital media management relies heavily on the use of descriptive information, or “metadata,” that envelops rich media files like video clips, audio files, high resolution photographs, and CAD/3D files. Good metadata permit quick search, extensive reuse, and consequently cost savings. If the metadata are inadequate, the file languishes unused and unusable. We propose a standard for metadata that does away with the trouble and expense (and inherent frustrations) of mandating terminology and thesaurus standards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00364"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "143rd Technical Conference and Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Media Friendly Microprocessor Architectures and Tools: 143rd",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ralph Biesemeyer"
                  ],
                  "abstract": "Video, audio and graphics capabilities are increasingly important for microprocessors to handle new software functions. Software engineers require better tools to minimize development time and maintain platform compatibility for media applications. Revolutionary system architectures allow clustered desktop processors to become fault tolerant high-speed server and rendering systems. Recent improvements in these three areas can help engineers build COTS open platform media systems that perform and scale better than ever before.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00959"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Two-Way Satellite Broadband: New High-Speed Connections for the Production and Post-Production Communities",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marty Stein"
                  ],
                  "abstract": "A number of services/networks will launch during the next two years that will provide two-way, high-speed Internet connections via satellite. These new networks will be based on Ka band satellites that enable “bandwidth on demand” (rather than leasing fixed bandwidth transport) with data rates typically from 100kbps to 45Mbps. This new technology will offer two significant benefits to the production and post-production communities: a) high-speed connections from virtually any location on earth and b) a broadband connection that supports widely varying bandwidth usage models. — These new networks are typically based on one of two different system architectures: 1) “bent pipe” where signals are bounced off of satellites and routed via the land-based Internet between earth station gateways, and 2) on-board switching systems where IP/ATM connections are set up by ground-based network management earth stations, but are switched using ATM switches on the satellite. The satellite switched architecture has an advantage for production and post-production use in that point-to-point connections can be quickly set up, allowing studio-studio or studio-remote types of high-speed connections. — This paper will explain the network, satellite, earth station, and satellite terminal technology that is currently under development and will suggest the applications, benefits, and tradeoffs for production/post-production companies deploying this technology.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00962"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Monitoring and Control of Audio-to-Video Delay in Broadcast Systems",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Tucker",
                    "Dan Baker"
                  ],
                  "abstract": "We have come to expect much of television over the last decade, including increased channel capacity and video and audio quality improvements due in large to new digital processing capabilities. However, one of the first viewer determinates of television program quality has proven to be the proper and consistent synchronization of the visual and audio signal elements, otherwise referred to as lip-sync timing. This paper will provide a brief overview of the reasons for the increasing audio-to-video delay problems, discuss the thresholds for audio-to-video delay perceptibility that have been accepted in recent documented studies, and introduce a new “in-service” A/V delay measurement and auto-correction method based on digital watermarking of video signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00964"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Digital Rights Management and Windows Media Player",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marcus Peinado"
                  ],
                  "abstract": "Digital rights management (DRM) is gaining importance as an enabling technology for electronic commerce in digital goods. The purpose of a DRM system is to allow the owners of digital assets (e.g. movies, songs) to distribute these assets electronically in a controlled way. After a general introduction to DRM technology, this paper discusses special properties of video content and their impact on DRM. Finally, the paper describes the Windows Media Rights Manager—the DRM system used in Windows Media Technologies for audio and video content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00961"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Protected Storage Area Networks for Broadcast Environments",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Jason Mancebo"
                  ],
                  "abstract": "In this paper we discuss the advent of standard information technology (IT) storage products into the broadcast industry. Additionally, we present an analysis of existing topologies, technologies, and implementations that many broadcasters are currently using. We also examine how the incorrect infrastructure, technology application, or lack of protection from operations affecting nominal performance can limit choices, reduce flexibility, and endanger on-air product.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00967"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Content Creation Utilizing Large-Scale Archive with Content ID and Original Time Code",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Haruo Hiki",
                    "Yoichi Ishibashi",
                    "Masaru Kawabata",
                    "Fumio Hasegawa"
                  ],
                  "abstract": "Stored video data in the large-scale archive will be used primarily for content creation and secondarily for content distribution. In both cases the protection of intellectual property is an indispensable issue. A good solution of this issue may be to adopt Content ID (identification) being promoted by the Content ID Forum. Content ID is a unique identifier to realize some benefits of materials (or contents) distribution. A part of the Content ID will be watermarked on video itself. In the Content ID, we propose to include an Original Time Code that is a time code from an original tape (or cassette). Through the network, how to get the materials for preview is another issue. We chose MPEG-4 as the compression technology. The first of choosing reasons is the lower-band transmission capability. Second is that the Content ID could be easily carried with MPEG-4 stream. Remote editing terminal outputs an Edit Decision List (EDL) to an editing studio for high quality editing. In this process the EDL is created with the Original Time Code. On the other hand the local Time Code might be used in the editing studio. In such case some Time Code conversion is needed to execute the EDL.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00966"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Encrypted Satellite Multicast: Quality, Security, and Reliability Considerations Attending the Distribution of Television as Addressable Data",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dom Stasi"
                  ],
                  "abstract": "Analog video distribution is fast going the way of the vinyl LP.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00963"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Enabling Network Interoperability between Video File Servers: The SMPTE 360M General eXchange Format (GXF)",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ray Baldock"
                  ],
                  "abstract": "The availability of high speed network transports worldwide make it practical and economical to exchange files over data networks making delivery of material faster and more convenient than ever before. With a network transfer, not only can a single user initiate a dub, but all of the metadata associated with the clip can also be transferred avoiding the re-entry of basic information. Distribution of commercials using IP over satellite, as well as exchange of news stories via wide area networks, is now commonplace and is replacing both tape and analog satellite transponders as a distribution medium. File transfer allows the user to control cost by selecting a transport medium appropriate to the urgency of delivery. Options range from transfers that may be slow but are free-of-charge via the web, to extremely fast transfers over a highspeed ATM connection. With the release of SMPTE 360M manufacturers and users alike are provided with a simple file format that can be applied to the movement of audio, video and metadata between professional television equipment. SMPTE 360M provides all the capabilities needed for publication of content from the production world ready for distribution. Using this standard, network interoperability of compressed files can quickly be achieved with thousands of server products already deployed around the world. This paper reviews the basic structure of SMPTE 360M, and it's capabilities and limitations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00969"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Stream and File Formats – Where are We Now?",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bob Edge"
                  ],
                  "abstract": "Broadcast file formats have evolved over several years. Some of these have been standardized, a few new ones are in the process of being standardized, and others are being held as proprietary technology. The first to be standardized, Digital Moving Picture Exchange, is used for uncompressed material transfers by telecine and image rendering systems. The next format to be standardized was General Exchange Format (GXF), which is intended for news, sports, and on-air operations. The AAF Association has released a format that has a feature set designed for post-production and rich editing applications. And, finally, the Pro-MPEG Forum is developing a new file format—the Material Exchange Format—which that has a large feature set. The proponents of Material Exchange Format plan to support a broad range of applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00970"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Fault Tolerance in a Distributed Media Server",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Donald Craig"
                  ],
                  "abstract": "A new generation of media servers utilizes component building blocks interconnected with a variety of networking technologies. These architectures are made possible by the dramatic advances in network performance of the past few years, and permit the bandwidth and fault tolerance of the server to be tuned on an application specific basis. This paper briefly reviews the evolution of media server designs over the past decade, then examines specific configurations of a modern architecture in particular applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00968"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "CTVNEWS.com Case Study: Rich Media Content Management Meets Interactive News",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jamie Ollivier"
                  ],
                  "abstract": "In early 1999, Blue Zone—a Vancouver-based software development company—approached Canada's largest private broadcaster, Canadian Television (CTV), and presented Blue Zone's patent-pending, rich media content management and publishing software, MediaBZ™, as a foundation for a convergence strategy for CTV. Using the technology, CTV could power its 24-hour news station, CTV Newsnet, as well as a complementary Web site and other interactive properties. By implementing this strategy, CTV's interactive properties would take the lead among broadcasters in terms of process automation, rich media content delivery and multi-platform support. Blue Zone won the contract and was given the opportunity to design and implement a customized version of MediaBZ to make CTV News interactive. In September 2000, CTV launched its new interactive site, CTVNEWS.com. Powered by MediaBZ, CTVNEWS.com content is published simultaneously to the Web, interactive TV (WebTV), Palm and Pocket PC handheld devices and Web-enabled cell phones. Since implementation, CTVNEWS.com has consistently outperformed other news networks in speed to market, length of visitor sessions and volume of stories at a fraction of the cost of large U.S. networks. In less than a year, the CTVNEWS.com team of 15 content creators has published more than 20,000 interactive story packages.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00960"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Overview of the CBC Radio Digital Archiving System",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Holden"
                  ],
                  "abstract": "RADIOLA = Radio Archives Digital Interactive On Line Audio, a system for automatically and manually capturing radio programs for archival preservation, remote preview and rapid retrieval for further use. This paper describes the RADIOLA system located at the Toronto centre for CBC's English Radio Networks, its conception, implementation and evolution through the 1990's and considerations for the future. It explains the rationale for the use of CD-ROM as the archival medium and MPEG Layer 2 for audio encoding. RADIOLA is positioned within the framework of a Media Asset Management System, along with other related CBC systems. The twists and turns in design from 1995 RFP to commissioning in 2000 are described along with the issues and technologies that may shape its future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00965"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "In Pursuit of the “Agile Codec” – Parallel Processing Enables Flexible, Low-Cost Digital Cinema Solutions",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "B. Jason Crew"
                  ],
                  "abstract": "As the motion picture industry shifts to a digital distribution model, technology providers are faced with serious challenges in meeting the compute intensive requirements for realtime processing of cinema-quality digital content at both the studio and the theatre. Additionally, the potential to seamlessly integrate local and national advertising content, provide support for rich “alternative” content, and support emerging compression, packaging, and hardware interface standards requires that technology solutions be flexible enough to grow with the Digital Cinema business model as it develops. This paper will discuss how solutions based on a low-cost, massively paralleled “pixel-processing” approach can provide real-time Digital Cinema functions while supporting emerging standards and practices via simple software updates.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00992"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "1080p/24 – 2001 Review",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Strachan"
                  ],
                  "abstract": "The 1080p/24 format has become widely popular for transferring film images to HDTV tape at the native 24 frames per second film rate. No doubt, the immediate appeal of 1080p/24, encouraged both Sony and Panasonic to expedite development of their 24p cameras, to enable cinematographers to record directly into this video format. These cameras have enjoyed a tremendous reception by those eager to try 24p, as an alternative to 35mm film. The following is a review of the new format and some of the tools available to take advantage of the technology.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00984"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Using 35 mm Digital Intermediate to Provide 70 mm Quality in Theaters – A Progress Report",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roger R. A. Morton",
                    "Michelle A. Maurer",
                    "Gabriel Fielding",
                    "Christopher L. DuMont"
                  ],
                  "abstract": "We report progress on research into film based Digital Intermediate or Data-centric systems. Our goal is a cinema delivery system that provides onscreen cinema quality that is superior to today's 35 mm quality. A system that consistently provides across all theaters, improved realism or classic looks, and can also enable new looks, artistic and special effects. Furthermore, we seek to eliminate perceptible digital artifacts and improve productivity in post-production. We also outline a two variable method for conceptually assessing the overall performance of digital systems and report on some capabilities provided by algorithms created in support of this research.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00979"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Design Improvements for Motion Picture Film Projectors",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher L. DuMont",
                    "Andrew F. Kurtz",
                    "Barry D. Silverstein",
                    "David H. Kirkpatrick"
                  ],
                  "abstract": "This paper describes design improvements developed for motion picture film projectors that are intended to improve the quality of the overall screen image. In particular, new designs for the intermittent, or Geneva mechanism, and for a “Universal” lamp house are described. These improved designs allow the system light efficiency and uniformity to be improved, resulting in significant increases in screen luminance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00978"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Applying DRM Techniques to Video on the Internet: Characterizing Problems and Solutions",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric Grab"
                  ],
                  "abstract": "Digital distribution of media files through the public Internet presents myriad legal, technological, sociological, economic, and moral implications. The digital music debacle begs the question: Is there a workable security solution tailored to the digital distribution paradigm? The Digital Millennium Copyright Act (DMCA) has done little to promote a sensible and practical examination of the hot-button issue of digital rights management (DRM). In the post-Napster era, all major Hollywood studios are moving toward an Internet Protocol (IP) based video-on-demand solution and hundreds of thousands of unprotected full-length films are transferred over the Internet daily [1]. The urgent need for a reasonable and workable approach to digital video security is underscored at every turn. An intelligent approach to digital rights management on the Internet should address business and technological issues though a software-based, flexible, rapid -response security solution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00995"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Experimental Ultrahigh-Definition Color Camera System with Three 8M-pixel CCDs",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kohji Mitani",
                    "Masayuki Sugawara",
                    "Fumio Okano"
                  ],
                  "abstract": "An experimental ultrahigh-definition color camera system with twice the horizontal and vertical resolution of HDTV has been developed by using three 8M-pixel (4046 times 2048 active pixels) CCDs. It uses progressive scanning at 60 frames per second, so its data rate is eight times as high as that of an HDTV signal. It uses eight parallel HD-SDIs for data transmission as the output signal interface, which enables us to use various kinds of HDTV equipment. This paper describes the goal of our study, the structure of the 8M-pixel CCD, and the specifications of the camera system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00991"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "“Need for Integration of Physical and Virtual Media Asset Systems”",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hugh R. Heinsohn"
                  ],
                  "abstract": "Many media and entertainment-based organizations are currently examining various Digital Asset Management (DAM) systems and attempting to develop a digital asset management strategy to handle the increasing volumes of content passing through their facilities. All such organizations, however, have large amounts of media content already stored in various tape and film formats, including analog and digital formats, in various states of preservation. Most content owners will find that the most effective systems will support well-organized, searchable and controlled libraries of physical assets with a combination of appropriate DAM systems for their particular applications. A well thought out, comprehensive system will optimize the utility of existing libraries containing huge amounts of content, allow new content to be produced and stored in virtual formats, maintain integrated access to all of these materials, and allow easy extraction, conversion and metadata generation from library materials.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00981"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Intelligent Infrastructure for New Digital Installations",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Geoff Bowen",
                    "Martin Holmes",
                    "John Shike"
                  ],
                  "abstract": "There is a growing trend for broadcast installations to become more complex, covering more channels, with fewer trained staff on site and on hand. Industry changes such as Central Casting, diversification of broadcast channels across multiple media, and content provider aggregation are driving this trend. This paper will show some of the technology that is being used in existing and new installations to provide intelligent control and monitoring of the broadcast infrastructure, to maximize the effectiveness and efficiency of the available engineering staff and minimize system downtime. There are 2 fundamental parts to this technology. Firstly, the infrastructure itself should, wherever possible, have intelligence built in. Secondly, sophisticated, flexible, and easy to use user interfaces are required to access the inherent intelligence in the infrastructure.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00973"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "A Tour up the Gray Scale Vector of the RGB Color Cube: How Computer Graphics Color Spaces Relate to Digital Video Color Difference Space",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Leonard J. Reder",
                    "Michael Farris"
                  ],
                  "abstract": "In the RGB color space, where color is defined by relative intensities of red (R), green (G), and blue (B), the gray vector is defined by the RGB color cube diagonal where R, G, and B are all equal. This paper takes the reader on a tour up the gray vector within the RGB color cube, starting from black (R=G=B=0) and moving to white (R=G=B=1). Along the way, we stop and examine special color planes perpendicular to the gray vector. At a point one-third of the way up the gray vector, the plane has vertices defined by the pure red, green and blue primary colors of the RGB color space. Continuing to halfway up the gray vector, each edge of the color plane intersects one of six sides of the RGB cube, each intersection at a midpoint. This “halfway” plane forms an equilateral hexagon and is used to describe how RGB space and HSV (or HLS) space are related. At two-thirds the way up the vector the plane has vertices defined by the complementary colors to the pure red, green and blue; these are the pure magenta, yellow and cyan points in the RGB color cube. — Then, using the definition of Rec. 601 for standard color difference space Y, B-Y, R- Y (or YCBCR) within a digital video signal, we show geometrically how this relates to both the standard RGB cube and the HSV color space in 3- D and in various 2- D color plates. These relationships lead to insights and knowledge of YCBCR color space and how computer graphics color space differs from digital video color space. — The formulations and color plates generated in this paper will provide the reader with a more intuitive and analytical understanding of how computer graphics color spaces and video color difference space relate. This should prove useful in the development of computer- generated color graphics for video production and helpful to individuals developing color-processing algorithms such as color correction, color enhancement and color for streaming video content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00976"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Advanced Techniques for Conversion to and from p24",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jed Deame",
                    "Scott Ackerman"
                  ],
                  "abstract": "The 1080p24 format is gaining acceptance as a worldwide interchange format for film originated material as well as 24 frames per second (Fps) video originated material. For content mastered on film and transferred at 24 Fps, the conversion to 1080p24 is transparent. For content previously transferred at 30 Fps, and subsequently processed, the conversion to 1080p24 becomes much more challenging. This process is complicated by such factors as electronic editing, vari-speed, video effects, video titles, fades, film compositing, and animation. Proper handling of these “exceptions” is essential to maintaining high quality through the conversion process. Also challenging is proper conversion of 25 Fps film to 1080p24. This paper will examine the advanced techniques required to properly address the conversion requirements to and from p24.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00983"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Video Content Management in Broadcast",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Derek N. Gascon"
                  ],
                  "abstract": "Broadcasters and other media and entertainment companies have already begun a migration from analog to digital production and distribution of video content. As the adoption rate continues to grow so too does the recognition that effective mechanisms are necessary to catalog, manage and provide access to relevant video content for collaboration in the production process. The implementation of high-speed internal networks and storage area networks (SAN) have demonstrated efficiencies and productivity gains that the digital environment can provide. Specifically broadcasters in hard news, sports and long form production are ingesting greater amounts of content in digital form and are recognizing the benefits of working in this environment up through distribution. Metadata is a key aspect to allowing this system to work effectively in managing the storage, use and movement of digital files within a broadcast news and production facility. Technologies from CONVERA™ such as Screening Room® provide the ability to begin the process of indexing video content as close to, if not at the point of content creation and allows for its management throughout the content life cycle. Entities in the broadcast and entertainment segments have begun their evolution toward a digital video solution and examples are used to describe their implementation in the body of this paper.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00987"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Development of Electronic Camera Systems Using Progressive Scanning",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James M. DeFilippis"
                  ],
                  "abstract": "A current trend in television show episodic production is the use of electronic camera systems that capture moving images using ‘progressive scanning’ techniques. We at Fox have been investigating progressive scan camera systems over the past few years and beginning two years ago, embarked on a project to develop state of the art electronic camera systems that can be used for television productions that currently use film.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00982"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Application of the Latest Technologies to a New Fujicolor Negative Film",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kiyoshi Kawai",
                    "Katsumi Makino",
                    "Hikaru Murakami",
                    "Sam Yamaryo"
                  ],
                  "abstract": "Against the backdrop of increasing use of high-sensitivity motion-picture negative film and the widespread adoption of daylight lamps as a light source, Fuji Photo Film Co., Ltd. developed a new daylight type motion picture color negative film called REALA 500D. Utilizing Fuji's proprietary “fourth color-layer technology,” REALA 500D Type 8590 (35 mm), 8690 (16 mm) boasts a sensitivity of E.I.500, the world's highest among daylight-type films. We are confident that this new film, with its outstanding faithfulness to color, superb adaptability to mixed lighting environments and improved reproduction of skin tones, will further expand the choice of locations for film shooting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00977"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Centralized Network Origination (CNO) White Paper",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Adam Semcken"
                  ],
                  "abstract": "The most common operational paradigm for a traditional broadcast origination facility includes several basic areas: media acquisition, screening/conformance, newsgathering/news production, post-production, and transmission. When analyzed as a singular entity, each of these processes is required for the daily operation of the facility. However, when multiple facilities are brought together as a station group, often under a network content provider, several of these areas may be redrawn to take advantage of economies of scale not attainable by a single facility or broadcaster. — Consolidation of individual broadcasters under a network or corporate station group must take into account certain inefficiencies due to redundancy of efforts within the group. While the local segment of any single broadcaster is not ideally suited to consolidation, much of the network operations can lend themselves to this approach. — As broadcasters struggle with the global concern of a unified Media Asset Management System (MAMS), one of the primary hurdles involves identical media ingested at multiple points. Specifically, differences between titling information, metadata entry, and even video/audio standards could result in the same physical media having, in effect, multiple personalities within the system as a whole. — This paper will serve to describe a concept for Centralized Network Origination and Operations. The concept attempts to address the challenges presented by the network/station groups stated strategy to reduce redundancy within current media handling and transmission processes, while serving to enable DTV broad- and data-casting modes within SDTV/HDTV requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00972"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Color Space Conversion with 3-D LUT for Laser Film Recorder",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ado Ishii"
                  ],
                  "abstract": "A new method of color space conversion for the laser film recorder is proposed. The input image file (10 bits or more, RGB) is converted by a new three-dimensional look up table (3-D lut), then fed to the film recorder as data of 10 bit RGB. By using this conversion method, the image on print films are colorimetrically improved and matched to the image on the CRT monitor. The paper reviews the color transformation by the conventional film recording, that uses only a one-dimensional lut, then, the 3-D lut is built based on a gamut mapping algorithm to compensate for the difference of the color gamut between the CRT monitors and the print films employing a new soft clipping method. Also, three gamut compression (clipping) methods are evaluated. The calculation on the 3-D lut is based on CIE LAB color coordinates and the evaluation was performed by several observers from the post-production department. The paper additionally discusses a guideline for quality control in color management in film laboratories. This new system was successfully applied to actual production of feature animation footages.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00975"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Satellite, Broadcast, and Broadband Networks Powered with Storage Area Networks (SAN)",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Greg Reitman"
                  ],
                  "abstract": "The emergence of Digital Television (DTV) digital media integrated with Storage Area Network (SAN) systems creates one of the most significant technological change ever experienced by the broadcast, entertainment and media industry. A whole new set of variables and business issues are emerging which impact the entire video distribution chain for production houses, content aggregators, broadcasters and even service providers. As a result, industry players must adapt their IT infrastructures for new challenges such as: the transition from analog to digital formats (including HDTV), new codecs, implementing media asset management, digital rights management, IP and ATM video transmission, and transitioning from tape libraries to SAN based disk architectures. This paper will examine the video supply chain management workflow process in the media and broadcast environments and the impact of intgrating storage area networks for streaming video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00996"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "“The Business of Digital Cinema—the Exhibitors‘ Perspective”: Presented at the 143rd SMPTE Technical Conference and Exhibition New York, New York November 7, 2001",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Fithian"
                  ],
                  "abstract": "This paper has two objectives – to emphasize the importance of technical standards for digital cinema, and to describe a set of other issues that must be addressed before distributors and exhibitors can begin a serious roll out of the new technology. As for the former, the National Association of Theatre Owners (NATO) strongly endorses the standards-setting efforts of the Society of Motion Picture and Television Engineers. This paper offers suggestions for continued SMPTE progress in the context of multiple standards-setting organizations. As for the second objective – analyzing pending issues other than standards – exhibitors and distributors must address costs, control, quality, security, alternative product, participation, and legal issues before the transition can occur. The paper concludes with a note of optimism that industry leaders will find a way to address the difficult issues and that a careful transition to digital cinema will occur.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00990"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Real Time Video and Audio Content Delivery over IP Packet Networks - TrueCircuit® Implementations after One Year",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Carsten Baumann",
                    "Yendo Hu"
                  ],
                  "abstract": "Ethernet (IEEE 802.3) and packet switching have long been the underlying technology for computer networks and the Internet. They are starting now to be used for voice and video communications as new and improved network technologies, such as DiffServ, MPLS, and VPNs become widely available. Utilizing those new technologies, the former unreliable and unpredictable nature of IP networks, will now offer highest Quality of Service (QoS). These new services, in combination with highly developed IP gateway technology allow for the exchange of high quality real-time and latency sensitive applications over IP networks as an alternative to existing distribution methods, such as satellite, leased lines, and ATM. From a business perspective, IP networks are becoming economically more attractive to distribute high quality video and audio content. At last year's SMPTE Conference and Exhibition in Pasadena, we introduced TrueCircuit® technology which insures deterministic, real- time data delivery over Ethernet LAN. This technology has since been extended to address critical QoS issues over legacy backbone MAN and WAN networks. A number of successful field trials over the last year give credit to this technology's importance and value. This paper provides an update on the evolutionary development process that has moved realtime content distribution over IP Wide Area Networks closer to reality. It addresses the trial results and deployment issues faced as we incorporated this technology into real customer driven applications. A detailed cost analysis, which compares other real-time data protocols such as satellite, leased lines, and ATM, is provided for comparison. In addition, the paper covers standardization, interoperability, process considerations, and an industry future outlook as IP networks are adopted for real-time data delivery.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00997"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Coding of Natural Audio in MPEG-4",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Schuyler R. Quackenbush"
                  ],
                  "abstract": "MPEG-4 standardizes natural audio coding at bitrates ranging from 2 kbit/s, suitable for intelligible speech coding, to 64 kbit/s per channel, suitable for high-quality audio coding. Within this range, three categories of coding are defined: parametric coding, Code Excited Linear Predictive coding (CELP) and time/frequency (T/F) coding. The unique contribution of MPEG-4 audio is that not only does it scale across a wide range of bitrates, but it also scales across a broad set of other parameters, such as sampling rate, bandwidth, voice pitch and complexity. This paper presents an overview of the MPEG-4 natural audio coding framework and each of its component coding techniques.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00980"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "The Search for a Universal Timing Reference Signal",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Symes"
                  ],
                  "abstract": "For many years the timing reference for most television equipment has been a “color black” or “black-burst” signal of the appropriate standard. Although this approach has served the industry well it does have limitations, particularly in facilities that need to operate in multiple television standards. — There are difficulties inherent in replacing any established standard; the new proposal must offer substantial value when compared to the costs of making the change. This is particularly challenging in the case of the timing reference. The distribution of this signal is one of the most fundamental components of a facility infrastructure, and backward compatibility seems to be an essential element of any practical proposal. — A concept has been presented that appears to offer most of the desired attributes for a future reference signal. The paper will describe this concept, and present a view of the discussions underway to define a transport that meets industry requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00985"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Extending Video Networks with IP and Ethernet",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ted Brunner"
                  ],
                  "abstract": "This paper presents a gateway between a packet video network and a packet data network. It extends the size of an IEEE 1394 network by “tunneling” through an IP and gigabit Ethernet network. It transfers video between IEEE 1394 buses, while maintaining the video timing constraints. It uses standard IP and gigabit Ethernet switches, standard Quality of Service mechanisms, standard encapsulations on IEEE 1394 and on IP and Ethernet. And it uses GPS for a clock source. — These technology choices emphasize low cost, high flexibility and adherence to standards for greatest interoperability.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00998"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Log #74: Controlling Complex Broadcast Infrastructures",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Julian Williams"
                  ],
                  "abstract": "Making the complex simple - The key to managing broadcast systems is the integration of control in a way which matches the intuitive thought processes involved in the operation. This paper will discuss the design considerations in the construction of a control system for the broadcast environment including both human factors and engineering criteria. It will show how the desired broadcast processes can be mapped into the design of the control system. Computer science principles such as object-based design and human computer interaction are discussed in order to provide a clear understanding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00974"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "UMID Watermarking for Managing Metadata in Content Production",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jason Pelly",
                    "Daniel Tapson",
                    "John Stone",
                    "Stephen Keating"
                  ],
                  "abstract": "Watermarking is a technique for embedding data within images or audio and is best known in the field of copyright protection. This paper explains how watermarking can be used to embed a unique material identifier (UMID) into every frame of video material to enable content tracking throughout the production chain. As the UMID is embedded into the image itself, it cannot be separated and hence lost. The UMID is embedded at the point of acquisition and enables the linking of the video material to its associated metadata for rights tracking, technical information, or added-value data services in digital broadcasting. In order to allow a change of UMID, the watermark may be removed, or “washed”, and a new UMID embedded with no significant generation loss.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00989"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "The Material Exchange Format (MXF) and its Application",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Wilkinson",
                    "Bruce Devlin"
                  ],
                  "abstract": "This paper will describe the specification of the Material eXchange Format (MXF) currently under joint development by the Pro-MPEG forum [1] and the AAF (Advanced Authoring Format) Association [2]. As the name implies, the specification is focussed towards the exchange of programme material between devices that support the MXF.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00971"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "How to Easily Move and Utilize Film Images as Data in a Real-World Video Facility",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Roach"
                  ],
                  "abstract": "This paper presents an alternative use for Standard video pipelines and transport layers. It suggests taking advantage of SMPTE 292m serial digital video connections for highspeed data transport within a traditional video environment and its subsequent use, storage and transfer with non-traditional platforms. A new transport medium for film data images is introduced. The proposal includes how data images can be viewed, stored, and processed, and how standard video connections can move the data transparently. The format is described as a video-compliant data structure with variable resolutions and aspect ratios. Existing installations are described as application examples.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00986"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Case Study of an Early Adopter: The CNN Digital News Archive",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Samuel R. Shore"
                  ],
                  "abstract": "In recent years many media organizations have expressed interest in migrating from the world of videotape and text based catalog systems designed to keep track of what exists on these videotapes. One organization has made the leap and is implementing a high-resolution video digital news archive. In 2001, CNN will begin operation of an entirely new library and archive system designed to eventually hold over 125,000 hours of news video collected since 1980. An essential element in this new system is the metadata, or data about the material stored in the archive. The requirements for the metadata model were collected over many months and careful attention has been paid to insuring a standards based data dictionary. This case study on the creation of the metadata model offers insight to any enterprise considering a similar undertaking.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00988"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "The Laser Cathode Ray Tube – A Paradigm Shift in Illumination",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael D. Tiberi",
                    "Glenn Sherman",
                    "Vladimir I. Kozlovsky"
                  ],
                  "abstract": "The Laser cathode ray tube or “Laser-CRT” is a novel, high power light and image source for application in projection display, telecine and film recording. In a Laser-CRT, a semiconductor laser faceplate replaces the phosphor. A scanning electron beam impinges upon the faceplate and light is produced at each point along a raster by laser action. The Laser-CRT combines the best of CRTs and lasers; that is high- resolution, multi-sync, multi-format, reliability and low-cost of CRTs with the rich saturated colors, wide gamut and high contrast ratio available with lasers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00993"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "A Review of Survey Responses to High Quality Digital and Film Presentations",
                "article_url": "https://journal.smpte.org/conferences/143rd%20Technical%20Conference%20and%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles S. Swartz"
                  ],
                  "abstract": "On May 18 and 19, 2001, the Hollywood section held its annual Spring Seminar, in cooperation with USC Cinema's Entertainment Technology Center. The theme was “The Cinema - Now and the Future.” Because the event was held in the Entertainment Technology Center's Digital Cinema Laboratory, it was possible to show a wide variety of both 35mm film and digital material in high quality presentations to an industry audience of more than 400, including guests. After the Seminar, an online survey was posted and its link sent to every attendee's email address. Out of 375 paid attendees, 110 responded over the next month. The responses provide an insight into how industry professionals view the strengths and limitations of cinema digital display in its current form compared with film display at its best. Their overall view rated film as superior, but digital performed well, especially considering the immaturity of its technology compared with that of film.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2001-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00994"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "2000",
        "conferences": [
          {
            "conference_name": "34th SMPTE Advanced Motion Imaging Conference: Bandwidth Bitrate and Resolution",
            "conference_url": "https://journal.smpte.org/conferences/34th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference:%20Bandwidth%20Bitrate%20and%20Resolution/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Measuring Return Loss on HDTV Cabling",
                "article_url": "https://journal.smpte.org/conferences/34th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference:%20Bandwidth%20Bitrate%20and%20Resolution/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Lampen",
                    "Marty Van Der Burgt",
                    "Carl W. Dole"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001000"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "The up Conversion Option",
                "article_url": "https://journal.smpte.org/conferences/34th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference:%20Bandwidth%20Bitrate%20and%20Resolution/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Wilson",
                    "Adolfo Rodriguez"
                  ],
                  "abstract": "Today we will cover various aspects of Up Conversion for HDTV digital Broadcasting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001001"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "DVD Meets Internet (#34-18)",
                "article_url": "https://journal.smpte.org/conferences/34th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference:%20Bandwidth%20Bitrate%20and%20Resolution/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Taylor"
                  ],
                  "abstract": "WebDVD is the combination of two of the hottest technologies: DVD and the Internet. DVD makes up for the bandwidth limitations of the Internet, while a Web connection makes up for the static nature of DVD. This paper discusses features and advantages of Web-connected DVDs, how it all works, and what tools are available.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001002"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Video Testing in a DTV World",
                "article_url": "https://journal.smpte.org/conferences/34th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference:%20Bandwidth%20Bitrate%20and%20Resolution/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Fibush"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00999"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "142nd Technical Conference and Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/",
            "articles": [
              {
                "article_local_id": "10",
                "article_title": "Interactive Television Content Authoring",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Mitchell"
                  ],
                  "abstract": "This paper discusses adapting already successful Internet content creation methods for the development and presentation of interactive television programming.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00150"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Advanced Television Broadcasting in a Digital Broadband Distribution Environment",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ian Oliver",
                    "Brian Holmes"
                  ],
                  "abstract": "This paper is intended to be of use to members of the broadcast television engineering community in their efforts to address the challenges and opportunities presented by the various broadband digital distribution models available to them. It must be noted that the scope of a fully detailed discussion of even one of the digital broadband distribution models considered herein would produce a paper of an unreasonable length. Therefore the various broadcast models are examined and discussed from what might be considered an engineering management perspective. In that regard, the authors have also briefly addressed certain economic considerations of the various distribution models, especially as likely to impact engineering design and capital expenditure decisions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00141"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "“Cable-Compatible” Digital Television Receivers and “Receiver-Compatible” Digital Cable Television Systems",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bernard J. Lechner"
                  ],
                  "abstract": "In February, 2000, the Consumer Electronics Association (CEA) and the National Cable Television Association (NCTA) reached agreement on a set of network interface specifications that, when adhered to for digital transmission by “Receiver-Compatible” digital cable television systems, will allow “Cable-Compatible” digital consumer electronics products to be connected directly to the cable television system. Such “Cable-Compatible” products will allow consumers to view and record digital programs transmitted by the cable television system in the clear, including terrestrial broadcast programs. When equipped with a Pont-of-Deployment (POD) replaceable security module, “Cable-Compatible” digital receivers and VCR's will also be able to receive subscription programs such as HBO and Showtime as well as pay-per-view programming that is ordered by placing an 800-number phone call. — The agreement between CEA and NCTA also addresses the specification of the POD module interface and the carriage of Program and System Information Protocol (PSIP) data to support the navigation function in the receiver. Future efforts by CEA and NCTA will extend the network and POD interface specifications to include reverse data channel parameters for use on two-way cable television systems. This will allow “Cable-Compatible Two-Way” digital receivers to provide interactive cable services such as impulse-pay-per-view and video-on-demand.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00143"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Time Division Multiplexing (TDM) Video and Data Streams into a 1.5Gb/s HDTV Stream",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keping Chen",
                    "Randy Conrod"
                  ],
                  "abstract": "This paper describes a new standard, SMPTE 346M that defines the time division multiplexing (TDM) of various standard-definition digital video and generic 8-bit data signals over a single high definition serial digital interface (SMPTE 292M). The objective of this single High Definition Multiplexed Interface is to use a single physical link to transmit, distribute, route and switch a complete family of existing 10-bit video formats and various data formats. — Active video and vertical blanking areas in the HD SDI stream are time divided into multiple channels. The standard uses 19 time-interleaved channels. The header data of the first channel is reserved to indicate the data valuation of the remaining 18 channels. — A single video or data stream is multiplexed into one or more channels of the total 18 data channels. A control packet is multiplexed into horizontal ancillary data space of the luminance parallel data area after the switching point of the HD stream for each video or data stream. The control packet indicates how and which TDM channels are used for this video or data stream. It also contains a stream clock reference signal (SCR) for clock recovery of the original clock signal. — According to the standard, multiple video or data streams could be multiplexed into and demultiplexed from a single HD SDI stream with a total delay of less than 4 us which is the time of the horizontal ancillary data space of the HD stream with additional processing delay. — A comparison between SDTI and TDM is made, pointing out the advantages and disadvantages of each type of interface.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00146"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "TrueCircuit™ Technology: Distribution of Video / Audio / Control and Meta Data via a Paradigm IP Network using QoS, High Bandwidth Efficiency, and Low Latency",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Carsten Baumann",
                    "Yendo Hu"
                  ],
                  "abstract": "More and more broadcast stations, Production, and Post-Production houses are planning to use standard IP networks to distribute video, audio, control, and meta data in real time. Standard Ethernet networks suffer from problems such as, non-deterministic bandwidth, latency and excessive jitter for reliable real time transport of video/audio. — Ethernet (IEEE 802.3) and packet switching have long been the underlying technology for computer networks and the Internet, but are now barely used for voice and video communications. This is due to the unreliable and unpredictable nature, of the so-called “best-effort” service provided by IP networks. This result in a high degree of uncertainty in how quickly a packet will be delivered to its destination. — New real-time Internet protocols are being developed to guarantee a requested quality of service over an Internet connection. However even where implemented, they do not guarantee end-to-end delay or latency only bandwidth. Without latency guarantees, IP networks will not be truly able to distribute real time video and audio content. — TrueCircuit™ technology has been developed to provide QoS guarantees over Ethernet LANs and WANs. This technology involves conditioning real-time traffic before it is transmitted. TrueCircuit™ provides a proprietary virtual circuit protocol that enables real-time traffic flow. TrueCircuit™ equipment allows complete backward compatibility with standard IEEE 802.3 Ethernet. In a fully integrated TrueCircuit™ environment the bandwidth efficiency can increase up to 94% while guaranteeing very low latency through the IP network. — The paper will address first the legacy issues of standard Ethernet networks. Then it will describe the TrueCircuit™ technology, the critical missing link in this technology revolution and how the Broadcast, Production, and the Post Production facilities can benefit using this technology in the very near future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00144"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Multi-Channel Serial Digital Video Transmission, Distribution, and Reception",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raj Chandrasekhar",
                    "Norm Tarleton",
                    "Michael Johnson"
                  ],
                  "abstract": "At Honeywell, a team of engineers and scientists, including these authors, researched and developed technologies for seamlessly tiling arrays of displays to render ultra-high resolution imagery. Fully scalable, their architectural design provided viable paths for delivering tens of millions of pixels to the viewer. The topic of this paper was born from the need to provide and to deliver ultra-high resolution imagery. The method described below describes the development and implementation of a compact, low cost, scalable-by-design, video transmission scheme. The objective was to deliver a MxN array of video streams to a JxK array of seamlessly tiled displays, thereby enabling the display of ultra-high resolution, many millions of pixels video. The image source material is digital, but the COTS (Commercial Off The Shelf) board that provides an interface to the source material uses an analog transmission scheme, undesirable for many reasons in the system. The transmitter described in this paper taps into the digital 8-bit video stream on the COTS board and creates a serial digital bit stream. The serial video is then transmitted over a coaxial cable to the receiver. The receiver de-serializes the bit stream and recreates the 8-bit video. By going to an all-digital transmission scheme, multiple analog/digital conversions and its associated pitfalls are avoided. Used in an array, each COTS-Transmitter-Coax-Receiver channel enables a fully scalable image delivery system, especially useful for ultra-high resolution imaging systems for digital cinema, medical and similarly demanding applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00145"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Balancing Technology in Digital Cinema Systems",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. A. Morley",
                    "K. S. Thyagarajan",
                    "A. C. Irvine"
                  ],
                  "abstract": "An efficient digital cinema system design balances the use of off-the-shelf technology with specialized hardware and software designed to meet the specific needs of this application. For instance, the use of standard computer, storage, networking and communication equipment results in cost-effective design that benefits from other widespread uses of these technologies. However, certain functions required for a high quality, reliable, secure digital cinema system must be custom developed specifically for this application. The electronic projection equipment, image compression system and security sub-system are three such areas where existing technology developed for other applications will not be adequate to meet the demanding needs and current practices of cinema operations. — This paper addresses the proper combination of off-the-shelf high-volume equipment and technology specifically developed for an acceptable digital cinema system solution. A detailed discussion is given on the requirements of the necessary custom functions and why existing alternatives are not appropriate for the digital cinema application, particularly in the area of image compression methods. Finally, a proposed solution for the custom developed technology is presented and an approach is discussed in which this technology gracefully fits in a system architecture taking maximal advantage, where appropriate, of high-volume available technology. Specifically, a discussion is presented on an Application Specific Integrated Circuit (ASIC) that has been developed to perform security and decompression processing of digital cinema image and audio programs as part of a flexible, cost-effective digital cinema system-level solution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00149"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "How ATM Networks Ensure a Transparent Transport of Real-Time Professional Broadcast Services",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jean Chatel",
                    "David Mouen Makoua",
                    "Laurent Thebault"
                  ],
                  "abstract": "With the combination of digital TV and digital networking technologies the transport of professional broadcast services is undergoing a tremendous evolution. After a move from analog to digital, specialized leased lines are progressively being replaced by powerful general purpose ATM (Asynchronous Transfer Mode) based networks. — The most critical issue for the adoption of this new technology by the broadcast industry is the transport of live real-time broadcast services, for which the most serious constraints appear. The level of performance, which can be expected for this type of application, is a key point for the end-user broadcaster. — Real-time services are most often transported compressed using video compression formats such as MPEG-2 or DV. Transit delay, jitter performance, robustness against transmission errors, synchronization between receivers and emitters are typical parameters to qualify the related constraints. — After reminding some key elements of the ATM technology, this paper focuses on performance aspects. The mechanisms put in place, leading to commitments that both the end-user broadcaster and the network operator have to fulfill to meet a given level of performance are explained. Practical performance results are given, and examples of large-scale deployments are described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00142"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "The Future of the Moving Image",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "Electronic cameras and projectors are improving at a rapid pace. Computational elements are increasing in power to the point where substantial processing can be applied to the image stream. Compression algorithms have improved to the point where very high quality can be maintained at high compression ratios. The combination of high resolution and high frame rate can bring unprecedented image clarity to an electronic imaging system. With high quality compression as a central system element, image capture and presentation systems can realize their full technology potential. While it is evident that uncompressed digital video at standard definition is widely available for many video system elements, it is only now becoming apparent that imaging systems are poised to jump orders of magnitude in quality beyond this. HDTV implementations of the last decade begin to look like a small step in comparison to the leap in quality that is now anticipated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00147"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "The Technology of Enhanced Color Saturation: Kodak Ektachrome 100D Color Reversal Film/5285",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Long"
                  ],
                  "abstract": "As a result of customer needs research identifying value in the production of a high color saturation capture film capable of ‘alternate looks’ in commercials, television, and features applications, Eastman Kodak Company has developed enhanced color technology for inclusion in a new motion picture reversal film, KODAK EKTACHROME 100D Color Reversal Film/5285. — In this paper, background will be offered into the unique color technology that makes Ektachrome 100D film so saturated in its rendition of imaged colors while conversely remaining true to flesh tones and scene neutrals. Special attention will be given to the theories of color gamut and color reproduction palette as they relate to the techniques employed within this technology. Sample images will also be shown to demonstrate the look that can be achieved ‘right out of the camera’ with Ektachrome 100D film.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00164"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Removal of Spatial and Temporal Alias Artifacts in Format Conversion and Display",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Glenn"
                  ],
                  "abstract": "Scan conversion from interlace to progressive scan usually brings with it the temporal alias that causes interline flicker. Spatially sampled images or images displayed on a trinatron frequently have moiré beats (spatial alias frequencies) between the video, the system clock and the display sampling structure. This paper will describe ways to prevent these aliases from becoming visible without sacrifice resolution or motion rendition.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00166"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Transcoding: A Step into the All-MPEG World",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marty Stein"
                  ],
                  "abstract": "The construction of MPEG-2 transport multiplexes for final transmission to the home is becoming more complex for Broadcasters and Cable System Operators. The rapidly increasing array of new content types and formats that are leading to a new viewing and entertainment experience means that these service providers have to carefully manage and mediate the composition of their fixed transmission pipes. This paper describes the basics of a relatively new technology, called MPEG-2 stream transcoding, that is now being deployed to help with these tasks.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00167"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Archival Video Status?",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Wheeler"
                  ],
                  "abstract": "Archivists who keep videotapes for 50 years or longer have different needs then do Broadcasters who may think of “archival” as anything that is not on-line and who consider ten years to be the lifetime for most video. This paper informs technical people in the Broadcast Industry about issues in long-term storage of videotapes. Among these issues are physical problems with tape, including binder breakdown, fungus, and thin basefilm. Another issue has to do with equipment-both obsolescence and proper alignment and cleaning. Video formats are an additional major area of concern, particularly because the machines that meet criteria as an archival format are too expensive for archives or the video is compressed and degrades the original analog material. Is there a truly archival video medium/format in the near future?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00157"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Paper Abstract",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mitch Seigle"
                  ],
                  "abstract": "Reducing the time to produce videos is important to anyone working in the industry. One timesaving element available is the implementation of storage area networks (SANs). SANs use high-bandwidth interconnects that enable transmission of blocks of video data for editing and production, as well as compressing streams of data for server and broadcast operations. This paper will discuss the role and benefits of SANs in video applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00155"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Data Broadcasting Solutions for Broadcasters",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brett Jenkins"
                  ],
                  "abstract": "With the advent of digital TV in the United States and worldwide, broadcasters are searching for new opportunities to enhance the programming they offer. In addition many in the industry believe that potential new sources of revenue can be unlocked by providing consumers rich digital content. This year Thomcast Communications and PBS teamed to test an end-to-end data broadcasting solution. This paper presents an update of those trials. First a general data broadcasting architecture is discussed along with the technical requirements to support various potential business models. This includes a discussion on what is required to deliver IP content over MPEG-2 networks. The needs of both the network facility and the local station are addressed. Finally, solutions that have actually been implemented and tested in the field are presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00154"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Mastering and Archiving Uncompressed Digital Video Test Materials",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles Fenimore"
                  ],
                  "abstract": "This is a report on the status of a Society of Motion Picture and Television Engineers (SMPTE) Ad Hoc Group charged with creating a master set of images for subjective testing of electronic systems. The images are to be sold at cost by SMPTE for use in the evaluation of electronic systems. The first task is creation of a master representation of the image sequences to enable preservation of the images in a consistent and stable storage environment. Once the many images available to the Society are restored and returned to a pristine image state when possible, they will be provided to the SMPTE in a digital file format. The Society will then offer the video sequences for sale in various formats [both in digital data media and uncompressed digital videotape] for the purpose of subjective testing of electronic systems. This report also includes representative images from the image sequences in a set of standard definition materials, the first fruits of the Ad Hoc Group. Finally, the report is a request for feedback and suggestions on the quality of, and the interest in, this process.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00158"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "The Pro-MPEG/AAF Association Material Exchange Format (MXF)",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James H. Wilkinson"
                  ],
                  "abstract": "This paper will describe the Material eXchange Format (MXF) currently under joint development by the Pro-MPEG forum [1] and the AAF (Advanced Authoring Format) Association [2]. — An MXF file is a ‘wrapper’ for containing audio-visual material in a playable stream format. Each file contains a comprehensive metadata structure together with component parts which enable MXF files to be written and read directly by AAF compliant hardware and software tools. The entire coding structure is based on the recently approved SMPTE standards relating to metadata coding using the KLV syntax [3] and standardised metadata dictionary items [4]. At the time of writing, the work is progressing to conclusion, but is not yet complete. — Therefore, some aspects described in this paper represent work-in-progress and may be subject to change in the final specification. — This paper will describe the MXF format with particular emphasis on the file data structure and modelling for the metadata.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00156"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "A Very High Bit Rate Image Data Recorder",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dave Bancroft"
                  ],
                  "abstract": "A number of applications for high-resolution image capture and processing operate with data derived directly from the colorimetric values of the image source rather than with video signals. One purpose is to accommodate more flexibly the greater variations in spatial resolution, color gamut, transfer characteristic and aspect ratio that can occur when the original is film-based, rather than video camera based. Another is to allow universal mastering that can deliver the finished content to a variety of destinations-conventional cinema, digital cinema, DVD and broadcast video-without the need for re-mastering each one. — Several products now exist to support operations in this desirable data form, including disk-based storage of very high speed and capacity, but what has been missing so far has been a suitable mass storage backup device: data representing high-resolution moving images is extremely voluminous, and the limited capacity and transfer rate of most tape-based storage devices has until now caused backup and restore operations to be a major bottleneck in the workflow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00159"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "An Open Architecture and Realization for the Integration of Broadcast Digital Video and Personalized Online Media",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Norbert Gerfelder",
                    "Matthias Finke",
                    "Luc Neumann"
                  ],
                  "abstract": "With the introduction of digital broadcast, e.g. DVB, the question arise which kind of new interactive services can be offered to the viewer. Until now, these services concentrate on EPGs, video on demand, and basic E-Commerce services presented on TV sets. On the other side new generation TV sets are able to access the Internet and to present WWW content. — One aim of this paper is the presentation of an new architecture which allows the genuine combination of broadcast and Internet content, allowing the creation and use of hyperlinked interactive video. Adding hypermedia capabilities to objects inside video streams opens the opportunity for new kinds of synchronized content presentations with a wide variety of applications. — A main requirement which is fulfilled by the proposed architecture is the support of existing or upcoming formats and delivery channels and to be open for further developments and applications. For hyperlinked digital video we present a concept which consists of three independent components: the video content, the specification of selectable objects and the linking information. Furthermore, the system consists of a client-server architecture which allows global interaction. Based on this separated components the system is open for customizations and the introduction of personalization. — Personalization allows the filtering and adaptation of content based on device and user profiles. With this methods, different presentation devices can be supported, ranging from small, restricted mobile appliances up to large screen stationary presentation equipment and, furthermore, the consideration of user preferences. — The client-server concept and the adaptable components allow the application of hyperlinked interactive video in pure Internet environments, e.g. the WWW, and in broadcast environments with different realizations of a return channel.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "interactive digital video",
                      "hyperlinked video",
                      "media filtering and adaptation",
                      "personalized presentation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00151"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "The Present and Future of Channel Branding",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Brice"
                  ],
                  "abstract": "Today's TV viewer has much in common with today's hypermarket shopper faced with a bewildering choice of similar products. This compelling analogy has spawned a new terminology for television, borrowed from the world of consumer markets, that of “channel branding”. In such a market environment, the development of clear and understandable channel brands will be crucial to winning viewers and subscriptions and thereby maintaining revenue. TV companies which understand consumer brands and how they can be built and exploited will be the successful ones. Starting out by looking at the range of current master-control and “channel branding” products, aimed at providing broadcasters with a range of tools to provide distinctive and attractive “house styles”, the paper goes on to cover current and future developments in multi-channel, multi-stream, shared-operator and operator-less environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00162"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Considerations for Moving to a Video Server Based Facility",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roger Crooks"
                  ],
                  "abstract": "Moving to a video server based environment requires an analysis of the total workflow of the facility. Without understanding the big picture, it's easy to make a costly mistake. This paper will help highlight the right questions to ask and looks at the advantages and disadvantages of different approaches.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00161"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "4:4:4 Compression of Moving Pictures for Digital Cinema using the MPEG-2 Toolkit",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael W. Bruns",
                    "James T. Whittlesey"
                  ],
                  "abstract": "The scope of compression techniques provided in the MPEG-2 toolkit is broad enough to meet today's picture quality expectations of digital cinema theatrical presentations with enhancements in rate control, 4:4:4 chroma format color space, and greater color precision than the profiles that are defined for television. This optimization for the unique requirements of digital cinema, while beyond currently defined MPEG profiles, is enabled by the wide range of the MPEG-2 toolkit and can be implemented using standard off-the-shelf silicon devices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00148"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "SMPTE 334M Data there is a Whole Industry before Emission",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. F. Carruthers"
                  ],
                  "abstract": "Data, particularly interactive content data and metadata such as movie industry related support data needs to ‘stick’ to the video and sound from creation through emission. The new SMPTE 334M approach to encoding data in the VANC portion of the SMPTE 229M signal offers a simple yet powerful way to deliver this data while using proven broadcast procedures and processes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00152"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "High Performance Electro-Optic Camera Prototype: 142nd Conference of the Society of Motion Picture and Television Engineers",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen A. Stough",
                    "William A. Hill"
                  ],
                  "abstract": "A prototype camera was built to determine if the color space, exposure range, exposure latitude and alias-free resolution of an electronic capture system could match that of a film camera. Certain design techniques of astronomical sensors were combined with new methods of CCD charge transfer and large-format integrated circuit fabrication to create a 4,096 pixel × 3,112 pixel detector. This detector was integrated into a prototype motion picture camera system and subjected to engineering tests. It will be used in screen tests this autumn. This paper describes the design goals, the overall design of the prototype system, and the initial test results. A brief description of alternative technologies is given. Areas of future research are outlined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00175"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "A Multi-Format HDTV Camera Head",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Centen",
                    "Ton Moelands",
                    "Jan van Rooy",
                    "Mike Stekelenburg"
                  ],
                  "abstract": "A novel way for capturing native 1080P, 1080I and 720P at 16:9 aspect ratio and a CineScope aspect ratio in 1080P of 2.37:1 will be presented. The architecture of the multi-format HDTV camera head is based on a newly designed Frame Transfer CCD-imager. It enables the design of a camera head that has multiple formats available at the HD-SDI (SMPTE 292M) output of the camera head itself. — The camera head utilizes 3 Frame Transfer (2/3 inch) CCDs with 9.2 M-pixels each (including overscan). Through the use of a 12-phase system all the vertical resolutions of the SMPTE 274M and SMPTE 296M standards are possible. Under software control (Dynamic Pixel Management) these pixels are pre-arranged, at the CCD, into image cells. The image diagonal (11-mm) is independent of spatial resolution and therefore the same for all scanning formats. — The video processing chain consists of three 12 bit ADCs followed by two newly designed ASICs that allow multi-format video processing. Amongst many other outputs, the ASICs have an SMPTE292M compatible 20bit parallel output can be serialized to obtain a HD-SDI output at the camera head. The above video chain offers full digital processing capability. — A dockable concept is exploited in full to enable: • A multi-purpose adapter for ‘stand alone’ operation with battery power input, gen-lock Input and HD-SDI output (1.5 Gbps), • A wide band analog TRIAX adapter (Y = 30 MHz, Cr, Cb = 15 MHz) for transmission up to 3000 ft of cable. • Future adapters to offer the possibility of optical fiber transmission with longer cable lengths or a (DCPRO HD) camcorder",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00163"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Images and Formats",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David J. Bancroft"
                  ],
                  "abstract": "Two previously separate industries — motion picture film and television — are merging their applications and their technologies. The question arises as to which industry's technologies should be chosen to solve which new problems. — One issue in particular is the way in which moving images are represented electronically. Should television standards such as HDTV be used for cinematographic images? Conversely, would television benefit from discarding transmission-standard-based video formats in post-production in favour of data formats developed originally to represent film frames? — This paper examines these questions and offers some guidelines for the user to determine the best answer for specific situations, rather than a blanket statement to cover all applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00165"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Blue Screen Matting using Curved Separating Surfaces",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yasushi Mishima"
                  ],
                  "abstract": "The purpose of this paper is to propose a new ‘blue screen matting’ digital solution, which employs ‘curved separating surfaces’ in RGB colorspace. The ‘separating surface’ model was examined by Jim Blinn and Alvy Ray Smith at the 1996 Siggraph conference, and is the recognized model that is employed in two of the most common matting products being used by the industry today, the Ultimatte keying technology and IMAGICA/Photron's Primatte. With this paper, we extend the concept from the earlier model, which was defined with coarse polygons, to curved surfaces that maintain a more natural pixel distribution of the foreground data against the background screen. In this paper, I introduce a constrained grid surface patch (referred to as ‘OGP’ in this paper), which achieves a fast, practical computing solution for natural matte generation and background suppression. OGP offers the advantage of working with uneven green or blue screen conditions without a decrease in performance. An additional solution called the ‘Extended Matting Problem’ is also presented that uses two additional curved separating surfaces for background spill removal. I will also demonstrate how the new method processes difficult matte frames.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00168"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Serving up Data for Enhanced DTV Programs",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gomer Thomas"
                  ],
                  "abstract": "An important feature of digital television (DTV) is the ability to insert data into the broadcast stream to enhance the TV programming. Examples of applications enabled by this technology include interactive ads, interactive access to sports statistics during sports events, and interactive access to supplementary information during talk shows, news programs, documentaries, etc. This paper describes the basic technology for such enhanced DTV programming, and analyzes the architectural and scheduling issues that arise in connection with inserting data into the digital broadcast stream to support it. The primary focus is on so-called ATVEF (Advanced Television Enhancement Forum) applications in the context of the ATSC digital television standards, but most of the analysis applies equally well to other forms of enhanced DTV programming where data must be coordinated with the audio-video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00153"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "2000 SMPTE Technical Conference and Exhibition: “Digital Video Recorders: All-in-One Content Recording, Storage, Playback and Management System”",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bentley Nelson"
                  ],
                  "abstract": "“Personal video recording” is revolutionizing the way we view, record and playback television programs and is predicted to grow to an installed base of 14 million users by 2004, according to Forrester Research, making this one of the hottest new product categories ever introduced by the consumer electronics industry. At the heart of each personal video recording device is a hard disk drive which provides the ability to record without tape, and to access recorded programs instantly. Further, digital video recording on hard disk drives enables simultaneous recording and play back, making it possible to pause live TV and perform instant replays of live broadcasts in the viewer's home. — As the engine for the entire personal video recording industry, the DVR may provide all of the capabilities to record, store and play back digital content within the hard disk drive itself. Thus, the DVR has not only made possible “personal video recording,” but will be the vehicle for a wide variety of revolutionary and innovative hard drive-enabled consumer electronics products. In the near future, we will witness this technology being embedded in products ranging from television sets and cable and satellite set-top boxes to audio jukeboxes, game consoles and Internet appliances, creating new means of enjoying digital entertainment for consumers everywhere. — As a content recording, storage, playback and management system all in one, the DVR encompasses all the basic ingredients of a television broadcast facility in one simple box, which has applications at both the broadcast site and at the reception site.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00160"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Seamless Audio Splicing for ISO/IEC 13818 Transport Streams",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Seyfullah Halit Oguz",
                    "Sorin Faibish"
                  ],
                  "abstract": "The work reported in this paper addresses the processing of the packetized audio elementary streams (ESs) during the splicing of ISO/IEC 13818 (MPEG-2) transport streams (TS). An algorithm is developed which without the need for decoding and re-encoding the audio ESs, produces a continuous audio ES across the splicing point, avoids all noticeable audio artifacts and hence provides a seamless audio splice. The perfect continuity with respect to the presentation time stamps (PTS), and the careful management of the audio buffer level at all times lead to a glitch-free audio play-out for an unlimited number of splices. The proposed algorithm parses the packetized audio ES up to the audio access unit (AAU) level and is computationally very simple. — In the MPEG-2 syntax, the coded data of the two fundamental signal components, namely the video and the audio, are encapsulated in the so called access units (AUs). An AU is the smallest self-contained segment of the compressed data which can be decoded and presented. The coded representations of one video frame and a certain number of audio PCM samples (depending on the audio encoding algorithm layer), correspond to AUs for video and audio respectively. The play-out (presentation) duration of a video access unit (VAU) is a function of the input video source format (NTSC or PAL) whereas the play-out duration of an AAU depends on the audio encoding algorithm layer employed and the sampling frequency of the audio signal. It turns out that with the allowable ranges of these parameters, the decoded forms of video and audio AUs known as presentation units (PUs) are practically never aligned in terms of the ending of their play-out durations. This misalignment brings in the problem of having an unequal (in terms of total play-out durations) amount of video and audio data when a program is terminated at a splicing point. The processing of the packetized audio elementary streams so far was achieved either by leaving an audio gap at the splicing point leading to an undesirable audio mute or by decoding and re-encoding of the audio signal which is computationally very costly. — We propose a solution to this problem by introducing the so called “best aligned audio presentation units (APUs)”. The best aligned APU for an ending program is defined as the APU whose presentation interval's ending time is best aligned with the ending instant of the presentation interval of the last video presentation unit (VPU) to be displayed from this program. For a starting program, the best aligned APU is defined similarly but this time with respect to the starting instants of the relevant PUs. Based on the best aligned APUs of the ending and starting programs, the audio PTSs in the starting program are re-stamped to achieve a continuous audio stream across the splicing point. It can be easily proved that through the use of the best aligned APUs, the audio-visual skew introduced in the starting program is upper bounded by half of the play-out duration of an APU which is far below the sensitivity of the human observer, (typically a fraction of the video frame interval). Cases where the immediate use of best aligned APUs is possible are known as minimal achievable skew cases. The inevitable change in the mean audio buffer level of the starting program introduced by the re-stamping may make the immediate use of best aligned APUs impossible. This will be due to an original audio buffer level dynamics in the starting clip which is not safely bounded away from underflow or overflow. Such marginal cases are carefully managed by making a possible addition to or a deletion from the set of APUs described by the best aligned APUs. Consequently, the inevitable change in the starting program's mean audio buffer level is introduced in a controlled fashion in the proper direction which will avoid underflows or overflows. Cases where a deviation from the use of best aligned APUs is necessary are known as minimal achievable safe skew cases. It can again be easily proved that the minimal achievable safe skew is upper bounded by the play-out duration of an APU which is again well below noticeable limits. A very simple model of the packetized audio ES is also developed which can facilitate the classification of the starting program's audio buffer dynamics as mentioned above. — The principles of the proposed algorithm are very general and can be easily extended to cover other audio encoding algorithms with AU based data encapsulation and other forms of data encapsulated in AUs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00170"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Audio in Cable, Broadcast, and Satellite Distribution Issues & Solutions for the Digital Transition via Audio Metadata",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jeffrey Riedmiller",
                    "Tom du Breuil"
                  ],
                  "abstract": "This paper covers the audio content delivery processes currently used throughout the video industry with a specific focus on the cable distribution infrastructure. This infrastructure has, for the first time, the capability of delivering high quality digital audio services and programming to subscribers' homes. These systems give the subscriber the ability to make new listening choices, based on their own needs and desires. Enabling these new subscriber choices requires greater care than ever before in preserving all the audio information from its original creation through the programmer uplinks and cable headends to the subscriber's home. Historically, each signal routing point between content origination and the subscriber's home has applied some processing to the signals as they pass through; providing the highest quality audio with these new features to the subscriber requires rethinking many of the current practices such that the actual digital audio information is carried without manipulation through to the subscriber's home. These new features are supported by the metadata carried within the Dolby Digital bitstream, and this paper describes this metadata and how to put it to proper use in cable delivery systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00171"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Metadata for Enhanced Electronic Program Guides",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gomer Thomas"
                  ],
                  "abstract": "An increasingly popular feature for TV viewers is an on-screen, interactive, electronic program guide (EPG). The advent of digital television (DTV), with the high digital bandwidth it provides, has the potential to support more and better EPG functions than ever. However, currently the best EPGs are available only in proprietary environments. The reason for this is that the current DTV standards only support data for the most basic EPG functions. To make enhanced EPG functions ubiquitous, enhanced DTV standards are required. One capability that is of great interest to broadcasters and advertisers, if not consumers, is the ability to include general purpose advertising in EPG displays. This paper lays out the vision of future EPGs, describes the standards activities currently underway to support them, and suggests a possible business model for supporting general purpose advertising in EPGs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00172"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "24-Frame and Multiple Frame-rate Post Systems and Equipment Design Considerations",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Wiswell"
                  ],
                  "abstract": "With the growing interest in 24-frame high definition video production certain realities are becoming apparent. The first reality is the great difficulty in creating a flexible and affordable high definition production environment that possesses the user's required performance attributes. The second reality is that cost factors weigh heavily on design considerations for system designers as well as for equipment manufacturers. — Panasonic is approaching the 24-frame issue as part of a multiple-format solution for users who do a great deal of work with film-originated video. Electronic shooting can not match film's image performance and it's highly unlikely that technological developments in the near term will lead to an electronic system capable of displacing film's desirable attributes. Therefore, 24-frame video is more appropriately an element of the evolving high definition entertainment industry, not a solution in and of itself. Television equipment that is limited to 24-frame high definition functionality with separate equipment for 25, 30 or 60 frame video is not a viable economic picture for manufacturers or for cost-sensitive production of high definition programming. Panasonic believes that only multiple-use systems and production devices will lead to the widespread and long-term success of high definition television. — Implementation of multiple-image format and frame-rate systems and devices creates a new set of design challenges for image and control systems. Videotape continues to be the backbone of modern television production. This paper will address new system and performance criteria for the multiple-format mastering video recorder. Engineering considerations to be addressed include the need for multiple timecodes, transcoding timecodes, internal and external image format conversion requirements, remote control and system environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00174"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Diamond Audio — Explained",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Neil Karsh",
                    "Ian Puszet"
                  ],
                  "abstract": "Diamond Audio by Leitch Inc. is an audio compression system utilizing the enhanced apt-X™ algorithm. This proprietary compression algorithm, developed by Audio Processing Technology Inc (APT), combined with an advanced feature set and simple user interface provide an effective method of encoding and decoding multi channel audio signals for the Post Production and Broadcast environment. — This paper will address three areas: • How the enhanced apt-X™ algorithm functions • The features added to the core technology to aid the end user • Integration of the technology into a Post Production or Broadcast environment. — Superb audio quality, a simple to use human interface with features not found in other systems, combined with packaging and integration options that fit a wide variety of applications are what Diamond Audio technology offers the Post Production and Broadcast professional.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00169"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "A Platform for Constructing Distributed Asset Management Systems",
                "article_url": "https://journal.smpte.org/conferences/142nd%20Technical%20Conference%20and%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steven Bilow",
                    "Scott Libert",
                    "Anil Murching",
                    "Dave Slack"
                  ],
                  "abstract": "With television's transition to digital comes the requirement to manage a variety of distributed assets. A facility-wide management system must oversee these assets even if the creation and storage systems already include smaller-scale management tools. We believe that it is unreasonable to assume that software vendors will give up control over their own asset management in favor a completely centralized system. Therefore, the greatest chance of success is through tools that allow a variety of systems to collaborate. The objective of the ContentShare Platform is to enable this collaboration. Neither a monolithic database, nor an end-user asset management system, the ContentShare Platform is a set of active software components, called agents and brokers, that allows application software to include standardized data exchange interfaces. These interfaces present a layer of abstraction allowing multiple applications to share information about their assets, in a peer-to-peer environment, without giving up control. This ultimately permits systems to grow as a facility grows and allows an organization to expand with minimal architectural impact.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "2000-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00173"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1999",
        "conferences": [
          {
            "conference_name": "141st SMPTE Technical Conference and Exhibition",
            "conference_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/",
            "articles": [
              {
                "article_local_id": "16",
                "article_title": "An IEEE 1394-Based Architecture for Media Storage and Networking",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Camden Ford"
                  ],
                  "abstract": "As broadcast facilities transition from analog to digital, new disc-based storage systems and integrated networking technologies are changing the landscape of these installations. In the past five years, many different types of storage and networking technologies have been developed to improve the efficiency of media storage and the speed in which that media can be distributed. Videotape is rapidly being augmented by random access devices such as laser disc recorders, still stores, digital disc recorders, standard PCs, and other disc-based storage devices. The advent of cost-effective video compression hardware and low-cost, high-capacity disc drives has made many of the above devices pervasive in today's broadcast environment. — The primary advantage of disc-based systems over tape-based systems is the speed and flexibility in which users can access the stored material. The significant advantage of a well-designed networking topology is low-latency distribution of the material. Video servers are valuable products because multiple users can access any material quickly and simultaneously. Now larger, more flexible disc-based systems are providing storage capacities greater than one thousand hours and shared access to this material through multiple I/O interfaces such as SDI, SDTI, Ethernet, Fibre Channel, ATM, and IEEE 1394. Even though the new storage devices provide significant capacity increases and some shared access to the stored material, the primary mode of accessing content stored on these devices is through a traditional point-to-point video network usually based on a large, multi-layered video and audio routing switcher. As the number of video compression formats increase and as the capacity of storage systems increase, the networks that provide access to this content become more important. By providing simple and efficient access to stored material, control and facility operations are simplified; costs are reduced; and higher-quality, reliable service is possible. — This paper examines the characteristics and benefits of several existing network-based storage architectures including: Traditional storage shared via a standard analog/digital router, networked video file servers, Storage Area Networks (SAN), and enterprise data networks (Ethernet, utilizing Storage Area Networks and Network Attached Storage—NAS). For each system architecture mentioned, we will discuss details of specific device I/O and control, redundancy strategies, and scalability. This paper will also propose a new system architecture based on IEEE 1394 networking and Network Attached Storage. This new architecture provides all of the benefits of the other systems discussed with few of the limitations. New system architectures based on IEEE 1394 networking and Fibre Channel storage technologies will set new standards for flexibility, scalability, access, and reliability at costs far below traditional approaches.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00322"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Color in 1080p24 and Electronic Cinema: Converting between R′G′B′ and 4:2:2",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles Poynton"
                  ],
                  "abstract": "An important challenge in the standardization of electronic cinema is the choice of a color representation. Among the possibilities are R′G′B′ and Y′CBCR. In this paper, I explore the relationship between the two. — Film, video, and computer-generated imagery (CGI) all start with red, green, and blue (RGB) tristimulus components proportional to intensity—“linear light.” A nonlinear transfer function is applied to RGB to give gamma corrected R′G′B′. This is the native color representation of video cameras, computer monitors, video monitors, and television. — The human visual system has poor color acuity. If R′G′B′ is transformed into luma and chroma, then color detail can be discarded without the viewer noticing. This enables a substantial saving in data capacity—in “bandwidth,” or in storage space. Because studio video equipment has historically operated near the limit of realtime capture, recording, processing, and transmission capabilities, the subsampled Y′CBCR 4:2:2 format has been the workhorse of studio video for more than a decade. — The disadvantage of 4:2:2 is its lossy compression. Upon “matrixing” from 8-bit R′G′B′ to 8-bit Y′CBCR, three-quarters of the available colors are lost. Upon 4:2:2 subsampling, half the color detail is discarded. But production staff are facing increasing demands for quality, and increasing demands to integrate video production with film and CGI. The lossy compression of 4:2:2 is becoming a major disadvantage.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00307"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "If You're No Longer Using Your Father's Video Editor, Why Are You Still Using His Router?",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dimitri Chernyshov"
                  ],
                  "abstract": "Today's workstation-based video creation and manipulation tools allow users to treat video as discrete chunks of images and sounds that can be manipulated in various ways. This abstraction provides the freedom to focus on content generation rather than on the tools used to create the content. Yet, while the latest video tools allow far more creativity and functionality, the way video is distributed among these tools remains unchanged. Storage Area Networks (SANs) are the basis for a new video distribution system. They allow the video moving between the tools to be treated in the same way as the video inside the tools - as discrete chunks of images and sounds. SANs empower entire teams of people to focus on the process of creation and creative collaboration rather than on how to best move materials between workstations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00316"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Loop Bandwidth Optimization and Jitter Measurement Techniques for Serial HDTV Systems",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Atul Krishna Gupta",
                    "Aapool Biman",
                    "Dino Toffolon"
                  ],
                  "abstract": "This paper describes a system level optimization of a studio serial digital interface for uncompressed High Definition Television (HDTV). The HDTV data rate is 5.5 times that of Standard Definition Television (SDTV) which allows little design margin for jitter. An intuitive time domain discussion of different sources of jitter is presented. This paper provides design guidelines for video sources, routers, digital signal processing units with serial interface, distribution amplifiers and production switchers. These guidelines reinforce the SMPTE 292M standard and other recommended practices, e.g. EG33-1998. Using commercially available general-purpose test units and some custom built boards it is shown that some of the important jitter parameters associated with serial HDTV can be easily measured.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00314"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "HD/DTV and the Closed Captioning Food Chain",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Strachan"
                  ],
                  "abstract": "More than 20 million people in North America are either hard of hearing or clinically deaf. Closed Captioning television techniques provide these viewers, with the ability to appreciate the audio speech as well as the video content of the programs being offered. Closed Captioning is also useful in noisy environments, subtitling of foreign languages and for educational material In the NTSC television system, captions are encoded onto line 21 of the Vertical Blanking Interval (VBI). This data may be decoded by the NTSC television set and displayed as subtitles on the screen. The advent of DTV brings enhancements to captioning capabilities and new challenges for the television engineer. It becomes necessary to encode the DTV EIA-708 compliant closed captioning data into the DTV bitstream, at the same time as retaining the NTSC captions required by EIA-608 compliant receivers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00315"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Technical Aspects of the New World of Multi-Format DTV Embodying Progressive, Interlaced, and Segmented Frame Video Format",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurence J. Thorpe"
                  ],
                  "abstract": "The past year has seen an unprecedented flurry of industry activity on the product and system development (and standardization) of a 24 Frame progressive scan HDTV production system (now generally known as the 24P system). — Two marketplace imperatives are driving this: Digital Television production for multi-format DTV, and a digital adjunct to motion picture film for Movie production. Issues of Acquisition, Transport, and Postproduction relating to this format must all be encompassed in their respective overall system designs. 24P offers novel solutions to managing postproduction in our new world of multi-format DTV which encompasses both progressive and interlaced scanning. — Meanwhile, a separate initiative, this time in the arena of HDTV international standards development, finally bore fruit in a stunning accomplishment in 1999 within the International Telecommunication Union (ITU). On June 3rd, 1999 the ITU issued a press release which reported on the achievement of a major milestone in the history of television with their adoption of a new electronic production standard for television program origination. Their addition of the 24 frame capture rate to a family of other rates surrounding their novel concept of a Common Image Format for HD production could, in the words of the press release: “well revolutionize the film and television industries”. — The new ITU standard reached out to encompass the 50 and 60 Hz systems (in both their progressive and interlace embodiments) as well as adding the 24, 25, and 30 frame progressive scanning formats. They further recognized the important merits of the segmented frame transport mechanism and have embodied this into the Recommendation for the 24, 25, and 30 frame systems. — Suddenly, the old established world of analog 50/60 Hz interlaced video is about to be replaced by a world of mixed progressive, interlaced, and segmented frame digital video—all operating at a variety of frame and field rates. Understanding this new world, and the options available to sensibly implement flexible systems, will be helped by a better understanding of the essential differences between interlaced, progressive and segmented frames video structures. This paper will attempt to outline the basic technical characteristics of each.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00309"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Navigating the Rapids of DTV Standards Conversion",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Wilson"
                  ],
                  "abstract": "In the modern world of DTV we have, perhaps rashly complicated our lives beyond all reason. For various techno-political reasons we now have to deal with TV formats that come in an abundance of flavours. 702 worst case!! We have progressive or interlace, in a multitude of field or frame rates. You as users or originators of DTV programming may have to deal with all these formats.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00311"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "NASA's Myriad Uses of Digital Video",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rodney Grubbs",
                    "Walt Lindblom",
                    "Sandy George"
                  ],
                  "abstract": "Since it's inception, NASA has created many of the most memorable images seen this Century. From the fuzzy video of Neil Armstrong taking that first step on the moon, to images of the Mars surface available to all on the internet, NASA has provided images to inspire a generation, all because a scientist or researcher had a requirement to see something unusual. — Digital Television technology will give NASA unprecedented new tools for acquiring, analyzing, and distributing video. This paper will explore NASA's DTV future. — The agency has a requirement to move video from one NASA Center to another, in real time. Specifics will be provided relating to the NASA video infrastructure, including video from the Space Shuttle and from the various Centers. — A comparison of the pros and cons of interlace and progressive scanned images will be presented. — Film is a major component of NASA's image acquisition for analysis usage. The future of film within the context of DTV will be explored.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00318"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Transitioning to File-Based Electronic Media Storage",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John F. Hennessy"
                  ],
                  "abstract": "Traditional television programming has historically been produced and aired via videotape. Most video programming worldwide is still archived on videotape. With the advent of computer based video servers, television organizations are beginning to transition from videotape based archives to file-based electronic media storage. The purpose of this paper is to explore the advantages of treating video segments as data files along with the technical and operational challenges presented by the change. The paper includes a detailed discussion on the integration of networked video servers with associated disk storage and tape-based data archives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00321"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Integrated Wide-Area ATM Solutions for Broadcasters and Production",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anthony Magliocco",
                    "Sam Kershaw"
                  ],
                  "abstract": "Broadcasters production and post facilities use a variety of public and private wide-area network technologies to connect remote studios to broadcast centers for voice, data and video communications services. By migrating all these services onto a single ATM infrastructure, a number of broadcasters production studios are now gaining significant operational and economic benefits. This paper describes how these integrated wide-area network services are deployed and provides details of the new TV networking services supported by an ATM infrastructure.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00330"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "A Comparison of Alternative High Definition Display Technologies to CRT",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter F. van Kessel",
                    "Terry A. Bartlett",
                    "Scott Dewald",
                    "Gregory S. Pettitt"
                  ],
                  "abstract": "Over the last 18 months, high definition home entertainment systems have become available to the US consumer, albeit at a substantial price tag. These systems are based almost exclusively on direct view and rear projection CRT technology. More recently however, a number of manufacturers have made announcements portending the arrival of HDTV projection systems based on alternative display technologies such as transmissive and reflective LCD, and DLP™. Many of these announcements promise excellent image quality, but demonstrations of prototype systems have shown that there is much variability in subjective image quality from system to system. As the incumbent technology, direct view and rear projection CRT have set the image quality standard by which alternative technologies will be judged. Virtually all of the CRT's competitors in the HD arena are based on fixed matrix modulators with substantially different electronic and optical characteristics. It would be of interest to explore how these differences manifest themselves in terms of image quality relative to that of CRT technology. — In this paper, we will examine some of the image quality characteristics of representative samples of several LCD and DLP based projection display technologies as compared to those of CRT-based HD sets. MTF characteristics will be compared, as well as quantitative image quality metrics utilizing several established methods.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00324"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Strategic Implications for Future Content Management Systems",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John D. Litke"
                  ],
                  "abstract": "The broadcasting industry is facing massive investment requirements for digital production and distribution technology. At the same time, industry competitive relationships are changing, business models being challenged, delivery mechanisms changing and content formats proliferating. Asset and media management systems pose particularly difficult investment decisions because of their central role in the production infrastructure and their cost. After reviewing the business issues, the paper suggests that content management systems should expect to work in distributed, federated and collaborative contexts. This implies specific requirements on content management systems for content location and identification, for version and configuration management, and for project and task control systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00320"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Managing the Content Explosion with 24P Universal Editing + Mastering",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Phillips",
                    "Peter Fasciano"
                  ],
                  "abstract": "Executive Summary — Content distribution channels are expanding at an ever-increasing pace. Today, hundreds of channels of narrowcast programming are available from traditional broadcasters, cable content providers and multiple satellite delivery systems, creating a huge appetite for content. This wider choice of content creates greater competition for viewers. How do you break through the clutter? And, how do you create content that is more compelling and relevant to more viewers across many geographic and demographic boundaries? This is the new challenge for post-production. — In this paper, we look at the four basic dimensions of a broadcast format: resolution, scan formats, frame rate and aspect ratio, within the context of the new challenges for post-production. This identifies 24P as the ideal mastering format. We introduce Avid's 24P Universal Editing and Mastering technology—a revolutionary set of capabilities that will help you meet the new challenges and take advantage of the considerable opportunities in a multi-format, multi-version world. These capabilities are included in the Avid Symphony Universal system, a new model in the Avid Symphony product family. An offline version of this technology was introduced with Media Composer 9.0 XL for Windows NT. 24P Universal Editing and Mastering will provide enormous benefits to three types of projects: | Projects with multi-format delivery requirements | Film-originated projects | HDTV projects — Universal Mastering includes tools to digitize 24P content using standard NTSC and PAL decks, edit and finish in native uncompressed 24P, and then to output multi-format masters, including NTSC and PAL. Other important tools include Pan and Scan, timecode management and new film-tape-film-tape (FTFT) capabilities, all of which are discussed in detail in this paper. All of these capabilities, together with Total Conform and a collaborative environment of editing, finishing, audio, graphics and effects tools, have made an end-to-end nonlinear high-end post-production environment not only possible, but more powerful than linear alternatives. Now, all editorial, graphical and effects decisions are carried seamlessly between the offline and finishing stages, allowing you to spend time on creative finishing work rather than mechanical conforming chores. Once the online is finished, you can quickly produce NTSC and PAL masters in 4:3 and 16:9 aspect ratios, as well as an EDL for HD conform and frame-accurate film cut lists. — Finally, we present Avid's integrated family of solutions for editing and finishing in a collaborative, multi-version, multi-format environment. These products are the building blocks in a scaleable, flexible and economical approach to handling the content creation challenges of today and tomorrow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00308"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Discreet: The Universal Mastering Format for Post-Production Finishing: 1080p/24",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "The following paper format as a result of international acceptance of DTV broadcasting standards, and the ensuing demand for more programming content in various addresses the need for a Universal Mastering formats. Nonlinear disk-based finishing systems offer a flexible solution. Market needs, system requirements and descriptions of several possible post-production workflows are examined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00310"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Global Contribution Video Networks: Criteria and Implementation",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steven L. Storozum"
                  ],
                  "abstract": "New transmission technologies are enabling high-speed, uncompressed or lightly compressed digital video signals to be sent through fiber optic backbone networks across a region or a continent. As bandwidth costs continue to drop, this trend will extend itself across the globe, making worldwide terrestrial digital contribution networks a reality. These networks will permit collaborative production of high-definition television anywhere throughout the world and will deliver production-quality, uncompromised high-definition video signals worldwide destinations. However, certain design criteria must be met if these networks are to be technologically feasible. This paper explores some of these criteria from the video, transmission, and control points of view, and suggests possible methods for implementing these networks.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00328"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Utilization Issues for Large, Consumer Video Displays",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jeffrey B. Sampsell"
                  ],
                  "abstract": "The acceptance by US consumers of large screen, rear projection video receivers has grown until this segment of the TV market accounts for approximately a million units per year and the largest share of profit from sales. The near term availability of high definition digital television (DTV) signals in the US, Japan, Europe, and elsewhere will continue to drive growth in this sector. New market opportunities will emerge for rear projection, front projection, and flat panel large screen displays. — This presentation will briefly review the diverse technologies available to serve these three types of display. Comparisons will be drawn between the quoted/expected display specifications (which tend to be driven by engineering and marketing criteria) and the actual performance required and/or likely to be achieved in the consumer's dwelling (which tends to be determined by architecture, furniture, children, pets, school, work, dinner, and the limits of personal wealth).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00325"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Cinema Projection Distortion",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ronald A. Petrozzo",
                    "Stuart W. Singer"
                  ],
                  "abstract": "This paper addresses projected image Distortion in a cinema setting. Several types of distortions are defined and examples are presented to show that the degree of distortion in the image can be calculated based on the theater geometry as well as the film format and projector lens specifications. This paper concentrates on inherent distortion values that typically effect the overall shape of the picture area and the relative shapes of all subjects being viewed as well as the audience's perception of imaged picture quality. Since distortion changes only the shape of objects in the picture and not how well the viewer can see them, there is little basis for objectively derived design limits. Further, when viewing a real scene that does not contain a perfect rectilinear test grid, the eye accommodates small amounts of distortion, which is therefore not perceived. However, moderate to severe amounts of distortion, and particularly distortion in memory objects such as curved horizons and leaning or curved flagpoles, is disturbing to viewers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00323"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Networking–Requirements for Production and Post Production Applications",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward Hobson"
                  ],
                  "abstract": "Production and post-production applications for television are collaborative in nature. The intricacies of a production involve a number of people throughout concept creation and development, scripting, research, casting, location scouting, shooting, editing, audio recording, audio dubbing, video effects, audio effects, music composition, scoring, and recording. These processes often involve personnel with skills and tools unique to a particular portion of the process. Each may require access to the material used in the production. Sharing this material is akin to the way computers share information in a computer network.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00327"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Ultrahigh-Sensitivity Color HDTV Camera for Shooting Heavenly Bodies",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keizo Majima",
                    "Shunji Sunazaki",
                    "Junichi Yamazaki",
                    "Takashi Ando"
                  ],
                  "abstract": "An ultrahigh-sensitivity color HDTV camera has been developed that consists of three proximity-focused image intensifier tubes of large image size (useful area: 40 mm diameter) and three FIT CCDs of 2/3-in.2M pixels. The images are relayed by high-quality lenses with a reducing power of 1/3.6. The camera's sensitivity is 3,000 times higher than that of a conventional HDTV CCD camera. This camera has made it possible to take rare shots of a meteor from the ground and video images of the various hues of celestial bodies by means of an advanced astronomical telescope.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00317"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "High Definition Stripping, Genlock, and Timing Regeneration for Multiple Formats of High Definition Video & Film",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Poimboeuf"
                  ],
                  "abstract": "For High Definition Video & Film outputs, both symmetric (1-to-1), and asymmetric combinations of sources and timings are used for output genlock. This paper describes techniques being used in a system to lock both types of combinations. To simplify the numerical complexity of these timing relationships, a new mathematical notation (recently invented for describing digital audio timing relationships), called the “Log Prime” vector is introduced. This paper considers timing stability challenges for High Definition interfacing, and presents the genlock architecture of a High Definition I/O board now being used in multiprocessor computer servers and graphics supercomputers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00312"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "An Alternative Architecture for High Performance Display",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "R. W. Corrigan",
                    "B. R. Lang",
                    "D.A. LeHoty",
                    "P.A. Alioshin"
                  ],
                  "abstract": "The Grating Light Valve (GLV™) technology is being used in an innovative system architecture to create a high resolution projected image by optically scanning a linear array of GLV pixels. We will discuss the real-time video processing used to optimize the performance of this unique architecture for applications such as Home Theater and Electronic Cinema.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00326"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Quality in HDTV Post",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Horton",
                    "Bob Pank"
                  ],
                  "abstract": "The expectation of high definition television is that it should at least be a technically superior viewing experience - so picture quality is immediately an issue. Maintaining quality through post production is vital as it is a part of the complex path from scene to screen. More than that, with far greater picture detail, corrective measures to improve the pictures also assume a high importance as does the tool-set to enable program makers to accomplish their planned results. Achieving such aims economically appears to be hampered by the very high data rates and storage needed for HD but by examining a number of alternatives acceptable schemes can be found.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00313"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Audio-Video Synchronization Across DTV Transport Interfaces: The Impossible Dream?",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Randall Hoffner"
                  ],
                  "abstract": "The end-to-end DTV production, distribution, and broadcast system is a complex assemblage of many digital processing and storage devices. A number of interfaces are required to transport the compressed and uncompressed DTV audio and video signals between devices in the system. — Each component of the DTV system imposes its own latency on the audio and/or video signals flowing through it, and the delays imposed on audio and video signals respectively are typically unequal, compromising audio-video synchronization. It is incumbent on those implementing DTV production, post production, and broadcast systems to be aware of the latencies present at each interface, and to take steps to correct synchronization errors at each stage, thereby preventing the buildup of lip sync errors. This paper will discuss the potential trouble spots within the DTV system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00341"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "The Use of OE MPEG Profile for Production, Contribution and Distribution Networking",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Louis Cheveau",
                    "Anthony Caruso"
                  ],
                  "abstract": "The EBU permanent services first had the opportunity to assess MPEG-2 / 4:2:2 equipment in 1997, when dual standard Professional Profile/Main Profile encoders and IRDs were installed at the Eurovision Control Centre, Geneva, and tested for possible use on the Eurovision Network. Two bit-rates 24 Mbit/s and 8.448 Mbit/s were selected for operational reasons.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00346"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "A Pragmatic Approach to Data Networks in Media Production",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S.J. Owen"
                  ],
                  "abstract": "The need for a viable data networking solution in production has never been greater. The requirements to handle more production formats and metadata combined with the relentless drive for efficiency is placing the current video infrastructure under pressure. Fast data networks are increasingly available and potentially help solve many problems. To gain the maximum benefit from mainstream network technology it is important that the production environment understands its capabilities and limitations. This paper argues that for many applications the cost and complexity of networks supporting advanced services, such as quality of service, is not warranted and its benefit is outweighed by the interoperability and affordability of simpler solutions. The availability of general purpose high-bandwidth, low latency networks with good vendor support will prove invaluable to the production system designer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00329"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Real-Time Remote File System for Production",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Atsuhiro Tsuji",
                    "Yukiko Itoh",
                    "Shinzo Doi",
                    "Kouji Kubota",
                    "Tsutomu Tanaka"
                  ],
                  "abstract": "The distributed file system provides a facility for sharing files in a network environment to exchange program material as bit-streams. However, the current distributed file system doesn't support the realtime access of files yet. We propose a distributed file system that has the real-time access capability to be used in a professional broadcast environment. This distributed file system enables the non-linear editor to edit programs through direct accesses to the contents in the remote server, and it will enable the diskless non-linear editor.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00331"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Smart Digital Video Interfaces Solve the Problem of Multiple Standards",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Greg Sadowski"
                  ],
                  "abstract": "Recent introduction of many new digital high definition video standards has created a challenge for interfacing various types of video equipment. On the same physical interconnections a variety of different video and audio formats can be transported. There are already over 57 new different video formats standardized, and the number will likely continue to grow. — The formats may have any combination of the following parameters: • active raster size (display resolution), • progressive or not, • different vertical rates, • RGB or YUV color space, • different synchronization references, • ancillary data presence and type, • multiple transport links (auto-adjustment of phase) • timing reference signals — Future digital video equipment will incorporate smart interfaces to relief users from the burden of “running around” and manually switching modes of different “boxes”. Smart interfaces will increase productivity of video studios, video databases and such. — This paper describes a computer system (with storage) employing a smart video interface to automate system interaction with the outside video equipment. The paper also explores detailed technical solutions to the smart video interface challenge. Example of “High Definition Video I/O” card from SGI (former Silicon Graphics) is used to illustrate how the right architecture can allow for implementation of various circuits for automatic recognition of video formats. The card received two awards (“NAB 99 editors' pick of show”, and “The Tommy Award” from Millimeter magazine“) and great applause from the video post-production community.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00334"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Conversion of Film-Based Interlaced HD Material to Progressive: Harmony or Cacophony?",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Randall Hoffner"
                  ],
                  "abstract": "Interlaced HDTV material derived from 24 Hz film may be successfully converted to HDTV and SDTV progressive-scan formats such as 720P and 480P, using a frame-based process. Such a conversion, done properly, can produce a progressively scanned product with excellent spatial and temporal resolution, and without interlace artifacts or the mixed film-frame artifacts that are the inevitable result of 3/2 pulldown when applied to interlaced video. — Proper reconstruction of progressive frames requires assembly of the correct fields, which in turn requires accurate synchronization to the 3/2 cadence of the interlaced source material. — This paper will discuss the methods used to convert interlaced video material derived from 24 frame film to progressive and the factors that must be considered in order to make high quality, artifact-free conversions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00333"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Implementation of SMPTE Metadata for Advanced Authoring Applications",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Oliver Morgan",
                    "Tim Bingham"
                  ],
                  "abstract": "Following from the publication of the Final Report of the EBU/SMPTE Task Force for the Harmonization of Standards for the Exchange of Programme Material as Bit Streams (TFHS), standards-writing has proceeded within SMPTE W25 and other committees, and has now produced several approved standards and many others in draft. Together, this work comprises the SMPTE Data Model and Dictionary, a significant step forward for the industry. The SMPTE Data model and the standardization projects have been described in several previous papers by Morgan and others.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00319"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Motion Compensated De-Interlacing: The Key to the Digital Video Transition",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jed Deame"
                  ],
                  "abstract": "As the video industry transitions from analog to digital, more and more video processing equipment will also need to transition from analog to digital. The current analog television standards, NTSC, PAL, etc., are based on interlaced formats. As these standards transition to digital, the demand for progressive material will increase, causing a directly proportional increase in the demand for video processing products with high quality de-interlacing. — There are many ways to perform the de-interlace process, with varying levels of quality and corresponding compute requirements. This paper will emphasize the importance of proper de-interlacing, examine some of the currently used techniques for de-interlacing video, delineate a new de-interlacing technique, and discuss applications where this new de-interlacing technique can improve the end-to-end image quality of any DTV system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00336"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "A Picture Format Converter Using Motion Compensated De-Interlacing",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenji Sugiyama",
                    "Neil Neubert"
                  ],
                  "abstract": "Picture format conversion is an important technology for multi format broadcast. Many interlaced DTV transmissions are likely to be conversions from other interlaced acquisition formats and the main topic of this paper will be conversion from one interlaced picture to another interlaced picture. Practical realization of this conversion is accomplished by dividing the processing into two parts, de-interlacing and line re-sampling. In this structure, suitable de-interlacing can be applied using motion compensation. Further, a new de-interlacing method is described to solve problems introduced by motion compensation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00337"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "DTV Audio Mixing for Maximum Impact and Compatibility",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Hilson"
                  ],
                  "abstract": "With the advent of digital television transmissions, new opportunities and challenges have emerged for audio production. What began as a simple monaural audio production can now be produced with the same sonic quality and 5.1 channel experience that viewers have been able to experience in the cinema for many years. — The rapid acceptance and growth of DVD, with its full 5.1 channel audio capability and component video is proof that consumers want better sound and picture in their homes. Until terrestrial digital television broadcasting began in November 1998, consumers had a better audio and video system available to them from DVD and DSS. The broadcasters were left behind. — Now that the broadcasters have the capability to carry 5.1 channel audio with digital television transmissions, there are many questions to be answered about how to best accomplish the audio mixes for these programs. The purpose of this paper is to provide a basic starting place for the audio mixer, station management and engineering personnel as they embark on the 5.1 channel audio production experience.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00339"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "MPEG-2 Video Archive System for Live-Broadcasting Using IP over ATM and a Study on Video Retrieval System for Large-Scale Archives",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kazuhiko Matsubayashi",
                    "Haruo Sakurada",
                    "Kengo Nomura",
                    "Teppei Shimoyama",
                    "Takashi Kato",
                    "Shoichiro Ogawa",
                    "Keigo Majima",
                    "Toshihiro Uehara"
                  ],
                  "abstract": "To ensure that the new form of interactive programs is fully functional as we enter the era of digital broadcasting, NHK has prepared an array of equipment for such programs in its HDTV and SDTV studios. This equipment centers around a video file system that uses a video server and is used with a fast network that employs IP over ATM.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00332"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Audio Metadata Authoring and System Integration",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen Lyman"
                  ],
                  "abstract": "The ATSC Audio system depends on audio metadata for many of its most attractive features, Listeners gain the ability to tailor the presentation of different styles of program to their individual requirements. Producers gain a great deal of control over how individual program material is presented to the listeners. They have, for example, direct control over the balance of downmixes of multichannel material, and can choose how the dynamic range of a program is reduced, if the listener chooses a presentation with less than the full original dynamics. — The metadata associated with a particular program must of course accurately reflect the characteristics of that program, if the system is to operate correctly. This implies that a new set of metadata parameters has to be created (or authored) for each program, and in that sense, metadata authoring can be seen as a parallel and very similar process to the creation of the audio program itself. — The paper will examine the creative aspects of authoring metadata and the range of choices that are available to the program producers, and several different methods of specifying the various parameter values. Metadata can be created at several different stages of program production; these will be examined to determine the most appropriate “location” at which to author the parameters, with particular attention paid to the process of production of broadcast material. Metadata can be monitored and edited as it passes through a typical broadcast chain. Reasons for doing this and appropriate methods of changing parameter values are also discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00340"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Chemical Processing of Digital Soundtracks—Future Challenges for the Laboratories",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ujwal N. Nirgudkar"
                  ],
                  "abstract": "Sound is an integral part of any Motion Picture Film. With the advent of new technologies in Sound recording and reproduction, and as a tool of special effect, Sound has become an important factor of the motion picture film, in today's Digital era. Chemical processing of sound negative film, as well as processing of soundtrack on a positive film, has to be done with utmost care now-a-days. — Most Motion Picture laboratories use conventional processing machines for processing positive films. Although these machines are good enough for processing the conventional (regular mono) soundtracks, Digital sound requires a special treatment and more stringent quality control. — This paper discusses the present soundtrack redevelopment system used in laboratories, their advantages, disadvantages, and modifications required to adapt to new Digital sound processing standards. — This paper also discusses following points in detail with respect to processing of Digital soundtracks on the positive film. (1) Positive Film Processing Chemistry. (2) Soundtrack Redeveloper Applicator Design. (3) Viscosity Of Soundtrack Redeveloper. (4) Speed Of Positive Processing Machines. (5) Surface Characteristics Of Various Films. — An idea about replacing the separate Sound and Color negative system, by a Common Duplicate Negative using new Digital Sound formats, is also expressed here. — In the coming millenium, all countries will need to exchange informations, films, sounds and languages in various options available, which can be used by the entire world. This will need a common uniform Digital sound format. A new concept of Information Track which can store information about soundtrack and subtitles in various languages is also discussed here.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00345"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "A New Film Scanning Machine for Film in a Digital World",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Corbitt"
                  ],
                  "abstract": "This paper describes some of the difficulties the design team of ITK had to overcome to build their new high definition telecine based on CRT/flying spot technology. It also aims to explain how some old problems in this field were resolved with new concepts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00344"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "The Latest Emulsion Technology on New Super F Series",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Katsumi Makino",
                    "Ryoji Nishimura",
                    "Yasunori Mimaki",
                    "Sam Yamaryo",
                    "Hikaru Murakami"
                  ],
                  "abstract": "Fuji Photo Film has introduced the New Super F Series F-250 and F-250D Color Negative Films in March of 1999, following the previous introduction of the New Super F Series F-64D, F-125 and F-500 Color Negative Films in 1998. The introduction of these two new film stocks completes the upgrading process of the entire line of Super F Series film stocks and offers cinematographers world-class imaging quality and superior digital manipulation compatibility. — The improvements in image quality of the New F-250 and F-250D film stocks are comparable to the dramatic improvements attained last year in the New F-500. This paper discusses the benefits offered by the New F-250 and F-250D film stocks and the technological developments utilized in their design. — The New Super F Series F-250 and F-250D Color Negative Films incorporate two significant proprietary technological developments which results in significantly improved granularity, sharpness, color reproduction, latitude and telecine transfer characteristics. — The first of these developments is Fuji's Super Uniform Fine Grain (SUFG) technology. This proprietary advancement is particularly effective in increasing fine-grain sensitivity, which has previously been unachievable in high-speed photosensitive materials. The SUFG technology is incorporated into all layers of the new F-250, F-250D and F-500 films and is responsible for their remarkably fine grain. — The second development is Fuji's unique DIR technology. — This proprietary improvement is also a critical factor in the new emulsion's performance equation and brings vast improvements in sharpness and color reproduction over traditional high-speed emulsions through more precisely controlled release of a highly diffusible development inhibitor.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00342"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "DVD Dailies: Creative Collaboration for Feature Film Makers",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kim Aubry",
                    "Richard Mizer"
                  ],
                  "abstract": "Executive Summary — Film and sound media are essentially linear, and the process of recording performance or documentary images and sound are likewise linear in their essence. Of course, we may selectively choose to turn the camera on and off to compress time and to conserve media materials during subsequent editing. — But the collaborators in film projects relate to the materials in a non-linear way. The photographer, director, costume designer, producer all may have specific needs to view captured images, sounds or meta-data and may wish to navigate through media in differing and customizable ways. — In this special report, the author(s) will give a brief history of the filmmaker's traditional production and post-production process using examples of film “dailies” and historical photos. The author(s) then will present a new approach employing DVD as a universal non-linear and interactive media tool for those working on film and video projects. As DVD is in its infancy, we will explore some potential benefits of the medium and propose basic architectural concepts for DVD authoring in this application. — By simulating the process of making feature film dailies, this concept of using DVD instead of tape was investigated. This report will describe the results of these experiments, and the exact configuration and equipment used will be described. During the telecine process, the video and audio were captured to Betacam tape, as before, but the signal was also fed into a MPEG-2 video encoder and an audio encoder and captured to disc. These files were imported into DVD authoring software using templates and macros to accelerate the process, and a DVD-R was burned for delivery to the director. While it normally takes up to a week, or about 40 working hours or more to make a DVD, for this application to succeed, it can take only about 2 hours after the telecine transfer was completed to have the disc ready for review.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00343"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Video Performance Measurements in DTV Transmission Systems",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward Reuss"
                  ],
                  "abstract": "During the transition from analog to digital, the typical video facility will have to support a mixture of both analog and digital video equipment. This mixed facility requires a combination of analog and digital video performance measurement tools to verify proper video image quality. In many cases the traditional analog video performance measurements can be used to infer proper performance in a digital video transmission system. This paper summarizes some of the performance issues in analog, digital and mixed analog/digital video transmission systems and some of the methods that can be used to verify proper video performance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00347"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "MPEG-2 Transcoding from the Production-Into the Emission Format",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rolf Hedtke",
                    "Matthias Schnoell"
                  ],
                  "abstract": "MPEG-2 ML@4:2:2P Compression with I-frames only and a datarate of 50 Mbit/s has been recently proposed by EBU and SMPTE as one of two compression schemes that would be utilized in the production process. The coding format used for digital emission is based on MPEG-2 MP@ML with a long group of pictures and a typical datarate of 4–6 Mbit/s. Therefore a transcoding with high quality is needed. The non-real-time method explained in this paper delivers a much better subjective picture quality in comparison with the first generation realtime encoding even with transparent ITU-R 601 inputs. Therefore by a given picture quality for emission the bit-rate needed for the datastream can be drastically reduced.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00335"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Impact of 5.1 Audio in Television Production and Distribution",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim DeFilippis"
                  ],
                  "abstract": "In this paper we will survey the current audio for television production paradigm and investigate the change from 2 channel stereo to 5.1 channel surround. — Some real world examples with details regarding the difficulties encountered will be discussed. Future technical and operational requirements will be proposed. The current status of standards and practices for 5.1 will be explained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00338"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Management and Control of Receivers in a Satellite Distribution Network",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marty Stein"
                  ],
                  "abstract": "Managing and controlling a network of satellite-linked users presents a number of challenges not present in wired networks. In many cases receive sites are unattended or have no access to wired communications, so maintaining the integrity of the satellite link and implementing built-in recovery schemes is necessary. Over time, several techniques have been devised to control receivers via the broadcast signal and to allow receivers to automatically find their “home” frequency should some perturbation cause a temporary loss of signal. This paper describes the basic elements of satellite networks designed for program distribution and examines some of the techniques employed to maintain connection with receivers and to control the network.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00348"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "Monitoring and Control for Digital Transmission Systems",
                "article_url": "https://journal.smpte.org/conferences/141st%20SMPTE%20Technical%20Conference%20and%20Exhibition/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Melissa D. Lowver"
                  ],
                  "abstract": "• The complexity of digital multi-channel services has prompted the broadcasting industry to seriously consider how to improve management and control of the network as a whole. • The traditional method of tracking channel integrity with a monitor and an operator is no longer cost-effective or technically feasible. • By capitalizing on digital compression and multiplexing techniques, broadcasters can maximize bandwidth on transmission delivery systems, bringing with it significant commercial advantages. • The structure of digital signals allows for the detection of many problems at an early stage, as well as some automatic replacement of the signal to correct the problem. • Early warning is essential. Control is also required, to instigate fallback services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00349"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "9th Conference and Exhibition of the SMPTE Australia Section",
            "conference_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/",
            "articles": [
              {
                "article_local_id": "5",
                "article_title": "High Definition Studios, OB Vans and Playout Centre",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stuart Pointon"
                  ],
                  "abstract": "Panasonic have been the major installer of High Definition studio's and OB Vans in Japan, and have also designed and installed the High Definition Release Centre for the ABC Network in the USA. — Some of the HD Studio's to have been built by Panasonic include all 7 HD studio's for NHK, Studio's and OB Vans for Fuji (CX), YTV and NTV. — This paper will discuss issues that have been confronted by the design engineers who have put these facilities together. Some of these issues are:- • Monitoring • Cabling • Interfacing • Distribution • Ergonomics • Customer input — As part of this paper, an overview of the new DVCPRO100 series ENG products will be discussed and compared with the top end HD products that have been designed for high definition production work.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001164"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "DVB-T Hierarchical Modulation: An Opportunity for New Services?",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gerard Faria"
                  ],
                  "abstract": "The European DVB-T standard includes a large number of transmission modes able to adapt the COFDM signal to a wide variety of broadcasting services. Among others, the hierarchical modulation mode allows to broadcast, on the same radio frequency channel two independent transport streams (MPEG-TS) having each a dedicated protection. With this apparently strange & complex modulation mode, it becomes possible to imagine new broadcast services: • to define two distinct coverage areas for a transmitter, • to address both mobile and static receivers, • To simulcast digital programs in standard (SDTV) and high definition (HDTV) formats, combined with the natural advantage to operate several transmitters in an iso frequency network (SFN - Single Frequency Network), the hierarchical modulation highlights the tremendous capacities of the DVB-T system. — After an educational explanation of the COFDM signal, details are given on the way to perform simulcast or mobile services with DVB-T hierarchical modulation. Is the DVB-T hierarchical modulation an opportunity for new digital terrestrial TV services? The author intends to bring his conviction in this paper.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001167"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "DVB-T Testing and Monitoring",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Leighton Reed-Nickerson"
                  ],
                  "abstract": "This paper is of interest to anyone who is responsible for operating and maintaining a DVB-T (COFDM) transmitter. We examine the OFDM Transmitter starting with the interface to the exciter. We look at data randomizing, Reed-Solomon Coding, Convolutional encoding, Trellis encoding and Viterbi Decoding. Each scheme is described in a simplified matter so the audience will have an understanding how each works. We then explore testing and monitoring methodology and examine how distortions common to the RF sections of a transmitter effect the OFDM signal. The paper also looks at hardware and describes how the manufactures have designed their transmitter. The final part of the paper looks at the recommended DVB-T measurements required to assure optimum performance and coverage, how these measurements should be made, and what is acceptable performance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001168"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "The In-Station Coaxial Transmission Line: What Changes and Why with HDTV?",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dale Reed"
                  ],
                  "abstract": "HDTV in-station coaxial frequency requirement limits are defined, as well as a discussion of the wireline system components, the need for new products and what product characteristics are driving design features. The presentation will include some basic teaching on fundamental RF issues such as frequency, return loss, insertion loss, use of harmonic wave forms for square wave digital performance, wave size, and bandwidth.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001160"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Production and Transmission Considerations in 1080i and DVB-T",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Christensen"
                  ],
                  "abstract": "We will take a close look at some of the issues that broadcasters are confronted with in a 1080I environment. Based on the recent broadcast experiences in North America, we will gain some insight into possible studio and control room systems and the challenges such as; multi-format operations, picture aspect ratios and multi-track audio recording. We will also discuss larger network issues including digital video transport solutions for STL, remote broadcast events and affiliated broadcast services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001162"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "High Definition Production in the USA",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Larry Thorpe"
                  ],
                  "abstract": "In the spring of 1998 the major U.S. broadcast networks formally confirmed their tentative choices of signal formats for DTV transmission. Some major cable MSO's also identified their preferences. With those announcements it was clear that the new digital broadcast marketplace had splintered into almost every variant of the now-famous ATSC Table 3 of DTV scanning formats. DTV in the United States will mean a potpourri of digital services: HDTV transmissions will bring radically enhanced new viewing experiences, and multi-channel SDTV will signal many variants of enhanced new services. Some broadcasters plan a mix of the two – by day-part. — Program production for this brave new world is expected to dramatically expand. Yet, concerns abound as to what is the best medium to embrace for production of programs that will surely end up being distributed in most of the prominent DTV formats, as well as the ongoing analog NTSC. The U.S., being a powerful engine of program production for the global marketplace, must also look to continuing to feed the international analog PAL/SECAM markets, in addition to being cognizant of the new DTV developments in regions like Australia, Japan, and Korea. Widescreen DVB is also a large new reality in Europe. — Motion picture film has long constituted a flexible “high definition” production format in the U.S. 35mm film, especially, has long been recognized here as being agnostic to television standards, and possessed of a quality overhead that more than adequately meets the most demanding quality criteria of domestic and international program distributors. As such, 35mm film is expected to flourish as a production medium in the global DTV rennaisance. Super 16mm, and especially 16mm film, are being viewed more warily now in light of the new HDTV demands. However, motion picture film production costs are soaring in the U.S. – for television production and for movie-making. The networks, especially, are presently embattled in a huge struggle for marketshare as they vie with a cable industry at the peak of its ascendancy. This has sparked a quest for new controls on production costs. — Electronic Cinematography has suddenly garnered a broadening attention. The spectacular breakthroughs of the past five years – both in closing the quality gap between film imaging and digital acquisition, as well as the dramtically lower costs of media and postproduction, have thrust HDTV program origination squarely onto the program production stage. The arrival of the HDTV camcorder (at a price lower than that of a Super 16mm film camera) has finally unfettered HD production and allows shooting in the most remote of locations. U.S. rental houses have already acquired a large number and many television programs and independent filmmakers are presently using this new medium. A major 22-episode television series “The Adventures of Young Jules Verne” is presently being shot entirely in HDTV, using the Sony HDCAM camcorder operated by traditional film crews. The results are generally recognized as superb and the producers have widely reported their dramatically lower production costs. — Three large mobile HDTV OB vans were constructed in 1998 and are now being heavily deployed across the country covering major sporting and entertainment events for those networks and broadcasters mandated to be on air with DTV in 1999. Three more HDTV OB vans are on the drawing boards for 1999. — Cablevision, the owners of the famous NY arena – Madison Square Gardens – installed two major HDTV production facilities in the arena in the summer of 98 and are already covering many major games in HD. — Over the past twelve months new HDTV postproduction facilities sprang up around the country – in Seattle, Los Angeles, Washington DC, Dallas, and New York. More are slated throughout 1999. — During the past six months a major new HDTV movement sprang to life in the U.S. The marriage of HD and the 24 Frame capture rate of film had long been seen by many to constitute a medium that would wed the best of the two media. In particular, the postreduction facilities see the mastering of film originated material in 1920 × 1080/24 P HD as being the perfect solution to the specter of having to service multiple HDTV/SDTV formats for the various broadcasters. Having the system also operate at 25 P will likely gain international support Sony and other manufacturers are working feverishly to complete the development of a complete 24/25 Frame progressive scan HDTV production system. The 24 P postproduction portion of the system will be unveiled at NAB '99. The 24/25 P camcorders and cameras will emerge at the end of 1999.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001163"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "The History of the Television Receiver and its Future Direction",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lincoln Wong"
                  ],
                  "abstract": "The television receiver has undergone a solid & successful transformation in its history. It has developed from a humble ‘wooden box’ to what could be regarded as the major Home Entertainment Powerhouse. This presentation will discuss the development of the TV set, with a special focus on the Australian market and the impact of sales driven by technological advancement. — In addition, the global market will be reviewed in conjunction with the local segment followed by a briefing of the future technology and market directions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001177"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Wireless Data Broadcasting: An Evolution towards Mobility",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Guy Carrere"
                  ],
                  "abstract": "Data broadcasting represents in the world a real market because of many factors (diversity of contents, more sensibility of people to the consumption of information, Internet fast increase, diversity of networks, good penetration of PCs, availability of receivers,…)",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001179"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "A New Solution for Wireless Interactive TV Based on DVB-T Standard and SFDMA Technique",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "F. Scalise",
                    "A. Charles",
                    "D. Gill",
                    "D. Callonnec",
                    "G. Faria",
                    "J. A. Carral",
                    "L. Lauer",
                    "G. Masera",
                    "O. Souloumiac",
                    "P. Senn",
                    "J. C. Point",
                    "R. Kopp",
                    "B. Wynne"
                  ],
                  "abstract": "The recent establishment and implementation in Europe of the DVB-T standard for digital terrestrial television has opened a broad range of applications beyond the pure broadcasting services of digital TV. The European ACTS iTTi project (‘interactive terrestrial TV integration’ with more than 12 European partners) has been started in March 1998 to define the system specifications of an enhancement of DVB-T standard towards wireless interactive applications. The downstream of the iTTi interactive system (from the base station to the user) is simply DVB-T, to allow full compliance with the pure broadcasting services in the terrestrial network (UHF/VHF band), while the upstream (return channel) is based on a newly proposed approach called Synchronous Frequency Division Multiple Access (SFDMA); such approach is basically a combination of TDMA and FDMA in order to build a multiple carrier return channel, that will be available for multiple users to feed back to the base station through the same set-top antenna. The iTTi project are prototyping a complete hardware demonstrator for field trials and lab test in co-operation with European broadcasters in summer 98. In view of a VLSI implementation of the proposed system, a complexity estimation and optimised architectural solutions will be carried out.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001180"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Experiences in Establishing a Digital Transmission and Performance Verification of an OFDM Transmitter",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Claus Wittrock"
                  ],
                  "abstract": "With the advent of digital terrestrial television broadcasters and equipment manufacturers alike are facing new challenges. Although the ETSI standard very precisely defines the coding and modulation to be employed for the C-OFDM principle for TV transmission, a number of choices in the design of transmitter system are still left open. This paper deals with a number of these; in particular emphasis is placed on solutions chosen for easy and flexible interfacing between the various processing units in a TV transmitter. Solutions to both multi and single frequency network operation are presented. Also discussed is the interface to a high power transmitter where a/o, linearity, filtering and pre-correction are subjects for discussion. Finally a number of test methods and associated test signals are suggested suitable for verification of the performance of the TV transmitter.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001169"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Dynamics Processing in Future Digital Transmission Environments: Maintaining Signal Quality and Level",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Lund"
                  ],
                  "abstract": "The kind of dynamics processing used in FM transmission is not the optimum solution prior to the data compression codecs used in digital broadcast. Therefore audio for DVB, DAB and Internet should be processed differently than in a FM transmission signal chain. — This paper will present a road map to digital dynamics processing and transmission. — Additional topics to be discussed: Resolution, distortion and audio bandwidth requirements of the digital broadcast signal path.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001165"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Reception and Distribution of Terrestrially Delivered Digital Channels in the Existing Analogue Environment",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "George Kozak"
                  ],
                  "abstract": "The forthcoming introduction of terrestrial digital television broadcasts while heralding a new era in television also ushers in a lengthy period of coexistence with the existing well established analogue system. — While this dual mode of broadcasting theoretically can be accomplished quite easily, the real world practical implementation can turn out to be somewhat more involved and problematic. — Utilisation of the adjacent unused guard band channel while providing for an efficient use of available bandwidth together with compatibility of existing receiving antennas and distribution infrastructure, does not however allow for the deviations often encountered. — Broadcasts emanating from one or more towers while of the same power do not necessarily translate to even levels in received signals at a reception site. — While antennas and associated distribution components all display a degree of uneven response over their operating bandwidth resulting in distortion of levels received from theoretically even field strengths, far greater and often unavoidable fluctuations can occur prior to reception of these fields. — The reliance on 10dB or more of level difference to provide protection to the analogue channel could turn out to be ineffective in numerous instances. Going by the differences in non-adjacent channels, with the expected similar propagation in the adjacent digital channel, protection can rapidly approach 0dB! — Together with the inheritance of over forty years of non-engineered and poorly installed distribution systems, the introduction of digital might not prove to be the simple task that the theory might suggest.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001166"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Conversion of Digital Video Signals into a High Definition Transmission System",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roderick Snell"
                  ],
                  "abstract": "It is generally agreed that the most cost-effective method of generating high definition television signals is to up convert existing 525/625 serial digital video signals. This paper looks at the implications of up-conversion to HDTV and examines such issues as 60Hz to 50Hz conversion, aspect ratio conversion as well as the implications of system noise and other unwanted artifacts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001161"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Planning and Regulatory Progress for Digital Terrestrial Implementation in the UK",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gregory Bensberg"
                  ],
                  "abstract": "The world's first commercial digital terrestrial television service will be launched in the UK in November 1998. The 6 multiplexes being launched will be providing a mix of free to air public service channels and new pay services which will be available to between 70 and 90% of the population within 1.5 years of launch. — This paper will describe how the UK approached the spectrum planning and licensing of these services. The paper will highlight: • The spectrum planning process. • Criteria for licence award. • Interoperability concerns (digital satellite, terrestrial and cable service accessibility). • Ancillary service delivery (subtitling, Audio Description and Signing). • The development of Open standard digital terrestrial television receivers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001170"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Mobile Reception of DVB-T",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ralf Burow",
                    "Peter Christ",
                    "Peter Pogrzeba"
                  ],
                  "abstract": "This paper gives an overview of the performance of DVB-T in the case of mobile reception. Failure point criteria to assess the systems performance are explained. Results of laboratory measurements and field trials performed within the ACTS project MOTIVATE are presented. The limits of mobile DVB-T reception are explained. Conclusion will be made for the choice of suitable modes for mobile applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001171"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Contribution and Distribution of Multichannel Audio",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Lyman"
                  ],
                  "abstract": "The transition from 2 channel to 5.1 audio poses many challenges to audio distribution from the content producer to the point of emission coding for consumer delivery. This paper describes the application of a newly developed audio coding technology, Dolby E, to allow a 2 channel digital audio infrastructure to carry multichannel audio. The Dolby E coder is specifically tailored for use in with professional video, and provides a number of important features such as editibility in the coded domain, and carriage of audio metadata appropriate for the Dolby Digital emission coder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001174"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "DVB in Australia",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter MacAvock"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001176"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Solutions for DVB-T Systems",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alexander Rensink"
                  ],
                  "abstract": "The digitisation of terrestrial transmission has arrived. Throughout the world pilot schemes and commercial preparations have started. Digital transmission enables many more programmes to be broadcasted in the same bandwidth, so that there can be a substantial increase in revenues for network providers and a considerable reduction in costs for existing service providers. In addition the prospect of digital transmission brings crystal clear pictures and sound to the consumer. As an added bonus, the digital era opens the gateway to compelling additional services such as electronic programme guides, pay TV, data broadcasting (e.g. transportation of high-speed IP data) and enhanced broadcasting (e.g. home shopping, quiz). — This contribution addresses several key issues that play a key role when constructing digital terrestrial systems based on the DVB-T standard. Various solutions will be presented that enable broadcasters and network operators to achieve their business goals. The following topics will be addressed: • video encoding in conjunction with statistical multiplexing; • primary distribution; • remultiplexing; • splicing; • (joint) bit rate transcoding; • logo insertion; • network management; • SI (re-)generation and distribution; • conditional access and DVB simulcrypt; • enhanced and data broadcasting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001172"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Dolby Digital Audio Delivery to the Consumer",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Lyman",
                    "Craig Todd"
                  ],
                  "abstract": "The Dolby Digital (AC-3) audio coding system is the means to deliver high quality multichannel audio to the consumer. The system is used by many media, including LaserDisc, DVD, cable, satellite and terrestrial DTV. This paper will present an overview of the Dolby Digital coding system, and delineate the important features which ensure that high quality program content can be delivered to, and meet the needs of, a wide range audience of listeners with differing requirements in audio presentation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001175"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "The Application of MPEG-2 MP@ML within TV-Centers - Mandatory, Useful or a Nuisance?",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Juergen Heitmann"
                  ],
                  "abstract": "MPEG-2 MP@ML will play an important role not only for distribution purposes but for the contribution of TV - contents to the main broadcast centers. It's the base for DTV in the US and DVB in Europe. This fact is very often used to assert that the use of MPEG-2 MP@ML - signals within television studios will become mandatory. To check the validity of these arguments, this paper analyses the problems, which are related to such an approach, and their proposed solutions. It is the task of this paper to discuss the implications for typical operational practices within TV-studios, which are arising with the proposed use of MPEG-2 MP@ML. This type of signal should not be confused with the MPEG-2 4:2:2 P@ML professional studio-format at 50 Mbit/sec, which was especially created for the use within TV-studios. — Two opposite statements are made at the present time: • MPEG-2 MP@ML is a distribution and transmission format and therefore not suited for the operational procedures within a TV-studio. • Above assertion is a pure prejudice, an opinion without analyzing the facts. — Mid of the eighties a similar discussion took place. Two camps fought over standards for a new digital studio format. The arguments used were quite similar to the ones used today in the battle over MPEG-2 MP@ML for studio use. • PAL/NTSC are distribution formats. The operational procedures within TV-studios can only be performed by using digital component signals. • Due to the fact that PAL/NTSC are used for distribution, it would be very beneficial to remain in these composite formats for studio applications in the digital domain as well. — Today we know that technological progress together with changed operational needs and practices has proven right those people who argued in favor for giving up the identity of studio signal and distribution signal. It is not without historical irony that today we would never discuss a possible use of the MPEG-2 MP@ML distribution format for use within TV-studios without abandoning the distribution formats PAL/NTSC for production purposes. Nevertheless, on the basis of the historical similarities of the used arguments, it will be of interest to draw a comparison between the distribution formats PAL/NTSC and MPEG-2 MP@ML for studio applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001190"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Adaptive Encoders: The New Generation of MPEG-2 Encoders",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Philippe Guillotel",
                    "Dominique Thoreau",
                    "Pierre Ruellou",
                    "Philippe Bordes",
                    "Bertrand Chupeau",
                    "Christophe Chevance"
                  ],
                  "abstract": "Whereas current debates concern more object oriented technologies, such as the MPEG-4 standardization process, this paper would like to state the art concerning the MPEG-2 technology. The standard was adopted 4 years ago, and is now currently used for broadcasting digital TV worldwide. Some comments and requirements from the first field trials require new generation of MPEG-2 compression systems, and it was the objective of this paper to try to give some inputs for them. — Whereas the first generations were mainly an optimization of the TM5 model with new motion estimators, new bit-rate control strategies and sometimes new mode selection algorithms, this new generation will be adaptive to the picture content and complexity. This adaptation concerns either the input data (such as picture resolution, noise reduction) or the encoder itself (GOP structure, local adaptation, multipass encoding), but also the bandwidth (statistical multiplexing). From the results presented in this paper a 20% to 30% bits saving can be expected on average, and locally more than 50% (for special cases where the encoders fails, i.e. noise, scene cuts, fading,) — After being in the cost and system software, the competition is now clearly on the compression efficiency to add as many programs as possible into one single channel. The new techniques developed and introduced in this phase of optimization will certainly be exploited in future standards such as MPEG-4 or MPEG-7 where respectively segmentation and scene characterization will be key technologies.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001191"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Architectures for High-Definition MPEG Encoders",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter D. Symes"
                  ],
                  "abstract": "The paper discusses architectures for MPEG-2 encoders capable of operating at High Level as required for the transmission of high-definition television. The computational requirements of such an encoder cannot be met today by a single process; some degree of segmentation or parallel processing is required. — Some designs of high-definition encoder achieve this segmentation at a system level by dividing the high-definition image among a number of standard-definition encoders and subsequently combining the encoded datastreams. This approach offers simplicity of design and may appear to offer certain advantages to the user. — The paper discusses various aspects of the operation of encoders, including the coding of I-frames, the generation and coding of motion vectors, and bit allocation. It describes a number of problems with this type of segmentation, and shows that optimal efficiency cannot be achieved. The paper further suggests that the apparent user benefits are difficult to realize, and concludes that a purpose-designed “full-frame” high-definition encoder provides a superior solution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001192"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Technical Product Update – Vision 800T – Highest Speed Stock in the Marketplace and Vision Print Films – A New Range of Print Films",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Waygood"
                  ],
                  "abstract": "Kodak Vision 800T Color Negative Film 5289/7289 leverages advances in emulsion and manufacturing technologies, which make it more sensitive to light without amplifying grain. Tim Waygood takes you through a technical demonstration of the world's fastest motion picture film along with an example of the new KODAK Vision Color print films.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001195"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Image Quality – The Importance of Projecting a Quality Image – Issues Associated with Electronic Projection",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Sanderson"
                  ],
                  "abstract": "“Don't tell me about the labour pains, show me the baby” - a phrase which can be attributed to a lot of the speculation about the future role of technology in the exhibition market. As with all advances in technology, there are still many bridges to cross and issues that have a fundamental impact on the speed at which change can occur. At the end of the day only the market allows profitable change to happen. The market will be looking for ‘better quality and more value‘. For success, these criteria will need to be met. The paper takes a look at a range of issues that must be taken into consideration and the likely impact on cinema today and into the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001196"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "The New DTV Production System",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Karen Eastmure"
                  ],
                  "abstract": "DTV has arrived and the transition to the future has begun in terms of installation of infrastructure that will revolutionise the business. Karen Eastmure reviews some of the considerations and issues surrounding the “digital revolution” as it relates to production and looks at the interaction of film and digital television to achieve the best possible results.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001197"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "The Kodak PreView System",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary O'Brien"
                  ],
                  "abstract": "The KODAK PreView System provides a representation of the projected motion picture image. Gary O'Brien discusses the technology behind this new and innovative product, developed in collaboration with Panavision. The KODAK PreView System lets everyone see things the same way.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001198"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Integrating DVB/MPEG2 Technology with IP Based Protocols and Applications into Satellite Architectures – How can this Open a New Market for Satellite Multimedia Services?",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rob De Poorter"
                  ],
                  "abstract": "The success of DVB on the one hand and of the Internet on the other hand has been the premise for the development of the DVB data Broadcasting Standard also known as DVB-SI-DAT standard. This standard already in commercial use in Europe and becoming a de-facto world-wide standard, is mainly used for the provision of IP based data broadcasting services as well as hybrid interactive services (e.g. satellite broadcast + terrestrial return).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "interactive service",
                      "satellite communications",
                      "multimedia",
                      "IP over DVB"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001182"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Netcasting – Case Studies in the Industry",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Kennedy",
                    "Mark Muggeridge",
                    "Scott Pearce"
                  ],
                  "abstract": "Streamworks will present a case study looking at the 1999 netcast of the Sydney Gay & Lesbian Mardi Gras Parade and Festival and looking at the production in August of this year of Bizau.com to be transmitted live from the exhibition floor of the 1999 Interact Asia Pacific Multimedia festival. The team will discuss how they deal with the broadcast signal for the Internet and outline the future of Internet broadcasting in Australia.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001185"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Interactive Services Protocol Standardisation for HFC and LMDS Networks: A Review",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jean-Charles Point"
                  ],
                  "abstract": "The HFC cable networks, which have been used so far extensively for broadcast TV application, can be adapted to a cost-effective introduction of interactive services to the subscriber. In addition mixed LMDS/CATV architectures become price competitive. — The paper reviews and explains the particular issues that must be addressed, and gives state of the art solutions. — It is organised in the following manner: • Interactive applications are defined, as well as their corresponding traffic model and quality of service requirement; • Details of the network architecture are provided and the corresponding network capacity and traffic throughout are derived; • A brief description of the channel models for HFC return path and LMDS is given, according both to system calculation and measurement results performed in several networks and countries; • The status of current standardisation work is given for DVB, DAVIC, ETSI, with a particular focus on the common standards for HFC and LMDS. The details of this latter ETSI standards, based on DVB-RC and DAVIC work, are described. • A rough cost analysis is performed and introduction scenarios are reviewed; • A complete interactive system description is provided with the details concerning both the headend and subscriber products.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001181"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Interactive Television: The Cusp of Convergence",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Mitchell"
                  ],
                  "abstract": "One of the major benefits of digital television will be its ability to carry substantial amounts of auxiliary data, both program-related and otherwise. This is a result of both the maturing of broadcast television technology as well as the increasing sophistication and demands of audiences. In this regard, TV data broadcasting can be considered the zero-point of intersection for convergence of computers and television, allowing the embrace of an interactive television experience by both PC and TV platforms. — Yet exactly how this is to be successfully accomplished remains under debate. The uncertainty is amplified by the relative lack of established creative aesthetics and consumer preferences in such a new environment, as well as the pressing economic exigencies of enhanced-content providers. The need for technical standardization in this nascent domain is unanimously held, however. — This presentation will discuss methods of adapting already successful compositional styles and data transmission standards for the creation, transport and delivery of interactive television and other TV data-broadcast material. It will propose practical yet extensible solutions to this issue of profound relevance to television's future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001184"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "DVCPRO News/Production Server System with Native File Transfer",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stuart Pointon"
                  ],
                  "abstract": "In this paper, two DVCPRO based server systems will be discussed that are targeted at either the small to medium station and the medium to large station. — System 1 Digital News Automation (DNA System) — DVCPRO News Automation (DNA) is a digital Client-Server end-to-end solution for news postproduction and distribution. To increase production efficiency and maintain digital production quality, native files move between clients and server at faster than real time. The broadcast server offers multiple incoming and outgoing video ports for playback to air or recording from sources, and easily replaces aging robotic playback units or multiple manual load VTR's. Media files maybe quickly distributed to clients on the network for simultaneous use. The server can feed multiple distribution channels to maximise production assets. — System 2 8 Channel Server with Non-linear cuts editing and Networked Non-linear editors. — The AV-SS500 8 Channel server is designed to be a very cost effective and versatile DVCPRO based server. The server can have a number of different ways of editing and outputting material:- (1) Direct record and then editing the material on disk with a “virtual EDL”. This allows cut editing in a non-linear mode without the need to transfer material to a workstation (2) Editing tape to disk with a standard linear editor. The VTR acts as the player, and the disk acts as the record VTR. (3) Transfer material to a non-linear editor such as Panasonic Dvedit or Quick Cutter. This allows for real-time 2 stream video effects to be added. These non-linear systems allow direct to disk recording for very fast editing. With Quick Cutter, 4x faster than real time transfer to disk is available from its internal VTR. (4) Files can be transferred on a network using 100 Base-T or Giga-bit Ethernet. (5) Remote Terminal software allows control of a channel from a remote location. This control includes standard VTR features. (6) The server can also act as a virtual VTR, with features such as slow motion, shuttle, play and record etc. — With both of these systems, because they use DVCPRO compression, can transfer video/audio files with other manufactures equipment, allowing for an open system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001187"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "At-Will Real Time Multichannel Servers – An End to End News Solution with Archiving",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Christensen"
                  ],
                  "abstract": "Digital Newsrooms solutions have been proposed over the past four or five years in an attempt to streamline operations in the hectic, chaotic world of the newsroom. With new technology and tighter integration, the reality of a real Digital Newsroom solution has become possible. Industry experts have predicted that these solutions are still two to four years away. New developments in processor speed, integrated control, and integrated applications are making these applications a reality today.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001186"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Migration from Analog to DTV … Is it a Broadcasters Nightmare?",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Dare"
                  ],
                  "abstract": "The migration from the analog emission world to the new DTV emission world has begun amongst a multitude of uncharted waters. The TV stations, networks, content providers, advertisers, and the consumer industry are all feeling their way along the migration path. The focus of this paper will deal with the issue[s] of data broadcasting, and the potential new business model that the TV station will have to deal with. — Migrating to digital is not simply a replication of the Analog service, if it was that simple one would question why are we spending so much time defining in great detail the syntax of the transmitted bit stream. The digital pipe line to the home is approximately 20Mb/s wide, 20Mb/s of what???. Some would believe that the 20Mb/s simply consists of picture and sound, WRONG. The digital pipe line to the home can carry HDTV channels, SDTV channels as well as Data channels. — So what is so complicated about carrying the data channels??, putting aside the regulatory issues there are numerous points to be considered, how will the service be sold, will the content provider have to pay for announcements, who will maintain the data service transmission schedule, will content providers also want data channel space, who will own the bits, etc. etc. — Transmission of Data can be opportunistic, synchronous, or even better synchronized. Many of these issues are not obvious at a first glance, with just a little exposure to the issues the topic can expand into a major area of concern, and an area where false moves can create a model that will never make any money for anybody. — This paper will deal only with the unidirection data broadcasting model, an even more complex set of issues surrounds the Bidirectional interactive model, that will have to wait for another time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001178"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "The Use of OFDM in the ENG Market",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Noel Matthews"
                  ],
                  "abstract": "The paper will look at the challenge facing ENG users as they are forced to move to digital and the problems of implementing digital ENG in a multipath environment. It will also consider the practical use of multi carrier modulation schemes to overcome these problems and we will present results of tests carried out at Channel 9 in Melbourne to prove the benefits to be had by adopting such as scheme.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001188"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "MPEG Multichannel Audio in DVB",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Boltze",
                    "Leon van de Kerkhof"
                  ],
                  "abstract": "DVB has adopted the international standards ISO/IEC 11172–3 and ISO/IEC 13818–3, better known as MPEG-1 Audio and MPEG-2 Audio respectively, for transmission of high quality audio accompanying MPEG-2 Video. These decisions were based on solid commercial requirements, formulated by the members of the DVB consortium. These include broadcasters, research institutions and manufacturers. — The paper will give a brief overview of the standardisation processes, both in MPEG and DVB. It will then discuss the fundamental requirements for audio in MPEG and DVB and motivate the major design decisions in both systems. The implications for e.g. the scalability of the transmission system and the receivers (cost and complexity issues) will be explained. — Forwards and backwards compatibility of the compression system was a major requirement during the development of both systems. The concepts and their implications for consumer products and plant operation will be examined and compared to systems where these requirements were not existing. Matrix surround systems are widely used in the consumer markets and quite some material is coded with one of these systems. MPEG has been designed to be compatible with matrix surround systems and can carry them in a transparent fashion. Examples from every day practice will be given. Special attention will be given to the sound quality issue. ITU and EBU tests document the high quality of MPEG audio. — Finally, interoperability between different services (cable, satellite and terrestrial, but also DAB) is of major concern to broadcasters. The DVB system addresses these concerns by using MPEG audio, video and systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001173"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "A Practical Integration of Key MPEG-2 Technologies",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "K. Tatsuzawa",
                    "Y. Murakami"
                  ],
                  "abstract": "MPEG-2 is the premier coding scheme used widely in Digital Television Broadcasting. As a flexible compression scheme, MPEG-2 can be potentially and effectively used at every stage in the broadcast system. In acquisition, Betacam SX can be used as an MPEG-2 camcorder with a simple stream converter. An optical disk camcorder with an MPEG-2 Intra-frame encoder is currently being developed. In contribution/distribution, a narrow band channel requires high efficiency in compression. 4:2:2 long GOP is predominantly used in this application. — What would be the compression scheme of choice in the broadcast studio? The SMPTE/EBU Task Force has recommended 50Mbps Intra-frame coding and this is expected to become an ITU-R Recommendation shortly. The 50Mbps Intra-frame compression schemes based on MPEG-2 and DV are both believed to be applicable for high quality applications. — With MPEG-2 50M Intra-frame compression, the link which has been missing from broadcast studio stage now provides seamless interconnectivity. A full MPEG-2 compliant broadcast chain can now be created. — The paper will focus on MPEG-2 implementation of the broadcast chain as a whole. An instance of a practical MPEG-2 compliant broadcast system is considered with supplementary explanation of the essential MPEG-2 technologies, such as transcoding, splicing, and SDTI CP interfaces. $B!H (Jhistory Data $B!I (J, which is a form of $B!H (Jmetadata $B!I (J from t forms of Metadata. The efficient use of $B!H (Jhistory Data $B!I (J is very use the implementation of MPEG-2 based systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001189"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "ATVEF: A Specification for Interactive Television Based on Internet Standards",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Skip Pizzi"
                  ],
                  "abstract": "It is becoming clear that one of the major benefits of digital television will be its ability to carry substantial amounts of auxiliary data, both program-related and otherwise. This is a result of both the maturing of broadcast television technology as well as the increasing sophistication and demands of audiences. In this regard, TV data broadcasting can be considered the zero-point of intersection for convergence of computers and television, allowing the embrace of an interactive television experience both PC and TV platforms. Yet exactly how this is to be successfully accomplished remains under debate. The uncertainty is amplified by the relative lack of established creative aesthetics and consumer preferences in such a new environment, as well as the pressing economic exigencies of enhanced-content providers. The need for technical standardisation in this nascent domain is unanimously held, however. — This presentation will discuss methods of adapting already successful compositional styles and data transmission standards for the creation, transport and delivery of interactive television and other TV data-broadcast material. It will propose practical yet extensible solutions to this issue of profound relevance to television's future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001183"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "API Standardisation for Digital Television",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wim Mooij"
                  ],
                  "abstract": "The paper addresses various initiatives that are being made to solve the problems associated with the standardisation of an Application Programming Interface. A number of different initiatives can be identified: (1) DVB in Europe (2) ATSC in the USA (3) DAVIC",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001205"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "Distribution Costs for Digital Television Networks",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dominic Stone"
                  ],
                  "abstract": "Television networks rely on the cost effectiveness of synchronising the activities of several separate stations. Generally, operational cost savings can be achieved by reducing the level of local input in favour of distribution from a common central site. However the loss of input of local material can mean reduced revenue, identity and reliability. — With the emergence of DTTV and the rising cost of bandwidth the economics of networking must be revisited. Networks must decide on the degree to which they should build a digital structure that is aligned to their existing analogue system. They have the opportunity to build a different structure in the light of new technology and distribution pricing regimes. There is also the possibility of modifying their analogue systems in anticipation of the new digital frameworks. — This paper is a discussion of three different modes for distribution to a network; locally managed breakaways, multiple central sites and centre control local insertion. — Timing delays are considered and cost comparisons made. Factors relate to the network configuration and to the use of MPEG compression. This paper includes a way of modelling some of these factors to produce relative pricing of alternative configurations. It concludes with some observations about the current and likely future developments in MPEG switching.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001207"
                  }
                }
              },
              {
                "article_local_id": "49",
                "article_title": "Server Based Content Delivery Systems",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/49/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ian Shelton",
                    "Nick Thexton"
                  ],
                  "abstract": "Telecommunication options for the broadcast industry are changing rapidly. This means that many areas of business are likely to be affected by new ways of transferring programme content and data. One such area is the contribution / distribution market in which the transfer of programme content and data is managed between studios, outside broadcast sites and ENG units. Digital transfer between sites offers flexibility and scalability beyond that of traditional analogue contribution and distribution networks. — In the digital domain Store and Forward servers handle the task of shuffling material between sites. Material and metadata can be stored and transferred as files, allowing alternative network types like low bandwidth IP networks to be utilised. Benefits of manpower reduction, flexibility in data delivery and network cost bring new options to the broadcaster to scale costs to match the priority of the programme material. This paper discusses these issues and provides example scenarios for the use of servers in content delivery systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001208"
                  }
                }
              },
              {
                "article_local_id": "50",
                "article_title": "A Holistic Approach to Designing A/V Distribution Servers",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/50/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Al Kovalick"
                  ],
                  "abstract": "An overview of the data, control and management planes for A/V Servers, and logically all facility devices. The three planes are introduced and discussed with examples. This is new paradigm that SMPTE is using as their reference for standards development. Up until now, device manufacturers did not adhere to any strict model for device control and management. This paper outlines a preferred way that is gaining momentum in our industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001209"
                  }
                }
              },
              {
                "article_local_id": "51",
                "article_title": "TV and More in the Next Millennium",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/51/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Pete Schirling"
                  ],
                  "abstract": "The technology shift from an analog based TV system to a digitally based infrastructure will forever change how the world views and uses the medium of television. It will also make both mediums dependent on a single parameter, BANDWIDTH. Though the distinction between the traditional TV and the Personal Computer will only be evident to the viewer by the content received rather than its underlying technologies, bandwidth will be the key factor in the industries ability to deliver content. The interface between TV and the rich media that will be part of medium will be presented. Emerging technologies including displays, security, networks and content and their impact, both direct and indirect, on the medium and our lives in the 21st Century will be discussed in this presentation but above all it will be bandwidth and its utilization that will dominate the industry and this talk.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001210"
                  }
                }
              },
              {
                "article_local_id": "52",
                "article_title": "Presenting the Sydney 2000 Games to a World Audience",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/52/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Geoffrey Healy",
                    "Trevor Bird",
                    "Slobodan Dumic",
                    "Cris Van Haren",
                    "Raymond Reynolds"
                  ],
                  "abstract": "The Sydney Olympic Broadcasting Organisation (SOBO), the Host Broadcaster for the Sydney 2000 Olympic Games, is responsible for orignating the coverage of the greatest television event on earth. A team from SOBO will describe the planning of the 3,200 hours of live sporting coverage and the design and construction of the International Broadcast Centre, for two months next year the largest broadcast centre in the world, home to 10,000 international broadcasters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001211"
                  }
                }
              },
              {
                "article_local_id": "54",
                "article_title": "The Application of Storage Area Networks for Post-Production Environments",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/54/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Garry Claridge"
                  ],
                  "abstract": "Storage Area Networking (SAN) is the design methodology which adapts well to the digital storage needs of post-production environments. This methodology allows for the rationalisation of shared media storage across multi-workstation facilities. — The Fibre Channel (FC) networking technology is fast becoming the major medium for SAN's. FC is versatile, very fast and has Classes of Service. FC can be configured into local loops, switched loop-to-loop networking and peer-to-peer topologies. These topologies can be applied to common functional groups and connections between groups in post-production. Because of the Gigabit-per-second speed of FC the same piece of media can be accessed, and played, concurrently between video/audio workstations. — Other technologies, such as Ultra SCSI, Firewire, USB and SSA, either supplement or compliment FC in the SAN. Legacy storage can be either reproposed or integrated into the post-production environment. All storage must be considered and rationalised. — Management of the SAN is an issue currently for which many vendors are rapidly developing applications. These applications range from simple read/write permissions coordination to drive format resolutions across different computer platforms. SAN management can include integration with metadata for total control over digital media assets.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001213"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "The Universal Preservation Format - A Dream or a Realistic Option?",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Juergen Heitmann"
                  ],
                  "abstract": "Users are showing an increasing awareness of archiving related problems. There is first the limited life time of any physical storage medium and necessary reproduction equipment that is posing insurmountable tasks to the archivists again and again. On the other hand the realization is growing that the real asset of all broadcast companies is the content of their archives. Multiple re-use of audio-visual program material is gaining a steadily increasing economic significance. The first broadcast of a program is currently covering approximately 60% of the production costs only. That is of huge financial consequences for all broadcasters. Efficient archiving is becoming an economical force. — The idea of an Universal Preservation Format is pushed forward by the archivists community. They are not very excited about the “Wonderful Digital Age” due to the fact that digital technology has resulted in a veritable explosion of formats. They complain about thirteen different digital tape formats already on the market. For the archivists this is a nightmare. On one side of the room you have to store the tapes, on the other side the tape machines and spare parts. There will always be a storage format that media has to be stored on and this format will always become obsolete at some time. The archivists are therefore not looking for just another recording mechanism, but for an Universal Preservation Format which basically is a file format.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001194"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Film Visual Quality – Alchemy is Not Dead",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dominic Case"
                  ],
                  "abstract": "As the quality and accuracy of colour and tonal reproduction of film emulsions continues to improve, filmmakers are seeking more creative ways to express mood in a film, or to gain greater impact in their photography. The colour film process, once regarded as an immutable standard, is now just one more of the variables in the photographic system, to be added to art direction, lighting and exposure on the set, to film grading for theatrical prints, to video colour correction and most recently to digital colour correction. In some ways, these techniques simply restore the full set of tools to the cinematographer that the stills photographer has enjoyed since the invention of photography. The more conservative view, that any post production technique that alters the image is somehow denying the cinematographers' control, is indicative of the general change from non-interactive (pre-planned) to interactive (flexible) methods that many technologies have passed through. — As an example of processing variation, the technique of “bleach bypass” is explained, with examples demonstrating the effects of interaction of lighting, exposure, processing and grading on the eventual quality of the image. The relevance of this technique in the future context of digital film grading is discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001199"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Film Scanning for HD Post Production and Beyond",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Swinson"
                  ],
                  "abstract": "Film and video co-exist in the television environment. As we move forward to high definition the role of film becomes even more significant. Film has many advantages as an image capture medium namely, definition well beyond HDTV, a colormetric capture range that exceeds any video signal, and a ready 50 year archive for HDTV transfer. — C-Reality, Cintel's new film scanner has been designed to meet the demand for the highest quality imagery from all 35mm and 16mm film content, be it 525/625, HDTV or real 2K, without compromise. This paper will describe C-Reality and how it has broken the SD and HD ‘video’ barrier to take users into the ‘image data’ world.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001200"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "Recent Advances in Transfer and Manipulation of Film Images in the Data and HDTV Domains",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Bancroft"
                  ],
                  "abstract": "At the SMPTE '97 Conference and Exhibition, the concept of representing motion picture film images in a universal data format was presented. Since then, the enabling technology has met with widespread acceptance, with over 80 units of the core product being installed worldwide. — During this time also, several key building blocks have been added by the same supplier to extend the film-in-data concept, allowing the full power and flexibility of computer workstations, coupled with tremendous hardware acceleration, to be applied to the creative production and post-production processes. The successful data concept can even be ‘tunnelled’ through the high definition video domain, allowing the major benefits of the data process to be achieved in real time and using low cost video tape storage. — The paper will examine these advances, both in a tutorial manner and with illustrations of some of the real world applications, such as complete feature film post-production and multi-format DTV production, to which users are successfully putting this new technology.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001203"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "The 2K Grading Room – Digital Intermediate Film",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Doyle"
                  ],
                  "abstract": "As film scanning and recording between film and the digital world become faster, better and less expensive, we are now approaching the reality of an electronic intermediate. An entire feature film production can be digitised, gaining access to all the grading tools traditionally only available on telecine for a TV finish. Peter reports on Dfilm's progress in this direction.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001202"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Considerations in Evaluating and Choosing HDTV MPEG-2 Encoders",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robin Wilson"
                  ],
                  "abstract": "The paper covers considerations in choosing a high definition MPEG-2 encoder. — Areas explored include; Tiled versus striped architectures and the underlying problems; How motion vectors need to be cross coupled to conserve efficiency; What motion vector range REALLY means to performance; What is the difference between hierarchical, partial exhaustive and fully exhaustive search is, and why bigger numbers may mean poorer performance; How buffer management can significantly effect the subjective performance of an encoder; The importance of dynamic performance testing vs. steady state including caveats of using some current objective and subjective test techniques: Statistical video and data multiplexing with mixed HDTV and SD.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001193"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Colour Calibration in Digital Film Systems",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glen Kennel"
                  ],
                  "abstract": "This paper is an end-to-end discussion of calibration in digital film systems, comparing this system to the traditional film duplication process. The characteristics of colour negative films establish the requirements for scanner calibration. Digital versus film display characteristics are reviewed. And finally, the requirements for recorder calibration are described in the context of colour intermediate and print film characteristics.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001201"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "Advances in Content Management and Protection",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wim Mooij"
                  ],
                  "abstract": "The need for content management and protection has resulted in significant progress being made in this area for a flexible, low cost open system that is applicable to a wide range of consumer electronics equipment. — Examples are presented that show how the new Content Management and Protection Technology can be applied to: • DVD Disks • Digital TV Broadcasting • CD Games • Electronic Banking • Internet Content Delivery",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001204"
                  }
                }
              },
              {
                "article_local_id": "64",
                "article_title": "Technology and Teamwork – HDTV at AFTRS",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/64/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Annabelle Sheehan"
                  ],
                  "abstract": "Annabelle Sheehan will report on the HDTV Drama Workshop that AFTRS Masters students recently completed. This workshop emphasises collaboration and creative work in the context of managing changes in technology and shifts to the post production path. Students produced 3 short dramas and met a range of technical specifications associated with provided material for HDTV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001223"
                  }
                }
              },
              {
                "article_local_id": "65",
                "article_title": "Connecting SD and HD via Gigabit Ethernet in the Studio",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/65/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John O'Neill",
                    "Bob Pank"
                  ],
                  "abstract": "The use of network connections is set to expand rapidly in television. At the same time television is changing faster than ever with new formats, DTV and high definition on the horizon. The object is to specify and create an open network appropriate for today's requirements as well as meeting tomorrow's growing, and more demanding needs. This has to work in parallel with the existing connections to provide additional I/O and without compromising their performance. For economy and compatibility the base technology should come from the computer industry but the choices require careful study. Quantel's work has resulted in Clipnet which is aimed at more efficient operation and better access to material.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001224"
                  }
                }
              },
              {
                "article_local_id": "66",
                "article_title": "Distribution and Routing of Digital HDTV Signals in the Production Plant",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/66/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Birney Dayton"
                  ],
                  "abstract": "This paper investigates the technical requirements for distributing 1.5Gb/s digital signals in a typical production facility. It covers router architectures, relocking methods, cable characteristics and equalization, distribution amplifiers, and fiber optic interconnects. — It looks at expandable and non-expandable routers and focuses on the technical requirements to build a reliable expandable switch at these high data rates. The paper tabulates distance limitations of coaxial cable at 1.5Gb/s and shows how fiber optic cable can be used cost effectively for longer runs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001225"
                  }
                }
              },
              {
                "article_local_id": "55",
                "article_title": "Dynamics Processing in Digital Production Environments: Maintaining Signal Quality and Level",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/55/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Lund"
                  ],
                  "abstract": "Multi-band dynamics processors are finding their way into broadcast production and OB areas, because they can ensure consistent audio quality despite a high working speed. — This paper will discuss multi-band dynamics processing for the digital era, while being able to cope with the mixed analog and digital equipment of today. — Additional topics to be discussed: Spectral balancing, interfacing, level meters, loudness.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001214"
                  }
                }
              },
              {
                "article_local_id": "57",
                "article_title": "Moving Tape to Non-Linear",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/57/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jeff Stewart"
                  ],
                  "abstract": "Digital nonlinear finishing is becoming a reality in the television industry. Work on many television programmes, commercials and promos is moving away from traditional tape based linear suites and being onlined on digital nonlinear systems. Broadcasters, production companies, editing companies, and post facilities are faced with a wide range of choices in the move away from tape and the question is not is the time right for digital nonlinear finishing?, but rather which nonlinear finishing system is right for me? — This paper examines some of the benefits this new technology brings to the online and summarises Avid's three television finishing solutions, identifies the types of programming most appropriate for each system, and highlights how each system is uniquely optimised for different types of work.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001216"
                  }
                }
              },
              {
                "article_local_id": "60",
                "article_title": "Integration for Education",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/60/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Clive Jones"
                  ],
                  "abstract": "Integration for Education explores the progression made by the Curtin Business Schools Media Producer Clive Jones, in bringing to fruition the integration of the world of the PC to that of video, and how the different mediums can be integrated. — The end result raises the challenge of putting 25-minute videos onto the Internet for live streaming, and shows how an integrated Web page is used for teaching a Masters degree course.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001219"
                  }
                }
              },
              {
                "article_local_id": "58",
                "article_title": "Becoming Digital: The Facility Migration into Digital and Multichannel Broadcast Television Operations",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/58/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Donald P. Archiable"
                  ],
                  "abstract": "The ‘Transition to Digital’ affects every facet of the turn of the millennium television operating facility. Even the most creative department manager or broadcast executive will be challenged by the changes that digital technologies will require. News, transmission, master control, production, sales, traffic, studios (with related control rooms) all will be affected in terms of their operational and staffing needs. Added to this is the need to consider, in the strategic planning process, business opportunities to generate added revenue streams. Networks, group-owners and local stations alike face a brave new world. More than ever, ‘branding’ and marketing must team up with engineering and MIS/IT operations to achieve the excellence that will be expected. — ‘Transition to Digital’ will address the process of evaluating and selecting the technologies, defining their impact on the operations, and planning for the facility changes necessary to accommodate the new technologies. This paper will also discuss the following issues: analog to digital transition; interface to progressive; SDTV to HDTV; 4:3 to 16:9 aspect ratio; and the multitude of equipment alternatives and technical decisions, and their impact on operational infrastructure requirements. — In addition to the changes in engineering, new challenges in broadcast facility architecture are equally significant. New studio cavity formulas for 16:9, more advanced lighting angle calculations and grid relationships are all changing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001217"
                  }
                }
              },
              {
                "article_local_id": "63",
                "article_title": "Training of Broadcast Engineers in the Digital Era",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/63/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Philip C. Nottle"
                  ],
                  "abstract": "As broadcasting embraces the digital era the issues of how to train the technical staff, together with the skills needed by this elite band of specialists come sharply into focus. — The introduction of new technology over recent years has seen a steady decline in technical staff numbers due to improvements in equipment reliability. There has also been a decrease in numbers of technical traineeships. As a result the average age of technical staff across the industry is high (approximately 45–48 in the ABC alone). — How then does the industry plan to be viable into the next millennium? Where do the resources come from to digitise the entire industry, both radio and television, while keeping the existing systems on-air? Where will the broadcast technical ‘think-tanks' of the future come from? The industry will need to take a fresh look at what will be the technical needs of the future and then make some hard decisions on how to meet these needs. And the scrutiny will need to continue as technological change continues and accelerates. The ABC has reviewed how it is going to meet the challenge. There will be new trainees, who will enter with a mix of educational qualifications and be provided with in-house, broadcast-specific courses. The training will address convergent technologies and will attempt to provide the trainees with knowledge and skills that can be adapted for the changing technologies which will be encountered. For our existing staff, we are constantly developing courses to upgrade the skills of the staff in relation to the changes being wrought.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001222"
                  }
                }
              },
              {
                "article_local_id": "61",
                "article_title": "The Broadcast Engineer Training for 2000 and Beyond",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/61/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Melanie Knight-Smith"
                  ],
                  "abstract": "1999 will prove to be one of the most challenging for our broadcast and radio frequency engineers. Current policies between FARB and the ABA are determined to define and provide digital services within the L-band around the year 2000. This combines with issues where telecommunications and broadcasting are converging to shifting the knowledge base from one of primarily electronics to one of telecommunications and network technologies particularly to on line encoding. There isn't a lot of difference now between a large computer network, a telephone digital network, and a broadcast network, particularly once you get up to the ISDN Primary rate service at 2MB/s and higher. They basically all use the same ITU recommendations in the ITU seven-layer model to frame the data. — Replacing yesteryears Broadcasting Operators Certificate of Proficiency is a basic Diploma in Electronics with Broadcasting major. RMIT is still the leading engineering school within Australia and provides training within these areas. — Lecture will provide examples of how different countries have converged to digital broadcasting at their own rate. For example, the diamond project in Canada, its dependence upon the digital Eureka 147 broadcasting system and how this has influenced their broadcasting training programs. Also the BBC their course structure for broadcast engineering, the difference to Australian requirements and how they are tackling training for beyond 2000. — The dilemmas to teaching these specialist engineers will be outlined along with suggested solutions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001220"
                  }
                }
              },
              {
                "article_local_id": "56",
                "article_title": "Digital Television Monitoring Systems: Challenges and Opportunities",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/56/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Guy Cherry"
                  ],
                  "abstract": "Today's broadcast facilities are increasing in complexity by an order of magnitude. The relatively straight-forward media formats of the past are being replaced by elaborate packet protocols that combine multiple video, audio and metadata into a digital multiplex. In such a highly computerized system there are many opportunities for error but there are also opportunities for self correction, intelligent report generation, and operator notification. This paper will describe various system monitoring architectures, categorize the types of errors that can be detected, and discuss a number of strategies for recognizing, logging and correcting errors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001215"
                  }
                }
              },
              {
                "article_local_id": "59",
                "article_title": "Digital Reality – Engineering and Operating a Multi-Channel Digital Broadcast Platform",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/59/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Robertson"
                  ],
                  "abstract": "STAR TV has operated an eighty plus channel DVB compliant digital broadcast platform in Asia for the last 3 years. STAR originates 22 channels from our Broadcast Centre at Clear Water Bay in Hong Kong. We operate a total digital facility that includes 40 disk based servers for commercial replay. STAR's Systems Engineering group has made most of the mistakes possible in implementing this system. This paper describes the good and bad parts of STAR's system and the pitfalls that we found along the way.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001218"
                  }
                }
              },
              {
                "article_local_id": "62",
                "article_title": "Broadcast Engineering Courses and the Australian Qualifications Framework",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/62/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rodney Staples"
                  ],
                  "abstract": "Convergence of technologies and increasing globalisation are driving change in education as in broadcasting. Changes too in the process of specifying courses means that course distinguishing features are defined by the Australian Qualifications Framework, and in the VET sector course outcomes are defined by training packages driven by industry standards. The old “content-driven” model of course definition no longer applies. — The broadcast industry can influence training in the new system by becoming involved in training package development through relevant Industry Training Boards, by participating in the development of resources, or by supporting flexible delivery including workplace delivery. It can also customise courses developed for other relevant industry sectors. — While change is occurring, the development of resources is the responsibility of providers: it is no longer being publicly funded. Development needs industry support if it is to progress faster than it currently is. Assistance in developing resources using the expertise of broadcasters would bring the joint benefit of ensuring relevant content and speeding global access.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001221"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "HDTV – What this Means for Microwave STL and ENG Applications",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward J. Giovannini"
                  ],
                  "abstract": "The paper will deal with: — The different configurations which are available to the broadcaster for transmitting their HDTV and analog signals through an STL. — Should the Broadcaster combine the existing analog signal with the new HDTV signal over a single microwave path or use separate links for each signal. — Using Digital modulation to transmit Broadcast Quality Video and Audio, why is this considerably different from Analog Video and Audio transmissions. — Redundancy vs. Non-Redundancy for HDTV STL. — Why Forward Error Correction and Dynamic Adaptive Equalisation is vital to the HDTV STL and ENG Microwave transmissions. — Benefits and Pitfalls of the different Digital Modulations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001206"
                  }
                }
              },
              {
                "article_local_id": "68",
                "article_title": "A Multi-Frame Rate, Compression-Free, Video Recorder for Universal DTV Mastering in High Resolution",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/68/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David J. Bancroft"
                  ],
                  "abstract": "The advent of the Digital Television (DTV) broadcasting era offers the prospect of higher-quality delivery of content through more access channels to the home, but it could also mean greater complexity in production and post-production. DTV involves the continuing support of legacy television formats such as PAL and NTSC in programme production for many years, while at the same time expanding the capacity and capability of facilities to accommodate the new demands of the HDTV options that are also available within DTV standards. — Several initiatives are helping to tackle this challenge. These include the work on the Common Image Format in the ITU-R and the proposal within the SMPTE for a 24-frame progressive variant on existing HDTV standards to make a mastering format for production that can be universal and generic to all world DTV and legacy TV formats, just as its inspirational force, 24-frame motion picture film, is universal and generic. — A key element needed to support such a universal mastering format has so far been missing. This is a video tape recorder, of sufficient internal bandwidth to perform the basic functions expected of a classic post-production VTR, but at high definition bit rates, and without recourse to compression. Not only that, but it is equally important that the machine be adaptable in frame rate, to cover both universal mastering and international distribution formats for DTV. — This paper therefore describes a new video tape recorder shown at the recent NAB convention in Las Vegas that satisfies these requirements. Adherence to important SMPTE standards is also covered, together with a development path planned for the technology that covers issues such as RGB recording and film image data recording.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001227"
                  }
                }
              },
              {
                "article_local_id": "67",
                "article_title": "Multi-Format Signal Distribution and Synchronisation",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/67/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chuck Meyer"
                  ],
                  "abstract": "This paper describes a general concept for a multi-format digital studio with an emphasis on signal distribution, interconnection, and synchronization. The concept plant is broad in scope, acting as a basis for facilities with more narrow scope. This concept is designed to be functional today while including the capability of incorporating future technology within reasonable economic constraints. — A number of HDTV, DTV, DVB, and SDI signal formats will be discussed in technical detail with respect to timing and format composition providing a sound technical basis supporting the feasibility of multi-format synchronization as well as a strong argument for incorporating this technology in any new facility. Fiber and copper interconnection technology will be discussed as part of evaluating how future LAN and telecommunications technologies may be incorporated into this concept facility, and how these technologies could be used in combination with conventional methods to implement digital studios with reasonable longevity. — Pertinent block diagrams, tables, and graphs, and comparative performance analysis data will be included to support the design concepts of this plant.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001226"
                  }
                }
              },
              {
                "article_local_id": "53",
                "article_title": "Applied Metadata Management Systems for Post-Production",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/53/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Garry Claridge"
                  ],
                  "abstract": "Metadata is data describing media-assets, i.e. 3data about data2. Effective metadata management is paramount for the efficient operation of post-production projects. These projects can be media neutral, that is, they can be film video-tape, graphics and animation, all of which have similar metadata descriptors. The integration of media-assets, of different source types, into compositions is much easier to manage when the metadata has been accurately identified, labelled and associated to the source media. — Vendors of digital media production and manipulation tools generally provide a degree of asset manageability for their own media-assets. As media-asset production and manipulation can be by many sources, generic management tools are hence necessary to achieve total control of all media assets. With the introduction of the Open Media Management (OMM) and Advanced Authoring Format (AAF) protocols we can use generic tools to access, and manage metadata originated from various sources. Open Database Connectivity (ODBC) and Java Database Connectivity (JDBC) technologies add to the ability of developers to maintain truly open metadata management utilities. — Clients/Users on intranets (and the Internet) are now able to perform enquiries, previews and updates of the metadata databases via specific user interface programmes or generic Web-browers. Composition descriptors, such as, EDL's, OMFI, Cut-lists etc, will be able to be exchanged with much greater confidence of accuracy of content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001212"
                  }
                }
              },
              {
                "article_local_id": "69",
                "article_title": "Integrated Decision Support Environments in Distributed High-End Audio-Visual Content Creation: The Use of High Performance Computing and Networking",
                "article_url": "https://journal.smpte.org/conferences/9th%20Conference%20and%20Exhibition%20of%20the%20SMPTE%20Australia%20Section/69/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Antonis E. Karidis"
                  ],
                  "abstract": "This contribution presents the findings and experiences from the utilisation of a Distributed Collaborative Environment established among a typical group of small and medium European audiovisual content production companies and their clients to support the pre-production and proofing stages of high-end audio-visual content creation. — The Distributed Audio Visual Content Development and Creation Environment (code-named: DAVID-E) was implemented by intergating commercially available content creation and communication/collaborative tools. The presented activity, by virtue of a series of real-life production cases, implemented all proofing phases of the development and creation of content (including those phases performed today in conventional ways), within the above networked environment and demonstrated considerable and measurable benefits in time, costs and productivity. — These results are considered of high importance in the production/post-production industry, as they are directly applicable and could readily be replicated in similar environments throughout the world. — The work presented in this paper was part of PST activity No. 24810 Project D.A.Vi.D. (Distributed Audio-Visual Content Development), supported by the EC ESPRIT 4th Framework Program on HPCN.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001228"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "Proceedings 33rd SMPTE Advanced Motion Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "The LDK2000 Multistandard Camera, and the Evolution to DTV",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jan van Rooy"
                  ],
                  "abstract": "How the transfer to digital television will impact on the studio has been the subject of many discussions. The large installed base of equipment suggests that a gradual transfer will be the most viable model. With studio HDTV on one end of the quality scale, and typical aerial reception of NTSC on the other end, a number of quality steps can be defined. Even with the existing studio equipment a major step can be made in the picture quality seen by the end user. The first step is the transfer to DTV itself, removing the NTSC artifacts. The next steps may include the optimization of the video signal for DTV by employing progressive scanning. This will also remove the well known interlace artifacts and increase vertical resolution. A native progressive scanning format is more suitable for converting to other scanning standard as might be done in the DTV receiver. — The 480p video format puts modest demands on the MPEG coding of DTV and permits multiple channels and a mix with data transfer allowing for new business. It is therefore expected that this format will gain a strong position in DTV. — After the transition to DTV, having the option of progressive scanning without large investments in studio infrastructure seems very logical. — The Philips LDK2000 is designed as a multistandard camera with its scanning format switchable between 480i60 and 480p30, and of course between 16:9 and 4:3 aspect ratio. The Frame Transfer CCDs are newly developed devices capable of a non-compromised output in both cases. — In this paper the camera design will be explained, as well as the system approach to achieve a high quality 480p chain.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00936"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Applying SMPTE Metadata in Software Systems",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Oliver Morgan"
                  ],
                  "abstract": "Following the publication of the Final Report of the EBU/SMPTE Task Force for the Harmonization of Standards for the Exchange of Programme Material as Bit Streams (TFHS), work has proceeded rapidly towards implementing the report's recommendations. These include the establishment and management of an SMPTE Registry of Metadata, the documentation of an SMPTE Data Model for description of Content Packages, and the specification of several different Wrapper formats for different applications including both simple or and complex Content Packages.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00945"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "The Growing Needs for Automated System for Control and Management",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "St'Iphane Savard"
                  ],
                  "abstract": "The EBU SMPTE task force for harmonized standards for the exchange of program material as bit streams has discovered through its proceeding that system control and management will play a key role in system design in the future. With the growing complexity of television stations where more and more services are asked to the television station combine with the new tools and techniques like content servers, it is no longer possible to accomplish all the tasks with additional people. It has become too complex and too costly to do so. In order to resolve the problem, the task force has concluded that it is necessary to draw a reference object model to enable the designers of automation systems to integrate their pieces together and to build a system that works seamlessly throughout the station and the network. — This paper will address the different problems faced in the television today towards the conversion to DTV including simulcast of HD material. — The problematic related to the exchange program material from servers in different locations throughout networks such as the internet and how this problematic is been addressed by FeedBuilder, the system we have built and have been used as a major input into the task force report. — Furthermore, the paper will address the new opportunities that will evolve from using such tools. This include the fact that the technical side of the station will play a more important role in a TV station by providing new products that the station or the network may offer to its advertisers through the use of that technology. — Control system in management is a critical success factor of a successful technical manager in a television station today and it will probably result in such dramatic results as whether or not a station will be able to compete effectively in tomorrow's market place.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00947"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Interconnectivity in the DTV Era: The Emergence of SDTI",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alain Legault",
                    "Janet Matey"
                  ],
                  "abstract": "Serial Data Transport Interface (SDTI) is emerging as the standard for transporting packetized audio, video, and data between cameras, VTRs, editing/compositing systems, video servers, and transmitters in professional and broadcast video environments. SDTI builds on the familiar SDI standard that is now widely used in studios and production centers to transfer uncompressed digital video between video devices. SDTI saves time and maximizes video quality. It provides for faster-than-realtime video transfers and a reduction in the number of decompression/ compression generations required during the video production process, while utilizing existing SDI infrastructure. Silicon and board-level adapters are starting to become available to allow manufacturers to build cost-effective, computer-based systems implementing SDTI. — This paper provides an overview of the SDTI (SMPTE 305M) specification. It also describes SDTI implementation issues related to computer-based equipment design, operating systems, and application software. The DV format, PCI-bus computer system architecture, Windows NT operating system, and editing application software are used as specific examples.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00948"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "HDTV – The Limit of Copper Cable?",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen H. Lampen"
                  ],
                  "abstract": "Video distribution and transmission has historically been handled by coaxial cable. No other cable design, besides coax, features the combination of impedance stability, with moderate to low capacitance, low cost, and ease of connectorization. Analog video bandwidth of 4.2 MHz was easily handled by coax. — As analog distribution gave way to digital distribution (SMPTE 259M), up to a bandwidth of 135 MHz/270 Mbps, it became obvious that cable design parameters were a significant limitation to distance. A new generation of video cables emerged, featuring gas-injected foam dielectrics, for significantly lower high-frequency loss, and high-density hard-cell foam, to approach the impedance stability of the old analog solid polyethylene core cables. — With the advent of uncompressed HDTV transmission, at 750 MHz/1.5 Gbps, cable technology was asked to accomplish yet another leap in bandwidth. This paper will explore copper coax cable performance in light of these new requirements and examine the limitations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00949"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "The Connection Guide for HDTV",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fred Della Iacona"
                  ],
                  "abstract": "The purpose of this paper is to provide a users guide for the selection of BNC connectors, video jacks and patch cords in HDTV applications. It further outlines the use and limitations of triax for high frequency transmission. The critical components of each of these passive devices that can effect electrical performance and long term reliability are discussed. The paper provides the user information to determine the product best suited for the intended application.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00950"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Multivideo-Server-Based News Exchange System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shozo Fukui",
                    "Satoshi Shibuya",
                    "Satoshi Harada"
                  ],
                  "abstract": "The Japan News Exchange (JNEX) system centralizes the management of videos and corresponding scripts by computer. From news programming to broadcasting, as well as news exchange with affiliated stations, JNEX facilitates the workflow with minimal personnel. The video server dedicated to broadcasting forms the core of JNEX, and has 8 different outputs which can used to provide videos to terrestrial news broadcast, 24-hour satellite news channel, feeds to affiliates and Internet news. JNEX can be accessed from all parts of Japan, to check and order the video of news materials. Its impact has been tremendous.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00940"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Technology for “Big Resolution” Solutions",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kirk A. Law"
                  ],
                  "abstract": "There are many goals in the world of digital image manipulation. A few years ago, it was thought that real-time film manipulation would be a long way off. The push for the many DTV resolutions has caused many to dream of digital film mastering and “publishing” to the respective distribution formats. But, handling film in a manner that is common place for standard resolution video requires an understanding and appreciation of the acquisition, movement, processing/manipulation, previewing, and handling various output or data “publishing” methods. What does it mean to have a system and applications that are scalable and support scalable resolutions so that the artist “could” use similar systems for standard resolution through film resolution work? How close are we?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00937"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Video Editing in the Modern Shared-Storage Environment: Specific Costs, Benefits, and History",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher J. Stakutis"
                  ],
                  "abstract": "For several years, the non-linear digital video editing community has been tempted by promises of faster and more efficient editing through the use of servers and other data-sharing approaches. The early adopters of such visions encountered countless technical operational problems and steep costs, only to realize that their investment was superceded every 12 months. — Several years later, what is the current status of networking non-linear editing (NLE) systems together? Can the user community procure the appropriate mix of gadgets and tools to have value, without the high cost? Where does one start in understanding and selecting the technology? And from where does the resultant value come?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00943"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Compression Formats and Interoperability: Picture Quality Aspects and Consequences for Future Networked Television Production",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Reinhard Knor"
                  ],
                  "abstract": "The information offered in this paper is based on the findings from a specific project carried out on behalf of the Public Broadcasters of Germany, Austria and Switzerland and from the analyses and results of the working group on compression of the joint EBU/SMPTE Task Force for “Harmonized Standards for the Exchange of Programme Material as Bitstreams”. — The paper reports on the results obtained when testing the subjective picture quality within a conventional production scenario using different compression formats and format transitions. A particular emphasis was placed on the performance within a realistic production scenario containing long production chains of those compression families, which have been endorsed by the Task Force. Based on these results and the analyses of the EBU/SMPTE Task Force, the advantages and system aspects of new compression systems in a future networked production environment will be outlined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00942"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "A SMPTE-292/OC-48c Video Network Access Unit (VNAU)",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Philip S. Crosby",
                    "Scott W. Lowrey"
                  ],
                  "abstract": "Transmission of uncompressed high-speed digital SMPTE-292 video data is currently limited to relatively short distances; an electrical cable connection of up to 100m, or a direct optical fiber connection of up to 2km. We have demonstrated a prototype Video Network Access Unit, which implements transport of uncompressed SMPTE-292 serial video data packaged into ATM cells over a SONET OC-48c link. This allows long-distance transport of uncompressed HDTV video using the public switched network. Network performance testing using the Tektronix Video Network Access Unit (VNAU), the FORE Systems ASX-4000 switch, and the ATDNet was conducted at FORE Systems (Warrendale, PA) and the Naval Research Labs (Washington, D.C.). Network performance was monitored using control signals from the VNAU Direct Digital Synthesizer (DDS). The VNAU operated with the FORE switch and over ATDNet with no problems whatever. The DDS allows a straightforward measurement of ATM cell latency without additional hardware.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00939"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Principle, Benefits and Applications of Variable Bit Rate Coding for Digital Video Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Si Jun Huang"
                  ],
                  "abstract": "This paper studies the principle and benefits of variable bit rate coding of MPEG-2 video compression. The study starts from the fundamental difference of rate control algorithms for constant bit rate (CBR) coding and variable bit rate (VBR) coding. Comparison test results from the real-time video encoder and decoder operation using a PAQ200 picture quality analyzer as the tool for coded video quality measurement are reported and analyzed in association with the rate control algorithms. The combined theoretical analysis and experimental results show that the VBR coding has a significant bit saving potential over the CBR coding for the same coding quality. To effectively utilize the gain from the VBR coding, three bit stream transport mechanisms are introduced. Finally some potential applications that can benefit from the VBR coding have been identified.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00951"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "The Public Network, Making it Work for Digital Video and Entertainment Production",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anthony Magliocco",
                    "Keith B. Nesson"
                  ],
                  "abstract": "This paper is designed to assist broadcasters, motion picture and television production management, and information technologists, understand the issues surrounding moving content between facilities across town or across the oceans. — The digital television revolution has created confusion and opportunity. TV broadcasting has taking on a new meaning to us all. Television is now digital, interactive and will be delivered to your home via methods different than before. The range of digital video, and entertainment products now include, direct satellite, digital terrestrial broadcasting, DVD, and Internet Broadcasting. All of these new sources and distribution technologies are based on digital. — The demand for content or software as it is called in the consumer electronics business has created new centers of content creation. The number of people required to produce the thousands of hours of content consumed each week is rising quickly. No longer can you count on all of your team or resources being in the same city or state. The Internet and high-speed modems have fostered the idea of collaborating across the “Ether,” and it works. Video-conferencing that was the sole domain of large corporations is now available to everyone who owns a PC and an Internet connection. Broadband communication is the current wave of technology to provide new and exciting tools for the creative professional.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00954"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "800MHz-Band OFDM UHF Link",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ryoichi Yajima",
                    "Kazufumi Takizawa",
                    "Shun Morisawa",
                    "Shigeki Moriyama",
                    "Kenichi Tsuchida",
                    "Takanori Izumi",
                    "Akihiko Nakamura"
                  ],
                  "abstract": "As digital TV broadcast technology has progressed, systems for transmitting digital program material have become increasingly important. In 1997, a technical standard for 800MHz-band OFDM UHF links was established at ARIB (Association of Radio Industry Businesses) and it is the first digital link that employs the OFDM modulation method. We have developed an 800MHz-band OFDM UHF link for digital transmission equipment. The specifications of the OFDM UHF link conform to the ARIB standard. The carrier modulated by the OFDM method transmits an MPEG-2 compressed 525-line video signal using an 800MHz-band wave. The OFDM UHF link was first used in live program production in June 1998, and it will become the key equipment for mobile transmission.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00938"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Seamless Splicing for MPEG-2 Transport Stream Video Servers",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Ward",
                    "Clifford Pecota",
                    "Xiaobing Lee",
                    "Gary Hughes"
                  ],
                  "abstract": "Current uncompressed video servers are capable of streaming multiple video clips back to back such that they appear to be a single uninterrupted stream. This is a relatively simple process made possible in part by the fact that frame boundaries are equally spaced and there are no inter- frame dependencies. With the adoption of MPEG-2 and DV digital television standards, the distribution of video in compressed format will become more common. This change is fueling the development of video servers capable of distributing compressed video in broadcast ready format. The seamless concatenation and splicing of streams that has been taken for granted in the uncompressed domain becomes complex in the compressed domain due to mechanics of MPEG-2 encoding. This paper describes the problems associated with concatenating MPEG-2 Transport Streams (TS) and describes a technique to perform frame accurate seamless splicing from one MPEG-2 TS to another on compressed stream video servers such as the Silicon Graphics Incorporated Origin 2000. Using this technique, a transition clip is constructed to replace a short segment of each MPEG-2 TS near the splice point. Shortly before the splice point, the server begins streaming the transition clip which contains the actual splice. At the end of the transition clip, the playout engine switches to the second TS. The transition clip must be constructed such that when concatenated with each TS, the resulting stream is still valid. This approach offers several benefits for use with video servers: neither of the original transport streams is modified; transitions for pre-scheduled splices can be calculated in advance; transitions can be generated once and later reused without additional overhead.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00953"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "How Digital Broadcasting and Interactive Technologies are Changing the Future of Electronic Commerce over Broadcasting Networks",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gadi Tirosh",
                    "Ian Tapp"
                  ],
                  "abstract": "With its Broadcast ELC system, NDS employs its proven Conditional Access to enable secure electronic commerce of all types of goods—hard and soft—over digital broadcasting networks. Several operating scenarios arc described, each addressing the needs of a different business model. Among the features described for Broadcast ELC are: credit/debit card payments, payments via the broadcaster's SMS, local transactions, micro payments, delayed transactions, support for incentive programs, and the secure interface between two cards used in a set-top box or PC.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00955"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "The New Storage Paradigm for Multichannel Video Transmission",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John L. Pittas"
                  ],
                  "abstract": "Throughout the world broadcasters are planning upgrades to existing single-channel facilities or launching new sites. They're quickly capitalizing on new capabilities to deliver six to 10 digital programming services on satellite transponders that formerly carried only one analog program. In addition to digital encoding, multiplexing and modulation technologies that are central to delivering multiple programs in a digital bouquet, a multichannel high-capacity video server is usually required to economically exploit this newly found programming bandwidth. — Today numerous disk-based products support digital video storage and delivery. However, not all products may be appropriate solutions in a multichannel facility. What are the initial cost implications for increases in storage and I/O? Can the systems be scaled to support broadcasters' evolution into the multichannel opportunity? Also, some video server products require users to integrate external components from different vendors to create a complete solution. This approach can be time consuming, technically difficult and often results in poor system performance. — Multichannel capabilities present a new opportunity and a new paradigm for broadcasters. This discussion will focus on the requirements for capturing, storing and delivering high-quality MPEG-2 video streams. It will highlight new methods for networking in Local Area Networks LAN and Wide Area Networks (WAN) environments and how those methods relate to archive and other interface issues.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00946"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "A Universal Format Conversion Architecture for Simultaneous Video and Computer Generated Imagery Scaling",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniel Zhu",
                    "Kevin Stec"
                  ],
                  "abstract": "In DTV post production environment, the use of video and computer generated imagery (CGI) of different formats becomes commonplace. High quality, real time video raster CGI format conversion will be an integral part of the routine operation for efficient DTV content creation and delivery. Most existing video/graphics workstations rely on the CPU and its graphic-subsystem muscle to perform image interpolation in software. In those cases, incoming materials have to be rendered in a suitable format before image editing or composition can take place. A more productive alternative is to use a dedicated hardware format converter such as the Panasonic universal format conversion (UFC) ASIC. The UFC ASIC not only provides numerical accuracy required by professional video applications, it also provides filtering versatility such as programmable response characteristics that can be tuned to specific applications. — Due to their distinct signal characteristics (e.g., the bandwidth), a format converter optimized for video scaling isn't necessarily suitable for CGI. Performance compromises such as image aliasing, ringing and blurring artifacts usually have to be made within a single interpolator design. To overcome the performance barrier constrained by one interpolator, we propose a new UFC architecture for simultaneous video and CGI scaling based on dual Panasonic UFC ASICs for DTV post production applications. The interpolators residing in the two UFC ASICs are designed to have complementary characteristics so that better performance can be attained through image fusion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00944"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Protecting Content in the Digital Home",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Beth Erez"
                  ],
                  "abstract": "With digital broadcasting, every copy becomes a perfect copy. Add to that the quality of high definition television, and the viewer at home will store a copy of higher quality than that he could buy on a DVD today. The digital home, with linked digital devices, will be able to maintain an archive of digital entertainment equal to that of a broadcaster. This presentation will review the scope of the problem, discuss the existing solutions and their limitations and look at frameworks being suggested to address the problem from the viewpoints of the content producer/provider, the broadcaster, the producer of fixed media, the consumer electronics manufacturer and, of course, the consumer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00956"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Parallel Processing Solves the DTV Format Conversion Problem",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jed Deame"
                  ],
                  "abstract": "The FCC mandate to broadcast Digital Television (DTV) has forced broadcasters to face the challenge of integrating High Definition Television (HDTV) programming into their NTSC or 601 plants. In the early stages of the DTV rollout, broadcasters will be required to simultaneously broadcast program material on both digital and analog channels (simulcast). In addition, broadcasters will need to combine locally generated advertising, programming and logos with network generated programming. However, this material will now be in a variety of different high definition and standard definition formats. This will force the broadcaster to convert most of their material from standard definition to high definition (up-convert), from high definition to standard definition (down-convert), or from one high definition format to another (side-convert). Often all of these conversions will need to be performed simultaneously. This has created an instant need for a variety of format converters. — The typical approach to format conversion is to “hard–wire” the processing algorithms using Field Programmable Gate Arrays (FPGAs) or Application Specific Integrated Circuits (ASICs). This approach has several disadvantages such as limited adaptability to new formats and lack of expandability to higher complexity processing algorithms. This paper describes an alternative approach using massively parallel computer technology to create a fully programmable video processor. This “Video Computer” can be programmed to perform a variety of video processing functions and provides the flexibility and scalability to support emerging formats and expanded capabilities without requiring a system redesign.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00941"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Building Cross-Platform Media Workgroup Solutions",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David E. Acker"
                  ],
                  "abstract": "The purpose of this technical paper is to present several of the key development considerations pertinent to the creation of a new non-linear editing (NLE) system that operates on the Windows NT platform. A significant factor in this regard is that the new system is based, to a large extent, on a product that was initially developed for the Mac platform. The initial product operated with Apple's QuickTime file compatible standard that offers several advantages as a result of QuickTime's file architecture. The resulting new NLE developed by Media 100 Inc. is called Finish™. The product is a cross-platform compatible system that permits easy access to the hardware by other applications as well as the use of a substantial number of QuickTime-compatible software applications. — Another related factor is that the initial signal architecture readily lends itself to the inclusion of more recent interface standards including DV (IEEE 1394) and SDI. This is a consequence of the inherent flexibility stemming from the design choices initially made. Based on the ITU-R BT.601 YCrCb, structure, the system design also interfaces to CAV component analog, Y/C and, CVBS (composite) sources.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00958"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Statistical Multiplexing with Look-Ahead Using MPEG-2 Video Encoding",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lilla Boroczky",
                    "Agnes Y. Ngai",
                    "Edward F. Westermann"
                  ],
                  "abstract": "In this paper a statistical multiplexing system to encode several video programs in parallel using MPEG-2 compatible video encoders, is presented. Particularly, an external joint rate control algorithm with look- ahead has been developed. It distributes the channel bandwidth dynamically among the encoders according to their relative complexities using picture and coding statistics. The proposed scheme allows, at start of encoding, adaptive distribution of the channel bandwidth among the programs based on their relative scene contents. It also assures quick reaction for scene changes, while a feedback approach requires an unavoidable delay. Experimental results show that the presented look-ahead approach results in improved picture quality in comparison to the feedback approach, which is a special case of the proposed algorithm.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00952"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Interlace and Progressive Scan Comparisons Based on Visual Perception Data",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%2033rd%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Glenn"
                  ],
                  "abstract": "Progressive scan is being favored over interlace by the computer industry and many proponents of video transmission systems because of the artifacts present in interlaced displays. The visibility of interlace artifacts depends on the acquisition method, the display, and viewing conditions. The perceived sharpness of an image is considerably less for an interlace image than for a progressive image. The reasons for these differences will be explained based on visual perception data. The differences in perceived sharpness will be quantified. All of the advantages of progressive scans can be realized with receiver signal processing of a standard interlaced transmission system as long as the originating camera and final display are in progressive format.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1999-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00957"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1998",
        "conferences": [
          {
            "conference_name": "140th SMPTE Technical Conference and Exhibit",
            "conference_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/",
            "articles": [
              {
                "article_local_id": "15",
                "article_title": "Wrappers and Metadata Progress Report",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Oliver Morgan"
                  ],
                  "abstract": "This paper reports the findings of the Subgroup on Wrappers and Metadata of the EBU/SMPTE Task Force on Harmonization of Standards for the Exchange of Programme Material as Bit Streams (TFHS) and the standardization projects now under way. This paper is not a full description of the work of the EBU/SMPTE Task Force, for which the reader is referred to the various reports and papers (1,2,3,4); this paper concentrates upon describing the architecture of the proposed overall solution for Wrappers, by reference to some example applications, and some issues of integration with existing standards and extension of the standards in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00276"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Factors to Consider when Choosing an MPEG-2 Encoder",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Neil Brydon"
                  ],
                  "abstract": "This paper intends leading the audience through some of the important criteria to consider when selecting a video encoder. In addition to discussing features, the presentation will outline the practical tests that users can perform to assess the relative merits of MPEG-2 encoder products. — MPEG-2 video encoders have been on the market now for nearly five years. By now buyers may have expected to be able to call on a strong pool of expertise to assist in picking through the hype and so reach a rational conclusion. This dream scenario is far from complete. — Many people forget that MPEG defines the standard characteristics of the stream such that it can be decoded. This successful strategy for standardization permits a degree of freedom in the design of encoding systems. Subsequently, there are a variety of encoder designs but also a correspondingly wide deviation in the picture quality for a given bit rate. Performing a feature check and determining whether an encoder can produce syntactically correct MPEG streams is easy. The difficulty arises in determining whether an encoder is efficient. — Although some users are now very comfortable with the application and selection of compression systems these users remain a strong minority. One of the fundamental problems with video encoding is that the underlying compression efficiency is very hard to measure. This issue is even more acute when running the encoder at very low data rates where the difference between encoders could mean substantially reduced bandwidth costs if the most efficient design had been selected. Although we are now seeing some admirable measurement devices that go some way to measuring picture quality, they can only tell part of the story. — This paper will explain how to augment objective measurements with additional tests and feature analysis. This should place the buyer in a better position to unzip the hype and fully evaluate the strengths and weaknesses of an encoder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00268"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Contemporary DTV Acquisition – Some Perspectives on the Related Standards, the Technologies, and the Creative",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurence J. Thorpe"
                  ],
                  "abstract": "The arrival of DTV has created a curious maelstrom of tentative engineering excitement, business anxiety, creative skepticism, and spotty consumer anticipation. In light of the imminent debut of the new DTV services, the lingering technical debates on DTV formats have now become unhelpful, and, in the larger scheme of things, they are already anachronistic. — In the context of the front end of the new television system—DTV image acquisition—technical debate certainly still swirls unchecked. This paper will attempt some perspectives intended to urge a move to the next and most important phase of this interindustry DTV movement, namely, proactive implementation by the creative program production community. — The present technical status of DTV image acquisition will be shown to be better than many believe. It is suggested that the rigorous implementation of Standards should be subservient to the paced and incremental march of Technology, and that it is the Creative community that best drive the pace of advance of the latter. At some point, it becomes essential for the realities and subjectivity of digital program creation to supplant misguided engineering rigor. — Resolution will be central to much that is examined here. There is surely no technical performance parameter that is so carelessly bandied, and so grossly misunderstood, particularly when it comes to the realities of widescreen SDTV and HDTV picture acquisition.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00265"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "WRAL-HD DTV Complete Field Testing Report",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Luther H. Ritchie"
                  ],
                  "abstract": "WRAL-HD conducted one of the nation's first DTV field tests. This report will explain the testing methods, results and analysis of this test with the final section devoted to comparisons with measured NTSC reception. The testing consisted of four phases that explored different aspects of the new transmission service. In the different areas of testing the results found were that outdoor service availability of the 100 kW HDTV service was 89.6% when measured to 65 miles. Also, a horizontally-polarized transmitting antenna was compared to a circularly- polarized transmitting antenna with no significant advantage or disadvantage found for either antenna to existing receive antennas. Testing was included from inside of various residences and showed that the problems, which have always affected indoor NTSC reception, will need to be addressed with DTV. Finally, WRAL-HD's side-mounted DTV transmitting antenna was tested for pattern nulls and receiver white noise enhancement and showed that the tower does have an effect on the DTV transmission, but it is minimal and should not prevent the implementation of this type antenna. This report also contains some detailed comparisons between a 5000 kW NTSC signal and the DTV signal. With the NTSC signal enjoying not only a greater power but other transmission advantages as well, the outdoor service availability of the NTSC was 92.5% and for the DTV signal it was 91.8%. These comparisons were also evaluated for indoor reception. This report will detail these and other findings.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00271"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Transport Stream Splicing for Broadcast Networks",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Barry L. Hobbs"
                  ],
                  "abstract": "The everyday operation of a broadcast facility involves editing and joining of program content to form the broadcast transport stream. While much of the program editing can be done off-line there are many scenarios where program content must be switched live-to-air: for example, insertion of advertising into digital transport streams. Such applications are of paramount importance for the maintenance of revenue and for the smooth running of multi-source programs such as news broadcasts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00269"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Optimization of DTV Signals within a Transmission Plant",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brett Jenkins",
                    "Ray Kiesel"
                  ],
                  "abstract": "With the transition to DTV, some of the old challenges in maintaining signal purity through a high power transmitter become more complex as the signal can be much less tolerant to distortions. Comark has been researching new technologies to minimize and compensate for distortions in DTV transmitters for over four years. This paper will explain why these distortions are so important and what methods Comark is using in its new DTV transmitters to insure that the highest possible quality signal is transmitted at all times. Real world examples from high power DTV transmitter installations will be presented and explained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00272"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Video Compression: The Case of the Reluctant Reality",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles Hintz"
                  ],
                  "abstract": "Some talk about video compression as if it were one thing. It is worth reviewing the reality—video compression is a large number of things, good and bad, strategically applied in a number of different ways in a best-effort attempt to glean the best displayed picture out of the least transmitted data. Because channel space remains so highly valued, effective use of small channel space is greatly desired in video. — This paper is the result first of technical conversations around the coffee machine and later lectures to my telecommunications, videoconferencing, and distances education classes at the California State University, Hayward campus. — Whether the material in this paper is new to you, a limited relearning past experience, or a reawakening memories half faded, video compression is here to stay and, I feel, a topic well worth the overview.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00266"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "A Verification System for Cinematographer Image Generation Tools",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher C. Woollard"
                  ],
                  "abstract": "The Production Workstation developed at the University of Greenwich is evaluated as a tool for assisting all those concerned with a Production. This enables the Producer, Director and Cinematographer to explore the quality of the images they will obtain when using a plethora of tools. Users are free to explore many possible choices, ranging from 35mm to DV and combine these with the many image manipulation tools of the Cinematographer. The validation required for the system is explicitly examined, concerning the accuracy of the resulting imagery.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00264"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "New Technology on Fujicolor Negative Film",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ryoji Nishimura",
                    "Katsumi Makino",
                    "Yasunori Mimaki",
                    "Sam Yamaryo"
                  ],
                  "abstract": "Fuji Photo Film Co., Ltd. has recently completed development of a new and completely redesigned highspeed F-500 color negative motion picture film stock (EI 500T) which offers the cinematographer dramatic improvements in image quality. — This next-generation film stock incorporates two major Fuji proprietary technological developments which results in significantly improved granularity, sharpness and color reproduction. — The first of these developments utilized by the new emulsion is Fuji's Super Uniform Fine Grain (SUFG) technology. This proprietary advancement is particularly effective in increasing fine-grain sensitivity, which has previously been unachievable in high-speed photosensitive materials. The SUFG technologiy is incorporated into all layers of the new F-500 film and is responsible for its remarkably fine grain. — The second development utilized is Fuji's DIR technology. This proprietary improvement is also a critical factor in the new emulsion's performance equation and brings vast improvements in sharpness and color reproduction over traditional high-speed emulsions through more precisely controlled release of high-diffusional development inhibitor.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00263"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Metadata Issues for ATSC Audio",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stan Cossette"
                  ],
                  "abstract": "The audio decoder in a consumer DTV receiver conforming to the Advanced Television Systems Committee (ATSC) specification needs two types of data in order to work properly. The data stream it receives must contain coded audio as well as audio metadata. Audio metadata is a group of parameters that describe the audio program data being transmitted and control some aspects of how the audio program is presented in the consumer's receiver. — This paper will provide an overview of the audio metadata parameters. It will discuss the purpose of the parameters and how they are chosen. The paper will also discuss the effect that each of these parameters has on domestic receiver operation. The operational implications of authoring the different parameters at different points in the production or distribution chain will be examined. Some different methods for authoring the metadata will also be proposed. These methods will include those necessary during the transition period when proper metadata authoring and monitoring equipment may not exist.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00286"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Implementation of Intranet Scene Preview for Feature Animation",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Leonard J. Reder",
                    "Gene Takahashi"
                  ],
                  "abstract": "This paper describes the development of an Intranet scene preview capability within Warner Bros. Feature Animation. This capability was developed so all members of the production staff could easily view production material as it was being animated. — The animation production process as it pertains to the preview capabilities is presented and the organization of the server is reviewed. A discussion of HTML along with the structure and function of the custom software developed is given. Performance and enhancements of QuickTime downloading and playback is also discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00262"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Networking Infrastructure for DTV",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Owen"
                  ],
                  "abstract": "This paper seeks to explore several of the key issues with regard to the interchange of video data between systems. It lists some of the attributes associated with the various image formats in common use in the television today. While the use of file transfer techniques via a network connection has some advantages over exporting as video streams it also has other characteristics that require managing to stop bottlenecks occurring. — This paper lists the requirements of a system to transfer video at high speed via a network connection. It includes information on the efforts of some of the standards bodies to harmonise the transfer of video images in this way. It then lists findings on video networking formed while designing a new video networking system called Clipnet.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00279"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Advanced Television System Considerations for Compression",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "Many picture and signal format issues have been argued in isolation. However, in reality the quality of delivered images will be determined by the interaction of these format and processing issues throughout the entire production and delivery chain. Of particular concern is the way that compression reacts to signal and picture formats. Compression of the final image using a squeeze of two orders of magnitude forms the critical bottleneck in the delivery chain. It is this bottleneck that primarily determines potential delivered quality. — Display and channel noise considerations may initially limit or affect delivered quality. However, displays and picture delivery are likely to eventually improve to the point where compression quality determines the appearance of the end result. — Compression is a set of processes for coding an image. These processes seek to discard data without undue damage to picture quality. Each process is affected by different issues, yet all of the processes react together to create the final result. In addition, other processes in the production chain prior to compression will interact with the compression processes. — The author and his company have been very active in exploring layered compression based upon MPEG-2. For many high resolution formats, a layered compression system will outperform a non-layered system. Further, layered compression has the advantage of substantially reducing the cost of decoders for the more affordable class of displays. — Although there is vigorous debate about television formats and signal practices, there is a strong desire to prepare and distribute high quality pictures. This paper attempts to identify the practices which lead to high quality pictures, as well as to identify those practices which hinder picture quality. The discussion further attempts to describe a way of conceiving digital video systems which leads to flexibility, as well as discussing those practices which limit and restrict the use of the advanced television video signals. The author has long been an advocate of interoperability and flexibility. We will take a fresh look at high definition video signals and practices from this perspective.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00277"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Format-Independent Post Production",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bob Pank"
                  ],
                  "abstract": "The adoption of the ATSC's Digital Television Standard means that pictures may be broadcast in a number of different formats rather than the 525/60I system used for analog NTSC. Many TV stations have already declared their proposed formats for SD and HD and it is clear that several will soon be in use. This paper establishes aims for such a scheme, examines possible ways of working with multiple input and output formats in post production and goes on to formulate a practical structure for such equipment. It also looks at the possible impact on operational practices that this may have.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00280"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Fast Transcoding of Compressed Bitstreams by Reusing Incoming Motion Vectors",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stuart J. Golin"
                  ],
                  "abstract": "Transcoding will be an important activity in the digital studio. People will transcode MPEG-2 bitstreams to resize images, to support progressive or interlaced receivers, to optimize for editability or storage/transmission efficiency, etc. Transcoding involves decoding a bitstream, possibly modifying the decoded pictures, and then re-encoding. Transcoding is expensive because encoding is expensive, and the major cost of encoding is ME (motion estimation). — We have developed a program, MVREX, that reuses incoming motion vectors during transcoding. MVREX (Motion Vector Reuse by EXtrapolation) assumes that motion is linear, and extrapolates known motion from input macroblocks to output macroblocks, avoiding ME. MVREX has transcoded both progressive and interlaced video between different GOP structures. It supports all MPEG-2 prediction modes for frame pictures, except dual prime. — In the cases examined, MVREX produces video whose PSNR is usually within 1 dB of that produced by a full search, but with orders of magnitude less computation. It continues to work well after multiple generations of transcoding, and appears to be a promising approach to transcoding. — After a brief review of MPEG-2, this paper describes the concept of motion extrapolation and derives basic formulas. It then presents several results and observations, and concludes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00270"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Discreet Multi-Channel Audio for Post and Broadcast",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Knapton"
                  ],
                  "abstract": "Digital Program delivery is becoming a reality. It offers more programs, a higher definition picture and an enhanced audio experience. In order to serve this market both contribution and distribution systems in the Broadcast and Post Production industries must move rapidly to provide the digital infrastructure to cope with this evolution. — This poses many questions. Not least is how to economically, (in terms of financial, technological and bandwidth constraints), sustain a quality multi-channel audio signal through a typical broadcast chain, allowing for interim signal processing requirements. — Psycho acoustic based algorithms by nature discard signal content to accomplish bit rate reduction. Although inaudible in emission environments, this information is irretrievable and therefore adversely affects post production processing. Given that the emission or final delivery system for surround sound transmissions, will utilise a reasonably high compression ratio, psycho-acoustic coding system, the broadcast industry is rightly showing concern that prior audio communications systems are carefully considered. The apt-X algorithm is well established in both the Post Production and Broadcast arenas and is widely recognised for maintaining audio signal integrity through both multiple encode/decode cycles and tandem coding with psycho acoustic algorithms. — This paper proposes the use of the apt-X algorithm as an ideal mezzanine level audio coding system for use in conjunction with DAB and DTV emission standards, to preserve the audio quality throughout the broadcast chain and alleviate production problems arising from psycho-acoustic artefacts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00284"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Compatible 1080P Display Using 1080I Transmission",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Glenn"
                  ],
                  "abstract": "A camera that produces 1920 times 1080 pixels in color progressively scanned at 60 FPS was described and demonstrated at the SMPTE convention in November 1997. This paper describes a method of transmitting this information using a standard MPEG 1080I compression format. Processing in a 1080P display can reconstruct the same image as is now displayed by the camera with the full 1000 line resolution and without the interlace artifacts. — A 1080I receivers will display it normally but with the interlace artifacts. This provides broadcasters a route to upgrade displayed images from 1080I to 1080P without changing transmission standards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00278"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Native 720 Progressive Transfers Using the Data Transfer Method — Or, How I Learned to Avoid Interlace and Love the Supercomputer",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Randall Hoffner"
                  ],
                  "abstract": "When ABC chose to broadcast HDTV in the 1280/720/60 progressive format, it was quickly decided to demonstrate the quality achievable with that scanning format using both video acquisition and film-to-tape transfer. An obstacle to achieving the best quality film-to-video transfers at that time was the lack of telecine facilities capable of generating a 720P video output. Consequently, the only 720P material readily available from film sources had been transferred as interlace and subsequently converted to progressive using a method that “printed” the interlace footprint into the progressive video. With the help of several parties, we were able to scan film generating not video but data files, and to use a supercomputer to create 60 fps progressive video from those data files. As in any trailblazing effort, some rough terrain was encountered. This paper describes that project and the results it produced.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00282"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Presenting Widescreen and Standard Services Side by Side: The BBC Experience",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ian Baker"
                  ],
                  "abstract": "Recently the UK has launched a range of digital widescreen services. The services are expected to replace the existing services, so it is necessary to transmit the same material on both the new widescreen services and the standard format analogue services. This provides challenges in producing material that is pleasing on both formats without remastering programs and having the expense of transmitting two separate channels. — The BBC has been transmitting these widescreen and 4times3 services alongside each other since the start of June. It is not easy to provide a continuing service to existing viewers and at the same time deliver an exciting service that people will buy. This paper describes the BBC's experience in providing a simulcast widescreen and 4times3 service — The issues in providing programming that is compatible with both formats are discussed. A cost effective way of providing the simulcast services is shown together with the policy options for shooting material. — The article concludes by discussing the best option for the delivery of simultaneous services so that all the viewer get the best out of our range of channels.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00281"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Approaches to Planning and Deploying MRC's Innovative Dual (Analog and Digital) Carrier Microwave System",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Glidden"
                  ],
                  "abstract": "MRC's TwinStreamTM radio is the first dual carrier radio for transmission of uncompressed legacy NTSC plus ATSC signals in a single 25 MHz RF channel. Featuring a proprietary, patent-pending approach to microwave system design, the TwinStream radio is ideal for studio-to-transmitter links (STLs), transmitter-to-studio links (TSLs), and satellite backhaul requirements. — MRC has been working closely with major network broadcast groups to provide the TwinStream radio for their November 1998 DTV sign-on requirements. MRC's support of these demanding new applications is the latest in its long history of providing market innovations for television broadcasting. — The TwinStream radio also is ideal for digital and analog programming feeds to cable headends and digital and analog newsgathering backhauls.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00273"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Capacity Requirements of Video Servers in Broadcast Television Facilities",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ying Ki Kwong",
                    "John Cvetko"
                  ],
                  "abstract": "Digital video servers are being rapidly adopted in broadcast transmission facilities. In such a facility, new materials must be cached to these servers, usually from tape media or, possibly, from media in an archival system. To deal with the finite capacity of these servers (usually with hard disk media), old materials must be purged to free up space. In this process, materials of different time duration are handled. Increasingly, materials with different data rates are also handled because of the use of different compression standards, compression ratio, and (with the advent of HDTV) different uncompressed data rates and formats. Since the cost of video server storage is significant, understanding the time-dependent requirements of server storage capacity is important for system-level planning. A good understanding helps avoid wasteful provisioning of storage capacity without sacrificing operational flexibility. This paper presents a model which we believe is useful for planning or analyzing capacity requirements of video servers. We will examine implications of the model for systems handling primarily long form materials, such as near-video-on-demand applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00275"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Globo TV's HDTV Experimental Transmission",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paulo H. C. V. de Castro",
                    "Ana Eliza Faria e Silva",
                    "Luisenrique P. N. da Costa"
                  ],
                  "abstract": "During the World Soccer Cup, Globo TV Network accomplished the first intercontinental live digital TV transmission in High Definition, using the ATSC format. A total of forty five matches were transmitted via satellite directly from France to São Paulo, in Brazil, where a digital 8-VSB UHF transmitter put them on the air. — The main objective of this experiment was to demonstrate to the Brazilian authorities involved in broadcasting policy planning and television professionals the advantages of digital television, especially in high definition. — The matches were produced at the stadiums by the Japanese NHK and a European consortium led by France 2. At the International Broadcasting Center (IBC), in Paris, the received signals were digitized, compressed in the ATSC format and transmitted to a satellite whose downlink spot beam covered Brazil. — In São Paulo, the signal was received on a pass-through station and, after demodulation, fed a digital transmitter set for channel 19, which covered most of the city's area. Several viewing sites were prepared in the downtown area. Each room was equipped with the appropriate reception equipment and some monitors and projectors for exhibition.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00274"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Improving Microphone Equalization for Dialog",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomlinson Holman"
                  ],
                  "abstract": "While anechoic microphone frequency response is a common specification, microphones in use for dialog are strongly influenced by their relative position to the talker. In this work, one reference microphone type and position is taken as representing the correct response for the talker, and other microphones and methods for their use are compared to the reference. Among the positions and types tested are those normally used on a boom for film and television use, and a lavalier. Equalization is designed to minimize the differences between each type and the reference, and in some cases, up to 10 parametric bands are necessary to produce a response that is about +/-1 dB of the reference over the voice range. Several room acoustic conditions were included in the survey, as well as the effects of windscreens. The presentation of the paper will include a recorded demonstration.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00283"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Improving the Quality of Film to Digital Transfers for Digital Cinema",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Loren Nielsen",
                    "Matt Cowan"
                  ],
                  "abstract": "High quality on screen picture performance is the ultimate technical goal of Digital Cinema. Tests have been performed projecting movies from standard and High Definition (HD) telecine transfers that were intended for home video and HD broadcast applications. The results of these have fallen short of the image quality needed for large screen theatrical projection. — This paper reports on work that has been undertaken to improve the image quality by altering the source characteristics through adjustments the telecine transfer process. The work is based on using a display with identical characteristics to the ultimate theatrical projector to perform the transfers. This has resulted in transfer images with a different quality to the “standard” transfers using CRT monitors as the transfer target. — The image was improved by concentrating on the treatment of the following: gamma, black and white crushing and clipping, colorimetry and digital enhancement. The results have been remarkable, as will be demonstrated in the presentation following this paper.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00296"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Making Digital Cinema Actually Happen – What it Takes and Who's Going to Do It",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steven A. Morley"
                  ],
                  "abstract": "The term “Digital Cinema” means different things to different people from “big screen television” on up. This paper addresses the ultimate Digital Cinema application—complete electronic replacement of film prints as a means to distribute first run feature films to any theatre in the world. — This inevitable revolution in motion picture distribution involves more than just a comparison of the quality of electronic projection techniques against traditional film projection. It provides the opportunity to meet many of the present and future needs and desires of concerned parties at all levels of the motion picture food chain—from directors and producers to those of us in the viewing audience. This paper explores some of the wish list items that exist for Digital Cinema and answers the question, “will this really happen and, if so, how soon?” — Finally, a complete end-to-end solution to meet these system requirements is presented that will shape the future of cinema distribution for the next millenium. A good electronic projector is just the beginning. The presented solution addresses the issues of cost, security, reliability, controllability, and ease of use.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00299"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Aspects of Digital HDTV Coding",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gordon M Drury",
                    "Alois M Bock"
                  ],
                  "abstract": "Practical High Definition Television [HDTV] broadcasting has been an objective for television engineers for decades and is now feasible through the use of the MPEG-2 compression algorithm. The source bit rate can exceed 1 GBit/s and the target rate for transmission is less than 20 MBit/s thus requiring a reduction ratio of more than 60:1. Implementing MPEG-2 for HDTV is a significant technical challenge because the processing speeds involved are very high and this particularly affects the motion estimation and compensation part of the process. This paper is concerned with how implementation issues affect the performance of MPEG-2 coding for HDTV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00267"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Program Presentation Using ATSC Audio Systems",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen B. Lyman"
                  ],
                  "abstract": "This paper is an overview of the Audio system that has been selected by the Advanced Television Systems Committee (ATSC) for use in the US and Canadian High Definition Television systems, and has been selected as the preferred method of carrying the audio in the Australian HDTV system. — It starts by start by examining why producers would want to use multichannel sound for television, what the requirements for a multichannel audio system are, and perhaps most importantly, the operational changes that will have to make in going from the one or two channel system used with NTSC television to a multiple channel sound system. — The paper continues by examining some of the features and service options that are provided by the ATSC specification, then examines a method of enabling the rest of the broadcast chain to handle multichannel sound and the metadata that DTV receivers depend on.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00285"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Right-Sized Server Solutions: Blueprint for Efficiency",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Allan Arthurs"
                  ],
                  "abstract": "The broadcast industry has long debated the relative merits of centralised versus distributed server architecture, the case of one large server or several smaller ones networked together. The relative merits and de-merits are a complex function of the individual application with all of its particular operational considerations along with channel bandwidth, storage capacity, redundancy and cost. This paper seeks to explore the underlying issues with a view to developing an effective strategy based on the smallest number of ‘right-sized servers’ for a variety of broadcast applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00291"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Living with Video Servers in a Digital Broadcast Facility",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael A. Pusateri"
                  ],
                  "abstract": "The Disney Channel has been playing to air from video servers since November 1st, 1996. Twenty-four hours a day, seven days a week, all programming and promotional materials play to air from a pair of redundant video servers under the control of an automation system. On April 18th, 1998, Disney Channel launched a new network, Toon Disney, which also plays to air directly from a video server. — Living with video servers is a coming reality for all broadcasters. Whether servers are used only in isolated areas or facility-wide, broadcast engineers will need to understand how to use these new tools effectively and learn their particular failure modes. Experience with computer operating systems and modern computer networking techniques is not only helpful, it is essential. — The Disney/ABC Cable Group's Network Operation Center (NOC) in Burbank, California was built in the Summer of 1996. The NOC went into operation in November 1996, with the origination of the Disney Channel from a new all-digital facility with ITU-R 601 digital component video and four channels of AES/EBU digital audio. The tape format is Sony's Digital Betacam and the robotics are the Sony Library Management System (LMS). The automation system is from Louth and the video servers are the Philips DVS Media Pool and the ASC Audio Video Corporation VR300. Routing systems are from Philips and NVision, under the control of the Philips Jupiter control system. — Disney utilizes a ‘full time caching’ concept for playback of Disney Channel and Toon Disney. The automation system is loaded with a playlist created by a separate traffic system. The automation examines the playlist and creates a caching list. The caching list includes all video elements needed for playback within the next 3–5 hours, programs and promotional material inclusive. The automation cues material on tape in the LMS and then records the item into the video server. Once the item is stored in the video server, the automation can play back the item at the correct time. The automation instructs the video server to play the items back-to-back in the correct order to produce a constant program feed that is fed to a master control switcher. The automation monitors the server storage and deletes items or caches new ones as needed. — This type of caching system allows for simple expansion to multiple time zone or regional feeds. Last minute changes to the playlist are simplified. VTR wear is reduced since multiple playbacks of high repetition items come from the video server rather than tape machines. Overall, the reliability of an automated server based playback system is higher than the reliability of an automated tape based system. — Many of the rules have changed in moving from the analog VTR world to the digital server world. The simultaneous introduction of a digital facility, automated network playback system, and video servers taught the Disney engineering staff many lesso In this paper, we intend to relate our experiences to help others plan and understand the coming change to server based facilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00290"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "A Broadcaster's Guide to WAN Connectivity",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Al Kovalick"
                  ],
                  "abstract": "For years the vast majority of audio/video assets have been moved between locations using both streamed audio/video and tape. With the advent of LAN and WAN (wide area networking) technology and associated infrastructure, new ways to move assets are available to augment the existing methods. This paper gives a motivation for broadcasters to use WAN methods for moving media files. Several very compelling reasons for using WAN technology as part of a broadcast facility are outlined. A brief overview of WAN technology is given with emphasis on the salient points for the broadcaster. Six different WAN technologies are compared. Some favorable trends are presented with a view to the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00293"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Adding Hyperlinks to Digital Television",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "V. Michael Bove",
                    "Jonathan Dakss",
                    "Stefan Agamanolis",
                    "Edmond Chalom"
                  ],
                  "abstract": "Hyperlinked video is video in which specific objects are made selectable by some form of user interface, and the user's interactions with these objects modify the presentation of the video. Identifying and tracking the objects remains one of the chief difficulties in authoring hyperlinked video; we solve this problem through the use of a video tracking and segmentation algorithm that uses color, texture, motion, and position parameters. An author uses a computer mouse to scribble roughly on each desired object in a frame of video, and the system generates a segmentation mask for that frame and following frames. We have applied this technique in the production of a soap opera program, with the result that the user can inquire about purchasing clothing and furnishings used in the show. We will discuss this and other uses of the technology, describe our experiences in using the segmentation algorithm for hyperlinked video purposes in both broadcast and on-demand modes, and present several different user-interface methods appropriate for hyperlinked video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00294"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Application of DLP™ Technology to Digital Electronic Cinema—A Progress Report",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William B. Werner",
                    "D. Scott Dewald"
                  ],
                  "abstract": "In the entertainment industry's quest for the “suspension of disbelief,” two primary sensory stimuli have been engaged: sight and sound. Since the advent of digital audio, a number of new multitrack digital sound formats have appeared in the motion picture industry, all in an attempt to achieve the ultimate audio experience. However, visual presentation has not advanced at the same pace as the aural experience. Many problems associated with conventional motion picture presentation and distribution can be overcome through a digital form of delivery. The missing link, however, has been an electronic display system that delivers cinema-quality images. Certainly the ultimate achievement in electronic projected image quality would be to match or exceed that of motion picture film. — Texas Instruments is studying the possible application of DLPTM technology to electronic cinema. This effort has involved a close working relationship with the motion picture industry to assess DLP performance from technical and artistic perspectives. Knowledge gained from this process has led to improvements in DLP technology that may someday lead to a DLP-based cinema application. This paper addresses some of the advances in image quality made in the quest to achieve the ultimate cinematic experience.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00295"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Automatic Luminance Distribution Tuning for High Intensity Xenon Lamp Consoles in Motion Picture Film Projection",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark C Regel"
                  ],
                  "abstract": "This paper details a method of automatically aligning high intensity xenon lamps, in three motorized axes within lamp-house reflectors, to optimize luminance distribution on motion picture screens. The existing methods of adjusting luminance distribution, “visual” or “spot-metering”, are highly operator dependant and often produce less than optimum results. In addition, the somewhat tedious process of “spot-metering” often leads to a compromise in lamp alignment, between “flat” & “scope” formats, being used. The automatic method of alignment, detailed within this paper, incorporates solid state electronics and CCD optics to provide quick, repeatable and optimal luminance distribution in any format and includes compensation for the vertical angle between the projector to screen light path and the screen to audience light path.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00289"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Digital Communications for Sound and Images: State of the Art, Fall 1998",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas A. Scott"
                  ],
                  "abstract": "Digital telecommunication techniques are revolutionizing the long distance contribution, collaboration and distribution of images and sound. This presentation will survey current applications of telecommunications technology to the problems of moving sound and images across town and across the world for Production and Post-production of Motion Pictures, Television, Commercials, and Music Recording.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00287"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "5.1 Audio – The Final Frontier of DTV",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joe Fedele"
                  ],
                  "abstract": "With the transition to digital television now underway the primary focus by many has been on the variety of video formats and the transmission of DTV signals. But the introduction of DTV also includes six channels of CD quality sound, more commonly referred to as 5.1 Audio, that has not received the intense scrutiny necessary for a complete transition to digital television. — This paper will outline some of the many issues facing broadcasters where multichannel digital audio is concerned. A brief introduction to the AES-3 and Dolby Digital standards, as well as some design solutions and possible scenarios for handling 5.1 audio, will offer engineers a general template that may be used to incorporate multichannel sound into their facilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00288"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Component Serial Digital Video Transport over Wavelength-Multiplexed Fiber Optic Systems",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Osmond",
                    "Steven Storozum"
                  ],
                  "abstract": "As digital video technology becomes ubiquitous, moving large quantities of high-quality, uncompressed digital video between distant locations has become a requirement. This paper addresses the application of optical transmission of these signals using Wavelength Division Multiplexing, a very promising technology for combining multiple high-speed digital video signals onto a single fiber. As each wavelength can readily carry at least one SMPTE 259M signal, Wavelength Division Multiplexing technology effectively breaks the bandwidth bottleneck that has existed until now. This paper discusses the issues presented above, outlines potential Wavelength Division Multiplexed solutions, and presents work currently under consideration by SMPTE regarding optical transmission of serial digital video signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00298"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Perceptual Effects of Noise in Digital Video Compression",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles Fenimore",
                    "John Libert",
                    "Stephen Wolf"
                  ],
                  "abstract": "We present results of subjective viewer assessment of video quality of MPEG-2 compressed video containing wide-band Gaussian noise. The video test sequences consisted of seven test clips (both classical and new materials) to which noise with a peak-signal-to-noise-ratio (PSNR) of from 28 dB to 47 dB was added. We used software encoding and decoding at five bit-rates ranging from 1.8 Mb/s to 13.9 Mb/s. Our panel of 32 viewers rated the difference between the noisy input and the compression-processed output. For low noise levels, the subjective data suggests that compression at higher bit-rates can actually improve the quality of the output, effectively acting like a low-pass filter. We define an objective and a subjective measure of scene criticality (the difficulty of compressing a clip) and find the two measures correlate for our data. For difficult-to-encode material (high criticality), the data suggest that the effects of compression may be less noticeable at mid-level noise, while for easy-to-encode video (low criticality), the addition of a moderate amount of noise to the input led to lower quality scores. This suggests that either the compression process may have reduced noise impairments or a form of masking may occur in scenes that have high levels of spatial detail.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00301"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Assessing the Quality of Compressed Pictures Using a Perceptual Model",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wilfried Osberger"
                  ],
                  "abstract": "This paper presents an objective image quality metric based on a model of the human visual system. It essentially consists of two stages. Firstly, a multi-channel early vision model, tuned specifically for complex natural scenes, is used to determine the visibility of coding errors at each location in the scene. A model of visual attention is then used to identify regions of interest in the scene. This allows the visible errors to be weighted, depending on the perceptual importance of the region in which they occur. It is demonstrated that this technique produces a high correlation with subjective test data (0.93), compared to 0.87 when only the early vision model is used, and 0.65 for PSNR. A description of how this technique can be extended to video quality assessment is also included.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00303"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Equipment and Stategies for Signal Quality Monitoring for Digital Television Networks",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. Baina",
                    "G. Goudezeune"
                  ],
                  "abstract": "This paper points out the problematic of objective assessment of signal quality on digital TV networks. It aims also to present an equipment for automatic audio and video quality assessment designed in QUOVADIS Project. The monitoring of signal on digital TV networks sets specific technical constraints that have to be taken into account.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00302"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "Testing Applications in Uncompressed HDTV Signals",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James R. Waschura"
                  ],
                  "abstract": "This paper focuses on testing methods and applications for the uncompressed HDTV signal, SMPTE 292M. It includes a description of the signal's electrical characteristics, digital format, and special protocols for embedding auxiliary information. This is followed by an explanation of testing methodologies and tools used to verify compliance to the SMPTE specification. Afterwards, the author suggests two specific areas for automatic testing in the product manufacturing cycle: design verification and manufacturing test.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00306"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Open Broadcast Networking",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chandy Nilakantan",
                    "Jonathan Claman"
                  ],
                  "abstract": "Broadcast networking describes the interconnections between autonomous systems that function as a whole to form the delivery chain of traditional broadcast services, such as television programming. The broadcast industry is in the midst of revolutionary changes that range from the adoption of digital content and transmission systems, to the delivery of a broader range of highly integrated and targeted multi-media services. This migration is occurring against a backdrop of major technological breakthroughs that will result in unprecedented system and component price/performance ratios, enhanced functionality and broader choice in equipment providers. The operational models employed by broadcast content providers and service operators will need to change in order to deliver these new services. The present day broadcast networks will prove to be inadequate to meet the new levels of connectivity, functionality, scalability, performance, reliability and security necessary to facilitate the emerging operational models. Open broadcast networking combines existing and emerging digital video and data broadcast standards with new developments in computer data networking to bring a new approach to building a scalable broadcast network. — In this paper, we will: • Examine the characteristics and limitations of present day broadcast networks • Discuss the elements of Open Broadcast Networks—a fully networked broadcast content acquisition, distribution, re-purposing and delivery system • Describe a new approach to service provider head-end architecture and introduce the notion of the “virtual head-end” • Endorse applicable digital video and data broadcast, and networking standards",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00292"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "Test Card “M”-Bitstreams for DVB Test and Measurement",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bruce Devlin",
                    "Paul W. Walland"
                  ],
                  "abstract": "Traditional television test and measurement techniques have used “test cards” as a tool in establishing the quality of the transmission link the digital domain differs in that the link is assumed to be good even when there are link errors. The concept of a test card which shows these problems is a vital one for proving system performance. Test Card “M” is a suite of bitstreams being developed by Snell & Wilcox in conjunction with its partners, the BBC, ITV, Channel 4 and the ITC. The project is part funded by the UK's Department of Trade and Industry and is intended to help UK Digital terrestrial television get on air reliably. — A set of synthesised bitstreams which have been created to stress certain aspects of the digital syntax will help in identifying malfunctioning equipment and weak links in the digital chain. This paper describes the scope of the Test Card “M” work as well as giving examples of the bitstreams being developed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00305"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Objective Picture Quality Measurements: Expectations Today and Tomorrow",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David Fibush",
                    "Mihir Ravel"
                  ],
                  "abstract": "In addition to traditional indirect signal quality measurements, today's objective picture quality measurements require analysis of picture changes caused by nonlinear and time-variant digital processing systems such as compression codecs. Although the objective measurement paradigm, based for the first time on estimating directly perceived changes in quality, is new, we can expect much the same confidence in system operation as today. For broad utility, these new objective measurements must be meaningful to the application, and generally have correspondence to subjective evaluation of the changes in picture quality caused by video processing. Objective measurements can also be expected to have advantages in providing much more rapid and consistent results over a wide range of picture degradations. As a guide to understanding the various attributes that are desirable for robust objective measurement methods, we discuss appropriate methods for correlating objective measurements with subjective results. The need for standardized test scenes is explained as well as considerations for in-service monitoring applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00300"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "The Video Quality Experts Group: Evaluates Objective Methods of Video Image Quality Assessment",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Philip Corriveau",
                    "Arthur Webster"
                  ],
                  "abstract": "This paper briefly discusses objective and subjective methods for video quality assessment and then focuses on the current work plan and schedule of the Video Quality Experts Group (VQEG). — Subjective assessment methods have been used reliably for many years to evaluate video image quality. They continue to provide the most reliable assessments. Some issues that arise with subjective assessment include the cost of conducting the evaluations and the fact that these methods cannot easily be used to monitor video image quality in real time. Traditional analog objective measurements, while still necessary, are not sufficient to measure the quality of digitally compressed video systems. Thus there is a need to develop new objective methods utilizing the characteristics of the human visual system. While several new objective methods have been developed, there is no internationally standardized method. — In October 1997, the VQEG was formed at a video quality experts meeting at Centro Studi e Laboratori Telecomunicazioni (CSELT) in Turin, Italy. The group is composed of experts from various backgrounds and affiliations, including participants from several internationally recognized laboratories working in the field of video quality assessment. The majority of the participants are active in the International Telecommunications Union (ITU) and the VQEG combines the expertise and resources found in several Study Groups to work for a common goal. The first task undertaken by the VQEG is to provide a validation of objective video quality measurement methods leading to Recommendations in both the Telecommunications (ITU-T) and Radio (ITU-R) sectors of the ITU. To this end, VQEG has designed and is conducting a test program to compare subjective video quality evaluations with a number of proposed objective measurement techniques. The first test program will evaluate objective model performance against subjective results for video quality in the bit rate range of 768 kb/s to 50 Mb/s.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00304"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "A DVB-Compliant Electronic Cinema Solution",
                "article_url": "https://journal.smpte.org/conferences/140th%20SMPTE%20Technical%20Conference%20and%20Exhibit/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wolfgang Ruppel",
                    "Stephan Breide",
                    "Michael Dutka",
                    "Christoph Moldrzyk"
                  ],
                  "abstract": "This paper describes a DVB-compliant HDTV transmission system for Electronic Cinema applications. Such applications include classical film projection as well as live event transmissions into cinema theatres. The concept has been successfully proven within the CyberCinema ESPRIT project under the lead of the European Audiovisual Center, Babelsberg, Germany. — The CyberCinema demonstrator has shown the feasibility of electronic film distribution via satellite to cinemas. A demonstration including five cinemas allover Europe has been set up in October 1998 showing outstanding picture quality and verifying the robustness of the DVB-compliant transmission system. — In this paper we will focus on the HDTV codec “Universal Coding System” used within this project and the implementation of DVB compliant in-band signalling using DVB Service Information (SI).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1998-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00297"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1997",
        "conferences": [
          {
            "conference_name": "Proceedings: The SMPTE First Annual Spring Film Conference & Exhibit",
            "conference_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert B. Kisor"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00563"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "The Gamma & Density “Thorough Control System”™ as Used in Post Production",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Y. Neyman",
                    "H. Sisko"
                  ],
                  "abstract": "Although hardware technology has made the film and video post-production industry more creative and has greatly improved the speed at which many job functions are performed, there still exists the “subjective” aspect within a film-to-tape telecine session. The Gamma & Density “Thorough Control System” has had a dramatic positive impact on affecting the degree of such subjectivity.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00567"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "“A Review of the Fuji Super F-Series of Motion Picture Products”",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "K. Noguchi",
                    "K.H. Kishimoto",
                    "K. Makino",
                    "N. Sasaki",
                    "Bruce Berke"
                  ],
                  "abstract": "Fuji began manufacturing motion picture film in Japan in 1934. In 1982, the Academy of Motion Picture Arts and Sciences awarded Fuji an Oscar® statuette for its development of a first of its kind 250ASA color negative film. In 1990, the Academy again recognized Fuji with a Scientific and Engineering Award in recognition of the F-Series of camera negative film stocks. In 1995, Fuji launched the successor to the F-Series, the Super F-Series. It is comprised of five new camera negative stocks ranging from E.I. 64 to 500, a re-engineered color intermediate, and a new generation of color release print stock.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00564"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Bedknobs and Broomsticks: Using a Distressed Work Print as a Color Master Positive",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Scott MacQueen"
                  ],
                  "abstract": "A twenty-five year-old, color-faded, heavily scratched 35mm Eastmancolor positive work print trim was the only existing preprint for one sequence of the restored special edition of Walt Disney Pictures' 1971 feature film Bedknobs and Broomsticks. The objective was to resurrect the degraded color imagery to a 35mm internegative of sufficient integrity so that this sequence could be reasonably integrated with original camera negative. Liquid gate duplication of the master print to a color-corrected internegative yielded an improved element for digital scanning. Electronic image processing permitted further image reconstruction before the data was output as an analog motion picture negative suitable for conventional motion picture laboratory printing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00566"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Optimizing Film-to-Screen Images with Integrated Projection Systems",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glenn Berggren"
                  ],
                  "abstract": "Your 35mm film projection system is neither optimized yet, nor integrated to be optimized! Film quality on the negative is always degraded before it reaches the screen, by two factors. First, the lab processing is a factor, and the projection system is second. The film types have been seriously upgraded in the past 8 years, so a superior release print can be made, but a seriously upgraded projection system has not happened during those 8 years–the film is ahead in the race-lets talk!",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00571"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The Digital Enhancement of High-Resolution Multi-Format Cinema Imagery",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Ostrelich",
                    "Lewis Merritt"
                  ],
                  "abstract": "There seems to be no boundaries on the artistic creativity of the cinematographer. To accommodate this apparent limitless capability, highly versatile equipment is needed to produce the final motion picture master. Until now, the requirement for multiple film sizes and formats has provided a real challenge in the design of film mastering equipment. Image Graphics has recently developed a universal cinema recording system designed with the primary objectives of flexibility, high quality (resolution) and high speed to satisfy the requirements of the industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00568"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "New Techniques for Measurement of On-Screen Projection System Characteristics",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roger Hibbard",
                    "Jack Cashin"
                  ],
                  "abstract": "We are seeing major improvements in the quality of movie presentation. Examples are the larger screens, stadium seating, torus screens and improved auditorium design. The improvements require new levels of performance from lamp-houses, projectors, lenses and screens. As the performance improves, we also need to improve our measurements and measuring techniques.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00570"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Traditional Film Restoration Techniques in a Digital World",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Eaves"
                  ],
                  "abstract": "In our present world of great technological advancements, we are constantly aware of the enormous changes that digital technology has made to our industry. It seems that every week we read how this technology has changed the way that production and post-production in both film and video is accomplished. And frequently, we are treated to the re-release of great movies in their new digitally-restored version. The results achieved are truly amazing but, as awe-inspiring as these results are, the fact is often overlooked that the cost of restoration via digital techniques frequently surpasses the original cost of production. — The use of traditional techniques for restoration of film elements is the methodology of choice for the majority of film producers and distributors. This paper will describe some of the considerations that must be made when assessing the condition of available printing materials, and how this assessment is used to determine the equipment and techniques required for a successful restoration.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00565"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Truetime®: An Alternative Approach to the Marriage of Film and Video",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20First%20Annual%20Spring%20Film%20Conference%20&%20Exhibit/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Luke Freeman"
                  ],
                  "abstract": "Production values for a video derived from a 24Fps film master differ between 50fps and 59.94fps derivations. Normally, the 50fps derivation is speeded up by 4%, producing timing discrepancies for the video content and pitch problems for the audio. The 59.94 derivation contains the motion artifacts associated with the 3:2 pull down process. — This paper explains that if the film material is shot at 25 rather than 24 Fps and a modified pulldown sequence is used, the timing discrepancies and pitch problems are removed from the 50fps derivation and the motion artifacts associated with the pulldown process are reduced in the 59.94 derivation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-03"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00569"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "31st SMPTE Advanced Motion Imaging Conference Technical Papers Program",
            "conference_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/",
            "articles": [
              {
                "article_local_id": "4",
                "article_title": "Crossing the Line: Bridging Traditional and Digital Post Production Processes",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael E. Phillips"
                  ],
                  "abstract": "It has been just over 4 years that a digital non-linear editing system has been creating to work at 24 frames per second. Since that time, digital technology has advanced very rapidly and has allowed a collaborative process to exist. It is the purpose of this paper to review further techniques that exist to further the definition of a “collaborative process”.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00198"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "The Current Limitations of Personal Computers in Replacing Traditional Video Production Equipment",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Hartford"
                  ],
                  "abstract": "Personal computer-based systems have made some inroads into the professional video production arena in recent years, serving primarily as non-linear editing and graphics workstations. However, they have thus far failed to replace single-function legacy equipment, instead functioning in addition to existing products such as video switchers, digital video effects systems, character generators, and audio mixers. The true benefits of the PC in video production will not be realized until the entire production process is integrated into one system. This step will use the economics of the general purpose PC to decrease the cost of video production dramatically, while making the entire process easier to learn and practice. It will also further expand the toolset available to producers by providing a myriad of tools from hundreds of developers, all for one platform. This paper examines the reasons why PC-based systems have failed to make this step thus far, and examines some solutions to these problems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00199"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "NLE System Design Using Mathematically Lossless Motion-JPEG",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alain Legault",
                    "Janet Matey"
                  ],
                  "abstract": "Most professional video applications, including nonlinear editing systems (NLE), digital disk recorders (DDR) and media servers systems, employ the ITU-601 video standard. The uncompressed, digitized 601 video signal contains 20 Mbytes of data per second of video. Storing or retrieving that much data to/from a hard disk in realtime demands a very high-performance system with high bandwidth characteristics throughout the entire system and massive storage devices, leading to a very expensive implementation. Until now, only high-end post-production houses have been able to afford such systems. — In order to reduce system cost, Motion-JPEG compression has been used in many system implementations to reduce data rate and storage requirements for digital video streams. However, the compression process introduces loss of information in the video signal. Video quality is inversely proportional to the compression factor—a higher compression factor leads to lower video quality, with more compression artifacts. Until now, users have had to make the tradeoff of either paying the very high price of uncompressed video systems or accepting the video-quality compromise inherent in affordable systems. — Early in 1996, Matrox introduced a digital video platform called DigiSuite that offers the quality of uncompressed video at a reasonable cost. Using mathematically lossless encoding, DigiSuite performs data reduction on the video image using the entropy encoding part of the M-JPEG standard. Entropy encoding introduces no artifacts or loss of information—the process is MATHEMATICALLY lossless, i.e. the digital binary code of the decoded image is identical to the source image. Users benefit from the data rate and storage space reduction of M-JPEG without the tradeoff of introducing artifacts into the video signal. — This paper describes the theory behind lossless M-JPEG encoding and goes on to examine the practical implementation issues that must be taken into account in system design. All the individual components such as the M-JPEG chip set, the disk controller and the storage technology are examined. As well, a system-level hardware and software architecture that is capable of performing data stream management and data buffering at the necessary speed is described. In addition, a test suite is described that can be used to prove that the compression method is, indeed, lossless.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00200"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "DV Format and IEEE-1394: Higher Quality, Lower Cost Non-Linear Video Editing",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Adam Silver"
                  ],
                  "abstract": "Two new technologies, DV Format and IEEE-1394 (also known as Firewire) are implemented in recently introduced Camcorders and Digital VCR's. This combination of technology opens a new market for PC based non-linear editing products which deliver very high quality video at a much lower cost than current analog capture/compression products. — Bringing DV Format into the PC environment opens a variety of opportunities for compression/decompression of DV data using the PC's host processor and for transporting DV data inside the PC. — The next 2 years will see the introduction of many more DV based and IEEE-1394 based products.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00203"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "A Visual Compositing Syntax for Ancillary Data Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Craig Birkmaier"
                  ],
                  "abstract": "Ancillary data transmission using the MPEG transport layer of the ATSC Digital Television standard can enable a wide range of new services for television broadcasters, and other distribution channels that carry DTV bit streams. This paper analyzes the data broadcast opportunity, and requirements for standards to support the local display of information carried as ancillary data. — Managing the program multiplex to optimize the utilization of MPEG transport packets presents a variety of opportunities and challenges to broadcasters. The paper will examine three types of data that will be carried in the multiplex: programmed; periodic; and opportunistic. Programming opportunities for each data type will be identified and the technical requirements examined. The ability to create local raster representations from ancillary data is a basic requirement for DTV receivers in applications that include: closed captioning for the hearing impaired; emergency messaging; and electronic program guides. A visualization and compositing syntax for ancillary data will be proposed and relationships to other standards such as HTML-based web browsers will be examined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00206"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Unconnected Islands for Video Editing is a Thing of the Past",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Stakutis"
                  ],
                  "abstract": "The non-linear video editing community living with unconnected islands, and either transporting material by sneaker net, or doing without, is unacceptable today. The rewards of connected edit suites are significant, provided the solution is affordable, sustains the needed data rates (as video is using lower compression), and provides the now-important collaborative workgroup environment. — Traditionally, in the non-linear video editing community, artists and other users worked as “islands of automation.” Because the volume of digital video data is so high and needs to be flowed at tremendous rates, typical networking and server solutions are far from adequate. Solutions that deliver the needed performance usually cost upward of a million dollars. — The data world was also once comprised of “islands of automation.” More than 10 years ago, when personal computers made their debut in offices, the 5 1/4“ floppy was the ”networking“ technology of choice, and business interoperability of different machine types wasn't a consideration. — Thanks to companies such as Novell, today virtually every computer in the marketplace is “network ready.” All UNIX machines, WinTel machines, and Macintoshes are delivered with inexpensive 10BaseT hardware and a variety of standard networking software. Connectivity is now “assumed” in the conventional data world. — It is expected that the video community will follow suit. With the availability of high bit rate and inexpensive hardware, and understanding of the value created by networking, will come the connectivity for video-editing applications. — It took the data world some time to appreciate all the tangential benefits of networking. More than just a way to replace the 5 1/4″ floppy, networking in the data world now means centralized backup, security, file sharing, simultaneous editing (Lotus-Notes style), and the universal shared access Internet. Networking in the video world will force a paradigm shift. Artists and video professionals use their non-linear editing in a certain fashion today with products such as Mercury Computer Systems' digital video server. Affordable, high-bit-rate networking will allow them to migrate into a new domain, where they will create higher-quality productions in less time, and with more security and ease, than ever before. — Interconnecting digital video editing workstations has long been a sought-after, but elusive feature due to the bandwidth demands. Recent advances in video technology have actually exacerbated the problem by requiring nearly uncompressed streams, multiple streams, and the need to share data in real-time with many users. Furthermore, numerous external forces such as increased broadcast channels, large cable channels, and of course the Internet, have all increased the need for efficient digital creation tools and the need to quickly “re-purpose” material. — While servers have been a wonderful boon to the data world, their architecture not well suited to the demands of video. When configured to provide adequate processing capability their costs are prohibitive. However, new storage connection technology is poised to have a positive effect on media sharing provided standard software is in place.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00197"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Darcy Antonellis",
                    "Mark Schubin"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00196"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "A Portable Field Editing System for Electronic News Gathering (ENG)",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher Golson",
                    "Kazumasa Yamamura",
                    "Toshiharu Kondo",
                    "Mark McGrath"
                  ],
                  "abstract": "The volume of programming for broadcast television news continues to grow rapidly. Attendant with this growth is increased pressure on the multi-disciplinary team that contributes, on a daily basis, to the creation of this competitive program material. News crews, reporters, journalists, editors, directors, producers, and supporting technical staff—all seek new operating efficiencies that can enhance their creativity and streamline their productivity. — New technologies of disk-based nonlinear editing systems, video servers, and high-speed serial audio/video digital interfaces, are bringing important efficiencies to the broadcast news operation. Bringing together video, audio, data, and text for story creation in a practical desktop journalist workstation is also a powerful addition to the news environment. — Similar efficiencies are sought in the field—for news crews, reporters, journalists, and editors. Portable acquisition systems, accompanied by a portable field editing system can dramatically enhance productivity in the field.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00211"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Cost vs. Quality in ATV Receivers",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "ACATS and ATSC have proposed formats for advanced television which have cost and quality implications for various types of receivers. DemoGraFX has an alternative approach to advanced television, which optimizes a different class of receivers. — The cost and quality issues for each type of advanced television format, on each type of receiver, are explored and analyzed. — Issues which arise are motion analysis, de-interlacing, frame rate conversions, aspect ratio conversions, and colorimetry conversions. For ATV formats which have non-square pixel spacing (as proposed in ACATS SDTV formats), the pixel spacing adjustment is also needed. — Decoding performance, and associated computation, are also an issue. When decoded formats don't match display formats, decoder and encoder tradeoffs have implications in the conversion processing. — These and other issues in receiver quality and cost are examined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00214"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "HDTV Camcorder–And the March to Marketplace Reality",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurence J. Thorpe",
                    "Fumio Nagumo",
                    "Kazuo Ike"
                  ],
                  "abstract": "A complex twelve year development of High Definition Television production standards has vied with consecutive generations of HD program origination equipment. While these attempted to aspire to the full promise of the ever-evolving standards, they were also grappling with a multiplicity of marketplace realities as separately defined by the world's broadcasters and program producers. HDTV program origination continues to be frustrated by unrealistic equipment costs, and a lack of mobile battery-powered HD acquisition systems. The latter is central to the proper exploitation of the significant enhancement to television imagery latent within the technical parameters defined by the latest SMPTE-274 M HDTV production standard. — This paper describes a bold development thrust that sought to simultaneously lower costs and produce a high-performance, highly-compact, HD acquisition system. The technological leap from contemporary HDTV cameras and digital recorders to an all-digital one piece HD camcorder called for the best in engineering innovation, pragmatic design decisions, and a massive commitment to custom-built VLSI. The paper specifically describes the prototype of the 1920 times 1035 (SMPTE 260 M) based camcorder that will make its product debut in late 1997 in Japan. A modified product, based on the later SMPTE 274 M standard (1920 times 1080 format), will follow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00215"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "525-line Progressive Scan Digital Broadcasting System via Satellite",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joji Urano",
                    "Hironao Sakaguchi",
                    "Shin-ichi Tamura"
                  ],
                  "abstract": "This paper describes the development of 525-line progressive scan (525P) digital broadcasting system, which provides cost effective high picture quality service. — 525P is a type of progressive (non-interlaced) scan format and the scan rate is exactly double that of the conventional 525-line interlaced scan (525I). This format has several advantageous features; better picture quality compared with 525I, lower encoder/decoder implementation cost compared with HDTV, high compatibility with 525I. That's why the 525P format enables cost effective high picture quality services especially adequate for consumer use TV. — The 525P digital broadcasting system prototype has been realized conforming to the digital broadcasting standard via communication satellite (CS) in Japan, which uses MPEG-2 video coding technology. For the implementation of 525P MPEG-2 encoder and decoder, Main Profile at High-1440 Level (MP@H14L) instead of Main Profile at Main Level (MP@ML) was used with a slight modification of MPEG-2 MP@ML encoder/decoder for NTSC/PAL service. This is the first implementation of real-time MPEG-2 encoder and IRD (Integrated Receiver Decoder) for 525P. MPEG-2 multiplexer for interfacing with 525P encoder was developed as well. Using this system, we have carried out several transmission experiments via CS and verified technical feasibility of high quality digital broadcasting service at the 525P video bit-rate of 9Mbps or around.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00218"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "High Speed Internet Access Using Cable Modems with Telephone Return",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jonathan Fellows"
                  ],
                  "abstract": "Telephone return cable modem systems provide a way to obtain early experience in the integration of data networks with cable access methods. For many current cable service areas, e.g. those that are small or sparsely populated, telephone return may be a viable long term technology for delivery of high speed data services. This paper summarizes the network design issues and approaches of the first generation of commercially deployed telephone return cable modems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00204"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert B. Kisor"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00195"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Microsoft ActiveMovie: A New Media Architecture",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Amit Chatterjee",
                    "Andrew Maltz"
                  ],
                  "abstract": "The Desktop Revolution in production and postproduction has dramatically changed the way film and television programs are made, simultaneously reducing equipment cost and increasing operator efficiency. The enabling digital innovations by individual companies using standard computing platforms has come at a price - these custom implementations and closed solutions make sharing of media and hardware between applications difficult if not impossible. Microsoft's ActiveMovie” Streaming Media Architecture and Windows Driver Model provide the infrastructure for today's postproduction applications and hardware to truly become interoperable. This paper describes the architecture, supporting technologies, and their application in post production scenarios.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00202"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Issues to be Considered—The Implementation of a Digital Distribution System by the Commercial Broadcast Networks",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brent L. Stranathan"
                  ],
                  "abstract": "The National Commercial Broadcast Networks' program origination and distribution/transmission infrastructures have gone through various technological and operational changes since the inception of the centralized Network to Affiliate interconnect systems were first developed in the 1950's. The Networks now face what is probably the most technologically challenging and far reaching change in their history—the migration to a digital distribution system. This paper will review the various technical, operational and economic/business issues that The Networks will be examining as they develop their digital migration plans. The issues will be reviewed in the context of how the distribution systems currently function and how the features and functions could operate in the digital world.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00207"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Digital Video Servers for the Television Industry Potential Applications/Features to Consider",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert J. Blackburn"
                  ],
                  "abstract": "For the broadcast TV, cable TV, and direct broadcast satellite TV industries, the use of digital video servers to play video from computer disks instead of from tapes provides the advantages of digital fidelity plus computer-based automation and computer networking for content loading, remote control, remote system maintenance, linking multiple servers together, and for Internet/Intranet applications. This talk describes several potential applications for digital video servers including a High Availability Broadcast Center, a Large Scaleable Network Operations Center, Time Zone Delay and Centralized Spot Insertion or Centralized Near-Video-On-Demand. These application examples give meaning to features that should be considered before acquiring a digital video server as a building block in a total automated solution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00208"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Fibre Channel Network Offers Gigabit Speed for Broadcast Industry",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Terry Anderson"
                  ],
                  "abstract": "Demand for digital storage in studio and broadcast facilities has been eclipsed by demand for better network solutions. Fibre Channel has been recognized in the broadcast industry as a key network solution for extending storage access throughout a studio or broadcast facility. It also has emerged as the popular choice for clustering servers. Three critical attributes of the Fibre Channel switching fabric are that it provides simultaneous video and data streaming, video serving applications and an uncompromising quality of service. Comparisons to FDDI, Fast Ethernet and ATM provide a broader context in which to evaluate Fibre Channel as a solution for the network backbone and workstation clusters.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00205"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Mysteries of Digital Video Disk Arrays",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles F. McConathy"
                  ],
                  "abstract": "It is the purpose of this paper to review data storage technology and to reveal some of the mysteries associated with video disk arrays as related to digital video editing and audio applications. Subjects such as embedded servo, thermal recalibration, mode page settings, head technology, UltraSCSI, Fiber Channel, and 10,000 RPM disk drives are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00210"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Worlds Collide: The Integration of “Black Box” Technology into Nonlinear Video Editing Systems",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter R. Challinger"
                  ],
                  "abstract": "There have been various disputes in the past over the relative merits of proprietary hardware versus software only running on standard platforms for post production editing. This paper looks at the strengths of both sides, how these can be merged most effectively and why video effects specific hardware is required for cost effective high performance systems. Some examples of the historical development of effects in editing are given and the trade-offs that occurred in effects capability when nonlinear editors first appeared are discussed. These issues are examined in the context of the merger of two companies and the combination of the respective technologies to create a nonlinear editing system with real-time high-end effects capability.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00201"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Digital HDTV: Why Bits are Not Just Bits",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Poynton"
                  ],
                  "abstract": "In its quest to assimilate other industries, the computer industry has adopted the rallying cry, “Bits are bits!” At face value the expression is tautological, but it is intended to imply that once a signal is digitized it enters the domain of computing. Sadly, the expression has come to imply that the technical parameters of the original domain can be ignored! I will give three examples. • According to “Bits are bits,” the proposal is made by the computer industry that the pixels of an image should be represented and processed independent of each other. However, this notion violates Shannon's sampling theorem: Without a certain degree of interdependence among samples—otherwise known as filtering!—a sequence of samples cannot be accurately reconstructed. • The computer industry represents pixels in RGB components, generally no reference to transfer function, no reference to primary chromaticities, and no reference to white point. Accurate reproduction of color is impossible without knowledge of these parameters, and inaccurate reproduction of color is certainly the norm in computing. • Finally, “Bits are bits” seems to imply that it is desirable to generalize the raster to dimensions of m by n, without allowing specification of any numerical values. In particular, the proposal is made by some participants in the computer industry to adopt an HDTV transmission system that makes no reference to an underlying raster standard. While this is a desirable goal for the design of a software system, it is hardly feasible to design a CCD camera or a plasma display panel without knowledge of the dimensions of the array! — The television industry must take some responsibility for the gap between computer image representation and digital video representation: The television industry has, on many occassions, adopted technical parameters that are antagonistic to computing. Examples from the past include the choice of asymmetrical coding for luma in Rec. 601 instead of the obvious symmetrical coding, and cositing of subsampled chroma instead of the interstitial subsampling that was chosen for JPEG. A very recent example is the choice of non-square pixels in the consumer digital video cassette (DVC) media and its DV interface standard. — A new dichotomy looms on the ATV front. The current ATSC standard calls for luma to be coded according to the Rec. 709 coefficients, instead of the conventional, widely used Rec. 601 coefficients. No compelling scientific study has proven any performance advantage over the Rec. 601 coefficients. However, adopting new coefficients would introduce a huge disadvantage: The Y'CBCR components of a “big” (HDTV) image would be coded differently from the Y'CBCR components of a “small” (standard 525/59.94 or 625/50) image. Introduction of this incompatibility into HDTV will cause trouble not only for computing, but also for video. I urge ACATS, ATSC, SMPTE, and the Grand Alliance to nip this problem in the bud.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00216"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Crystal Image: Bridging the Gap between Cinematography and Digital Image Processing",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marty Ollstein"
                  ],
                  "abstract": "The time-honored traditions of cinematography and the brash new frontiers of digital image processing use different tools, units of measurement and language. When the two disciplines meet in the production of special effects sequences, there is a need for a common ground. Crystal Image software provides a bridge between these worlds by providing an exact emulation of the Tiffen color and diffusion filters to the digital platform. The software uses the language of film to extend the art of cinematography into the digital realm.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00213"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Development of an SMPTE Standard for the Digital Interface between the ATV Transport Multiplexer and the VSB Transmitter",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raymond C. Hauge",
                    "Bernard J. Lechner"
                  ],
                  "abstract": "SMPTE has been asked by the Advanced Television Systems Committee (ATSC) to develop standards for the interfaces between the various subsystems that make up a complete compressed digital television broadcast plant. One of the interfaces is the interface between the output of the studio multiplexer that creates the MPEG-2 compliant ATV transport stream and the input to the VSB broadcast transmitter. In response to the ATSC request, SMPTE has created an Ad Hoc Group to develop this interface standard. This paper will describe the work of this Ad Hoc Group and present a report on its progress.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00212"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Advances in Server Technology",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Bennett"
                  ],
                  "abstract": "Disk-based technology has clearly moved into the main, stream broadcast environment. Stations increasingly choose to make the transition from tape to disk technology. Second generation server technology facilitates this migration, enabling broadcasters to improve operational flexibility and reliability while supporting new revenue opportunities. — First and second generation servers use a similar architecture, but the second generation adds significant capabilities. This paper explains the basic approach and workings of the latest broadcast server architecture, exploring the trade-offs required to develop a reliable, expandable and affordable system Focusing on on-air applications, the paper discusses approaches to distributed server implementations using MPEG compression and modern networking technology, and the impact of architectural choices on future capabilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00209"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "A Report on the Technology Tests of Advanced Video Services – MPEG2",
                "article_url": "https://journal.smpte.org/conferences/31st%20SMPTE%20Advanced%20Motion%20Imaging%20Conference%20Technical%20Papers%20Program/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard A. Mizer"
                  ],
                  "abstract": "This paper will describe the technology testing of Advanced Video Services based on MPEG2 compression technology. — It will summarize the existing service capability provided by encoders and decoders utilizing Main Profile@Main Level operating at bit rates compatible with the existing telecommunications networks, and emerging technologies for cable TV and telco distribution, including MMDS, DBS, HFC, SDV and ADSL, including transport over ATM, and interfaces required for storage in file servers such as SCSI2, FDDI, HIPPI, Fibre Channel and Firewire. These services are provided on both commercial networks such as DirectTV, and trial networks such as Pacific Bell Video Services Multipoint Multichannel Distribution Service network in Southern California. — It will also describe the existing state of the art MPEG2 equipment, which is based on chip sets provided by C-Cube, IBM, and others, including the video/audio multiplexing stage, the compression engine and the network multiplex stage. Board level approaches include VME bus and PCI bus backplanes. Issues such as the use of program streams and transport streams for different applications will be addressed. — The applications for this technology today require near-broadcast quality video and audio, and include entertainment television, distance learning, business conferencing and telemedicine. Other applications include MPEG2 over Inter- and Intra-nets, interactive MPEG, as well as other industrial and government applications, including teleradiology, remote surveillance and readiness training including battle simulation. A discussion of the subjective versus objective evaluation of picture quality for digital video will describe the latest approach of standards bodies called “correlation”, and include, for example, studies done of the impact of compression on the accuracy of teleradiology. — The paper will also address emerging applications for MPEG technology, especially for the entertainment industry's higher quality requirements for MPEG authoring systems, including DVD mastering, content compression for server distribution, remote review and editing and multimedia. The enhancements required for these applications include the utilization of component digital video and audio, 4:2:2 processing (the so-called professional profile), video preprocessing, selectable I, B, P Group of Pictures, and scalability. — Finally, a discussion of MPEG2 technology for Advanced Television formats, such as progressive scan displays and HD Television, such as the processing impact of scalable compression ratios for different exhibition formats.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00217"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "139th SMPTE Technical Conference and Exhibit",
            "conference_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/",
            "articles": [
              {
                "article_local_id": "4",
                "article_title": "Acquisition and Management of Digital Assets for the Transitioning Broadcast Facility",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Beth Rogozinski",
                    "Paul Stevens"
                  ],
                  "abstract": "Television stations and all entertainment industries are becoming more reliant upon digital tools for the acquisition, creation and management of media assets. This trend will continue and rapidly expand within the broadcasting realm as broadcasters around the world begin to transition their facilities to all digital workplaces in preparation for all digital transmission. While the future of “all digital” is still quite some time away for most broadcasters, it is inevitable also, that most, if not all, are in need of digital solutions to replace aging analog equipment. In addition, all broadcasters are concerned with and interested in beginning their transition to digital facilities in order to maintain an edge in this increasingly competitive industry. As broadcasters face the task of upgrading their facilities, they are all concerned with similar questions: How will digital equipment work with existing equipment, both analog and digital, that doesn't have to be replaced yet? How might new digital solutions increase productivity in broadcast stations, thereby cutting costs? How might digital systems help to increase and retain the value of media assets? How will the digital solutions purchased today prepare broadcast stations for the future? This paper addresses the questions facing broadcasters wishing to upgrade their facilities with digital equipment, both from an engineering and logistical perspective, as well as from a financial and business perspective.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00235"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The Future of Online Editing",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephane Blondin",
                    "Sandra Buckingham"
                  ],
                  "abstract": "Traditional linear online rooms have long acknowledged and coveted the nonlinear productivity benefits of real-time material access and versioning, but have been frustrated by the low image quality provided by the existing nonlinear systems. The online editing suites of the future must provide seamless integration into today's post-production facilities. The emerging breed of online, nonlinear, noncompressed editing system now intersects the two technologies to offer the best of past and present.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00237"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "The Three E's of Digital Cinematography",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Rose"
                  ],
                  "abstract": "The term ‘Digital Cinematography’ has very much become the maxim over the past few years for the ‘future’ of the moving image. Hyped, loved and reviled as it is, no one has yet found a satisfactory definition of the phrase. At OpTex, we feel that it depends as much on technique as it does, on either the recording medium or the equipment itself. Our involvement in developing add-on equipment has been very much driven by a philosophy that we like to term, ‘The Three E's of Digital Cinematography’, Engineering, Ergonomics and Enthusiasm.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00234"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "HDTV Production Formats for the New DTV Standard",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Pantuso"
                  ],
                  "abstract": "As the requirement to produce an increasing volume of HDTV-ready programs looms ever-closer on the horizon, the need to establish viable, cost-effective systems to create these programs becomes more important. — This paper analyzes current and proposed production standards in terms of technical adequacy, availability, interchangeability, and cost. Real-world conversion examples are analyzed, particularly with respect to edit master archival quality and compatibility with the receivers being planned by the consumer electronics industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00236"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Digital Video Origination Versus Film Origination: A Comparative Test",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rene Villeneuve"
                  ],
                  "abstract": "With the emergence of new digital video recording formats and the growing quality of video origination equipment, it has become attractive for many producers to consider these technologies in the production of features for television while addressing the possibility of a theatrical film release. — This study attempts to compare, through the subjective evaluation of selected video and film-originated scenes, the various options that are available to the low-budget filmmakers. We tested a range of digital video cameras and digital video recording formats and compared them to film origination which has been a reliable benchmark when it comes to quality theatrical viewing. — This paper describes the production of the test materials and the nature of the comparative evaluation which should help the viewers come to their own conclusions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00233"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "1920 × 1080 Pixel Color Camera with a Progressive Scan Output at 60 FPS",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Glenn",
                    "John W. Marcinka"
                  ],
                  "abstract": "A high definition camera has been developed that produces color images with 1920 times 1080 pixels progressively scanned at 60 frames per second (FPS). The camera uses two recently developed CCD sensors made by Eastman Kodak. One sensor detects luminance detail and is progressively scanned at 30 FPS. The other has color stripe filters and is progressively scanned two lines at a time at 60 frames per second. The second sensor is used to derive color and low resolutions luminance. Because of the progressive scan, the vertical and horizontal resolution is 1000 TV lines per picture height. Motion rendition is excellent. The sensor and processor are programmable so that all of the scan formats that are likely to be used in the near future can be produced by the camera.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00232"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Architecture and Design of a High Definition Television Production Switcher",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward Hobson",
                    "T. Takamori"
                  ],
                  "abstract": "In late 1996, the Federal Communications Commission ruled the United States would migrate to a digital television broadcasting system. The Commission chose the Grand Alliance transmission scheme and left the picture scanning format to the marketplace. High Definition video, at 1920 times 1080 pixels, interlaced scanning, at a nominal 60 Hertz field rate is one format in the infamous Table 3 of the ATSC document and FCC ruling. This picture format is also well on the way to becoming a universal format. — A new series of digital systems, conforming to the interlaced scanning format of SMPTE 274M- 1995 were recently introduced by Sony. This paper deals with the architecture, enabling technologies, and capabilities of a live and post production vision mixer from this family of equipment. — A modern, digital, high definition vision mixer, and associated digital effects and editing equipment, must provide producers, directors, and the artistic and technical staff employing them with similar capabilities as existing standard definition equipment—the visual effects expected by a sophisticated audience. These requirements are detailed in this paper and the vision mixer described is compared to similar standard definition devices. — The capabilities of the switcher resulted in an architecture for crosspoints, mix effects systems, key and video processing, control and external interfaces. Operational and maintenance aspects are also key factors in an architecture and include considerations for size, mass, power consumption and heat loads. Picture size and shape may change but control room and remote broadcast vehicle designs dictate limitations on these specifications. Trade-offs in capability and architecture are enumerated. — The data rates employed in HDTV (more than 5 times the rate of SMPTE 125M and SMPTE 259M) required additional new technologies, including the development of a series of Application Specific Integrated Circuits which perform the same functions employed in a standard definition product but at the higher data rate. These ASICs and their functions are described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00238"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "New Technology Prompts Expansion of the Use of Digital Fiber Optics: Networking for Collaborative Production Efforts",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hal Charnley"
                  ],
                  "abstract": "The world of video is undergoing dramatic change. The advent of complex animation and computer graphic effects in film and television production has sparked a demand among consumers for even more sophisticated programs. Simultaneously, advances in broadcast technology will be making it possible for viewers to receive high-quality HDTV broadcasts and to have access to more channels, and thus more programs than ever before. — To meet viewer demand for increased volume and more complex programming, studios and the production facilities that serve them must begin to work together in new and innovative ways. To meet the challenge of HDTV implementation and the 500-channel future, they must revamp their infrastructures to embrace digital technology. In both instances, they need to partner with manufacturers that understand both teleproduction and telecommunications technology. It is the merger of these two markets that will enable an effective migration to a digital production and broadcast world and make possible a collaborative network of facilities for the creation of advanced programming. — This paper investigates the trends that are impacting the teleproduction world today and makes a practical case for using digital fiber optics in conjunction with currently available technologies to create advanced switched digital networks, based on a common design platform, that will connect studios and production facilities for the purpose of collaborative production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00253"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Distribution and Emission of Multi-Channel Audio Programs, and Implications for Post Production",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Craig Todd"
                  ],
                  "abstract": "Many new digital television emission formats, including DVD, CATV, DBS, and terrestrial television, incorporate the Dolby Digital (AC-3) low bit rate audio coding system. This system is capable of delivering discrete multi-channel audio to the consumer, and it also offers several unique features such as dialogue normalization and dynamic range control. The Dolby Digital is intended for use in emission, which is defined as the final link in the delivery path to the consumer. Many of the features of Dolby Digital are best controlled in the post-production process. A distribution path is required between the output of post production and the input to the final AC-3 emission encoder. While the handling of multi-channel audio is routine in the post production area, the infrastructure needed to distribute multi-channel audio in the broadcast environment is currently lacking. — This paper will describe some of the unique features of Dolby Digital which should be understood and managed by those in post production. The paper also illuminates some of the problem areas in distribution of the completed multi-channel audio program to the actual point of emission to the final consumer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00240"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Digital Audio Post Production for ATV",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomlinson Holman"
                  ],
                  "abstract": "As digital television broadcast comes into being, changes are due in post production. Among the most prominent of these are: increasing use of digital audio recording and distribution, multichannel audio, production information contained within headers so that end user sets can make level more equal among other things, 100 dB dynamic range potential, and the removal of the 75 μs pre-emphasis used in analog broadcast. The impact of each of these factors will be felt in post production with a greater need for multichannel capability, and with new monitoring needs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00241"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "HDTV Post Production: Solutions for Today and Tomorrow",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Spencer"
                  ],
                  "abstract": "With the finalization of High Definition Television (HDTV) standards, one of the immediate tasks for broadcasters, production companies, and media conglomerates around the world is to prepare content for future high definition distribution later this decade. This is creating the need for facilities to have production tools that are able to work interactively with HDTV formats in addition to SMPTE 259M and CCIR-601. This paper documents the current abilities of open industry standard graphics workstations and servers to manipulate images in the proposed HDTV resolutions for editing and visual effects. It also quantifies the size and bandwidth requirements of HD throughout the computer system, the HD input and output options to workstations, and the ability of computer networks and servers to act as the highdefinition distribution system in a production facility. The goal is to demonstrate that computer-based production solutions promise to be the most economical and flexible path to offering HDTV services, and are immediately productive assets for standard-definition and film projects.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00239"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Compressed Video File Transfer for Professional Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Reuter"
                  ],
                  "abstract": "The ability to transfer compressed files in a broadcast facility from one video server to another or from acquisition equipment to video storage devices is a growing demand in the Broadcast industry. Various vendors have proposed a number of different approaches to this requirement. Philips Broadcast Television Systems (Philips BTS) has endorsed the emerging SMPTE standard, Serial Data Transport Interface (SDTI), to transfer compressed files from one device to another. This paper will discuss the various aspects surrounding server to server file transfers and issues related to moving files from one device to another and various aspects of different approaches including compressed serial digital interfaces and Fibre Channel Arbitrated Loop.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00247"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "MPEG Splicing: Tutorial and Proposed SMPTE Standard",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Norm Hurst",
                    "Katie Cornog"
                  ],
                  "abstract": "Commercial insertion, promo insertion, studio routing, camera switching, tape editing—each of these basic operations involves switching video and audio. We want to continue to perform these operations even as we move from using uncompressed video to using MPEG-2 compressed video, but these operations are far from trivial. This paper describes the MPEG bitstream constraints required to facilitate switching—or “splicing”—MPEG bitstreams. It also describes the refinements to these constraints being developed by the SMPTE Working Group on Switching and Synchronization which have led to an emerging SMPTE standard for “Splice Points for MPEG-2 Transport Streams”, which specifies bitstream constraints for both Seamless and Non-Seamless splicing. — It is ironic that while splicing is likely the simplest method of switching between MPEG-2 bitstreams, it is probably the most difficult to understand. This paper intends to alleviate the mystery of splicing by explaining the underlying principles clearly so that this simple yet effective technique may be put into wide use throughout the emerging digital television industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00242"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Comparison of MPEG-2 and M-JPEG Video Coding at Low Bit Rates",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lilla Boroczky",
                    "Agnes Y. Ngai"
                  ],
                  "abstract": "In this paper a comparative analysis of MPEG-2 and Motion-JPEG (M-JPEG) video coding is given. Particularly, the performance of these methods is compared via experiments. At first, the algorithmic differences are discussed. Experimental results are shown for various video sources with different image sizes and frame rates. The bit rate were ranging from 1 Mbits to 8 Mbits/s. The experimental results showed, that MPEG-2 I-only and IP encoding achieve higher picture quality at the same bit rate or equivalent picture quality at a lower bit rate than M-JPEG. This quantitative comparison as well as the subjective picture quality evaluation can trigger the use of MPEG-2 video coding instead of M-JPEG at low bit rates.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00251"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Hybrid Television and Computer Systems",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mike Croll"
                  ],
                  "abstract": "This paper addresses the need to integrate and relate the increasing range of broadcast and computer systems so that they may appear coherent to the domestic audience and can operate together in concert. The current proposals for digital broadcasting using the ATSC system involve a range of acquisition and display formats and resolutions. Digital broadcasting systems currently being installed in Europe will initially use the same line standard as current analogue services but at the 16:9 aspect ratio. Both European and American proposals provide for the delivery of new data services that enhance the television programme and need to be displayed together with it. — DAB (Digital Audio Broadcasting) services are being introduced in Europe that will convey a new range of audio and data services. — Internet is being used widely for data information services which provide ever improving services to a quickly growing international audience.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00249"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Temporally Continuous Evaluation of the Quality of Digitally Coded Sequences",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nagato Narita",
                    "Yukio Sugiura",
                    "Ichiro Yuyama"
                  ],
                  "abstract": "We developed an experimental device suitable for verifying whether assessors can evaluate temporal variations in picture quality subjectively. We also developed a technique suitable for processing opinion scores obtained by means of our device. We showed that this new method could solve some problems associated with the SSCQE method, which has been proposed at the ITU-R meeting, and was, therefore, more effective for evaluating the time-varying quality of television sequences than the SSCQE method.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00245"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Converting Standards in the Digital Future",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Wilson"
                  ],
                  "abstract": "The exciting future of Digital Television is upon us; the beginning of the next millennium promises a large choice of Digital TV Standards to choose from. “Isn't this great?”.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00248"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Reducing Aspect Ratio Aliasing in a Dual 16 × 9/4 × 3 Environment",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Pantuso"
                  ],
                  "abstract": "As more experience is gained producing programs for dual-use, in both 16 times 9 and 4 times 3 aspect-ratio environments, trends are emerging that define the limits of acceptable conversion from the requirement to image and edit separately. This paper will explore real-world experiences with down conversion and up conversion used in actual programs, and offer some tentative solutions to the challenges presented by the often conflicting requirements imposed by the artistic integrity of each standard and the financial realities of the production business. — The general conclusion of the paper is that the ability to produce simultaneous program outputs in both aspect ratios is program-type limited, and is also dependent on the primary delivery aspect ratio with respect to program revenue. Technical quality of real-world converters will are explored, and recommendations made regarding areas for improved performance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00243"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Vertical Resolution",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00256"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Digital Video Microwave Systems for STL and ENG Applications & Test Results",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John B. Payne"
                  ],
                  "abstract": "NAB97, the FCC ruling on deadlines for HDTV, and recent acts by Congress have signaled the dawn of a new era for digital video microwave for broadcast applications including Fixed Point-to-Point (i.e. STL, TSL, ICRS, etc.) and ENG in both the United States and worldwide. — The broadcast industry is being challenged to explore new technologies to enhance their existing systems and is subsequently turning to digital video technology. A wide array of digital products are currently being offered for many aspects of the production system, such as digital cameras, editors, storage devices, and encoders. However, there has been little discussion about converting the STL and ENG microwave links from analog to digital transmission, which are a critical part of the total production system. — This paper presents an overview of how the digital video microwave technology can be applied to STL and ENG systems and discusses the tradeoffs of digital vs. analog video microwave systems. It also presents actual laboratory and field results of digital microwave STL and ENG tests conducted by NUCOMM. — The results show that applying digital video to STL and ENG microwave systems can conserve frequency spectrum and yield superior quality and performance equal to or better than analog systems under both fading and multi-path environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00257"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Film Steers Though Sea of Video Standards",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00260"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Transporting Production/Mastering-Quality Digital Video Signals through the Public Network using SONET/SDH and ATM Technology",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William C. Philipson",
                    "Steven L. Storozum"
                  ],
                  "abstract": "Many video production and post-production organizations have changed over to digital facilities as the advantages of an all-digital plant have become more apparent. Along with this move to digital origination, storage, routing, and editing, the need has arisen for transporting high-quality digital video signals over long distances. Means for transporting uncompressed digital video signals have to date relied upon fiber optic overlay networks, but these networks are limited in transmission distances and require dedication of the fiber to solely video transmission. — This paper describes a method for transporting a variety of high-quality, standards-based digital video signals through the global SONET/SDH public network infrastructure by using cost- effective, flexible ATM technology. The difficulties of creating non-standard SONET/SDH tributaries within concatenated Synchronous Transport Signals are bypassed by using ATM-based multiplexing techniques. This approach greatly simplifies the design of SONET/SDH video terminal equipment, while permitting transmission of lower-speed data channels along with the high-speed video signals along the SONET/SDH backbone.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00258"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Film Scanning for DTV & Beyond",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter R. Swinson"
                  ],
                  "abstract": "The age of Digital television is here now, Standard definition and High Definition. — Film entertainment will form by far the greatest source of material for these transmissions. — The paper explains both the benefits of film sourced material and some of the pitfalls that can occur when considering methods to transfer film images to DTV. — The issues of both Widescreen Films and Widescreen TV are covered as well as the matter of whether to generate a single digital (video) master or provide individual telecine transfers for each standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00259"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Comparative Analysis of Full Bandwidth Versus Compressed HDTV Routing",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Berger"
                  ],
                  "abstract": "Broadcasters are now facing the dilemma of how to transition to digital distribution of HDTV signals. Central to this decision process is the need for modification or adaptation of an existing plant to handle the HDTV signal. This issue is extremely complex because system concepts and equipment designs are still in the formative stages, there is limited availability of hardware, costs are high and the FCC timetable for conversion to DTV is very aggressive. — For many installations a key consideration of the plant design is the possibility of employing an existing central router and the resultant need for use of signal compression. This is a fact of life since most if not all existing routers do not support the full bandwidth data rate required for HDTV. This study compares various routing scenarios in an effort to identify issues involved and determine the benefits and limitations of compressed versus full bandwidth routing configurations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00254"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Resolution Comparison of Digital (NTSC) Television vs. Digital HDTV",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Henry W. Mahler"
                  ],
                  "abstract": "Selection of the source formats and media which are appropriate to a particular television delivery system are central to achieving the desired image quality of a television picture. However, the resolution of the image can never be better than the resolution of the original source material, whether it is digitally generated, imaged electronically, or captured on film. For that reason, CBS has investigated the theoretical and practical limitations resulting from the use of various origination formats for HDTV. — The FCC has approved a system for transmission of HDTV images to the home, which can deliver a 1080 active line, 30 MHz bandwidth signal, with the horizontal resolution capability of 873 TVL/PH. Television images produced by HDTV cameras, and 35mm film will produce the full horizontal and vertical resolution that the standard is capable of. — However, since it will be necessary to upconvert 525 line images during the transition period, CBS has analyzed the resolution limitations of the proposed use of widescreen, 525 line sources. This analysis clearly demonstrates the significant reduction of horizontal resolution of the 16:9 sources as compared to a standard 4:3 source.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00255"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Practical Application of Objective Picture Quality Measurements",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David K. Fibush"
                  ],
                  "abstract": "Increasing use of compressed video methods in the generation and distribution of television programs has led to a requirement for objective picture quality measurement methods. Although traditional, indirect, signal quality measurements are still required for evaluation of the uncompressed part of the system, they are not adequate for evaluation of the compression-decompression process. Subjective testing methods are complex, time consuming and only applicable for development purposes. They do not lend themselves to operational monitoring, production line testing or trouble shooting. Considering the variety of video compression methods and growing ease of data interconnection, measurement of the resulting video quality must not be limited to a particular compression system. This paper describes the feature-extraction and picture-differencing objective picture quality measurement methods with reference to on-going research developments. Emphasis is placed on application of the human visual system model to picture-differencing as the preferred objective method. System requirements for application of the model are described in conjunction with a practical implementation of a measurement set.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00244"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Building Tomorrow's DTV Facility Today: A Real World Case Study",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lionel Hightower"
                  ],
                  "abstract": "Broadcasters renovating old facilities or building new facilities today face a daunting number of unknowns. There seem to be more questions and unknowns than answers. Will the facility provide “pass-through” capability of the HDTV compressed network signal? Will the station provide multicasting on a full or part time basis? If multicasting is desired, how many channels and at what quality level? How will the station cope with multichannel distribution and master control operations? — This paper will present a case study of two television stations currently undergoing major renovations that are being designed with HDTV pass-through and multicasting in mind. Approaches to floor plans, monitoring, master control, signal distribution, and production will be presented. The focus of the discussion will be to highlight design considerations that provide for a facility that is as “future proofed” as possible. — The case study will focus on two network affiliate middle market stations that cannot defer major technical renovations for a variety of business and technical reasons. Without the luxury of waiting for better definition of the broadcast landscape in the next decade, these stations will incorporate designs that acknowledge that change and refocusing will occur in the next few years. — This paper's goal is to bring into sharp focus the practical and implementable measures that broadcasters can use today to ready their facilities for the transition to DTV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00246"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Super 35, is it Super 35?",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tak Miyagishima"
                  ],
                  "abstract": "Questions which might have been lingering regarding the question “Super 35, Is It Super 35?” are discussed. — The era of simulcasting of both 4times3 (1.33:1) and 16times9 (HDTV, ATV, etc) and how best to prepare for this is now. For the producers and their production companies there are many questions which require answers so that intelligent decisions can be made. — This paper presents a better understanding of the available negative area for 4 perf, 3 perf and Super 16 for the future in preparation for both 4times3 and 16times9.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00261"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Design and Implementation of the ATSC Demonstration of HDTV at NAB'97",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Graham Jones"
                  ],
                  "abstract": "At NAB'97 the Advanced Television Systems Committee (ATSC) demonstrated high definition television (HDTV) and data broadcasting using the ATSC digital TV standard. The demonstration featured over-the-air broadcasts from a local Las Vegas television station, with program distribution from the model HDTV station in Washington, D.C. to Las Vegas. — This paper describes the design and implementation of the demonstration, including the main constraints and issues affecting the system architecture and equipment. Also mentioned are some of the problems encountered and how they were overcome. The paper concludes with the lessons learned from the demonstration, and how HDTV systems in the future may be improved using new techniques and equipment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00252"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "An Open Model for Audio Elementary Stream Encoding in a DTV Distribution Chain",
                "article_url": "https://journal.smpte.org/conferences/139th%20SMPTE%20Technical%20Conference%20and%20Exhibit/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kent Terry",
                    "Craig Todd"
                  ],
                  "abstract": "This paper addresses issues of audio distribution for modern DTV systems focusing on digital broadcast systems. In particular a model is described for handling audio and video elementary streams in existing distribution networks. The model supports new system architectures that allow audio and video coding to take place at many points in the distribution chain. The model covers both physical and logical interface formats, synchronization with associated video signals, and carriage of metadata associated with the audio. The model demonstrates that many audio features of new digital delivery formats can be exploited by existing broadcast systems with minimal additional equipment investment. The model makes use of existing AES and SMPTE standards, however new standards and recommended practices to support the open model may be desired by the industry. Specific recommendations are discussed. In addition, examples of systems applying the model to DTV broadcast facilities are described, including examples of products that implement the audio coding function using the model.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1997-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00250"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1996",
        "conferences": [
          {
            "conference_name": "138th SMPTE Technical Conference Technical Papers Program",
            "conference_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/",
            "articles": [
              {
                "article_local_id": "4",
                "article_title": "Contrast, Color & Light in Film and Video Projection",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glenn M. Berggren"
                  ],
                  "abstract": "This technical paper is to further explore areas of immediate improvement of the image on the “big” screen. In this case, “Contrast, Color & Light”. In addition, a transition, or crossover of these three prime factors between film projection factors, and video projection factors will be summarized. These three factors are included in a single SMPTE document, as each is intertwined with the next. For instance contrast is directly involved with color saturation, and light level is directly involved in contrast.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00096"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "An Engineering Approach to Consistent Images: Control of Video and Film Image Quality in TV Production",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fred Benedikt",
                    "David F.E. Corley",
                    "Robert Ross"
                  ],
                  "abstract": "Engineers, video operators, colorists and producers, all share the goal of excellence in television image quality. This paper explores the reasons why some popular and widely used techniques to standardize video and film quality have met with mixed success. A practicable solution is proposed. — Previous efforts have, by and large, lacked the precision to ensure consistent high quality images, particularly in regard to tonal range and color. The new system under discussion, while providing production teams with infinite freedom for artistic expression, controls the technical aspects of image quality from camera set-up through the post production process. — Using familiar waveform monitoring techniques, the system is comprised of two elements: (a) Optical Signal Generators (OSGs) precision test targets, and (b) a unique portable illuminator. — The system, now in day-to-day use in network engineering and studio operations, can provide similar benefits to the production community. A major advantage of using this proven engineering tool through all stages of production is that engineers, operators and production personnel can now all speak a common language. — The system benefits film production and scanner/telecine setup. Ongoing tests with major film transfer houses are also discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00097"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The Lost History of Film Formats",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniel J. Sherlock"
                  ],
                  "abstract": "Many stories of the development of some of the various film formats have acquired the status of “legend” which consists of a mixture of truth and fantasy. The development of some of the most famous film formats actually came about as a result of developments in other fields, or in adaptations of other ideas. This paper will present an overview of how this evolution took place for several formats, and will clarify several missing pieces of the lost history of film formats.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00098"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Post Production Synergy of Video and Film with Archival Quality",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Ostrelich",
                    "Lewis Merritt"
                  ],
                  "abstract": "The legacy of humankind is represented by how well we have documented our past achievements and how well they have been preserved. The creative efforts of computer generated cinematography is at risk of deterioration if archival techniques are not applied. A unique technological development has now made it possible to record high resolution cinema imagery directly on archival black and white silver halide film in the post production process as separations for a red, green and blue composite. The application of a high speed electron beam recorder as developed by Image Graphics will create on high resolution silver halide film a permanent archival master interpositive. Motion picture magic will occur when each frame of the 72 black and whites are recorded for one (1) second of imagery. In addition, the versatility of format is almost boundless and the same high resolution can be applied to all motion picture formats including 70mm. The larger venues in particular can take advantage of this technique for a truly spectacular presentation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00099"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Implementing Server-Based Systems in the Broadcast Environment",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lionel Hightower"
                  ],
                  "abstract": "This presentation will focus on the practical considerations of implementing a server in a broadcast facility. Beyond the selection process of the hardware and software involved, a successful installation and operation of a server-based solution involves a number of factors to be taken into consideration. A discussion of these factors and a real-world case study will be presented as illustration. — Broadcasters moving into the server-based production and playback arena also need to be cognizant of the impact a server will have on the daily operation of their facility. Usually there is an impact on the way work is accomplished, primarily to take advantage of the new capabilities that a disk-based server offers to the broadcast facility. A reevaluation of job functions and work flow is usually an integral part of the planning process prior to a server implementation. This presentation will offer a framework for this process, as well as offering a case study for examination.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00104"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Bitstream Transcoding in the Studio",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bhavesh Bhatt",
                    "Christopher Ward"
                  ],
                  "abstract": "One of the benefits of carrying video in the studio as compressed bitstreams is the great flexibility in trading off various compression parameters to optimize the bitstream for the task at hand, For example, when live switching is required, we may require frequent I frames and thus a high bit rate, but when the bit rate must be low, as when distributing video by satellite, the I-frame density must be reduced. Thus there is a need for studio devices that perform this bitstream transcoding. This paper will examine the requirements for bit rate transcoding and possible cost/performance enhancements that may be achieved in such devices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00106"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Controlling the Virtual Broadcast Studio",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Guzik"
                  ],
                  "abstract": "The shift from broadcasting video stored on tapes to entirely digital video stored on high speed servers allows for a dramatic change in the nature of controlling studio operations. The architecture of the studio shifts from a web of directly connected mechanical devices to a community of computers and peripherals that are linked together by a high speed wide area network. The job of managing studio operations becomes one of controlling these networked resources which enables the creation of a “virtual” studio where individuals can control the entire broadcast process from geographically independent locations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00107"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "A New Approach to Transporting Program Content",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Donaldson",
                    "Fred Huffman"
                  ],
                  "abstract": "The distribution of program content to broadcasters, cable headends, satellite uplink sites and between production studios is a high-volume and cumbersome process requiring immense resources. Today, content distribution is largely conducted via satellite circuits and physical tape. In certain cases, the element of time becomes important enough that physical movement of videotape is not even considered an option. Technological advances in the development of lower-cost, higher-powered computing and digital processing devices are finding wider use in the creation and delivery of programming. With server-based (digital) content storage, delivery becomes a matter of moving bits; however, digital program content transport requires payload bit rates from 20 Mbps to 270 Mbps. Existing electronic, network-based content delivery systems are limited in capacity, signal performance and flexibility. Leveraging advanced terrestrial digital networks holds the promise of removing these limitations. This paper will describe the development and envisioned uses of a unique Network Interface Device (NID) that is expected to make content transport via advanced common carrier (ATM and SONET/SDH) communications networks as easy as making phone calls.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00108"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Thorough Control System™: A Method of Color-Accurate and Contrast Consistent Film Transfer to Video Dailies",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Y. Neyman",
                    "S. Riviere",
                    "H. Sisko"
                  ],
                  "abstract": "The “Thorough Control System”™, from Gamma & Density Co., establishes a method to help cinematographers arrive at the “look” they desire during a film-to-tape transfer session and maintaining artistic and technical control over their images. The system begins on the set and establishes standards of communication with the telecine colorist in the film-to-tape transfer process. Now, instead of subjective and debatable opinions regarding images, the cameraman and telecine colorists are speaking a common language. — The key element of the system, the Gamma=lC Cinematographer's Control Chart, has one distinguished feature that sets this chart aside from any other charts: the idea of connecting brightness of the scene with scientifically calculated IRE unit equivalents printed right on each corresponding gray field. This chart creates a proper connection between the brightness of the scene and luminance of the electronically converted film signal. With the use of the system, the telecine colorist is able to transfer dailies with accurate and consistent contrast, color, and tone renditions. This continuity in dailies takes the guesswork out of the transfer set-up process.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00111"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "The Development of a 1920×1080 Pixel Color CCD Camera Progressively Scanned at 60 Frames Per Second",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Glenn",
                    "John W. Marcinka"
                  ],
                  "abstract": "A progressively-scanned video camera is under development using two 1920×1080 CCD sensors (made by Eastman Kodak) with square pixels in a 16:9 aspect ratio. One sensor does not have color filters and the other has color stripe filters. Detail luminance is derived from one sensor; color and low-resolution luminance is derived from the other. The camera output is progressively scanned at 60 frames per second. — If digitized, the output bit rate would be 2.4 gigabits per second. Consequently, subband coding will be used to compress the output to a bit stream that can be recorded on a D-1 or D-5 digital video recorder and still have enough “head room” for post-production processing. This paper will report on the status of the camera development and describe the options for providing good motion rendition without interlace artifacts by using progressive scan.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00095"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas J. Bentsen"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00093"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Media Pool - Flexible Video Server Design for Television Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charlie Bernstein"
                  ],
                  "abstract": "It appears to be an accepted fact that disk based video storage systems are viable solutions for broadcasters to store and play video in their facilities. One of the more accepted disk based video products in the broadcast facility is the video server. There are various approaches and technologies that manufacturers can use to build servers. All of these design decisions and trade-offs contribute to various video server architectures to address the task of delivering program content and commercials. The Media Pool video server offers a unique architecture and flexibility that leverages disk bandwidth and system modularity to provide a system capable of multiple full bandwidth CCIR 601 streams, system scalability, and standard industry interfaces, protocols to integrate the system into your facility. — A video server is made up of various sub-systems to allow the storage and retrieval of video and audio to and from hard disk in real time. The architecture of each of those sub-systems and the interrelationship between them have a major impact on the performance of the system in terms of system responsiveness, bandwidth capabilities, and system scalability. In addition, disk array configurations, system timing, internal data transport, data buffering schemes, and disk access algorithms will affect system operation. Providing separate sub-systems that focus on specific tasks allows for increased system performance and more flexible operation. — The Media Pool video server from Philips Broadcast Television Systems Company includes a Storage Sub-System, Input/Output Sub-System, a Video Transfer Sub-System, and a Control Sub-System. The Storage Sub-System is responsible for reading and writing data to and from hard disk drives in real time, perform disk synchronization, and data buffering. The I/O Sub-System (I/O) provides all of the connections to a broadcast facility, similar to the connections found on a Video Tape Recorder. The Video Transfer Sub-System takes care of bandwidth management from one or more storage arrays to one or more I/Os. The Control Sub-System allows for system monitoring, database administration, simultaneous multi-user access, and the support for integrated applications. — Other variables affect the performance of the system. These include system compression techniques, data striping, system bandwidth, and reliability features. — All of these topics and more will be covered in this paper in detail to describe a very effective approach to streaming real-time video from disk based storage to multiple channels in a broadcast facility.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00101"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Video Servers: “Shared Storage” for Cost Effective Real-time Access",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Todd Roth"
                  ],
                  "abstract": "The architecture used in defining a video server has been traditionally based upon the hierarchical storage model of a computer network. This model was typically specified as independent workstations with local storage connected via a high performance network to a more powerful server configured with a larger bank of remote storage. While supporting a large number of workstations or channels, this approach suffered the drawback of high costs and limited real-time availability to media. The channels are only able to offer realtime access to media on local storage (availability to media on the remote storage being limited by availability of the network), while incurring the cost of the server computer as well as the additional overhead of having material stored in multiple locations. — The shared storage approach to building a video server is a result on a different way of looking at bandwidth. This approach starts by defining the bandwidth of a single drive to be the maximum video channel data rate, and the bandwidth to the storage interface to determine the amount of channels. The shared storage video disk recorder model typically involves a high performance, real time storage interface such as Small Computer System Interface (SCSI) and a lower performance inter-channel synchronization/communication mechanism. The model for this is the multi-channel video disk recorder where each channel acts as an independent device with dedicated storage bandwidth. By virtualizing to storage a well designed system allows the total number of channels to be equal to the storage bandwidth divided by the maximum channel bandwidth. — With the advent of combined of advanced storage platforms such as SSA and Fibre Channel (FC), integrating support for multiple initiators (VDR channels) and tarets (storage devices), the topology for an advanced multi-channel “centralized media / distributed access” video server can be realized. FC with the advantage of its diverse supported topologies, will lead to a radical change in the modeling of future video distribution systems. Fibre channel both increases network bandwidth to 100 MB/sec (200 in the future) and supports both fabric, point-to-point, and arbitrated loop interconnections. The immediate benefit is a resulting five fold increase in storage bandwidth by moving from SCSI (fast/wide) to fiber channel arbitrated loop (FC-AL) and the corresponding increase in channel capacity. A 30 channel VDR in itself is a major breakthrough in product capability, while the increase in supported devices to 127 alleviates the total storage restriction. This combined with a clever implementation of RAID (intrinsically supported under FC-AL) eliminates the need for an external RAID controller. — The evolution of disk drives from being simple devices on an independent “storage-only” bus, to being self sufficient targets on an advanced multi-purpose network marks the start of a new paradigm in the design of distributed computing systems. Understanding and incorporating this new design approach into multi-channel VDR systems will pave the way toward the goal of an integrated digital broadcast environment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00102"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Servers Expectations Versus Reality",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter A. Dare"
                  ],
                  "abstract": "Over the past four to five years there has been a great deal of interest shown by the Broadcasters in implementing file servers in their operations, with the hope that with such implementation the use of video tape would be dramatically reduced and in some cases eliminated. The enabling technology that made the use of file servers a practicality is video compression. In many cases, the attractiveness of a file server has preceded the thought process of whether or not the system will work and what limitations the system may have. The expectation of many have not been able to be met in reality, the notion that a computer file server can be utilized in the video world has led to many misadventures in the world of video file servers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00100"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Improvement of Motion Judder on Converted Images by Telecine at the TV Station",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hajime Sonehara",
                    "Yuji Nojiri",
                    "Kazuhisa Iguchi",
                    "Yukio Sugiura",
                    "Hiroshi Hirabayashi"
                  ],
                  "abstract": "Video images converted from films show unnatural reproduction of movement. To correct this, it is necessary to utilize a motion compensation technique which has already been employed for television standards conversion. We modified an existing high-definition television (HDTV) standards converter[1] by adding the necessary functions for motion-compensated film-to-video conversion. To test the practicality of the modified converter, we detected motion vectors on it by using the video signals of images already converted from film by a telecine. Then we interpolated the images using the detected motion vectors to compensate for movement. The result was less unnatural movement and better quality moving images with respect to film-to-video conversion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00094"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "A Common Information Structure for Broadcast Applications",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jerry Boetje",
                    "David Collier"
                  ],
                  "abstract": "This paper defines an integrated data structure supporting the management of events, material, media, and playback resources. The structure supports any number of levels of abstraction for dealing with the complexities of modern broadcast, editing, and newsroom applications. The structure separates the compositional aspects of broadcast operations (the pieces that make up a program or story) from the representational aspects (the material that manifests the specified compositional pieces). As such, it differs significantly from other industry attempts to provide a unified data structure which do not separate the programmatic intent from the actual material which implements that intent. The data structure is a simple, two-level information structure where the levels are similar to each other, creating a recursive structure for operating within the commonly accepted abstractions of the industry such as rundown, event, story, program, pod, schedule, and channel as well as new abstractions that meet the needs of an increasingly complex industry. Sequencing constraints may be applied to elements in a time-independent manner. In addition, this two-level recursive structure is independently applied to both the compositional and representational aspects, supporting a rich expressiveness for planning, operating, and reporting the actions of a complete broadcast operation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00120"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "PC-Based Open Architecture Standards: An Overview",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alain Legault",
                    "Janet Matey"
                  ],
                  "abstract": "Hardware and software enabling technologies are now firmly in place for the migration to economical PC-based digital video solutions in many areas of the professional video industry. The move from “black boxes” to PC-based open systems is well underway. It began in the late 80's with nonlinear editing systems, and now PCs are becoming ubiquitous in all segments of the video industry from content creation, through post-production, to broadcast delivery. — There are many benefits inherent in using PC-based technologies in video system designs. The widespread use of PCs in other applications makes them cost-effective. They offer significantly smaller system size and power requirements than traditional ‘dedicated-box’ architectures. In addition, intelligent control over the entire video application is provided by the computer. Perhaps the greatest PC benefit is modularity and multi-vendor interoperability of hardware and software through open standards. — This paper provides an overview of some of the important enabling technologies for PC-based open architecture in professional video applications including PCI-bus, Movie-2-bus, Advanced ASIC technology and IEEE 1394 on the hardware front; and Windows NT, ActiveMovie and OpenDML software extensions on the software side. It directs the reader to sites on the World Wide Web where further information on these topics can be obtained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00122"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Developing New Program Production Techniques Using the “Virtual Set” and the Motion Capture System at NHK",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yoshikazu Taoda",
                    "Seiji Kunishige",
                    "Toshiyuki Sakamoto",
                    "Akira Suzuki"
                  ],
                  "abstract": "The practical usage of the virtual set and the motion capture system have been of interest to numerous broadcasters. The combination of these systems is expected to be an attractive tool for realizing a diverse new type of content for television broadcast programs. — Utilizing the latest computer technologies, we at NHK have recently developed a real-time computer graphics production system which combines our “virtual set” and motion capture system. The virtual set creates three dimensional computer images which are synchronized with camera motion or zoom. These three dimensional images can be composited into live video images. The motion capture system maps actual real-time human body motion onto a computer generated human character using data collected from magnetic sensors attached to the body. — We describe our recent works in various broadcast program productions such as the 1995 Japanese House of Counselors Election Coverage and the NHK special series TV programs and discuss solutions for the various problems regarding hardware and software systems and real-time three dimensional production methods. We also discuss what new talents and skills for these new types of productions need to be fostered.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00125"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Methods for Evaluation of Digital Television Picture Quality",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Y. Zou",
                    "Philip J. Corriveau"
                  ],
                  "abstract": "With the emergence and proliferation of digital video compression in television systems, there is an increasing requirement for effective methods to evaluate picture quality. In this paper, we describe traditional and novel objective and subjective test methods. We review standard methods to subjectively evaluate picture quality, outline their limitations and suggest ways to change these subjective methods. In addition, we also discuss research into objective methods that employs perception-based models with easily measurable parameters that could give a high degree of correlation with subjective evaluation methods. Finally, we draw some conclusions about the types of research needed to further the development of methods for picture quality evaluation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00110"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "A Studio Compression Format for HDTV Applications",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mahesh Balakrishnan",
                    "Kiran Challapali",
                    "Hayder Radha"
                  ],
                  "abstract": "This paper presents a video compression format for HDTV video to be used in studio applications. Digital HDTV signals need to be compressed in order to be routed or stored within a studio. The bitrates targeted support the use of viable networking technologies such as SMPTE-259 and OC-3. The requirements of a studio are considered in the choice of the format. These requirements include excellent picture quality, good quality even in the presence of cascaded coding, adequate sampling of the chroma signal, support for studio operations such as chroma-keying, and frame or field accurate editing. We will also examine techniques for switching between highly compressed video signals, a requirement in the studio, both for production purposes and for transitioning between programs or commercials.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "HDTV",
                      "studio",
                      "compression",
                      "splicing",
                      "switching",
                      "editing",
                      "MPEG",
                      "422 profile",
                      "cascaded",
                      "multi-generation",
                      "ATV"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00105"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Using Intelligent Nodes and Fiber Optics to Control the Next Generation of Digital Television (DTV) Transmitters",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark A. Aitken",
                    "Gerry Wawrzeniak"
                  ],
                  "abstract": "When faced with the fact that the requirements for transmitting the Grand Alliance DTV signal are different from that of today's standard, many opportunities for improving the “State of the Art” exist. COMARK has taken such an opportunity to design a transmitter uniquely matched to the new standard, as well as other requirements broadcasters have requested.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00109"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Distributed Digital Post-Production",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Christopher C. Woollard"
                  ],
                  "abstract": "It is now possible to use powerful general purpose computer architectures to support post production of both video and multimedia projects. By devising a suitable portable software architecture and using high speed networking in an appropriate manner, a system has been constructed where editors are no longer tied to a specific location. New types of production, such as multi threaded interactive video, are supported. Editors may also work remotely where very high speed network connection is not currently provided. An object oriented database is used for the comprehensive cataloguing of material and to support automatic audio/video object migration and replication.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00113"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Twelve Bit Acquisition, the Next Step in Digital Broadcast Cameras",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jan van Rooy",
                    "Rob Voet"
                  ],
                  "abstract": "CCD image sensors are capable of delivering at least 600% of linear video to the signal processing. This headroom is needed to reproduce large scene contrasts in a convincing way on displays not capable to handle these large contrasts. — Today's cameras have 10 bit A/D conversion in the video path. This calls for some form of nonlinear analog processing like (pre-)gamma or (pre-)knee to handle these 600% signals. This weakens the well known arguments of better accuracy and stability for these digital cameras: non-linear circuits like knee, gamma and whiteshading multipliers are not the most accurate and stable analog circuits. — The move to 12 bit A/D conversion in the camera allows digital videoprocessing with sufficient dynamic range, and all non-linear processing in the digital signal path. — This also opens the way to reconsider processing, given the new possibilities of the digital domain. Examples will be given in the paper. Some items that will be addressed are: dynamic pixel correction, automatic skin contours and a new digital highlight compression with improved color fidelity. — The architecture of a 12 bit camera, the Philips BTS LDK20P will be explained in the paper, together with the algorithms used.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00112"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Database Applications for Server-Centered News Production",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stevan Vigneaux"
                  ],
                  "abstract": "A completely integrated television news production system, which produces video, audio, and text for news programs will require comprehensive and flexible database management tools. The purpose of this paper is to examine the various needs for database management, describe a potential set of features, and define the operational procedures likely to be encountered in a server-centered production system complete with robotic near-line storage. — The paper will examine issues surrounding the use of multiple separate databases and how they are linked and kept synchronized. Database redundancy and administration will be reviewed along with an analysis of the key responsibilities for the database administrator/librarian. The paper will consider the major elements of database customization on a per-site basis.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00119"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "CCIR 601, Future File Image or the Last Universal Video Standard?",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Owen"
                  ],
                  "abstract": "The fundamental nature of television standards has changed little in the first 60 years of broadcasting. The elegant solutions designed in the research laboratories of the twenties and thirties still endure to this day providing hundreds of millions of viewers with good images on economical home screens and programme makers with economical solutions to acquisition an production. Whilst two of the original 405,525, 625, and 819 line scanning standards have since fallen by the wayside, 525 and 625 are still going strong and are set to be with us for at least the next twenty years (so hopes the author and many millions of others who have recently bought new home receivers !). The ingenious aspect of those early standards was to incorporate a form of image compression which traded off spatial resolution for temporal resolution on moving scenes. This trick of using 2:1 interlace for the line scan / field scan relationship made the home receiver and studio camera not only technologically possible but also economised on channel bandwidth and in one step eliminated large area flicker and doubled the temporal resolution compared to the 24 frames per second of the cinema.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00118"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Surviving in the Format Jungle",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Wheeler"
                  ],
                  "abstract": "This year is the 40th anniversary of the Ampex Quadraplex videotape recorder introduced in 1956. The quad format dominated for over 20 years, until it was finally replaced by the helical format. Now, thousands of Quad tapes are sitting on archive shelves, but only a few quad machines exist in a few special facilities. — Since the helical videotape recorder was first introduced in 1962, there have been an average of about two new videotape formats per year. About half of these obtained some degree of popularity and half ended up on the format floor. This abundance of old tape formats is a major problem for anyone with old videotapes with no machines to play them on. As a member of the engineering team that developed the Ampex VR-660 in 1962 and several other Ampex videotape recorders since then, I have closely followed the development of videotape formats. A chart of about 40 of the more popular videotape formats is presented. — The problem of equipment obsolescence is a major problem and is magnified at a large Archive, like the Library of Congress. Recently, the Library of Congress held hearings at three cities in the U.S., at which they heard from national archives, regional archives, production studios, broadcasters, educators, and technology experts on the topic of “The current status of American Television and Video preservation”. At these hearings, several people voiced their concern about the problem of dealing with the continual birth and death cycle of videotape formats. — SMPTE Study Group V16.09 “User Requirements for Automated Storage and Retrieval” was formed in December, and members have expressed their concern about the format problem and that something should be done about it. Possibly, this SMPTE Group could work with archivists to specify a universal archival format.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00116"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Automated Video Indexing for On-Demand Retrieval from Very Large Video Libraries",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "H. D. Wactlar",
                    "A. G. Hauptmann",
                    "M. A. Smith",
                    "K. V. Pendyala",
                    "D. Garlington"
                  ],
                  "abstract": "The Informedia Digital Video Library project is implementing full content search and retrieval from digital video, audio and text libraries. This is accomplished through the utilization of integrated speech, image and language understanding technologies for their automated creation and exploration. Image processing analyzes scenes, speech processing transcribes the audio signal, and natural language processing determines word relevance. Together, these generate a meaningful index into the video content. Segment breaks produced by image processing are examined along with the boundaries identified by the natural language processing of the transcript to partition the video library into sets of segments, or “video paragraphs”. Automating these techniques into a unified collaborative system enables us to include and search through vast amounts of video data in the library.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00103"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "High Speed Data Recording: Digital VTRs Find New Applications",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Krooss",
                    "Philip Livingston",
                    "Stephen Mahrer"
                  ],
                  "abstract": "Entertainment production, be it cinema, television or even “game” software is turning increasingly to computer generated or manipulated information. Computer processing and digital manipulation has permitted the creation of images otherwise impossible, the production of effects not otherwise practical, and correction of innumerable image defects large and small. Given this combination of voluminous data and expensive hardware, the industry faced a dilemma: How to “move” jobs in and out of a facility quickly so the equipment could be made available to other clients and projects. — Existing small format data recorders generally have proven unsatisfactory for these purposes due to the limited data rates and media size. Current digital videotape recorders are now capable of data rates well in excess of 200 Mbps (25 MBps). Unfortunately, some recorders incorporate data compression rendering them only suitable for traditional video. Other video formats have been customized and re-purposed for data recording, but these machines are no longer applicable for video recording. — As the boundaries between the computer and video worlds blur, users need multipurpose solutions for both fast data storage of non-rasterized image information and high quality conventional video storage. Full bit rate uncompressed digital video recorders can provide the desired performance capabilities for both video and high performance data recording, allowing dual purpose use of the same transport and cassettes. — Panasonic developed the D-5 (uncompressed 10 bit ITU-R601) VTR format for high-end video post production, and it has met with wide acceptance. The Viewgraphics (Mountain View CA) “Dataview” is a VME interface device developed to allow large data files to be recorded on unmodified D-5 VTRs and to allow video to be input as data into platforms like the Silicon Graphics Onyx and Challenge. This paper describes the D-5 format, the Viewgraphics Dataview adaptor, and data recording on videotape.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00114"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "Contemporary Techniques for Digital Compositing in Motion Pictures",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Kanfer"
                  ],
                  "abstract": "In this paper, I will discuss my experiences as Digital Composite Supervisor for Digital Domain on the motion picture, Apollo 13. During the production of Apollo 13, it was my responsibility to maintain the look of the principal photography, practical effects elements, and computer generated (CG) elements throughout the digital process. Much of our work involved studying all available NASA footage. Everything was re-created from scratch. Not a single frame of NASA motion picture footage was used in our composites. We analyzed various phenomena that occurred in the NASA films, and made our work match it as closely as possible. Motion controlled model photography of the spacecraft was integrated with live action photography, digital paintings, and practical effects. Computer generated elements such as ice, condensation gas, vapor, engine blast, explosions and debris were synthetically created to complete the illusion. Camera shake was added to the shots using a special program that maintained natural motion blur between frames. The resulting composites had the look and feel of the NASA documentary films that we all remember. Yet, the superior image quality, unique camera angles, and continuity of lighting gave our footage the added drama necessary to re-create some of the most exciting and harrowing moments of the flight of Apollo 13.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00135"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Second Generation HDTV Switcher",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Vince Harradine",
                    "Alan Turner"
                  ],
                  "abstract": "High definition television systems were first shown at IBC, Brighton, UK in the early eighties but have since had only limited impact in specialist areas due to the size, weight and consequential cost of high definition processing, storage and transmission. — In Japan today at least 12 hours of high definition material are broadcast per day to more than 1 million receivers using a compression technology known as multiple sub-nyquist encoding or MUSE. — There is now a growing demand with Japanese broadcasters and programme producers to capture their original material using high definition systems. — Sony is responding by introducing a new generation of high definition products. The range of products is to include studio cameras, portable cameras, studio VTRs, portable VTRs, digital multi effects and digital switchers all suitable for live, production and post production use.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00138"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "A Virtual Studio-Set System of High Speed and High Functional Performance Realized with Dedicated Hardware",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ryu Watanabe",
                    "Akio Nishimura"
                  ],
                  "abstract": "NHK and Matsushita Electric Industrial Co., Ltd. have jointly developed a virtual studio-set system adopting the CG generation dedicated hardware based on their unique architecture. The newly developed system is characterized by its high speed, high functional performance, and its low cost, space-saving and low power consumption. — This paper describes the details of the development of this system, its functions and performance characteristics, together with how it is operated in the actual studio program production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00124"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Elements of a New Authoring System for Digital Video Disk (DVD)",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenji Sugiyama",
                    "Neil Neubert"
                  ],
                  "abstract": "The realization of DVD, Digital Video (Versatile) Disk, requires an authoring system to process the video, audio, sub-picture, and other program material before a disk can be made. Special DVD program material such as sub-picture, and the functions of a new DVD authoring system are presented. — The authoring system is composed of four functional elements; scenario converter, source encoder, pre-mastering, and checker. The functions of these elements are described in the paper. — The scenario converter element permits introduction of “navigation” data to program material so the viewer may interact with, and control program playback. — The source encoder element utilizes various compressed and non-compressed coding methods to encode video, audio and sub-picture. — The pre-mastering process creates a data stream conforming to compression system, and DVD format standards. Data stream checking includes playback emulation and verification of the data. — DVD offers new presentation display functions such as multi-point of view selection, and “pan and scan” picture area selection for wide screen programs. The authoring system permits these functions to be included in the DVD data. — The authoring system employs a new rate control method for variable bit rate encoding that yields both best picture quality and optimal fit of all data on the DVD disk. A two pass video encoding method has been developed to first analyze the program material, and then optimize the VBR rate control during the final encoding process. — The authoring system includes processes that thoroughly check and verify the data stream before it is recorded on the DVD disk.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00129"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Practical Studio Productions Using High Quality, Low Cost, Virtual Sets",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David N. A. Drew"
                  ],
                  "abstract": "Virtual Studios have been demonstrated at Broadcast Exhibitions since their first showing at IBC in 1994. They created an immediate impact as program producers were excited by both the technology and the potential for enhancing their own productions. Subsequent to the initial euphoria, it was soon realized that not only did these virtual studios require substantial amounts of computing power, but also needed a number of specialist staff to operate and design the virtual sets. Could a lower cost, simpler alternative be found? — The paper will discuss the requirements for operating a low cost 2D virtual studio. It offers a ground up approach on how virtual programs can be designed and produced, starting from a conventional studio or chroma key facility. The vital components for any virtual studio will be introduced and described, as will the potential benefits of using a virtual set",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00126"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Broadcasting and Processing of Program Guides for Digital TV",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephan Hartwig",
                    "Thomas Rautenberg",
                    "Tilman Bollmann"
                  ],
                  "abstract": "From the consumer s point of view the transition from analog to digital TV comes in two flavours, quantity and quality. First, the number of services increases significantly and second, there are new service types to come. Paper TV-guides with their linear and non-hierarchical presentation of program information are unlikely to assist any longer in service- and program event selection. Instead, Electronic Program Guides will provide an interactive user interface offering comfortable and fast program browsing functions. — Unlike in the computer world, the desired schedule information will just virtually be served from a local random access data base, but will mostly be fetched from the current transmission. Caching techniques will be applied, which are, however, restricted due to the lack of sufficient local storage media. This makes the development of transmission, processing and buffering strategies a difficult task, bearing in mind that users expect fast and random access, whereas the service provider wants to keep the transmission bandwidth allocated for this type of data as small as possible. — Starting with an outline of the DVB Standard for Service Information and an example EPG, this paper will analyse SI transmission schemes and SI caching and processing strategies. Typical hard- and software constraints of consumer Set Top Boxes are taken into account.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Digital TV",
                      "Service Information",
                      "Electronic Program Guide"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00123"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Picture Quality Editing for Variable Rate Compressed Video",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jay Yogeshwar",
                    "Mikhail Tsinberg"
                  ],
                  "abstract": "This paper discusses a novel video encoding system in which a user controls the quality of the encoded video. It uses an algorithm for re-allocation of target bits to the segment selected for editing or quality change. The algorithm is based on the availability of a log file containing statistics pertaining to the original run that produced the compressed video. A key aspect of the bit allocation is that subjective input from the user is used to alter the picture quality of the edit segment. Bitstream splicing is carried out to complete the process of edit. — The video is initially encoded according to an automatic process without user intervention. An operator then reviews it manually, and indicates that the quality of specific time periods or regions that is to be altered. A numeric value for picture quality is assigned in the range [−5, 5]. First, a common bit pool is created by removing a percentage of bits from the time periods or regions for which quality priorities have been specified. These are then redistributed as a function of the user selected priority. The bit assignments are adjusted such that buffer under-flow condition is avoided. Also, the buffer occupancy at the trailing edge of the edit segment is maintained at its original level. — After the assignment of new target bits, the average quantizer scale value is determined using a previously determined rate quantizer function. The video is then re-encoded with the new set of target bits to achieve the desired quality change. Bitstream and log files are updated by proper splicing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00131"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "A Unified Hybrid Recorder: Combining Hard Disk Drives, Betacam SX, and Analog Betacam",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "I. Sato",
                    "K. Hyodo",
                    "C. Golson",
                    "J.P. Creignou"
                  ],
                  "abstract": "Digital video and signal compression technologies have created an increasing demand for high performance, efficient systems with the promise of streamlined operations and increased productivity. The transition of the broadcast industry to an all-digital environment for the creation of television news programming and television broadcast operations poses some unique challenges. For a new system to satisfy these requirements, the core design imperative has to incorporate novel networked system concepts, and the best of contemporary digital compression technology with an efficient total video and audio data rate that supports higher quality than that of current analog ENG systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00115"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "The Professional Video Industry Needs a Standard, Over-The-Top Digital Audio/Video Expansion Bus",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alain Legault",
                    "Janet Matey"
                  ],
                  "abstract": "The use of economical, general-purpose PCs in demanding professional video applications like nonlinear editing, graphics creation, animation recording, 3D rendering, video-on-demand and commercial insertion continues to grow. In these applications, specialized PC adapters are typically used to handle the massive processing requirements for transporting natural data types in real time. Commonly used sub-systems include: video I/O, video processing (DVE-mixing), video compression/decompression (codec), audio I/O, audio processing (EQ-mixing), mass storage interface, network interface and video-in-a-window console display. Although it is possible to accomplish some of these tasks with host CPU software and a single highly integrated adapter, most professional systems require more than one adapter. — How to connect these multiple video adapters together inside a PC is a question that system integrators have been wrestling with for many years. The problem is essentially one of data rate considering that: • a single ITU-601 4:2:2 digital video stream = 21 MB/sec. (32 MB/sec. with key bus 4:2:2:4) • eight 48 KHz − 16-bit audio tracks = 768 KB/sec. • motion-JPEG compressed digital video stream at Betacam quality = 6 MB/sec. — This paper examines the limitations of commercially available busses in these demanding broadcast video applications, proposes the Movie-2 bus as a high-performance open-architecture standard that overcomes these limitations, discusses the Movie-2 bus in detail, and finally, presents a model of a typical nonlinear editing platform as an example of system-level Movie-2 bus implementation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00121"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Monitoring Sound in the One-Person Environment",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomlinson Holman"
                  ],
                  "abstract": "With the growth of personal computers as display devices for media has come the need to monitor sound accompanying images on these systems. Many of the same parameters that constitute the capabilities of large-scale systems also need to be addressed in small-scale ones in order to produce similar experiences of the program material. These include frequency range and response over the range, dynamic range, and stereo imaging capabilities. In addition, some new problems also arise, such as those brought about by being so close to the loudspeakers, and the difficult acoustical environment faced by the loudspeakers. Several methods are described which make the desktop environment useful in making professional judgments of sound usually reserved for calibrated monitoring systems in motion-picture dubbing stages. Having such a system extends the utility of digital audio and video workstations. Performance data is given.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00128"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Toward a Universal Data Format for the Preservation of Media",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dave MacCarn"
                  ],
                  "abstract": "There is a significant need for a Universal Preservation Format (UPF), designed specifically for digital technologies, that can store compound content (not only media itself but also information about it) so that the content can be accessed easily both today and into the indefinite future. The UPF could break the bond between the recording format and the machine through which the format is accessed. — This paper points out some existing technology that could be used, and is intended to provide a basis for industry discussion toward producing a universal preservation format.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00117"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "The Unified World Environment: Using 3-D Databases as an Aid to Visual Effects Production",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joel Hynek",
                    "John Gaeta"
                  ],
                  "abstract": "As we move steadily into the world of the digital backlot, methods of visual effects production that can efficiently integrate the vast array of required image elements become necessary. One such method, the unified world environment, answers the call. — This paper will present the unified world environment as developed at Mass. Illusion focusing on the role of pre-visualization and 3-D databases as the skeleton that holds the body of visual effects disciplines together.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00134"
                  }
                }
              },
              {
                "article_local_id": "48",
                "article_title": "Film Storage • What's Coming?",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/48/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Morten Jacobsen"
                  ],
                  "abstract": "Motion picture film has been with us for over 100 years. Very few of the original negatives from that period or for that matter any period are preserved. — 35mm film is the only moving media that has kept its physical properties unchanged. A film from that time can in principle be screened today. — 35mm film has always been stored in the tin in which the raw stock manufacturer supplied it in, nearly and in principle, yes. Tins have from time to time been changed to new ones when they were too rusty and bumbed, but basically no.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00140"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "Traveling Mattes: Above and below the Waterline",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jonathan Erland",
                    "Kay Beving Erland"
                  ],
                  "abstract": "This paper will discuss the most rapidly proliferating technology in current motion picture production: traveling matte composite photography. — The motion picture industry, and Visual Effects in particular, is undergoing a technological change unequaled since the advent of sound. The impact of computer digitization and manipulation of both sound and images has, during the last decade, profoundly altered the motion picture production process. — Probably the most dramatic impact has been felt in the field of traveling mattes, which have gone from an expensive rarity to becoming ubiquitous and relatively economical across the breadth of motion picture production. We now stand poised on the threshold of the full realization of the virtual set. Wherever a motion picture camera has been required to go in the past, a traveling matte technician must now also be prepared to go. — In the air, on land and even underwater are becoming routine venues for the demanding and complex technology of traveling matte photography. This paper will demonstrate a variety of approaches to the challenges of these new environments and describe advances in the systems for providing backings optimized for digital electronic compositing techniques.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00137"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "Optical Restoration of Faded 35mm Color Negative",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Kuran"
                  ],
                  "abstract": "Since 1950, color negative film has become the standard on which millions of motion picture and television films have been photographed. Since the early 1970's, it has become apparent that the color negative film stock on which these images were recorded was not entirely stable and was fading with time. Digital technology is beginning to offer solutions to saving these records but will continue to be unavailable to most of these records due to cost. Optical (Photo-chemical) restoration offers a cost effective alternative to preserving many film records that may be lost by the time digital technology is affordable.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00139"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Compression to Disc Building: DVD for Movies",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jerry A. Pierce"
                  ],
                  "abstract": "The process of building a DVD movie disc requires a new set of skills. In addition to the traditional skills required to assemble a Laserdisc title, the DVD production process requires knowledge of audio/video compression, man-machine interface, and the intricacies of the DVD Navigation specification. — This paper discusses the various issues involved in the total production of a DVD movie. It will discuss the choices for a DVD design, the assembly of original content, the design of a “standard” user interface, and an overview of the compression/authoring process.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00130"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Video Testing in Modern Television Systems",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David K. Fibush"
                  ],
                  "abstract": "Measurement of picture quality has been high on the list of television engineering priorities since video compression became a practical reality. This paper examines the modern television system outlining its elements and the appropriate levels of testing. The need for continuation of traditional analog and digital testing methods is emphasized as a prerequisite for both effective video compression and the measurement of resulting pictures. Proposed picture quality measurement methods and possible limitations of their application are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00133"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "DVD Premastering: A Facility's Perspective",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Bradley Hunt"
                  ],
                  "abstract": "Digital Versatile Disk Video (DVD-Video) is a revolutionary, new consumer video system. The expected demand for DVD programming represents a huge opportunity for the studios and content producers to profit from the sale of movies rereleased in this new format. Due to the richness and complexity of features and the image and sound quality of the format, content producers will need to work closely with DVD authoring facilities in the mastering of their movies to this new high-quality medium. From the facility's perspective, there are many steps involved in the DVD-Video authoring process. This paper will focus on the critical steps of element preparation, telecine transfer, video preprocessing, and compression which greatly influence the quality of the DVD-Video product.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00132"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Three-Way Loudspeaker Systems for Motion Picture Use",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Eargle",
                    "Mark Mayfield",
                    "David Gray"
                  ],
                  "abstract": "Digital sound tracks have the potential of delivering lower distortion signals with flat power bandwidth capability in the motion picture theater. Traditional 2-way theater loudspeaker systems are presently being pushed far beyond their original performance limits with digital sound tracks, and 3-way systems are now being considered as their future replacement. The authors have developed such systems for both small and large venues and will discuss the many observations, measurements, and decisions made during the engineering phase of development.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00127"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "The Studio of the Future - the Future of the Studio",
                "article_url": "https://journal.smpte.org/conferences/138th%20SMPTE%20Technical%20Conference%20Technical%20Papers%20Program/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Van Himbergen",
                    "Jeffrey A. Diamond"
                  ],
                  "abstract": "This paper explores “next generation” media studios and considers how traditional process methodologies and physical infrastructure requirements must adapt to an emerging media context. — The characteristics of the near future studio are evolving to operationally address the goal of an “end-to-end” process solution (from creation to distribution) in a more effective, networked manner. Applications of integrated production, post production, and electronic distribution will shape the studio's capabilities and alter its function in the creative community. Services including image processing, digital effects, rendering, film scanning and recording, distribution formatting, variable-term archiving and media asset management are being offered in much the same way that film lab services are today — Advanced studio solutions being designed and constructed as part of modernization and/or futurization initiatives for some of today's traditional studios. Such a “next generation” studio is already under construction: High Tech Center Babelsberg in Potsdam, Germany. High Tech Center is an advanced studio whose operational model is based on an innovative service provider axiom. — Another advanced technology and media content facility combines the development of technology with media content and features the distribution and warehousing of such content and software tools. This entertainment technology enterprise resembles what Gistics Group has defined as a 21st Century Asset Foundry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00136"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "International Workshop on HDTV '96",
            "conference_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/",
            "articles": [
              {
                "article_local_id": "6",
                "article_title": "Controlled Access System for HDTV",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Xiao-Wen Yang",
                    "Zhi-Hang Zheng",
                    "Cheng-Gang Duan",
                    "Xin-Biao Hui"
                  ],
                  "abstract": "In this paper, an architecture of the controlled access system for GA is discussed. It is different from the original analog conditional access system in many aspects. Three main blocks of the system are discussed here. Control center operation in transmitter end is discussed in detail because it is the core of the system. Much information like ECMs and EMMs has to be processed here, so that the multiplexer can place the information correctly in the Transport layer. It's suggested the ECMs and EMMs be transmitted safely to the subscripted user decoder by means of some syntactical fields in the Transport Stream packet, sometimes they are adaptation field and private data field. In this paper, other tools are used, that is, the descriptors in PSI tables. Two methods used in the block of scramble & descramble which performed at MPEG-2 Transport Stream level or PES level are proposed here. And the entitlement message decode is simplified.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001234"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Motion Estimation using Region-Based Segmentation Methods",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniele Bagni",
                    "Rosa Lancini",
                    "Paolo Vicari",
                    "Stefano Tubaro"
                  ],
                  "abstract": "This paper describes an algorithm which combines motion estimation and region-based segmentation techniques in parallel. The segmentation information is used to improve the quality of the estimated displacement vectors by affine models calculation within regions of variable shape.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "Motion estimation",
                      "Segmentation",
                      "Affine model",
                      "Temporal subsampling"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001235"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Motion Estimation Method using the Spatio-Temporal Characteristics of Moving Objects",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hajime Sonehara",
                    "Yuji Nojiri",
                    "Kazuhisa Iguchi",
                    "Yukio Sugiura",
                    "Hiroshi Hirabayashi"
                  ],
                  "abstract": "This paper presents a motion vector detection method which takes account of the spatio-temporal continuity of motion vectors and the local characteristics of pictures. First, we discuss a method for tracing motion vector trajectories to assess the spatio-temporal continuity of motion vectors and a method of motion vector detection using motion vector reliability. Next, we explain a motion vector estimation method in which the local characteristics of pictures are considered. The method consists of the removal of erroneously detected motion vectors by use of the luminance correlation of pictures to assign detected vectors. In conclusion, it is shown by simulation that these methods produce beneficial results for the improvement of motion vector detection.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001236"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Advanced Motion Estimation and Motion Compensated De-Interlacing",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E.B. Bellers",
                    "G. de Haan"
                  ],
                  "abstract": "This paper describes a new high quality de-interlacing algorithm applying motion estimation and compensation techniques. First, a comparison between two recently introduced de-interlacing concepts will be presented. One method is based on a generalized sampling theorem and the other uses time-recursion. The new algorithm aims at combining the benefits of both.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "de-interlacing",
                      "motion compensation",
                      "motion estimation",
                      "sequential scan conversion",
                      "generalized sampling theorem"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001237"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Motion Compensation by Adaptive Vector Quantization",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shankar L. Regunathan",
                    "Kenneth Rose"
                  ],
                  "abstract": "We propose an efficient motion compensation scheme where adaptive vector quantization (AVQ) is used to optimally compress the dense motion field. The vector quantizer codebook is designed on-line by backward adaptation based on previous reconstructed frames. It thus takes advantage of the information already available at the receiver for adapting the codebook without recourse to side information. The method adapts the codebook to local motion statistics and thus exploits interframe motion correlations. It also eliminates the need for extensive prior codebook training, as well as problems of statistical mismatch due to scene variation. Preliminary experiments on benchmark video sequences show average improvement of about 0.8dB in SNR, and improved perceptual quality of the reconstructed video. The enhanced performance is achieved at the cost of only a fractional increase in complexity as compared to standard motion compensation methods.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001238"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "An Implementation of the Media Processing Unit for Multimedia Communication Terminal",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kyeong-Yeol Yu",
                    "Jong-Hoon Park"
                  ],
                  "abstract": "In this paper, we propose the new architecture of the media processing unit of set top unit(STU) and show the result of its implementation in ETRI video on demand(VOD) system, IMPRESS (Interactive Multimedia exPRESS). The STU in our system has MPEG-2 video quality in movie on demand but low quality in bi-directional communication in consideration of implementation cost. The media processing unit in our STU consists of three parts. One is system control module which has RISC processor and it controls overall functions of the unit, another is MPEG-2 decoder module which decodes MPEG-2 transport stream(TS) in real time and presents the contents, and the third is audio/video communication module which enables bidirectional video conferencing each other.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001232"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "A Medical Application of High Sensitivity HARP HDTV Camera: Imaging Micro-Vessels in Various Organs",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ryo Mochizuki",
                    "Misao Kubota",
                    "Kenkichi Tanioka",
                    "Etsuro Tanaka",
                    "Hidezo Mori"
                  ],
                  "abstract": "High sensitivity HARP pickup tubes, developed by NHK Labs. for the HDTV cameras, have about 80 times (Super version) and 640 times (New Super version) as sensitive as a conventional camera tube, using an avalanche multiplication effect in the amorphous selenium target. — The HARP HDTV camera is a powerful tool not only in the outside broadcasting such as night time emergency news gathering, but also in scientific applications such as deep sea image acquision. Applications of the camera in the medical field was executed by NHK Engineering Services, Inc. — To visualize an X-ray image, ordinary image intensifier or CCD camera is not appropriate because of its poor resolution or sensitivity. We have succeeded in detecting the X-ray image using the high sensitivity HARP HDTV camera. The camera is appropriate in both high sensitivity and high resolution for identifying micro-vessels under the size of some dozens of μ m in various organs, and the system is proved to be useful for clinical applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001233"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Opening Remarks",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Davies"
                  ],
                  "abstract": "Fourteen years have passed since the first HDTV Workshop was held in Ottawa, in Canada, in the month of October, 1992. There began a series of very valuable events that brought together the experts in this rapidly evolving field of technology to share the results of their work and to exchange views on the future directions for research and development. Much has happened in those fourteen years since I had the pleasure of working with the late br. Chris Siocos of the Canadian Broadcasting Corporation, perhaps best known for his contributions in the field of broadcasting and communications satellites, and together we realised at that time the need for this special workshop, known then as the HDTV Colloquium. Even then it was conceived as an international event, a meeting of the experts and a catalyst to future progress. In Europe, a year or so later, Dr. Leonardo Chiariglione created the Aquila Workshop on HDTV and from these have grown these annual and truly international fora on HDTV.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001229"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Basic Function of Integrated TV Services for ISDB",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "K. Usui",
                    "K. Kai",
                    "M. Ueno",
                    "A. Ohya",
                    "T. Isobe"
                  ],
                  "abstract": "This paper first briefly summarizes how interactive multimedia services can be implemented in a broadcasting environment characterized by one-way transmission. Next, Integrated Services Television (ISTV) is proposed as an approach for realizing broadcast multimedia services in the digital age. It is shown that the structured data approach is capable of describing displays and services that are flexible and able to be extended. Finally, we assess the effectiveness of ISTV functions and the structured data approach using simulator and test programs. Viewers' responses to a menu display which displays a range of available services were solicited, and 90% of the respondents were found to be favorably impressed by the ease with which available services could be understood.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001231"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Edge-Preserving Recovery of Damaged Blocks for Block-Based Image Coding",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joon-Ho Chang",
                    "Choong Woong Lee"
                  ],
                  "abstract": "In this paper, we present a recovery algorithm for reconstructing damaged blocks for block-based coding. The proposed algorithm considers 2 properties of natural images, edge continuity and boundary smoothness, which are the most annoying unless they are not satisfied. It consists of edge estimation, spatial prediction, and POCS (Projections onto Convex Sets) iteration. Edge estimation and spatial prediction guarantee edge continuity and POCS iteration smoothes pixel values at the block boundaries. Simulation results show that the proposed algorithm outperforms the conventional ones.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001245"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "An Improved Source Splitting Scheme for Conditional Run-Level Coding of DCT Coefficients",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Seung Jun Lee",
                    "Jun Seok Song",
                    "Dong Wook Kang",
                    "Choong Woong Lee"
                  ],
                  "abstract": "Recently, an idea of source splitting [1] has been proposed, which reduces average bitrate for encoding run-level symbols of quantized DCT coefficients. This paper presents an efficient method which allows the source splitting idea to be practically applied to video coding systems. The proposed method consists of (i) an iterative pairwise splitting algorithm for fast finding optimal splitting indices; (ii) a memory allocation algorithm for determining the Huffman table sizes; (iii) and an exhasutive search algorithm for determining the number of Huffman tables to be used. Simulation results show that the bitrate reduction performance can be further improved by using the proposed improved method and that computational burden can be also considerably reduced with the proposed method.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001246"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "A Research of Multiresolution Image Sequence Coding System Based on Wavelet Transform",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Li Tao",
                    "Yu Sile"
                  ],
                  "abstract": "An integrated image sequence coding system based on wavelet transform is presented in this paper. First, by means of wavelet transform, an image signal is decomposed into a series of subspaces which make up a multiresolution approximation to the original image signal. On the basis of analyzing for the quantization noises, a bit allocation means of sub-images and two quantization methods involving intra-frame and inter-frame are derived. In accordance with the spatial orientation of sub-images, a proper scanning approach is selected for employment. A revised Test Model 5(TM5) bit-rate control scheme and a variable block-size multiresolution motion estimation(VBMRME) method are discussed. Finally, the simulation experiment is carried out and the satisfactory results are obtained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "wavelet transform",
                      "image sequence coding",
                      "multiresolution motion estimation",
                      "quantization",
                      "bit-rate control"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001248"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Spatio-Temporal Scalable Coding of Interlaced Video Sequences",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Katsutoshi Sawada",
                    "Masatoshi Asada"
                  ],
                  "abstract": "In this paper we present a spatio-temporal scalable coding scheme for interlaced video sequences. Resolution scalability refers to a picture coding property where pictures at lower different resolutions can be reconstructed by decoding only the subsets of a single coded bit-stream, while the full resolution picture is reconstructed by decoding the total bit-stream. The scalable coding scheme proposed in this paper employs frame subsampling associated with adaptive interpolation for temporal scalability. It also employs adaptive infield/inframe DCT for spatial scalability. This scheme can be applied to interlaced video sequences effectively and it provides four different spatio-temporal resolutions of a video sequence — two temporal resolutions, each consisting of two spatial resolutions. Computer simulation experimental results have demonstrated that this scheme shows better coding performance, especially for reconstructed low resolution pictures, compared to conventional non adaptive schemes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001249"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "A New Intra-Frame Coding Algorithm for Image Compression",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chenggang Duan",
                    "Zhihang Zheng",
                    "Xiaowen Yang",
                    "Xinbiao Hui",
                    "Zhu Zhou"
                  ],
                  "abstract": "In this paper, a new Intra-frame coding algorithm is proposed for image compression. Due to the small block size in transform coding, the DCT coefficients at the same frequency between the adjacent blocks have strong correlation with each other. For more effective coding, the interblock correlation is decreased. At last, this algorithm is compared with intra-frame coding method in MPEG.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001250"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Non Linear Effects in High Density Optical Recording",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "L. Agarossi",
                    "S. Bellini",
                    "C. Beoni",
                    "P. Migliorati"
                  ],
                  "abstract": "This paper presents a preliminary study aiming to define a non-linear model of an high density optical disc read-out process based on the Volterra series. Under high density condition indeed, because of the high linear density and reduced track pitch the signal read-out is not a linear process. To cope with such rather delicate problem, the identification of a suitable non linear model is required. According to the Hopkins analysis, a physical model based on the optical scalar theory was implemented. The results of such analysis have been then used to build up a non-linear analytical model based on the Volterra series. Some encouraging results based on a preliminary draft model are given.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001252"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "A Parallel Processing Architecture for HDTV Encoding System",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chieteuk Ahn",
                    "Hyunsik Chang",
                    "Jin-Young Yang"
                  ],
                  "abstract": "We propose a parallel processing architecture to encode HDTV(High Definition TV) signals by dividing input signals into several sub-pictures. Each sub-picture is encoded in parallel by a sub-picture encoding module(SEM) which has the capability to encode video signals according to MPEG-2 MP@ML(Main Profile at Main Level) specification. Each SEM consists of application specific integrated circuits(ASIC) we developed. The bit streams generated by sub-picture encoding modules are assembled into a single bit stream complying with the MPEG-2 MP@HL(Main Profile at High Level) specification. We also present a rate control scheme for parallel encoding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "SDTV",
                      "HDTV",
                      "MPEG"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001244"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Analog Implementation of Vector Quantization",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fabio Ancona",
                    "Stefano Rovetta",
                    "Rodolfo Zunino"
                  ],
                  "abstract": "Vector quantization is the main alternative to compression techniques based on the DCT. This work presents an analog VLSI implementation of a vector quantization system. Large-scale parallelism and analog computation are exploited to obtain a fast, modular system that is suitable for both simple encoding and adaptive compression, since appropriate control lines are provided. The analog VQ encoder is self-contained and therefore can be embedded into any system, either analog or digital. It implements in an efficient way the vector matching operations, therefore it can be exploited in systems based on any vector quantization algorithm. The circuit can be used to obtain very high throughput, which makes the approach suitable for high-quality image transmission.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001240"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Keynote Address: The Vision of HDTV",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark S. Richer"
                  ],
                  "abstract": "HDTV is defined by the International Telecommunications Union as: “…[A] system designed to allow viewing at about three times the picture height, such that the system is virtually, or nearly, transparent to the quality of portrayal that would have been perceived in the original scene or peformance by a discerning viewer with normal visual acuity. Such factors include improved motion portrayal and improved perception of depth.”",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001230"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Hardware Architectures for Vector Quantization in Very Low Bit-Rate Image Coding",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fabio Ancona",
                    "Stefano Rovetta",
                    "Rodolfo Zunino"
                  ],
                  "abstract": "The paper describes a board-based hardware implementation of a neural algorithm performing vector quantization for very low bit-rate video compression. The Neural Gas model has been chosen for its remarkable properties in terms of both consistency (quality of the quantization process) and easy implementation. The Neuro-board interfaces to a PC through a standard ISA bus. The system architecture is composed of a 70ns RAM bank, an FPGA-based control logic and mathematical coprocessor, and a DSP device for numerical computations. The board supports both training (codevectors adjustment) and run-time operation. The main advantages of the implemented solution lie in its simplicity and easy control for HW tests and SW development.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001241"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "A Programmable Video DSP Architecture for HDTV Applications",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takao Yamazaki",
                    "Akihiko Hashiguchi",
                    "Masuyoshi Kurokawa",
                    "Ken'Ichiro Nakamura",
                    "Hiroshi Okuda",
                    "Seiichiro Iwase"
                  ],
                  "abstract": "This paper describes a programmable DSP for real-time HDTV signal processing. The SIMD architecture with 4320 processor elements operates at 50 MHz with a peak performance of 216 GBOPS (Giga Bit Operations per Second). The single chip DSP can be used for various HDTV applications such as for noise reduction, color space conversion and format conversion (HDTV to/from NTSC).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001242"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "A Programmable and Scalable Architecture for Real Time Audio and Video Processing",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. Cucchi",
                    "M. Modena",
                    "G. Parladori",
                    "C. Zugno"
                  ],
                  "abstract": "Current Real Time Audio Video Processing demands flexible architectures and programmability in order to better match the application. — According to these requirements a fully programmable system, which extensively uses DSP technology, is presented. It is based on a VME bus structure and implements a scalable architecture. — Through extendible modular layers the computational power can be progressively increased and easily managed to perform different tasks. These features are particularly suited for implementing algorithms which are specified for different levels of quality/complexity like in the present MPEG2 standard (from MP@ML to HP@HL) [3]. — The software programmability of the system also enable to further improve and refine the current algorithm implementation without any hardware change. — The system has been developed within the framework of the EUREKA 1187 – ADTT project to allow, in particular, real time experimentation of Audio Video Non Broadcast Applications like Electronic Movie and Video Communication for professional environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001243"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Blind Equalization of COFDM Systems Based on the Minimization of a Quadratic Criterion",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Philippe Madec",
                    "Marc de Courville",
                    "Pierre Duhamel"
                  ],
                  "abstract": "The COFDM concept has recently been applied to the design of DFT-based digital modulations for use over frequency selective channels. The cyclic convolution property of the DFT enables a low complexity equalization scheme at the expense of bandwidth efficiency since a “guard time” is required. Moreover this technique is very specific to DFT-based OFDM systems. As digital modulations generate continuous signals after baseband level digital filtering, non-critical sampling is recommended, that is, some zero symbols must be appended to the block of symbols to be modulated. As shown in [10], minimizing a quadratic criterion based on the subband components of the received signal that should be null is sufficient to perform (blind) equalization. Therefore less channel capacity is lost since neither a guard time nor reference symbols are required. The performance of a linear equalizer using this criterion is studied here for COFDM systems with 64-QAM subcarrier modulation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001263"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Results of Laboratory and Field Tests of a COFDM Modem for ATV Transmission in 6 MHz Channels",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Y. Wu",
                    "M. Guillet",
                    "B. Ledoux",
                    "B. Caron"
                  ],
                  "abstract": "A prototype 6 MHz COFDM transmission system (COFDM-6) for ATV terrestrial broadcasting was evaluated at the Communications Research Centre (CRC). This paper provides the laboratory and field test results of the COFDM-6 modem.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001264"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Digital Transmission of HDTV via CS using MPEG2 CODEC",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenji Terada",
                    "Hiroyuki Tanaka",
                    "Yuji Okawa",
                    "Yasunori Iwasa",
                    "Kazufumi Takizawa",
                    "Yukihiro Nishida"
                  ],
                  "abstract": "This paper describes a transmission system for Hi-Vision (HDTV) program materials. The system consists of an HDTV coder-decoder (codec) using MPEG2, a Trellis-coded 8PSK* modem (TCM) and other equipment. Using the system and a Communication Satellite (CS), we realized a program transmission route which enables us to use various images and sounds sent from field broadcasting points. (*phase shift keying)",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001265"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "An Overview of the ATSC Digital Television Standard",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glenn A. Reitmeier",
                    "Terrence R. Smith"
                  ],
                  "abstract": "This paper provides an overview of the ATSC Digital Television (DTV) standard. The standard is based upon the Grand Alliance HDTV system, but has been extended to also include SDTV formats. This industry standard is currently under final consideration by the FCC for adoption as the approved method of DTV terrestrial broadcasting in the U.S.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001266"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "Advancing the Digital HDTV Grand Alliance System from the Test Laboratory to the Real World",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas M. Gurley"
                  ],
                  "abstract": "Digital advanced television in the United States is now moving from the testing phase into the implementation phase. Testing of the digital HDTV Grand Alliance System by the Advanced Television Test Center (ATTC) was completed in July 1995. The system performed well compared to the six systems tested previously, in terms of picture and sound quality and transmission robustness, and it met or exceeded virtually all of the performance targets established by the Federal Communications Commission (FCC) Advisory Committee on Advanced Television Service (ACATS). Although the testing process provided sufficient data to warrant recommendation of the system for adoption by the FCC, and it was proven well-suited to the terrestrial broadcast environment in the United States, several issues related to spectrum planning and RF implementation were not completely addressed in the ACATS testing. Since that time, ATTC and its successor organization, the Advanced Television Technology Center, have been conducting additional testing to address these issues. — The U. S. Advanced Television Systems Committee documented the Grand Alliance System as the ATSC Digital Television Standard, released in September 1995. In November 1995, the system was formally recommended to the FCC, which then incorporated the ATSC Standard in its Notice of Proposed Rule Making on Advanced Television, issued in May 1996. — Meanwhile, as the rule-making process moves forward, the FCC is awarding licenses for experimental HDTV stations. In April of this year, the industry-supported Model HDTV Station Project was announced. In July, the Project was licensed to operate an experimental station as WHD-TV, which first broadcast on July 30. The Project is sponsored by the Association for Maximum Service Television (MSTV) and the Consumer Electronics Manufacturers Association (CEMA), a sector of the Electronic Industries Association (EIA). The three-year project is funded by some 250 television stations and 16 equipment manufacturers. Among the member stations are both of the other stations that have received experimental licenses from the FCC. The host facility is WRC-TV, the NBC owned-and-operated station in Washington, DC. The Model HDTV Station Project will provide a “real-world” environment in which broadcasters and manufacturers can work together to evaluate a wide range of studio, transmission, and receiving equipment, to conduct propagation and coverage experiments, and to obtain practical training and experience in building and operating an HDTV station.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001267"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Interfacing HDTV and Motion Picture for the Electronic Movie-Theatre",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Galt"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001251"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "DCT Image Coding Employing Emphasis",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mario Sato",
                    "Tadahiko Kimoto",
                    "Toshiaki Fujii",
                    "Masayuki Tanimoto"
                  ],
                  "abstract": "Emphasis filtering is very effective to improve reconstructed image quality in subband coding. In this paper, emphasis scheme is applied to DCT coding which is performed with subband filter banks. The characteristics of emphasis filter are dependent on the source image signal. A decoded image is subject to de-emphasis filter of the characteristics inverse to those of the emphasis filter. To avoid transmission of filter parameters for every image, the pair of filters of predetermined characteristics are used for emphasis and de-emphasis. A two-dimensional(2-d) model for approximating image spectrum is proposed for designing these filters. Coding simulations have shown that the proposed scheme achieves about 1dB improvement in the SN ratio compared to the pure DCT scheme. Also, it is shown that the proposed 2-d spectrum model derives more effect of emphasis than conventional models.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001247"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Hardware Architectures for Vector Quantization in Very Low Bit-Rate Image Coding",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fabio Ancona",
                    "Stefano Rovetta",
                    "Rodolfo Zunino"
                  ],
                  "abstract": "The paper describes a board-based hardware implementation of a neural algorithm performing vector quantization for very low bit-rate video compression. The Neural Gas model has been chosen for its remarkable properties in terms of both consistency (quality of the quantization process) and easy implementation. The Neuro-board interfaces to a PC through a standard ISA bus. The system architecture is composed of a 70ns RAM bank, an FPGA-based control logic and mathematical coprocessor, and a DSP device for numerical computations. The board supports both training (codevectors adjustment) and run-time operation. The main advantages of the implemented solution lie in its simplicity and easy control for HW tests and SW development.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001253"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Services-on-Demand Laboratory Demonstrator with PC-Based Set-Top-Boxes",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bernhard Gross",
                    "Stephan Breide",
                    "Wolfgang Ruppel"
                  ],
                  "abstract": "This paper describes a Services-on-Demand (SoD) laboratory demonstrator with PC-based Set-Top-Boxes (STB). The implementation is part of a research project of Deutsche Telekom's Technology Centre. It aims at the verification and demonstration of the general concept to use the german public online service “T-Online” with internet access as a platform for SoD. Based on a first step configuration with two example applications, a first performance analysis has been made.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001256"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "A Wavelet Image Compression Scheme using PVQ",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rosa Lancini",
                    "Stefano Tubaro",
                    "Marco Barbieri"
                  ],
                  "abstract": "This work presents an application of Pyramid Vector Quantization (PVQ), with a global bit allocation on wavelet coefficients. First a two level bit-allocation strategy has been used: the available bit-rate is subdivided on the sub-images, and then for each sub-image an allocation strategy is used to distridute the available bits through the vectors to quantize. Sucessively a one-level bit allocation strategy (global bit-allocation) over all vectors of all sub-images has been considered. Simulations carried out on several test images give good subjective and objective results compared to other wavelet-based coding techniques already proposed in literature.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001258"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "A New Intra-Frame Solution for HDTV to SDTV Down-Conversion",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "L. Albani",
                    "G.A. Mian",
                    "A. Rizzi"
                  ],
                  "abstract": "In the last years, the High Definition Television (HDTV) technology has been successfully demonstrated and some products are available for video production. Since HDTV is gradually introduced, Standard Definition Television (SDTV) will coexist for a long time. Therefore, standard converters are necessary to interface equipment and systems of different formats. In this paper, a new solution is proposed for the conversion of interlaced video signals from a high resolution format down to a low resolution format, having good performance, low implementation cost and high design flexibility. Such a flexibility can be further exploited for an adaptive implementation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001239"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Multibest: Multiple Vector Interpolation for Vector-Quantization Based Image Compression",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "F. Ancona",
                    "F. Passaggio",
                    "S. Rovetta",
                    "R. Zunino"
                  ],
                  "abstract": "The paper reconsiders the applicability of Vector Quantization (VQ) to image compression for low bit-rate image transmission. The proposed method overcomes the basic, structural drawbacks of VQ by a general multiple-interpolation mechanism. The major advantages of the described schema are an improved generalization performance and a notable reduction in coarseness. The overall approach can then be integrated with classical adaptive methods to derive a flexible and effective compression schema without affecting compression performances. Massive experimental results on real and artificial images demonstrate the model's notable advantages over classical VQ systems and DCT-based standards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001257"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Projection VQ Applied to Video Sequence Encoding",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chul-Woo Kim",
                    "Kyeong Ho Yang",
                    "Choong Woong Lee"
                  ],
                  "abstract": "This paper proposes an video sequence encoding algorithm that adopts projection scheme on wavelet transform domain of image signal. Projection scheme is applied to the residual signals which resulted from motion estimation of consecutive image frames. Wavelet decomposed residual image is encoded by the result of projection along one direction out of eight which approximates the coefficients most closely to the originally transformed coefficients. These projection data are vector quantized using separate codebooks depending on the decomposition level and orientation of decomposed of image. Experimental result reveals that proposed scheme shows excellent performance in PSNR manner and also shows good subjective quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "keywords": {
                    "readable_descriptor": "Keywords",
                    "essence": [
                      "projection",
                      "direction",
                      "vector quantization",
                      "wavelet",
                      "motion estimation"
                    ]
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001259"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "A New NTSC Co-Channel Interference Rejection Filter with Coded 6-VSB Modulation for Improved ATV Coverage",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Samir N. Hulyalkar",
                    "Monisha Ghosh",
                    "Lee-Fang Wei",
                    "David A. Bryan",
                    "Carlo Basile",
                    "Ahmad K. Aman",
                    "Robert L. Cupo",
                    "George J. Kustka"
                  ],
                  "abstract": "The ATSC ATV standard and its service area predictions assume the use of a comb filter at the receiver. However, such a filter is not required by the ATV standard. There are also unresolved questions about the efficacy of the comb filter. We describe a new system, including an NTSC co-channel interference rejection filter with coded 6-VSB modulation, of comparable complexity, which offers improved ATV service area. Coverage analysis results demonstrate that the system provides much better co-channel performance today with a comparable carrier-to-noise (C/N) threshold and better threshold performance when NTSC transmission ceases in the future. The new system obviates concerns about the reliability of the comb filter under conditions of noise, interference, and multipath.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001261"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Mathematical Modelling of Prefiltering and Postfiltering Processes in the CCD Camera",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "V. Krasnjuk",
                    "M. Hribsek",
                    "D. Arandjelovic",
                    "M. Petrovic"
                  ],
                  "abstract": "In this paper the sampling structure of the CCD sensor and its influence on the aliasing components are analysed. The mathematical model of the optical part of the CCD camera is introduced. The use of the model is illustrated by some practical solutions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001254"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "A Development of 1/2-in. HDTV Digital VTR Incorporating Bit Rate Reduction Technology",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Toshihiro Uehara",
                    "Keigo Majima",
                    "Tatsuya Kurioka",
                    "Takashi Kato",
                    "Syouichiro Ogawa",
                    "Haruo Okuda",
                    "Hideo Ohshima",
                    "Junichiro Kawano",
                    "Shigemi Mikami",
                    "Mitsuo Chiba",
                    "Tatsushi Bannai"
                  ],
                  "abstract": "We have developed a 1/2-in. high-definition television (HDTV) digital VTR for program production, editing, and broadcasting incorporating bit rate reduction (BRR) technology. The objectives aimed at in developing the HDTV VTR are high picture quality, editing/trick play functions equal to those of conventional definition television (CDTV) VTRs, and a low running cost. — Based on the results of a subjective assessment test using compressed moving pictures, we have employed intra-field fixed length discrete cosine transform (DCT) in BRR and set the compression factor at 4.1 for 8-bit video signal quantization and at 5.4 for 10-bit quantization. To hold down the cost of development and realize its early application, we developed an HD processor, which encodes and decodes HDTV video signals, and added it to a D-5 VTR used in CDTV. The newly developed BRR HDTV VTR provides improved picture quality as well as effective error concealment through the incorporation of such new technologies as adaptive processing, overlap blocking, and individual sync block allocation for low/high frequency component codes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001255"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "A Prototype VLSI Solution for Digital Terrestrial TV Receivers Conforming to the DVB-T Standard",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "F. Scalise",
                    "M. Balanza",
                    "N. Chauve",
                    "P. Combelles",
                    "P. Penard",
                    "C. Del Toso",
                    "D. Hepper",
                    "G. Masera",
                    "C. Hernandez",
                    "F. Nicolas",
                    "D. Le Goff",
                    "P. Robertson"
                  ],
                  "abstract": "This paper is aimed to give a thorough overview of the technical activities carried out within the DVBIRD Project (“Digital Video Broadcasting Integrated Receiver Decoder”). The project results achieved in the design of the digital front-end stage of a receiver conforming to the new “DVB-T” European standard for over-the-air TV broadcasting are highlighted. This DVB-T standard is based on the COFDM (Coded Orthogonal Frequency Division Multiplexing) technique and is the result of the technical efforts dedicated to the definition of a digital terrestrial television system in the past years in Europe. An optimised channel decoder architecture, taking advantage of the most recent VLSI technologies in order to achieve a cost-effective solution for the receiver (or Set-Top Box), is proposed. This work is carried out to encourage an early introduction of a digital terrestrial television service in Europe, expected by the beginning of 1998, while the demonstrator is planned for extensive field trials in the second half of 1997. This four-chip prototyping is based on the state-of-the-art CMOS 0.5 μm, 3.3 V, 3-metal-layers VLSI technology. Moreover, a co-operative methodology has been implemented to validate the silicon and the demonstrator.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001262"
                  }
                }
              },
              {
                "article_local_id": "45",
                "article_title": "SSCQE (Single Stimulus Continuous Quality Evaluation): A New Subjective Assessment Method Introduced in ITU-R Recommendation 500-7: Presentation and Results",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/45/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thierry Alpert",
                    "Jean-Pierre Evain"
                  ],
                  "abstract": "Based on the work undertaken within the European Commission's project RACE MOSAIC to overcome specific digital picture quality issues (e.g. content-dependent encoding performance, codec cascading, dynamic statistical multiplexing), a new methodology was designed to allow subjective assessment of both picture and service quality in conditions closer to the actual home environment. This paper gives a description of this new method, recently introduced in ITU-R Recommendation 500 under the label “SSCQE” for Single Stimulus Continuous Quality Evaluation, including test results.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001273"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "A Conditional Entropy Coded Tree Structured Vector Quantizer for Video Coding",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jun Seok Song",
                    "Seung Jun Lee",
                    "Choong Woong Lee"
                  ],
                  "abstract": "In this paper, we propose a conditional entropy coded tree-structured vector quantizer for video coding, which efficiently exploits interblock correlation on motion compensated error images. Simulation results show that performance improvement by the proposed high-order encoding method is remarkable even with very low additional complexity.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001260"
                  }
                }
              },
              {
                "article_local_id": "46",
                "article_title": "Stereo Image Coding: Effects of Stereo Mismatches on Image-Quality",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/46/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lew B. Stelmach",
                    "W. James Tam"
                  ],
                  "abstract": "The present research sought to understand how the human visual system responds to stereo image sequences where the image-quality of the left-and right-eye views differ. Viewers received the left-eye view at a higher quality than the right-eye view, and rated the combined overall subjective quality of the sequence. Three stereo image sequences were used for assessment. Each sequence, in the ITU-601 format, was 10-sec in duration and the images for the left-and right-eye views were coded independently at bit-rates of 6, 3, 2 and 1 Mbits/sec. These were combined in a partial-factorial manner (i.e. left:right, 6:6, 6:3, 6:2, 6:1, 3:3, 3:2, and 3:1). The resulting stereo sequences were viewed by 26 subjects, and rated in terms of subjective image-quality. The rating methodology was based on the double-stimulus continuous-quality scale method described in ITU-R Recommendation 500. The results showed that the subjective quality of a stereo image fell approximately midway between the quality of the left-and right-eye views. For video coding this implies that the human visual system can tolerate discrepancies in the quality of left-and right-eye views in a stereo display. The results are consistent with known properties of binocular vision, in particular with the averaging of brightness of stimuli presented to the two eyes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001274"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "Field Test Results of the ATSC VSB Transmission System",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Sgrignoli"
                  ],
                  "abstract": "The Grand Alliance, a consortium formed in May 1993 by AT&T, David Sarnoff Research Center, General Instrument Corporation, Massachusetts Institute of Technology, Philips Electronics North America Corporation, Thomson Consumer Electronics, and Zenith Electronics Corporation, proposed the use of the eight-level, vestigial sideband (8-VSB) transmission subsystem for Advanced Television (ATV) broadcast service after extensive comparative testing of 8-VSB and 32-QAM at the laboratories of the Advanced Television Test Center (ATTC) and CableLabs. A high-data-rate 16-VSB transmission subsystem was proposed for cable use. A description of the VSB transmission system can be found in References [1], [2], and [3]. The Advisory Committee on Advanced Television Service (ACATS), an all-industry committee originally formed in 1987 to assist the FCC in establishing a new television service to replace the NTSC system currently in use, approved this VSB transmission subsystem recommendation as one component of the high definition television (HDTV) system under development",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001268"
                  }
                }
              },
              {
                "article_local_id": "44",
                "article_title": "Strategy for Promotion of HDTV Service and for Implementation of Digital Broadcasting in Japan",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/44/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takehiro Izumi"
                  ],
                  "abstract": "In 1984 satellite broadcasting started in Japan for SDTV service and the number of home receivers has reached 10 million sets by March 1996. Using one of the BS channels, HDTV service started in 1994 after 8 year experiment and the number of receivers that can receive HDTV programs now exceeds 550 thousands. Among these, 210 thousands are HDTV receivers with full decoding capabilities and the rest are widescreen TV sets with MUSEMTSC converter.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001272"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Evolution of Infrastructures Towards 16/9 Digital and High Definition",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jean-Pierre Lartigue"
                  ],
                  "abstract": "This paper aims to describe the overall evolution of the new 16/9 market in Europe and the progress which can be subsequently made in the field of High Definition. — The current efforts at establishing a 16/9 market in Europe illustrates very well the future steps needed to implement High Definition.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001270"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "Subjective Evaluation of the digital HDTV Grand Alliance System",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lew Stelmach",
                    "Annu Chopra",
                    "Philip Corriveau",
                    "Robert Leafloor"
                  ],
                  "abstract": "Subjective evaluations of the digital HDTV Grand Alliance system were performed by the Advanced Television Evaluation Laboratory of the Communications Research Centre in Ottawa, Canada. The overall quality of the Grand Alliance System in both interlaced and progressive modes was examined. Additional tests were conducted to assess the ability of the system to coexist with NTSC and to support scan conversion at the receiver. The system met or exceeded the specified requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001269"
                  }
                }
              },
              {
                "article_local_id": "43",
                "article_title": "HDTV in the U.S. – Progress Towards Commercial Service",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/43/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glenn A. Reitmeier"
                  ],
                  "abstract": "This paper provides an overview of the current state of digital HDTV development in the U.S. and the likely prospects for continued progress towards the introduction of commercial products and services. For those who are not intimately familiar with the U.S. situation, this paper summarizes the roles, achievements and status of various key organizations and projects.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001271"
                  }
                }
              },
              {
                "article_local_id": "47",
                "article_title": "The Video Z-buffer: A Concept for Facilitating Monoscopic Image Compression by Exploiting the 3-D Stereoscopic Depth Map",
                "article_url": "https://journal.smpte.org/conferences/International%20Workshop%20on%20HDTV%20'96/47/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sriram Sethuraman",
                    "M. W. Siegel"
                  ],
                  "abstract": "Compression can be achieved by exploiting knowledge both internal and external to a given image or video source. In this paper, we present means for generating and exploiting the specific external knowledge of a 3D stereoscopic depth map of the given scene to compress the given monoscopic source. Several instances in which the depth map can potentially increase compression or provide improved functionality are presented to motivate further work along this line of reasoning.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001275"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "Proceedings: The 30th SMPTE Advanced Motion Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas J. Bentsen"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00455"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "The Integrated Broadcast Facility",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Cirka"
                  ],
                  "abstract": "Brughetti, a division of Discreet Logic Inc., was formed in 1993 to design and develop an integrated resource management, content creation and transmission system for the broadcast market. The Brughetti System is a unique set of software applications that efficiently manages broadcasting and post-production resources. — The Brughetti System merges the worlds of computer and video. With the Brughetti System, facilities are able to efficiently connect, access and manage their existing resources. Brughetti's open, scaleable systems offer a flexible, digital-based solution which can be continually upgraded as client needs evolve and audience demands change. — This document provides an overview of the Brughetti System as it relates to integration, production and facility design for broadcasters. The Brughetti System offers broadcasters a long-term, innovative structure designed to help realize benefits such as improved reliability, quality, flexibility and productivity.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00457"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "The “Time Machine” Increases, Decreases and/or Shifts Time",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William B. Hendershot"
                  ],
                  "abstract": "A “Time Machine” has been developed which is capable of increasing, decreasing and/or shifting passages of time for television signals by at least 30 seconds each 1/2 hour period. This machine evolved from the Prime Image, Inc. “A/V Delay” product and is capable of changing time without changing the pitch (frequency) of the video or audio programming. This is accomplished by adding and subtracting packets of time. The process causes minimal to no degradation in the processed audio and video programming and can be accomplished in real time. The resultant signal is compatible with standard television signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00459"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "FARAD: A Storage System for Random Real-Time Data",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takashi Totsuka",
                    "Yasunobu Kato"
                  ],
                  "abstract": "Many multimedia applications demand real-time and high throughput data retrieval from a storage subsystem. Very often, the access pattern of such retrieval has random nature. This is due to realtime playback of video clips that are physically separated on the disk platter (non-linear editing), or due to serving many independent clients simultaneously (video on demand). Hence, minimizing the overhead incurred by random access is very important for multimedia applications. Moreover, the storage subsystem must response in real-time to such random disk access requests for failure to do so will cause uncomfortable noise on played images and sound. — We have developed a collection of technologies for multimedia storage systems, called FARAD. This paper focuses on the most important part of the technologies: a new disk management algorithm that minimizes the random access overhead. While existing algorithms treat the rotational delay as uncontrollable, the FARAD controls both seek and rotational delay by proper scheduling and data placement so as to reduce overhead under random data access environment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00460"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Optical Video Disk Recorder with Large Storage Capacity using Small Size Phase-Change Media",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "T. Matsui",
                    "T. Uchikawa",
                    "S. Itoi",
                    "M. Miyatake"
                  ],
                  "abstract": "We have developed optical video disk recorder with large storage capacity using small size phase-change media in which Silicon thin film is included. The recorder has a memory capacity of 10.4 Giga Bytes for both sides of the disk. — The recorder has proved 40 minutes recording at a bit rate of 34 Mbps. The recording signals are composed by compressed video signal at 25.8 Mbps and non-compressed audio signal and control signal. The recorder also possesses a feasibility of four hours recording in MPEG-2 signal format.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00461"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Practical Implementation of Advanced Television: Update 1996",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Y. Zou",
                    "James A. Kutzner"
                  ],
                  "abstract": "The official field and laboratory testing is now concluded and their results have yielded new insights as well as confirmed existing information regarding implementation of Advanced Television in the U.S. Concurrently, the FCC has issued a new Notice and the final implementation timetable is being debated. This paper presents summaries leading to more specific practical implementation models and techniques. Specific issues and findings regarding the network/station architecture, local station models, HDTV/SDTV operation, and simulcasting are discussed. The ATSC standard, signal formats, transmission schemes, and new presentation and storage methodology are discussed as the specific challenges are addressed. Finally, implementation cost models revised from previous discussions are presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00462"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Digital Light Processing™: The Convergence of Television and Computer Display",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Vishal Markandey",
                    "Gregory Hewlett",
                    "Gregory Pettitt"
                  ],
                  "abstract": "The distinction between the television and the computer is blurring. This is apparent by the increase in interactive video information services, computer video applications, and the growing number of products that encompass both computer and telvision functionality. — From a technical perspective, as television technology becomes increasingly digital, it is destined to meet the computer, which is already inherently digital and increasingly suited to handle the intesive processing requirements of digital video. Advances in capture, storage, transmission, and digital signal processing all contribute to the visual information migration from analog to digital. Digital Light Processing displays are optimally suited to integrate into the digital visual information infrastructure encompassing television, computer, and new cross-functional applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00471"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Temporal and Resolution Layering in Advanced Television",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "Current proposals for Advanced Television for the United States are based upon the premise that temporal and resolution layering are inefficient. These proposals therefore only provide a menu of individual formats from which to select, but each format only encodes and decodes a single resolution and frame rate. In addition, it is being suggested by some people that interlace is required, due to their claimed need to have one thousand lines at high frame rates, but based upon the notion that such images cannot be compressed within the available 18mbits/second. — This paper discusses an approach to image compression which demonstrably achieves thousand line image compression at high frame rates with high quality. It also achieves both temporal and spatial scalability at this resolution at high frame rates within the available 18mbits/second. This technique efficiently encodes 2 MegaPixel images at 72 frames per second, achieving over twice the compression ratio being proposed by ACATS for advanced television. Further, this proposed technique is more robust than the current unlayered ACATS format proposal for advanced television, since all of the bits may be allocated to the lower resolution base layer when stressful image material is encountered. — Thus, a number of key technical attributes are provided by this proposal, allowing substantial improvement over the ACATS proposal. These improvements include: the replacement of numerous resolutions and frame rates with a single layered resolution and frame rate; no need for interlace in order to achieve a thousand lines of two million pixels at high frame rates: and compatibility with computer displays through the use of 72 frames per second.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00472"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Motion Portrayal, Eye Tracking, and Emerging Display Technology",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Poynton"
                  ],
                  "abstract": "This paper explores how the temporal characteristics of image capture and image display devices interact with eye tracking. — A display system with a large pixel count can be exploited only by having a wide viewing angle, such as the 30 degrees of HDTV Eye tracking – which is insignificant for conventional television – becomes significant in HDTV. A fast-moving element might take as little as two seconds to traverse the width of a screen. For 1920 samples per picture width, this corresponds to 16 pixels per field time at 60 Hz. Artifacts due to temporal effects at the camera, and artifacts due to temporal effects at the display, can be expected to surface in HDTV displays. — Many emerging displays have pixels that emit a constant amount of light throughout a large fraction of the frame time – they have long duty cycles. We have little experience of motion portrayal on displays having long duty cycles. Computers cannot yet display full-screen motion, and although conventional television can display smooth motion, it is restricted to arrow viewing angles. But it's clear that wide-angle, long duty cycle displays will introduce substantial blur on objects that the eye is tracking, and thus will have poor motion portrayal. — Many emerging display technologies, such as plasma display panels (PDPs) and deformable-mirror displays (DMDs) are intrinsically bilevel: At any instant in time, light is either emitted or not at any pixel. Apparent grayscale reproduction can be achieved by pulse-width modulation (PWM). The PWM technique works well when image content is static. But when PWM is combined with eye tracking in scenes with rapid motion, a new class of artifacts is introduced. — Digital technologists have long speculated about displays where each pixel is updated independently. It is assumed that if updating is at least as frequent as the arrival of new frames, the display will be free of artifacts. I will prove using several very simple examples that artifacts will be introduced unless the updating process is spatially coherent.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00474"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Distributed Facility Control via Ancillary Data",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William C. Miller",
                    "Alfred Molinari"
                  ],
                  "abstract": "Remote control of television equipment is usually done with separate, dedicated cabling, using either hardwired connections, a data routing matrix or more recently a local area network. This separate cabling presents many problems to the design engineer. This paper describes a system for remote equipment control which embeds the control information within the serial digital video signal, enabling control to be established wherever the baseband video can be delivered.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00465"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Issues of Contention: Challenges in a Digital, Server Based, Broadcasting Environment",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard J. Echeita"
                  ],
                  "abstract": "DIRECTV, Inc., initiated operations at its all-digital Castle Rock Broadcast Center (CRBC) on June 17, 1994. The broadcast center contains a 512-by-512 SMPTE 259M serial digital router, controls more than 300 digital VTRs, and broadcasts nearly 200 channels via the DIRECTV geosynchronous Direct Broadcast Satellites. This paper describes the issues and challenges facing DIRECTV in evolving the CRBC and its other facilities toward a “server based” architecture. Tentative conclusions may change as requirements change and technology matures. This paper is intended to provide a basis for industry discussion of key issues.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00458"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "New DSP-Based Studio Platform",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Nitzsche",
                    "Larry Baxter"
                  ],
                  "abstract": "A revolution in high-end video hardware over the next few years will replace dedicated digital equipment with fast, reprogrammable computers. The advantages of high speed computers are compelling, including pay-as-you-go scalable architectures, single-reprogrammable-box replacements for multiple dedicated boxes, and the ability to utilize the profusion of high quality, low cost personal-computer graphics programs to enhance video productions. Mercury Computer Systems, with a decade of systems design experience in high speed parallel computing, is building a state-of-the-art real-time multiprocessing video platform for broadcasters and high-end studios.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00456"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Switching and Splicing of MPEG-2 Transport Streams",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bill Helms",
                    "Mike Perkins"
                  ],
                  "abstract": "Seamless switching between video sources is one of the most challenging operations in both the traditional analog and the newer uncompressed digital formats. With the advent of digital compression technology, such as MPEG-2, the problems associated with seamless switching (referred to as splicing within the standard) are even more complex. It is the purpose of this paper to detail the use of the syntactic elements within MPEG-2 that facilitate splicing, particularly those of the transport stream, and to discuss areas for which standards of practice need to be adopted. An example convention is given that would allow seamless switching of MPEG-2 transport streams.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00463"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Benefits of Motion Picture Delivery via the Internet",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Davis"
                  ],
                  "abstract": "At a time when nearly every motion picture studio maintains a World-Wide Web site, the process of delivering promotional movie content to cyber-surfers is both time-consuming and underwhelming in terms of impact. Today, Internet users compete with one another for bandwidth in accessing popular web sites – adding multi-megabyte movie clips to these web sites merely exacerbates this problem. All indicators suggest these Internet traffic jams will not subside, but will become more commonplace.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00469"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Video and UTP",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen H. Lampen"
                  ],
                  "abstract": "As the analog broadcast and digital data worlds converge, one area with a great deal of interest is in running video signals over unshielded twisted pairs (UTP). Because of the differences between coaxial cable and twisted pairs, the differences between analog video and digital video, and the wide range of picture quality attainable, there is a lot of confusion. This paper is an attempt to sort out the various parameters and requirements and allow an end-user to make an informed decision. — This paper is divided into four sections: Twisted Pair Technology, Analog Video, Broadband, Networking Digital Video, and Digital Video. Each has its own set of requirements and system parameters. Twisted pair technology is ideal with some and difficult with others.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00466"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Delivery of Distance Learning Content Across High-Speed and Low-Speed LANs in a Campus Environment",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David H. Dirks",
                    "Doug Coffland"
                  ],
                  "abstract": "While distance learning technologies have been in existence for over 30 years, new forms of transport and delivery are required to provide asynchronous or “just-in-time” instruction. Advanced Local and Wide Area Networks (LAN's, WAN's) allow distance learning content to be delivered in the form of video-on-demand to the corporate employee at any time and virtually anyplace. The Advanced Video Research Project (AVRP) at Lawrence Livermore National Laboratory (LLNL) is developing applications and tools to transport compressed video and audio content across low-speed and high-speed LANs to the employee desktop. Our efforts include finding cost-effective means to deliver MPEG-1 compressed content via 10 Mbps ethemet, 25 Mbps ATM, and 155 Mbps (OC-3) ATM. We are testing and evaluating commercially available systems. In addition, we have developed a custom user application and interface.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00467"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "The Generation and Delivery of Distance Learning Courses via Analogue and Digital Transmission Modes within the U. S. and Worldwide",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Aubrey Harris"
                  ],
                  "abstract": "This paper describes distance learning technologies utilized by the Stanford Instructional Television Network (SITN), which is the largest single university provider of televised graduate-level engineering and computer science courses in the world. Using a variety of delivery methods, SITN provides engineers, scientists and technical managers throughout the U.S. and worldwide a means to extend their education without leaving their workplace by delivering to them graduate engineering courses, degree and certificate programs, short courses and research seminars. Every year, SITN transports over 250 credit courses to more than 200 locations in the U.S. and throughout the world. During a typical week 75 credit courses are broadcast; SITN produces well over 200 hours of live television broadcasting every week. — Programming originates from ten specially designed studio classrooms each equipped as a complete TV studio utilizing robotically-controlled TV cameras, special-effects generators, student microphones, ‘return-video’ monitors and return-audio circuits from the distant sites. — The delivery modes utilized are: (1) a five-channel 2.6GHz microwave system using cardioid and point-to-point antennas, (2) two-way compressed video/audio using teleconference codecs on switched 56 Kbps and ISDN lines, (3) seven 6Mbps MPEG-2 channels on telephone company DS-3 fiber, (4) 45Mbps digital codecs through telephone company DS-3 fiber, (5) full-bandwidth and compressed, digitally-coded satellite transmission, (6) the World Wide Web on the Internet, providing asynchronous access to courses from university-based and distributed servers, (7) ATM and (8) Tutored Videotape Instruction: Up to 45 industry locations which are outside the microwave coverage area, receive classes using the Tutored Videotape Instruction (TVI) model. — Classnotes associated with the transmitted classes which were initially distributed by courier for locations close to the University and by overnight mail services to more distant areas are now made available over the World Wide Web providing immediate global access.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00468"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Aspects of Testing in the Convergence of Television and Telecommunications",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David K. Fibush"
                  ],
                  "abstract": "This paper describes test and measurement applications as seen by the television engineer from basic analog television to the convergence area defined by television and telecommunications. Emphasis is placed on compressed data, which is becoming a predominant factor for audio and video. Although there are many useful compression algorithms, MPEG-2 appears to be the most universal, along with its very complete and widely accepted system definition for the transmission of all the data encountered in multimedia applications. The MPEG-2 transport stream, with its small packets, was developed for transmission systems and can be used to carry all types of data. The paper outlines a layered model for systems and testing analogous to the OSI model for communications systems. Following a description of MPEG-2 transport streams, specific test methods for analysis and generation are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00464"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Picture Quality Assessment in Video Compression",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gordon M Drury"
                  ],
                  "abstract": "The current interest in video compression for a range of applications raises the question of how they may be assessed objectively. There is a need to define and to agree criteria and key parameters in order that standards are made as uniform as possible. — Compression systems introduce non-linear waveform distortion which conventional ITS waveforms reflect as poor performance but, when assessed subjectively, the picture grading is more acceptable than the objective measures suggest. Some codecs remove the VBI so any ITS is worthless for at least two significant reasons: firstly, the ITS has not undergone the same experience of coding and secondly a single line in the VBI for in-service measurement [instead of full-field testing out of service] is insufficient. The paper will discuss and clarify the measurement of compression system performance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00473"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Single-Chip 16.7-Million Color PDP Display Controller",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2030th%20SMPTE%20Advanced%20Motion%20Imaging%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yukio Otobe",
                    "Nobuaki Otaka",
                    "Masahiro Yoshida",
                    "Toshio Ueda",
                    "Masaya Tajima"
                  ],
                  "abstract": "We have developed a single-chip PDP display controller that increases the effective color depth from around 32,000 that the PDP can originally provide to 16.7-million colors using error diffusion. The new error diffusion circuitry operates at 50 MHz, allowing us to handle even HDTV images, whereas previous algorithms were limited to static image processing. This chip also provides gain-control and level-adaptive dithering to minimize the gradient distortion and flicker caused by the application of error diffusion to the PDP.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1996-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00470"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1995",
        "conferences": [
          {
            "conference_name": "New Foundation for Video Technology: The SMPTE Advanced Television and Electronic Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "8",
                "article_title": "An Innovative Approach to MPEG Mastering",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew Rosen"
                  ],
                  "abstract": "In this paper we detail the configuration of the Warner Brothers' Compression Facility at California Video Center, and outline the individual steps in our MPEG mastering process. — We address the importance of the inverse telecine and pre-processing steps. We discuss the challenge of achieving smooth looking 24 fps output from source tapes that have embedded SMPTE A Frame pattern disruptions. A novel technique is described for detecting and logging the SMPTE A Frame sequence into an edit decision list. — The issue of having to chose between pitch accuracy and motion smoothness is raised and we present our position that the most important aspect of the original film is the motion content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00830"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Mastery Learning as a Foundation for Technology Training",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dana Martin-Newman",
                    "Charles Hintz"
                  ],
                  "abstract": "Because technology is constantly changing, consistent and effective methods need to be used by technical instructors to equip support technicians with either new or updated skills specific to this new technology. However, before support technicians can be trained, instructors must learn about both the new technology and the most effective method of teaching this technology to their students. This paper introduces to instructors within the SMPTE community the Mastery Learning Model, an effective method of teaching technical students.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00839"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter A. Dare"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00823"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "The SMPTE D-6 Digital Recording Format",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jurgen K.R. Heitmann"
                  ],
                  "abstract": "The paper will describe the 19mm type D-6 digital 1Gbit/sec recording format which is presently under final review of SMPTE standardization committees. Part one of the D-6 format documents specifies the format and recording method of the data blocks which form the helical records on 19 mm tape. This part of the standard is totally independent of the nature of the recorded digital signals and need not to be changed if any new image interface standard is coming up. Part two of the D-6 documents specifies the content of the data blocks which form the helical records. The data recorded may be digital video and audio of various image standards up to approximately 1Gbit/sec. All image standards recordable by this new format employ identical track pattern, identical inner and outer error correction block structure and identical modulation code. Parameters which vary for different interface formats are listed in tables. The later adding of any new interface format can easily be done by adding one additional line with new parameters to these tables.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00831"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Video Compression: The Need for Testing",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "G. Beakley",
                    "C. Cressy",
                    "J. Van Pelt"
                  ],
                  "abstract": "Video compression continues to permeate the television environment, becoming more common place from the studio and edit suite to transmission and broadcast. Consumers will view video programs that will have compression added to compression. How will the quality be judged? is the compression really lossless or lossy? What is actually happening to the video? The fact is, video compression is here and will continue to expand and affect the production, postproduction, distribution and transmission processes. Now, more than ever, reliable testing methods are needed to quantify the performance of video compression Presently, standardized objective measurements do not exist for digital video compression testing. StellaCom has implemented measures from a number of sources and others of our own design on a low-cost workstation. These measurements utilize complex digital image processing techniques to analyze differences between source and processed video sequences. This paper presents some of the issues and concerns of video compression applications in a global television environment, and describes our implementation of an automated system to capture and test the quality of digitally compressed video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00829"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Report on the Technology Test of the Cinema of the Future",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Mizer"
                  ],
                  "abstract": "Since the 1950s futurists have envisioned an Electronic Cinema, especially including Francis Ford Coppola, who upon his return from viewing emerging High Definition Television in Japan in the early 1980s, became convinced of the role digital technology would play in the production and distribution of motion pictures. Beginning in 1992, Pacific Bell has been pioneering the implementation of that concept through the public demonstration of the “Cinema of the Future”. — This paper will provide the background for understanding this concept, beginning with a discussion of the relevant attributes of the movie production-distribution-exhibition value chain that exists today. Then it will describe the evolving network architecture and hardware requirements needed to implement electronic film distribution, from the current state-of-the-art to some predictable advancements. This will be representative of the work being done by Pacific Bell in testing this technology. — To get from where the industry is today to this theater of the future requires a transition plan that takes advantage of benefits that accrue from additional features and functions a digital cinema can provide, for example, eliminating piracy and other “leakages” through a secure digital transmission and storage network, that also provides dynamic scheduling, ad insertion, and demographic variations like rating and ending options. — Finally, the theater of the future will be a multi-use venue, showing closed circuit pay-per-view events, like sports, concerts or plays, business conferences for new product introductions or major announcements, and interactive live-action adventure rides, all of which will increase the utilization factor of theater seats. In concluding, it is announced that a technology test of the “Cinema of the Future” will take place in 1994, and that 1995 will mark the beginning of a transformation that likely will complete early in the 21st century.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00835"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Poynton",
                    "Peter D. Symes"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00824"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Non-Compressed NTSC Digital Video Disk Recorder",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "T. Matsui",
                    "T. Sekiguchi",
                    "T. Katagiri"
                  ],
                  "abstract": "A digital video disk recorder, whose net information bit rate is 93Mbps and whose recording capacity is 23GB, has been successfully developed. The recorder has a 32 minute recording capability for a non-compressed NTSC composite digital signal and can independently reproduce two, three or four channels. The unique recording method for constant bit-length, magneto-optical head implemented by a short wave-length laser and various reproducing modes by multiple heads are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00842"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "MPEG Compression of High Frame Rate Progressively Scanned Images",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Demos"
                  ],
                  "abstract": "This paper discusses experimental MPEG-2 (Moving Picture Experts Group) encoding of progressively scanned (non-interlaced) high frame rate (>70 Hz) ATV/HDTV (Advanced Television/High Definition Television) images at a bit rate appropriate for terrestrial transmission. The feasibility of scalable coding structures within the same bit budget is also being examined. — Image tiling of existing MPEG-2 decoders at standard definition television resolution can yield appropriate high resolution ATV/HDTV formats. The use of existing decoders in tiled formats provides an early way to implement ATV/HDTV receiving systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00843"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Simple Scalable Video Compression Using 3-D Subband Coding",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Glenn",
                    "John Marcinka",
                    "Robert Dhein"
                  ],
                  "abstract": "3-D subband coding as a video compression system is particularly well suited for use where inexpensive, simple encoders are needed. Program production or teleconferencing are good examples. Since the system uses octave width bands it is inherently scalable. Real-time programmable hardware has been built to process video at various bit rates using this technique. The results of these tests will be demonstrated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00844"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "A Proposal for Compatibly Improving the Scrambling of SMPTE 259M",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David L. Hershberger"
                  ],
                  "abstract": "A method has been devised which will inhibit the generation of pathological serial digital signals or other serial signals with poor statistics which adversely affect clock recovery and cable equalization. This is accomplished by adaptively dithering the LSB of certain video words only when such a pattern of poor statistics would otherwise occur. LSB dither will not be visible on picture monitors. Furthermore, the dither will occur very infrequently. A complementary descrambler has been developed which will reverse the dither when it occurs. The circuitry which accomplishes these goals is simple. There is no additional time delay introduced by the improved scrambling algorithm. The primary advantage of this system is that the serial digital signal is made much more robust.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00826"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Digital to Analog Conversion—Data and Filter Requirements",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dan Baker",
                    "David Fibush"
                  ],
                  "abstract": "Ringing in the analog waveform caused by the filter response to the converted digital data is not a new problem. Early digital-based character generators for composite television applications caused significant ringing because the digital data produced too sharp an edge in the picture. Due to the specifications of component digital video these edge effects are once again becoming more apparent in television operations. This paper discusses the results of using 13.5 MHz luminance sampling to obtain flat analog bandwidth to 5.75 MHz and how the filter template required by the international standard will inevitably result in some noticeable ringing on fast picture transitions. Data requirements in the digital domain are analyzed using 2-T pulses an example while suggesting a different edge transition that will produce much less ringing. Designers are advised to consider the application of filters or edge processing to reduce the ringing due to digitally generated signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00836"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "1280 × 720 Progressive - A Re-Evaluation",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William C. Miller"
                  ],
                  "abstract": "Until last year, the only production system utilizing the 1280 × 720 image format proposed for use in the United States was the 787/788 line progressive-scan format. This was designed for a hybrid analog/digital transmission scheme which has been superseded, and was not optimized for coexistence with SMPTE 274M, the family of production systems utilizing the 1920 × 1080 image format. The author and his colleagues reviewed the format, and reworked it for compatibility with SMPTE 274M. The resulting system has the same clock rate as SMPTE 274M. All frames are 750 total lines, and there are 1650 luminance sample clocks per line. The SMPTE technology committee and working group responsible for ATV production standards have recently reached consensus that this 750-line system should replace the 787/788-line one.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00832"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "The Art of Video Encoding: Optimizing MPEG Video Compression through Human-Assist Methods",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mauro Bonomi"
                  ],
                  "abstract": "The video industry is going digital, opening a world of new markets and distribution opportunities for content providers. Digital video compression is the key enabling technology behind this trend, trimming bulky video data down to fit bandwidth-constrained media such as CDs and coaxial cable. This paper explores a variety of “human-assisted” techniques and how they can be employed in a digital video publishing environment to dramatically increase the quality of the MPEG compressed video. It first describes MPEG encoding and some of the problems that can be encountered in the process, and then discusses several different tools that can be used to improve quality. It concludes with an overview of the entire compression process.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00827"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Switching Facilities in MPEG-2: Necessary but Not Sufficient",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. Merrill Weiss"
                  ],
                  "abstract": "MPEG-2 provides a number of facilities intended to permit the time concatenation of separately-compressed program segments. These are intended to permit the assembly and insert editing of programs downstream from their encoding or release points. They furnish, for example, an indicator for where switching can occur and a countdown to the switching point, as well as other such bits of information. These are necessary to support some of the mechanical aspects of switching between segments in the assembly of programs and other continuity elements for release and in the downstream insertion of commercials. — The switching hooks provided in the MPEG-2 Transport Stream packetization, however necessary they may be, are not sufficient to the task. Several operational steps must be taken for continuity integration to succeed in producing a smoothly flowing output without the appearance of a “channel change” at the switching points. Indeed, for the successful integration of material encoded at different facilities, these operational steps must be precisely defined and standardized. — This paper examines the supporting functions provided by MPEG-2 and will suggest a number of areas in which agreement must be reached on operations practices before successful networks can be built.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00828"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "European HD Video Coverage of Lillehammer Olympic Games ′94 in the Context of the European Widescreen Market",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michel Oudin",
                    "Jean-Pierre Lartigue"
                  ],
                  "abstract": "VISION 1250 is a European association of audiovisual companies, which represents the focal point for 1250 High Definition Video Production, the High Definition production standard chosen In Europe. 37 companies are involved in the activity of our grouping, in which they conceive 1250 HD Video projects together and study the strategic developments of the Widescreen and HD Video market. These companies are private or public broadcasters, independent producers, telecom operators, professional and consumer manufacturers. VISION 1250 is located in Europe, but it is open worldwide to the companies which meet its objectives. In practical terms, VISION 1250 provides expertise, common actions, exchange of information and program material. We also advise on actions aimed at the improvement of the mechanism available to help In 1619 production and 1250 HD. Indeed we believe that Widescreen and HD broadcast need viable programs and that the production program learning curve must begin now. VISION 1250 organizes the promotion of 1250 HD through international conferences, demonstrations and publications. It participates in training and seminar initiatives for the improvement of technical and production knowledge in High Resolution techniques. Its organizes every year the Widerview Conference which gathers together around the subject of HD Video production and the 1619 market, producers, broadcasters, manufacturers, facilities houses, international organizations and European experts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00833"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "A Guided Tour of Colour Space",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Poynton"
                  ],
                  "abstract": "Video processing is generally concerned with colour represented in three components derived from the scene, usually red, green and blue or components computed from these. But accurate colour reproduction depends on knowledge of exactly how the physical spectra of the original scene are transformed into these components, and exactly how the colour components are transformed to physical spectra at the display. These issues are the subject of this article.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00840"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "A Digital Editing Suite in an Analogue Environment",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Reinhard E. Wagner"
                  ],
                  "abstract": "After installing a digital serial editing suite with connections to analogue devices via D/A- and A/D-converters, the limit of D/A conversion was obvious. Rise and fall times after SAV and before EAV, which are not in conformity with the analogue requirements, are producing massive Ringing. Missing requirements in the CCIR 601/656 and SMPTE 259M are giving all designers the ability to interpret the Recommendations the way they would like to have it. ITU and SMPTE are paying attention on this fact, as well as Tektronix, after receiving my inquiry, how the Recommendations shall be interpreted. The implementation of digital filtering at the source, where the digital signal is generated is necessary.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00838"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Wide-Color-Gamut System",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ryoichi Yajima",
                    "Shinichi Sakaida",
                    "Masaru Kanazawa",
                    "Junji Kumada"
                  ],
                  "abstract": "The color gamut extention with the negative RGB method for the STEP 2 colorimetory has been studied. Along with the negative RGB method, we investigated into the color reproduction characteristics of conventional television systems, and propose a method to improve these characteristics. We developed a hardware, and confirmed that the hardware has widened color gamut effectively using the proposed method.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00834"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "A Proposal for Open Architecture Digital Communication Systems Based on Standard Media Publishing Apertures",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Craig J. Birkmaier"
                  ],
                  "abstract": "This paper explores requirements for an open digital imaging architecture, one in which content can be shared among industries and applications with diverse presentation requirements. It is based on an assumption that is rapidly becoming the new reality. Intelligence will be widely distributed throughout the infrastructure. Multipurpose information appliances will adapt to evolving standards by loading software objects that reprogram the appliance for a particular application; modular upgrades of processors, modems, compression codecs, and video processing subsystems will provide extensibility. Furthermore, performance and functionality can evolve with the digital infrastructure without making existing components obsolete, in much the same way that personal computers have evolved over the past decade. It should be noted that this assumption in no way precludes the development of single function, mass produced information appliances, optimized for specific applications. — Analog standards establish an upper limit on performance and functionality. These standards therefore, are often designed with significant headroom to allow for enhanced performance in the future. This practice allows mass-market standards to exist for economically viable periods of time; however, components that comply with the standard may be very expensive in the early years. — Digital standards should be enabling, specifying minimum rather than maximum levels of performance and functionality; these minimum standards support essential levels of interoperability. As such, they will form an affordable foundation upon which competitors can build the emerging digital communications infrastructure, continuously enhancing performance and functionality as the underlying technology evolves. — This paper explores the minimum requirements for Open Architecture Digital Communications Systems. Based on discussions of nine critical issues, it outlines an entirely new approach to the design of a digital communications infrastructure and the information appliances that will be connected to it. These issues include: (1) The establishment of scalable and interoperable hierarchies for basic image parameters; (2) Minimum requirements for common raster representations of visual information; (3) The establishment of multiple quality of service levels through the choice of spatial resolution families, with appropriate relationships between the service levels; (4) The establishment of multiple quality of service levels through the choice of appropriate temporal rate families, with appropriate relationships between the service levels; (5) The Establishment of Extensible Representations for Colorimetry, Dynamic Range and Transfer Characteristics; (6) Requirements for a safe aperture for electronic publishing over the National (or Global) Information Infrastructure; (7) Support for universal time-based media files with multiple content tracks identified by header/descriptors; (8) Support for local visual composition and navigation tools in information appliances; (9) Modularization of standards to support interoperability and backward compatibility with current television and motion picture standards. — In an open architecture digital communications system, the content producer should be enabled and encouraged to utilize the best tools to deliver the content (even tools we cannot imagine today). Such a system requires an entirely new kind of electronic canvas, optimized for the inherent strengths of digital networks and the intelligent information appliances that will be connected to them.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00837"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Are RAIDs Redundant?",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Turner"
                  ],
                  "abstract": "The impact of digital disk recording on the television industry has been widely acknowledged. Its zero pre-roll and single frame recording features have made it the tool of choice in both post production and graphics markets. Traditionally, DDRs have been of the “Parallel Transfer” variety. Rapid changes in disk technology have made longer duration RAID-based disks a reality. There is a great deal of confusion about the difference in these technologies and what impact future developments in disk technologies will have on RAIDs. A number of possibilities are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00841"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Video—For here or to Go?: Using Compression and Packetization in Television Production Facilities",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David J. Bancroft"
                  ],
                  "abstract": "There is considerable discussion today about the compression and packetization of video signals for broadcast distribution and emission. This paper however concentrates on the next candidate area for these techniques: broadcast-grade production, and highlights the economic and technical advantages they will bring into this area. Some of the issues may be easier to resolve than in broadcast emission, because the interconnection network will be more under the control of the user. Other issues will be harder, because of more stringent quality requirements. — Standards must be chosen now before multiple, incompatible formats proliferate; the criteria are being defined in working groups within SMPTE and will be discussed here. The layered approach of the telecommunications world promises durable, yet upgradable standards, and can be tackled with a “shopping list” philosophy, allowing the production industry to choose outside technologies that satisfy its unique technical needs, yet are in wide enough use elsewhere to offer significant economies of scale. — The speed of advance of higher speed networking technology will obsolete small incremental upgrades very quickly, so careful planning is needed in new plant design to prevent this trap and ensure that production facilities benefit from the rapid inward migration of ever-faster and more flexible signal distribution schemes, such as ATM. — The next ten years will see a change away from “home-brewed” interconnection methods and toward “imported” technologies, but the broadcast production industry will have to assert its own requirements very strongly to make these alternatives succeed. A successful outcome will be the integration of compressed, uncompressed, real-time and non-real time video traffic within a common interconnection medium.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00825"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Digital Acquisition without Compromise-the Missing Link",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alec Cawley",
                    "Peter Owen"
                  ],
                  "abstract": "Editing techniques in film and television are changing rapidly. Non-linear disc based systems already enjoy a substantial installed base addressing off-line, news quality and full post production requirements. Undoubtedly the role of the VTR in editing and post is diminishing, being superseded by more flexible and cost effective non linear systems. This trend suggests a tapeless future and proposals already exist for disc based camcorders and M/O technology archiving. Technologically exciting, many such schemes capitalise on the inflexibilities and occasional unreliability built into video tape formats by the need to edit on tape. — Starting from the viewpoint that all editing will be performed in a non tape environment, the paper analyses the true expectations and requirements of a tape format. Concentrating only on tape for acquisition, frees the format in many ways. Constant speed, constant data rate may be parameters of the past. Flying erase heads, full width erase heads and computer servos could be technology of the past. A cruder variable linear speed recorder may suffice. — Capable of handling compressed and full CCIR 601 quality — a new format could enjoy wide acceptance, through low cost flexible acquisition.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00846"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "ISDB and its Transmission System",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takeshi Kimura",
                    "Naoki Kawai",
                    "Kouji Ohsaki",
                    "Seiichi Namba"
                  ],
                  "abstract": "ISDB(Integrated Services Digital Broadcasting) is a concept for digital broadcasting which has flexibility, extensibility, interoperability with other media, etc., and provides various kinds of services via different types of transmission channels with maximum commonality. NHK originally proposed the concept of ISDB in 1985 and since then has been doing research on services, transmission systems and transmission channels based on the concept. This paper outlines the ISDB services and transmission channels, and highlights the transmission system of ISDB and prototype transmission equipment developed by NHK. — The multiplexing system of ISDB uses a packet multiplexing method that provides flexibility for various service configurations and extensibility for introducing new services. NHK has been contributing the concept of ISDB to MPEG2, therefore multiplexing of ISDB is compatible with MPEG2 part 1 (systems). The transport system employs a frame structure for robust synchronization against transmission error. It also employs a sub-frame structure for hierarchical transmission (or graceful degradation) and for reducing the speed of the decoding process to simply the decoders. NHK has developed a prototype ISDB system and experimental transmission equipment. The equipment is capable of broadcasting multiprogram TV services together with data services through satellite broadcasting channels, such as a 12-GHz-band 27-MHz-width channel. It applies a priority-based packet multiplexing and variable-bit-rate picture coding and multiplexing. The prototype equipment has been used in various tests and demonstrations: of multiprogram TV service, of HDTV service, of a captioning service, and of the statistical multiplexing of TV services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00845"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "New Foundations for Video Technology: Which Ones Do We Build on and Why?",
                "article_url": "https://journal.smpte.org/conferences/New%20Foundation%20for%20Video%20Technology:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Paulson"
                  ],
                  "abstract": "GIVEN The audience reading or listening to this paper is 100 percent composed of engineers and managers all searching for new foundations on which to build growing, profitable 21st century entertainment production and broadcasting businesses. “Technology” is in reality a two-headed beast which both helps and hinders this effort. Emerging technologies provide many types of foundations for the new business opportunities in view. But the merging of these technologies with others, as they emerge, creates more but undefinable new business opportunities, that the new foundations may not be designed to support. — The almost complete merger of the separate and bitterly competitive motion picture and television entertainment production and distribution industries of fifty years ago is an example of business opportunities in view. The just beginning merger of computer and television technologies to create “interactive” “multimedia computers,” which operate on “information superhighways,” et al, is an example of undefined business opportunities — THEREFORE Foundations for future motion picture or television production, postproduction and distribution systems therefore need to be designed as “future-proof.” How can that goal be achieved, if the opportunities are invisible behind the fog formed by these descriptors? — Directing the question to RCA Camden for an answer was a technique that worked in the 1970s. Choosing one hardware manufacturer for cameras, VTRs, cart machines and switchers, a second for editing and effects systems, and a third for master control and routing, was the more complex but still satisfactory 1980s technique. Engineers on staff and savvy broadcast industry consultants provided the facilities design expertise. — In the 1990s, –? Few companies have engineers on staff with time for detailed facilities design assignments. A comparison of the NAB exhibitor rosters of the mid 1980s and 1995 establishes that an alarming number of the old reliable hardware companies have been replaced by unknown but fast growing companies with strange coined names and software products. Computer technology dominates the design of hardware products. Product improvements are effected by installing a another software “rev.” Analog is being engulfed by digital, and compressed digital is the future. Long-time “filmless” facilities are now trending toward “tapeless.” Fiber is becoming the transmission medium of choice. The government-touted National Information Infrastructure and HDTV for the masses are posited as the future of the broadcasting industry. — Obviously, maintaining the viability and profitability of a motion picture or television facility into the undefinable future isn't doing more of what you did in the 1970s and 1980s.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00847"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "Proceedings 137th SMPTE Technical Conference and World Media Expo",
            "conference_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/",
            "articles": [
              {
                "article_local_id": "5",
                "article_title": "Concepts for Nonlinear Field Acquisition for Broadcast Operations and DNG Systems",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Fasciano"
                  ],
                  "abstract": "This proposal examines the opportunities for nonlinear disk technology in the area of on location digital video recording. Momentum for this effort comes from the growing population of finish quality, nonlinear editing systems and the desire of users to migrate front-end videography tasks directly into the digital domain. Industry acceptance is rapidly rising for compressed digital video technology and virtual for acquiring, managing, modifying, storing and distributing digital video and audio signals, suitable for broadcast.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00479"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Professional Video under 32-Bit Windows™ Operating Systems",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alain Legault",
                    "Jean Lapierre",
                    "Louis Dionne",
                    "Tim Cherna"
                  ],
                  "abstract": "The PC and 32-bit Windows operating systems are quickly becoming the platform of choice for professional video, film and multimedia producers. What 486 machines and Windows 3.0 did to expand the desktop publishing market; Pentium processors, the PCI bus and Windows 95 and NT are doing for the video market. With at least 10 times the installed base of any other platform, Windows users have long benefited from the time and money savings offered by “open platform” interoperability. Professional media producers need the same opportunity to be able to buy the best interoperable hardware and software, from a variety of vendors, at a variety of price/performance points to meet their individual requirements. Vendors are committed to delivering video and audio editing, multimedia authoring, plug-in effects, and animation and graphics creation applications that all work together on PCs with varying performance capabilities. Users can choose all the best tools for their jobs at competitive prices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00480"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Video Applications in the Era of Computer Networks - Computer & Video = Multimedia?",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Norbert Gerfelder"
                  ],
                  "abstract": "The areas of television, telecommunication, and information technology are converging, new services are establishing and new application areas arise. Aside from traditional delivery channels, computer networks play an increasing role for providing the new services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00481"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Stream-Based Computing and Future Television",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John A. Watlington",
                    "V. Michael Bove"
                  ],
                  "abstract": "The computational demands of encoding and decoding motion-compensated transform representations of digital video are well-known, and even hard-wired solutions to single algorithms remain a design challenge. When interactivity or personalization are added, and when algorithms increase in complexity to include structured or object-based representations, not only do the requirements increase but so too does the need for computational flexibility.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00482"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "A Server-Based Post Production System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bob Pank"
                  ],
                  "abstract": "The use of disks in video is spreading rapidly beyond individual machines and into servers. Several distinct application areas can be identified each with their particular demands for bandwidth and access which constitute major differences in performance - that of post production being the most demanding. The design fundamentals for this server and configuration of the whole post production system are reviewed along with its potential benefits in a practical system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00483"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "The Impact of Nonlinear Editing on the Post-Production Process",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael F. Korpi",
                    "Corey P. Carbonara",
                    "Vincent E. Young"
                  ],
                  "abstract": "This paper reports on a study conducted by the New Video Technologies Project at Baylor University which examines the effects of different editing machines on the editing process and answers the question: when compared to linear editing machines, to what extent do nonlinear editing machines affect the final product? The experimental findings show that the nonlinear editing system projects received higher scores and contained fewer mistakes. Additional observations include (1) a difference between education and industry expectations in learning editing techniques, (2) students spent more time on the nonlinear system, and (3) these students approach to editing was more sophisticated using the non-linear system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00484"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Moving Uncompressed Video Faster than Real Time",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Don Deel",
                    "Marc Friedmann",
                    "Howard Green"
                  ],
                  "abstract": "Economical methods are now available to move uncompressed digital video faster than real time in networked environments. Using an ANSI standard Fibre Channel interface on a Silicon Graphics workstation with optimized hardware and software, both computer-to-computer and computer-to-disk communications are possible which can transfer data at rates up to 640 megabits/second. By incorporating these interfaces, post-production facilities can achieve order-of-magnitude improvements when accessing and transferring large video files, and can gain the ability to move streams of digital video data faster than real time for collaborative creative efforts. Video server applications can use these interfaces for both storage access and communications for transporting up to 100 compressed streams simultaneously through a single port.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00485"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Timing and Synchronization Using MPEG-2 Transport Streams",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David K. Fibushs"
                  ],
                  "abstract": "MPEG-2 transport streams are being applied throughout the world to deliver compressed audio, and video in addition to data and control signals. An understanding of the timing and synchronization of compressed television is important to system design and operations just as it is with today's full bandwidth signals. This paper describes the formation of the transport stream with its timing elements as well as their use at the receiver. It also briefly describes test equipment that has been developed to stress the receiver reference clock phase-locked-loop and analyze transport stream data to determine the values and correctness of the various time stamps.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00486"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Practical Implementation of an Optical Network in Broadcast Stations",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Kamise",
                    "S. Ando",
                    "T. Shiozawa",
                    "N. Shimosaka",
                    "M. Fujiwara"
                  ],
                  "abstract": "The new broadcast center of Fuji Television Network Inc., which is to be under operation in 1996, is now under construction. The new broadcast center requires a large capacity and flexible routing network for video/audio signals. It has been decided to employ the newly developed Wavelength-Division and Time-Division hybrid multiplexed (WD/TD) optical network for video/audio signal distribution/transmission in the new facilities, in order to extend possibilities in the coming Multimedia era. This, to our knowledge, would be the world first implementation of optical networks in broadcast centers. A prototype WD/TD optical network has been developed to examine the basic operation and preliminary reliability issues. The prototype has been designed to distribute/transmit 240 digital NTSC video signals, employing newly developed flat gain optical amplifier, and 2.29Gb/s Time-Division Multiplexer/Selector. The prototype has shown successful operation and is now under field trials at the master control room of Fuji Television Network Inc. Based on the results of the trials, the network in the new broadcast station will be designed and constructed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00488"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Factors in Preserving Video Quality in Postproduction When Cascading Compressed Video Systems",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Katie Comog"
                  ],
                  "abstract": "Postproduction equipment increasingly uses video compression to achieve economies of storage and bandwidth. Users of compressed video systems need to be aware of the factors that determine video quality. As compression technology becomes more widespread, the cascading of multiple compression systems increases. The compression techniques which are optimal for transmission and distribution of video are not the same as those which are optimal for postproduction. This paper defines the important factors that determine video quality in compression systems. It describes the differing requirements placed on compression by postproduction and distribution. It concludes by examining results from three cascaded compression experiments using JPEG and MPEG-2.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00489"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Digital Triaxial Transmission Provides Total Digital Studio Camera System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "N. Murata",
                    "F. Ukigaya",
                    "Y. Eto",
                    "N. Sakuraba",
                    "T. Delp"
                  ],
                  "abstract": "Hitachi has developed a fully digital broadcast camera system in which all signal processing and transmission are accomplished in the digital domain. Digital transmission utilizes a newly developed time-division multiplex method that allows bi-directional serial digital transmission between the camera head and camera control unit over standard triaxial cable. All video and audio signals between the camera head and the camera control unit (CCU) are combined into a single 360Mbps serial digital signal for transmission. To provide the highest quality main video with the limited data capability of the triaxial cable, motion JPEG is used to compress the return video channel to 1/7 of its original size. 10-bit data accuracy is used for the Y, R-Y and B-Y signals transmitted from the camera head to the CCU. The Y channel data rate is the same as the CCD readout clock and the R-Y and B-Y data signals are clocked at half this rate. At the CCU, the digital video signals are digitally rate converted directly into either a composite serial digital signal (D2 type) or component serial digital (D1 type) signal for direct interface with digital studio equipment. With the fully digital camera, a true 62dB S/N ratio is available at the CCU output as well as 800 TV lines of high resolution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00476"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "A Digital Solution for Cost-Effective ENG",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Higuchi",
                    "Johann Safar",
                    "Ralph Biesemeyer"
                  ],
                  "abstract": "Electronic news gathering (ENG) gear has evolved into some of the most efficient and rugged video equipment available and over the last 10 years 1/2“ ENG has become the standard for news crews throughout the world. Now, accelerating digital technologies and standards have provided the possibility for even more rugged, lighter weight, and lower power ENG with better overall performance by using digital tape recording.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00478"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jeffrey Friedman"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00475"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Transmission Test Using a 42GHz-Band HDTV Digital FPU",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hiroyuki Tanaka",
                    "Fumiyasu Suginoshita",
                    "Hisao Nakakita",
                    "Kenji Terada"
                  ],
                  "abstract": "To transmit program materials from an outside location to a broadcasting station, FPU(Field Pick-up Unit), a ground radio equipment, is widely employed in conventional broadcasting systems. — Although, an FPU for the HDTV in Japan is allowed to use the 42GHz band on an experimental basis. NHK has been pushing for the development of an FPU in this radio frequency that can transmit HDTV signals without quality deterioration. — At this time, we have developed a new FPU for HDTV. This paper describes this new relay transmission system, and indicates the result of a field test to verify the system's performance.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00477"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Multi-Channel RAM & DISK Recorders for Sports Coverage",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurent Minguet"
                  ],
                  "abstract": "Instant play-back and editing have always been a request of the creative people in sport broadcasting. But VTR technology was not able to provide the best solution because only one single access is allowed to read or write the tape.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00498"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "High Resolution Realtime Scanning - Why it is Necessary",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mike Christmann"
                  ],
                  "abstract": "Mastering and archiving of film material for video distribution was discussed now for a long time. — Today, where the three independent worlds film, video and the computer industry growing together, it makes sense to think about a new philosophy in archiving and mastering film for TV and multimedia applications. — This paper proposes instead of individual film transfers for each of the different TV standards an electronic representation of the film original which allows to generate all desired output variants. The film has to be transferred only once, not twice. — The performance of high resolution realtime CCD film scanner technology, computer signal processing power and disk storage systems makes this new philosophy happen. — In addition the paper outlines the advantages of transferring film into an independent data format instead of a dedicated video standard. — Furthermore it describes a system proposal for this mastering and archiving concept and the necessary equipment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00500"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Computer Bus, Coax and Fiber Media Utilization in Multiple Function, Multiformat Digital Facilities Design",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Paulson"
                  ],
                  "abstract": "Television broadcasting is now in the last phase of its 20-year evolution from all-analog to all-digital facilities. Traditional transmission means of coax and STP (shielded twisted pairs) are still the standards for interconnecting standalone equipment via routers. But stand-alone high speed computers now provide multiple signal processing functions in compact desk-top consoles, moving signals about on parallel buses. Fiber is coming into its own as the medium for transporting broadband serial digital signals beyond coax cable's cliff effect distances. — This is a tutorial on those transmission means.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00501"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Broadcasting Digital Video Lessons Learned: Transmitting MPEG-1 Video over a Microwave Relay System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Koz"
                  ],
                  "abstract": "This paper explores a side-by-side comparison of the behavior of digital video and analog video in a test system, and demonstrates the consistent and controllable behavior of digital video. The video delivery system used for the tests was comprised of a PC-based MPEG-1 encoder, T1 telecommunications lines, a television settop box decoder, and a 27GHz microwave transmission system. Analog and digital video signals were then tested for responsiveness to noise, reduction of power, and interference. As the tests show, digital video has an unrivaled ability to provide consistently high results under very difficult transmission conditions. Unlike its analog counterpart, MPEG video is not susceptible to uncontrollable external factor, such as rain, snow and fog. This ability gives the broadcaster a much higher degree of control over video quality and the ability to evaluate cost vs. quality tradeoffs. For forward looking broadcast and entertainment companies and corporations, MPEG provides a cost-effective way of creating new services and improving the distribution mechanisms for existing services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00502"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "“Delivering the Image Electronically”",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Doyle Sturms",
                    "Bob Stewart"
                  ],
                  "abstract": "This paper will identify the history and the development of delivering the video image. It will describe the events and the technology leading up to today's methods of providing video to the Pre & Post Production Industry and to the theater.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00504"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "DVCPRO: A Comprehensive Format Overview",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "H. Uchida",
                    "H. Isaka",
                    "T. Yoshida",
                    "J. Safar"
                  ],
                  "abstract": "Currently, broadcast and ENG camcorders and video editors use mainly analog ½-inch (12.7 mm) equipment However, as news acquisition increases in importance and digitization occurs throughout broadcasting, more compact and cost-effective digital systems with easy editing, improved features, and high picture quality are now in demand. To meet this demand we have developed “DVCPRO”, a 6 mm video cassette format using digital component recording to assure picture quality that surpasses that of analog component VTRs. Two cassette sizes hold 63 minutes and 123 minutes, and have ¼ the volume, 1/6 the weight, and double the recording time of conventional analog ½-inch cassettes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00494"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Understanding the Video Server",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lynn Chroust"
                  ],
                  "abstract": "While much has been written about video servers at a conceptual level, i.e. the ability to instantly access material, multiple simultaneous streams, etc., little has been written about the key components of a video server and some fundamental rules under which these components operate. This article will endeavor to explain these components, how they work together and their limitations. In the end, after understanding the individual components and then viewing them as a whole system, it will become more clear as to how and why certain broadcast applications are feasible today, while others are on the verge of possibility.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00492"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "W-VHS, a New HDTV Video Recording Format",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Neil Neubert",
                    "David Gifford"
                  ],
                  "abstract": "The first affordable professional video tape recorder capable of recording HDTV production signals applies a unique adaptation of the standard, rugged and proven reliable S-VHS videotape transport technology developed by JVC. The new HDTV videotape recording format, W-VHS, offers significant new opportunity to economically distribute and display HDTV program material. W-VHS VCR's and videocassettes are uniquely derived from low cost VHS and S-VHS VCR and videocassette technology and components. W-VHS HDTV picture quality is, however, excellent, and suitable for many educational, medical, industrial, and entertainment industry applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00495"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Digital Video and Audio Transmission Alternatives",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keith Y. Reynolds"
                  ],
                  "abstract": "As television plants convert to serial digital video and digital audio, it becomes apparent that the analog and digital transmission requirements are vastly different. — In the analog video world, it is necessary to select the proper cable equalizer based on the characteristics of a coaxial cable to correct for the high frequency loss over short and moderate distances. For digital transmission, automatic equalizers are common, eliminating equalizer selection. Transmission distances are limited to about 300 meters (1000 ft) of coaxial cable, depending on the data rate and the characteristics of the cable. In many cases this is adequate in a television plant, but fiber optic links can offer a better solution where longer distances are necessary. This will be especially apparent as we move to HDTV where bit rates will be much higher.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00487"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Objective Assessment of Single and Concatenated Compression Codecs",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris J. Dalton"
                  ],
                  "abstract": "With the inception of broadcast equipments incorporating bit-rate reduction techniques, concern is being voiced by some broadcasters on the cumulative effects of cascading compression codecs of different types. Compression can now be found in all parts of the broadcast chain from acquisition, contribution, processing, recording and distribution. Subjective viewing can give an overall assessment of perceived picture quality but may not indicate the quantitative levels of distortion that could later affect post processing, or the susceptibility to gross errors if the signal is subsequently passed through further compression.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00490"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "MultiMedia Compact Disc: System Requirements and Channel Coding",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kees A. Schouhamer Immink"
                  ],
                  "abstract": "The MultiMedia Compact Disc is a proposal for a new optical recording medium with a storage capacity five times higher than the conventional Compact Disc. The major part of the capacity increase is achieved by the use of optics, shorter laser wavelength and larger numerical aperture, that reduces the spot diameter by a factor 1.5. The track formed by the recorded pits and lands as well as the track pitch can be reduced by the same factor. The storage capacity is further increased by a complete redesign of the logical format of the disc including a more powerful error correction (CIRCPlus) and recording code (EFMPlus). We will outline the system requirements of the MultiMedia Compact Disc and the related channel coding.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00496"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Statistical Analysis of Picture Quality for Digital TV Employing MPEG-2 Video Standard",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eisuke Nakasu",
                    "Katsunori Aoki",
                    "Ryoichi Yajima",
                    "Yasuaki Kanatsugu",
                    "Keiichi Kubota"
                  ],
                  "abstract": "A relationship between bit-rate and picture quality is a major issue of interest for digital broadcasting services. To evaluate coding performance of MPEG-2 video standard, subjective assessment tests for both Main Profile and Simple Profile as well as NTSC were conducted. Since picture quality in digital coding depends largely on such picture characteristics as spatial detail and motion, estimation of picture quality of TV program material requires statistical analysis. We have defined “criticality”, a quantitative measure of difficulty for digital coding, to analyze picture quality of TV programs statistically. We developed equipment to measure criticality and measured a large number of TV program materials for one week. Based on statistical evaluation of picture degradation in real TV programs, we have concluded that approximately 9 Mbps is an appropriate bit-rate for digital broadcasting to maintain picture quality comparable to that of studio NTSC.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00491"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "A New Digital Video Tape Recording System for Professional Use",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Neil Neubert",
                    "Hisashige Fujiwara"
                  ],
                  "abstract": "A new component digital videotape recording format for 525/60 and 625/50 television systems is introduced and described. Development concept for the new format is discussed and includes the technical performance and operational features that were incorporated to satisfy a wide variety of broadcast and professional video recording applications. The recording method, signal processing, and videotape track patterns are illustrated and specified, and the system signals to which the format interfaces are listed and described. The new format introduces a new level of economy and cost effectiveness for digital video tape recording and many of the reasons are highlighted in a discussion of the videotape transport and cassette. Bit rate reduction is utilized, and performance and operational requirements affecting the selection of compression techniques are outlined. The selected bit rate reduction method and its characteristics are discussed and summarized in various tables included. The paper concludes with discussion of variable speed playback, and error handling and correction, and further summarizes their influence on selection of the bit rate reduction techniques.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00493"
                  }
                }
              },
              {
                "article_local_id": "42",
                "article_title": "Optimizing the Digital Video Publishing Process: Coupling MPEG Video Encoding to Video Editing",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/42/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mauro Bonorai"
                  ],
                  "abstract": "The video distribution industry is going digital, opening new markets and distribution opportunities for content providers. Video compression, also known as encoding, makes digital video distribution viable, reducing video data down to fit bandwidth-constrained media such as CD's and ISDN lines. Little or no coupling has been developed between video editing and MPEG video compression. Standard edit decision lists (EDL's) feature information very useful to the encoding task. Coupling editing and encoding will yield superior image quality and productivity and will help the industry bring to market new and compelling interactive products.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00516"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Computer Images Implemented, Displayed and Re-Edited in Post-Production",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Reinhard E. Wagner"
                  ],
                  "abstract": "During the last few years the computer and the broadcast video-production-worlds have come closer together. How can transferring pictures from one source to another be performed, is asked frequently. To transfer an image quickly and easily is a problem, due to differences in pixels, size, shape and picture resolutions. Ways to solve problems and finding quick solutions are on one hand. On the other hand is the increase of education and knowledge. Investing money in huge amounts of software and hardware is sometimes not always cost-effective. A few smart interfaces are on the market that may fulfill all requirements. — From the post-production point-of-view the problem is how to satisfy in a competitive market, customers who are willing to accept reduced picture quality for financial reason and broadcasters who demand A1 picture quality. Our only hope in resolving this problem is the closer cooperation between the computer and broadcast development departments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00508"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "A Dockable Digital Disk Recorder",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark J. Norton"
                  ],
                  "abstract": "A new approach to capturing video and audio media in a field setting is described based on small form-factor disk drive recording package (FieldPak) and video compression technology. These have been combined to produce a dockable digital video recording unit which mates to a variety of ENG cameras, the Ikegami HS-57 for example. A system, hardware, software and feature view is presented to describe how existing technology components can be combined to form a field-portable, reliable digital media collection system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00497"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Effects of ATM Transmission Errors on MPEG-2 Decoded Quality of Service",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ji Zhang",
                    "Mike Perkins"
                  ],
                  "abstract": "This paper describes an experiment that introduced bit errors and bursty cell losses into an MPEG-2 transport stream transmitted using AAL-5. The error-containing transport stream was decoded using a real-time MPEG-2 decoder in order to subjectively observe the effects of the errors on the video quality. We found that not all bit errors or cell losses cause visible degradation of decoded video. Furthermore, given the same bit error rate or ATM cell loss rate, it is desirable for the errors to be clustered rather than uniformly distributed. The result of this study may help to provide guidelines for designing ATM congestion control policies for networks carrying MPEG-2.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00503"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Study Group on SMPTE Documentation of Television Recording Formats Employing Compression Techniques (V16.06)",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mikhail Tsinberg"
                  ],
                  "abstract": "A key issue and major distinguishing factor amongst manufacturers of compression-based digital storage devices are the proprietary algorithms used to compress the video data to be stored. The compression algorithms employed can have a significant impact on the resultant picture quality and deliverable features, readily differentiating one manufacturer over another. Similar to other video compression technology developers involved in such standardization efforts as MPEG-1 and MPEG-2, the algorithm developers for video storage equipment based on compression techniques are hesitant to include algorithm descriptions in standards documents.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00499"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "An SDTV Decoder with HDTV Capability: “An All-Format ATV Decoder”",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Larry Pearlstein",
                    "John Henderson",
                    "Jill Boyce"
                  ],
                  "abstract": "This paper describes techniques for implementing a video decoder that can decode MPEG-2 High Definition (HD) bit streams at a significantly lower cost than previously described high definition video decoders. The subjective quality of the pictures produced by this “HD-capable” decoder are roughly comparable to current DBS delivered Standard Definition (SD) digital television pictures. The HD-capable decoder can decode SD bit streams with precisely the same results as a conventional standard definition decoder. Note that the MPEG term Main Profile at Main Level (MP@ML) is also used to refer to standard definition video in the sequel.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00511"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "Utilizing “Synthe-Vision” for Drama Production",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Masashi Kumagai",
                    "Kiyotaka Aoki"
                  ],
                  "abstract": "NHK has been invented a unique contrivance called Synthe-vision that is a new image synthesizing technique with the eye to the future. It is the technique that has the ability filled with the idea to express such a super real space, therefore we regard Synthe-vision as appropriate for the TV programs for children. — This is the report to explain to use synthe-vision system, how to make the clear vision effectively and also how to cut the cost of production of the children drama.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00509"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Advanced Approach to Universal Video Format Conversion",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Clarence Hau",
                    "Kevin Stec"
                  ],
                  "abstract": "With the continuing evolution of the variety of digital video formats, a high quality conversion between formats is essential. This paper provides an overview of digital video format conversion and introduces a scalable parallel processing architecture that addresses spacial conversions. Video formats vary by sampling rate, line rate, aspect ratio, frame rate, and scan type. In a conversion between formats, these differences must be resolved through spatial resampling, frame rate conversion, and de-interlacing. — The architecture that is introduced tackles the two dimensional conversion that is needed for the sampling rate, line rate, and aspect ratio discrepancies. A resizing filter is at the heart of this processor for the sample and line scaling that is needed. The high sampling frequencies of high definition formats make it difficult to implement the required digital signal processing functions with existing technology. Therefore, a parallel processing approach is taken that permits processing at a more reasonable clock rate.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00507"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Integrated Narrowband/Broadband Access Architecture",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michele Kerrs",
                    "Greg Beall",
                    "Russ Couture",
                    "Douglas Ramsayer"
                  ],
                  "abstract": "SWBT Technology Planning chose a digital fiber optic, integrated narrowband/broadband Fiber To The Curb (FTTC) access architecture for deployment in the Richardson, Texas Video Trial. The trial architecture consists of a two level network: Level 1 and Level 2. The Level 1 network is the infrastructure provided by SWBT. The Level 2 network is that portion which provides the digital video services and the analog broadcast services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00505"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "PBS Delivers Digital Compressed Video, Audio and Data",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Scott Birdwell"
                  ],
                  "abstract": "Since 1988, Public Broadcasting Service (PBS) has embarked on a modernization plan to deliver to it's member stations, multiple digital video, audio, and data signals, via new satellite systems. The Ku-band transponders and ground stations have been in operation. The Technical Operations Center (TOC) at Braddock Place in Alexandria, VA continues the transformation to digital video and audio operations for improved quality of service and increased number television program channels. Those program channels plus auxiliary data are compressed with General Instruments DigiCipher™ I equipment with a planned upgrade to DigiCipher™ II technology early next year. This paper will provide a discussion of the systems, operations and enhancements for delivery of digital program services and information data, from the PBS facilities to the nation's public television stations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00506"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "The History of the Perfect Aspect Ratio",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Schubin"
                  ],
                  "abstract": "A debate is currently taking place over the appropriate aspect ratio for advanced television displays. Any selected aspect ratio is inherently incompatible with any other and will require the use of some form of accommodation technique. The derivation of the 16:9 (1.78:1) aspect ratio from accommodation techniques and display modes is explained. The relationship between aspect ratio and display memory is also explained. Research into the history of aspect ratios indicates that the 1.78:1 aspect ratio was adopted by the standards committee of the Society of Motion Picture Engineers in 1930. It also indicates that the factors that may have led to widescreen motion picture systems may no longer be applicable. The research for this paper found no clear indication of a preference for any particular aspect ratio for moving images nor any physiological reason to favor one over another. The research did show that cinematographers have not always favored a particular aspect ratio.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00514"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Virtual Sound Sources in the Total Surround Sound System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tomislav Stanojevic"
                  ],
                  "abstract": "The Total Surround Sound (TSS) System* has been conceived as a system for generating 3-D sound primarily in cinemas equipped with one of the current multichannel digital audio systems. The paper covers a simplified and relatively easily applicable variant of the system, which assumes a certain rearrangement of loudspeakers needed for surround sound reproduction in such modern theaters. The physical basis here is provided by certain psycho-acoustic laws, as well as an interesting experiment, related to the human ear's reaction to translating the so-called virtual sound source in the vertical plane. The paper also provides in general terms some of the possibilities of using this concept in the consumer technology, such as home video systems, PC multimedia, Interactive Video Games and so forth.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00510"
                  }
                }
              },
              {
                "article_local_id": "41",
                "article_title": "LLK 3 - A New Sound Camera Based on Laser Beam Exposure",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/41/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. P. Monch",
                    "J. Ristow",
                    "P. Stroetzel"
                  ],
                  "abstract": "In order to avoid the disadvantages of existing light valve cameras the new laser beam camera LLK 3 has been designed for recording of analogue tracks with high quality and long time stability. A newly designed drive control system with stepper motor enables bi-phase master and slave operation. In addition it offers the fast and easy implementation of already existing digital recording systems like DOLBY SR-D or DTS. The sound drum of the camera is fitted with a high definition incremental tacho unit which is used for synchronizing the laser beam scanner and the DSP system. The DSP unit takes care of the audio processing and switches the laser beam on and off by means of an acousto-optical deflector. The deflection system works completely without mechanically moved elements, therefore no mechanical resonance has an impact on the frequency response. All important adjustments like track position, exposure intensity, frequency response etc. can be programmed by means of a microcontroller. As the He-Ne Laser is operated at a low intensity level the long term stability and reliability is evident. A sophisticated monitoring system offers unique features such as simultaneous reproduction of the audio signal derived directly from the laser beam via a beam splitter. An ocular in connection with a rotating polygon mirror can be used for viewing the beam recording. Besides the two channel analogue input a digital audio input (AES/EBU-48 kHz) for direct transfer from digital systems is also available. The digital audio processing offers additional possibilities like the recording of special test and control signals or direct simultaneous recording of the DTS-Control signal, etc. The basic recorder model works without PC monitor and keyboard and is controlled only with conventional keys.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00515"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "Analysis of Electronic Cinema Projection with the Texas Instruments Digital Micromirror Device™ Display System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gregory Hewlett",
                    "William Werner"
                  ],
                  "abstract": "As audio and video applications make the transition from analog to digital signal representation, anticipation grows toward the age of the digital cinema, when motion pictures are recorded, distributed, and displayed as bits and pixels rather than as film. Electronic cinema will be digital cinema - and the Digital Micromirror Device™(DMD™) is well-suited to provide the motion picture experience to the digital cinema customer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00512"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "High Efficiency Light-Valve Projectors and High Efficiency Laser Light Sources",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20137th%20SMPTE%20Technical%20Conference%20and%20World%20Media%20Expo/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Glenn",
                    "Carvel Holton",
                    "G.J. Dixon",
                    "Phil Bos"
                  ],
                  "abstract": "The optical efficiency of a liquid-crystal light-valve projector is determined by the optical design, the method of modulation and the efficiency of the light source. A projector has been built with an efficient modulation technique. It employs unpolarized light by using a diffraction grating formed in the liquid crystal. The diffraction technique uses a Schlieren optical system. The light sources tested have been xenon arcs, metal halide arcs and efficient solid-state lasers. The optical system reduces laser speckle significantly when laser sources are used. All combinations exceeded 3 lumens per watt for white light Experimental results of the combinations will be given. This modulation technique obtains a high contrast ratio with smaller panels than can be achieved with rotation-of-polarization light valve projectors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1995-09"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00513"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1994",
        "conferences": [
          {
            "conference_name": "Proceedings: The SMPTE Advanced Television and Electronic Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "Visual Investigation on the Head-Tape Interface in a HDTV Digital Baseband VCR",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takeshi Ebihara",
                    "Jun Itoh",
                    "Yasuo Ohtsubo",
                    "Atsushi Takahashi"
                  ],
                  "abstract": "The spacing between a multi-channel cluster head and the magnetic tape has been investigated by using transparent dummy heads and an original image processing method to develop a 1.2 Gbps HDTV digital baseband VCR. The influence of the head projection and tape tension on the head-tape spacing in a cluster head system, which was unknown before, has been made clear. The authors found the effective improvements to reduce the head-tape spacing of the individual heads of a cluster, and to realize a low tape tension VCR system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00849"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David L. George"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00848"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Performance Evaluation: From NTSC to Digitally Compressed Video",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Y. Zou"
                  ],
                  "abstract": "This paper discusses the general approach of objective and subjective evaluations on digitally compressed video. After brief review of digital compression principles, artifacts associated with video compression are identified along with their origins. To investigate the usefulness of the conventional NTSC test signals and measurement procedures, both analysis and experiments were carried out. Observations are made based on the experiments. Also, some new objective test signals and measurement methods are presented and the application of these methods for assessment of compressed video is discussed. For subjective assessment, the design of testing is reviewed first. Issues which may affect success of subjective evaluation are discussed in detail. The importance of choosing critical test sequences is stressed and some guidelines on what kind of test material may be chosen are given. Finally, some new proposed methods and suggestions for performance evaluation are reviewed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00852"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "An Image Enhancer for a Small HDTV CCD Camera",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "K. Mitani",
                    "Y. Fujita",
                    "Y. Fukushima",
                    "H. Kanno"
                  ],
                  "abstract": "This paper describes an image enhancer which is small enough to be contained in the recently developed 2/3-in. 1.3M pixel CCD HDTV hand-held camera. At the beginning of the design process, we considered what structure would be most suitable to match the characteristics of the camera, which uses three 1.3M pixel CCD arrays in a Dual-green pickup method. We came to the conclusion that using an analog image enhancer with a glass delay line was the best choice for an HDTV hand-held camera, in view of power consumption. In addition, we employ a new CCD driving method in the camera to simplify the enhancer's circuits. By means of the built-in enhancer, the portability and picture quality of the hand-held camera has been much improved, increasing its usefulness in HD-ENG systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00851"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Scalable Speed Search Technique for Digital VCRs",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Masaaki Kobayashi",
                    "Akihiro Takeuchi",
                    "Yasuo Hamamoto",
                    "Chojuro Yamamitsu",
                    "Ichiro Arimura"
                  ],
                  "abstract": "The requirement to develop a VCR, which is capable of performing search play at variable speeds (picture in shuttle) in both forward and reverse directions of interframe coded signals presents a difficult task. — This paper describes a new trick play technique for interframe coded (MPEG like) HD-VCR data. The technique is based on analysis made on required picture quality and it involves special positioning of the data for the “trick” play mode. The basic criteria is that picture quality which is inversely proportional to tape speed (lower quality at higher speed) is acceptable to the viewers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00850"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Development of Studio Apparatus Supporting System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tsuneji Yasuda",
                    "Kengo Nomura",
                    "Kouichi Tobe",
                    "Hiroshi Kouchi"
                  ],
                  "abstract": "A studio apparatus supporting system has been developed for the stable operation and efficient maintenance of studio apparatus. The system has been installed in six of NHK's twenty production studios, mostly in ones used for live broadcasts or dramas. Real time monitoring of the apparatus facilitates the early discovery and prediction of accidents.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00853"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Universal Broadband Networx™",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve A. Day"
                  ],
                  "abstract": "Universal Broadband Networx™ (UBN) is a concept that has been developed to assist CATV Companies with plans to evolve into multi-media. Simply put, UBN places primary emphasis on the network's ability to evolve vertically to support an increasingly wide variety of information services. One of the most important demands being placed on MSO Engineering Resources is to invest in the network today. When future multi-media opportunities arise; the CATV system will not have to be burdened with second time investments. Figure #1 represents an overview of the UBN model.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00870"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Subjective Testing of Broadcasting Quality Compressed Video",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Y. Zou",
                    "James A. Kutzner",
                    "Paul J. Hearty"
                  ],
                  "abstract": "This paper describes a program of analysis and subjective testing of broadcast quality compressed video conducted by PBS and the CRC's ATEL. To fulfill the program objectives, a novel approach to test preparation and conduct was adopted. New methodology was employed in the development of a reference model and in the selection of test material. The tests were conducted in controlled viewing conditions, using internationally recommended methods. Statistical analysis was performed on the test results. Observations and conclusions are given based on the test results.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00858"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Delivery of TV over Existing Phone Lines",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter F. Prunty"
                  ],
                  "abstract": "A system for delivering compressed digital TV over existing phone lines concurrent with conventional phone service is described. — The system uses MPEG (Motion Picture Experts Group) compression and an innovative transmission technique, called Carrierless Amplitude Modulation (CAP). Some of the details of these technologies and how they are used in the system are covered. MPEG1 is an approved standard and is soon to be followed by MPEG2. — Some phone companies are seriously considering the use of such a system. Their interest was spurred by the FCC's Video Dialtone Order adopted July 16, 1992. One of the FCC-approved video dialtone trials, which began in mid-1993, uses the system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00857"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "525, 1:1, Progressive Scanning Television Camera with 16:9 Aspect Ratio",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Noriaki Wada",
                    "Shoji Nishikawa",
                    "Keijiro Itakura",
                    "Akihiro Hori",
                    "Tadao Kurosaki"
                  ],
                  "abstract": "This Paper discusses a 16:9 aspect ratio, 525-line, progressive scanning television camera. This camera employs a newly developed Multiple Frame-Interline-Transfer (M-FIT) CCD and employs digital signal processing technologies. Although picture quality is high, the cost of this camera is not far different from conventional interlace cameras. This paper deals with the M-FIT CCD, the digital signal processing, the transmission of progressive signals, and applications that make good use of the high quality progressive signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00865"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "From Post Production to the Cinema of the Future: Part One: Post Production",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard A Mizer"
                  ],
                  "abstract": "Early in 1992, the San Francisco SMPTE section meeting was held at Pacific Bell's Corporate Headquarters in San Ramon. The presentation was on the transmission of High Definition Television over the telephone network, and included a reenactment of the Golden State Warriors basketball game sent from the Oakland Coliseum, followed by a tour of Pacific Bell's Broadband Network Research Lab. Among those in attendance was Fred Meyers of Industrial Light & Magic, with whom it was decided to test this concept with a more practical application. This paper will describe with some detail how Advanced Broadcast Video Service was used in the making of Jurassic Park. — After the required regulatory approvals, a test network was built that connected ILM in San Rafael to Amblin Entertainment at Universal Studios in Southern California. Fiber optic terminals and digital video codecs were installed at each location and interconnected by digital facilities provided by Pacific Bell and Vyvx, a Williams Company. During the testing period, which lasted about nine months, a satellite link to Cracow was provided by San Francisco Satellite. This network enabled the daily review of work in progress remotely and kept the film on schedule. Enhancements developed by ILM dramatically improved the network's capability to provide interactivity between the director and the creative talent. — These technologies are now being made available to the entertainment industry as a whole, and this paper will include a discussion of how each of the production processes can take advantage of Advanced Broadcast Video Service by identifying applications, interface specifications, and hardware requirements. And finally, it provides a look into the future with a discussion of ongoing developments in Pacific Bell's labs of the next generation of film and video transmission capability.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00863"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "“Integrating Television into the Digital Telecommunications Network”",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard Meiseles"
                  ],
                  "abstract": "The television transmission medium of today is fiber optics – a nationwide route switched fiber-optic television network that transmits integrated applications such as broadcast and cable programming, home entertainment, business television and video conferencing within the digital telecommunications network.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00864"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Hierarchical TV Transmission by Spread–Spectrum Multiplexing",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yasuhiro Ito",
                    "Hiroyuki Hamazumi",
                    "Hiroshi Miyazawa"
                  ],
                  "abstract": "A potential drawback of digital transmission is that slight corruption of the digital signal due to poor reception can result in serious subjective degradation of the decoded signal. This problem is avoided in hierarchical digital TV transmission which uses broadened power spectra to achieve a dispersive threshold and reduce the effects of digital corruption. We have constructed a prototype adaptive weighted code division multiplexing (AW–CDM) model to investigate some features of the technique. — In the prototype AW–CDM model, the hierarchical information is divided into 128 orthogonal spread–spectrum binary subchannels, each of which has a different priority and therefore a different threshold. The model's transmission rate is 9.7 Mbps in the 6MHz band. The hierarchical information used is the video and audio signal, which is hierarchically coded into 3 layers: layer III (5.91 Mbps: detail), layer II (1.38 Mbps: medium) and layer I (0.38 Mbps: core). Indoor transmission tests prove layers III, II and I to be retrievable under conditions of carrier–to–noise ratio (CNR)=13.2 dB, 8.3 dB and 0 dB, respectively. The prototype AW–CDM model can, of course, be applied to HDTV transmission by simply changing the binary subchannels into multiple, e.g., quaternary or octonary, subchannels.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00862"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Monitoring and Diagnostics in Digital Television Systems",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William C. Miller"
                  ],
                  "abstract": "SMPTE's Working Group on Monitoring and Diagnostics in Digital Television Systems was formed to develop standards and recommended practices to aid in the analysis and maintenance of digital television systems. In the two years since it was formed, the Working Group has produced several such standards and RPs. It is the purpose of this paper to review these documents, to show how they interrelate to make up a comprehensive system for diagnosing and reporting the health of a serial digital television plant, and to identify areas where further work is needed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00854"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Synchronous Digital Fiber Optic Networks for Multi-Channel Video Transmission",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Regnier"
                  ],
                  "abstract": "New terminology is appearing in today's television system planning such as multi-media, video compression and communications “super-highways”. The underlying structure of these concepts is digital technology and digital transmission. In modern communications structures, fiber optics is the dominant medium for terrestrial transmission of digital signals, and digital fiber optic systems are becoming well established for transporting high quality video, audio and data signals. — Digital coding enables a very robust transport medium and has other practical system advantages. A multi-level, synchronous, time division multiplex (TDM) architecture is the key element in realizing the flexible, high performance advantages of digital transmission. The ability of a digital system to interface with multiple signal formats and the emerging telecommunications optical network standards is another important advantage. Considerations for a synchronous TDM, including an advanced design for distributing clock signals will be covered as well as signal interfacing aspects of a digital system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00861"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "The A.R.T. System™: Artificial Reality Television System™",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Terrenz Sword"
                  ],
                  "abstract": "The “Artificial Reality Television System” is an integrated means for producing and viewing stereoscopic imagery that is compatible with monoscopic viewing systems. It requires using two genlocked S.M.P.T.E. time coded recording devices for dual channel recording. It is offered as a standard for two track video that will remain compatible with any new method of stereoscopic video that may be developed in the future. It is based on already patented devices. It also calls for a dual channel video broadcast, and will work with a variety of steroscopic video playback devices from projectors to head mounted displays.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00859"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Video on Demand: Architecture, Systems, and Applications",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Winston Hodge",
                    "Stuart Mabon",
                    "John T. Powers"
                  ],
                  "abstract": "This article describes video on demand (VOD) and near video on demand (NVOD) and explains the differences between the various types of VOD systems as they relate to telephone company (Telco), commmunity antenna or cable television (CATV), cellular TV, and hotel applications. System similarities of the various carriers are described, with the intent to identify as much common equipment as possible that will be compatible across the various applications. Basic VOD functional requirements are also discussed. Hotel VOD systems are really small CATV or Telco systems that can be expanded into full-size, commercially viable VOD systems easily because of their scalable architecture. The roles of image compression, video-friendly disk-storage systems, video servers, encryption, switching, transmission, and control-system elements in this VOD application are also discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00860"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "The Merging of Computers and Video: Using Ethernet and SCSI for Digital Video I/O",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen Kilisky"
                  ],
                  "abstract": "As computer processing power increases and prices dramatically decrease, video facilities are looking to replace dedicated hardware with general purpose computers running software tailored for video applications. This revolution in the computer industry has also led to the proliferation of 3D computer graphics departments in most video facilities. — Ethernet and SCSI greatly enhance the versatility and functionality of video peripherals connected to computers. Currently Digital Disk Recorders are the most common video peripheral that use SCSI and Ethernet to integrate with computers. Ethernet and SCSI permit the disk recorder to take full advantage of the multi-user and multi-tasking UNIX operating system. In addition, Ethernet and SCSI are the simplest way to integrate video into a computer environment. — Today's engineer is faced with having to learn a new set of terminology and skills in order to integrate computer equipment into a video environment. This paper helps to explain some of the technical issues involved in integrating computers with video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00856"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Towards a Descriptive Language Codifying the Video Synchronization Signal",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gregory M. Eitzmann",
                    "John Hallesy"
                  ],
                  "abstract": "To reduce the complexity of the description of a video format standard, a language can be employed to fully specify the pattern of the video synchronization signal. The language describes the excursions of the video synchronization signal in both horizontal and vertical blanking intervals, and describes the relationship between sync and active portions of the line. The language can be processed by a computer program called a compiler which can derive information to provide information to hardware that generates the electrical output. The language is described both formally and by example.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00869"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Resolution Independent Film Scanning: How Independent is Independent?: For Presentation at 1994 SMPTE Advanced Television & Electronic Imaging Conference",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "P. R. Swinson"
                  ],
                  "abstract": "Any film image may be regarded as having 3 distinct dimensions. Height and width, which determine the surface area, and dye or grain density variations that determine the image brightness at any point on the film surface.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00867"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Intelligent Robot Camera",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Noritada Yamanaka",
                    "Yoshikazu Yamaraura",
                    "Kazuyuki Mitsuzuka"
                  ],
                  "abstract": "An intelligence robot camera system for broadcast use has been developed which automatically follows moving object in the picture. The video output signals from this camera is processed to generate movement data required to the pan and tilt head and the lens servo system. This landmark system's feature is real time following operation and any desirable camera shot is available at anytime.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00866"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Digital Multi-Media: Now that I've Got it, where Do I Put it?",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Martin J. Stein"
                  ],
                  "abstract": "Continued increases in processor performance, remarkable advances in data compression technology, and the emerging high speed local and wide area network standards are all converging to rapidly facilitate the handling of video and film as data. Three relatively new applications that are leveraged on the success of these new technologies are video-on-demand, computer-based digital film special effects, and new image-based information services. Now that commercial availability of these new technologies is on the horizon, the issue of storage and access to the avalanche of digitized video and image data that is likely to assault us during the next few years needs to be addressed. This paper will explore these new applications and the advances that are being made in mass storage to accommodate these new requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00855"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Desktop Systems Supporting Role in Traditional Production Environments",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brett Bilbrey"
                  ],
                  "abstract": "Although there is great excitement over the promise of desktop video systems replacing traditional production equipment, the reality of the situation is that for many applications, expensive, dedicated traditional equipment is still required to do the job. Although desktop systems are used for off-line editing applications, they have not replaced traditional on-line, or edit bay, production tools which are expensive, but capable. Until the day where technology advances to allow more inexpensive, versatile systems, how can desktop systems be used to complement traditional production tools today? — Desktop systems can provide services lacking in dedicated equipment, add convenient utilities to equipment in edit bays, and supplement expensive capital investments in equipment by off loading tasks to increase system throughput. — Desktop systems can provide: network connectivity for systems with limited networking abilities; broadcast video solutions for systems with limited display capabilities; data interchange and conversion between tape, disk, video and network interfaces; supplemental workstations for expanding an existing system's bandwidth; tools for touch up and matting; the importing or exporting of graphics. — The focus of this paper is to show how, with specific examples, desktop systems can supplement traditional production tools, increasing the cost effectiveness and efficiency of these tools.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00868"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "SMPTE '94 Conference & Exhibition, Sydney, Australia",
            "conference_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/",
            "articles": [
              {
                "article_local_id": "6",
                "article_title": "A New High Speed Motion Picture Film",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Boris Mitchell"
                  ],
                  "abstract": "Hi I'm Boris Mitchell from Eastman Kodak Motion Picture and Television Imaging. It's my pleasure to introduce our new Motion Picture Film: Eastman EMI Color Negative Film 5298/7298 (500T).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001125"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Environmental Process Development",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary O'Brien"
                  ],
                  "abstract": "The Eastman Kodak Company has a long standing commitment to product and process improvements across all of its business interests. Integral to the commitment in our Motion Picture line of business, is a defined strategy of environmental stewardship involving continuous improvement programs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001120"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Molecular Sieves - An Aid to Film Preservation",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Leigh Christensen"
                  ],
                  "abstract": "Motion Picture film has proven to be an excellent storage medium for preserving our visual heritage. Films made decades ago still provide entertainment and enlightenment for today's audience, and a significant source of revenue to the Motion Picture and Television industry. The film vault often holds a studio's most valuable asset.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001123"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "A Review and Assessment of Digital Production Techniques",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mike Seymour"
                  ],
                  "abstract": "Television is a powerful force, in Australia, we watch 22 hours, 45 minutes of television per week on average, with at least one TV in 99% of Australian homes. In North Africa, the Nomadic tribe of the Tuareg have delayed their annual camel caravan migration across the Sahara in order to watch the final episode of Dallas. It is the most influential form of mass marketing. A recent survey found that in Australia television advertising was eight times more influential than it's nearest closest rival, newspapers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001130"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Latest Technology and Developments in Film Cleaning",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jonathon Banks"
                  ],
                  "abstract": "I should like to begin by briefly describing the reasons for the need to change the type of solvent traditionally used for film cleaning and then to discuss what liquid and equipment alternatives are available to the film industry in the light of these changes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001121"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Completing the EXR System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Waygood"
                  ],
                  "abstract": "Good afternoon. A report on a new Eastman Color print film which is the latest addition to the EXR family of motion picture films.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001126"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Now it's Digital, We can Do Anything?",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Owen"
                  ],
                  "abstract": "Digital processing is available to all. From the high street desktop to the more powerful deskside workstation, computers are finding applications in all walks of life. Because most physical and abstract parameters (temperatures, size, lines, text) can be described numerically, computers can be applied to almost any task. Where data and processing requirements are modest i.e. text, slowly changing experimental information, 3D rendering, desktop and workstation provide unchallengable cost effective solutions. Where data represents real world images with its variety of hues, textures and contrast, the resulting quantity of data can smother all but the most powerful system. At this point the often heard exception of “now it's digital, we can do anything” loses its credibility.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001132"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "The New Production Company",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Richards"
                  ],
                  "abstract": "The video production and post-production industries are changing – very fast. Digital retooling is taking place, causing dramatic industry restructure. The old players – large post-production facilities using dedicated, proprietary equipment – are being replaced by new players – small production companies using personal computers to produce a diverse range of production media with the same professional finish, at a fraction of the cost.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001129"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Film Restoration Using Digital Technology - The Snow White Story",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Taysom"
                  ],
                  "abstract": "Good morning - today I would like to share some of what was learned during the commercial restoration of “Snow White and the Seven Dwarfs,” Hollywood's first feature-length animated movie.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001131"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "European High Definition - Double 4:2:2 Architecture",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thierry Long"
                  ],
                  "abstract": "As much as possible all along the processing chain.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001134"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Technical Overview of the D5 Format",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stuart Pointon"
                  ],
                  "abstract": "The D-5 format is the first digital component VTR to record non-compressed 10 bit CCIR 601 4:2:2 signals. The format is designed to meet the post production needs of high end users of computer graphics and digital video effects.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001135"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "The Evolution of Lighting Control Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tim Bachman",
                    "Aaron Humprey"
                  ],
                  "abstract": "The earliest version of lighting control was simply a valve on a gas line, and since the introduction of that rudimentary control system, the ability to control lighting has evolved considerably. Modern systems not only control dimmers, but also direct moving lights, cue specific special effects, and can run entire events without a human operator. Although we have moved well beyond gas valves and their kin, it is important to remember the earliest control schemes in order to understand the progress of the system over the years and to try to keep current as the speed of evolution accelerates.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001127"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Considerations for Digital Video Storage Systems",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rex H Stevens",
                    "Ajay Luthra"
                  ],
                  "abstract": "The professional television industry is entering a new era where many of the required tasks can be accomplished by utilizing technologies and subsystems developed for general purpose computing rather than utilizing custom systems developed specifically for television applications. This new freedom brings many new choices which require careful consideration. In this presentation we will discuss—from a pragmatic system implementation perspective—two topics, which will be key to many of the systems selections facing the professional television industry over the next decade.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001133"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "The AQ 235W - Panasonics New 16:9/4:3 Switchable Camera",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stuart Pointon"
                  ],
                  "abstract": "This paper discusses a 16:9 / 4:3 switchable aspect ratio broadcast camera. The camera employs advanced digital technology based on many years of experience with digital processing techniques in cameras.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001124"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Post Production Editing for Today and Tomorrow",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William F Carpenter"
                  ],
                  "abstract": "When you examine the component digital formats offered for use in post production only one has all the characteristics required by this most demanding application. The features most asked for are high signal quality, excellent multiple generation performance, high speed of operation, 525/625 line standard switchability, convenient archival storage capacity, good long term interchange, and low maintenance costs. The combination of all of these features are present only in the AMPEX DCT 700d tape drives. Prior to designing a format to meet these requirements we first looked closely at how well the original component digital format, D1, was meeting these goals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001137"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Resolving the Conflit between Timeline and EDL",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Muirhead"
                  ],
                  "abstract": "When I told people that I was going to give a talk about timeline editing, the response was usually, “Some interfaces are better than others, but basically they're all the same.” As more of these systems start to be used, editors are now starting to assess how well these systems work. A particular focus is how well they interact with Edit Decision Lists, because EDLs are the transfer format between offline and online.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001138"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Lillehammer '94 in High Definition",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jean-Pierre Lartigue"
                  ],
                  "abstract": "Two existing European channels offering 16/9 television broadcasts, France Supervision and TV Plus (Netherlands), were involved in the first major operation to have been made possible thanks to the subsidies granted through the European Commission's “Action Plan” –and also helped by members of VISION 1250; when they broadcast pictures from the high definition coverage of the Winter Olympic Games from Lillehammer. Whereas the High Definition coverage made at Albertville and Barcelona in 1992, served experimental purposes only, the pictures from the Winter Olympics at Lillehammer were used as an integral part of the programming by the two 16/9 channels between February 12th and 27th.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001149"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Multi-Channel Digital Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Graham Sharp",
                    "Chris Loberg",
                    "Mike Andrews"
                  ],
                  "abstract": "Digital broadcasting offers the potential to meet broadcasters demands for greater numbers of channels as well as higher quality. In order for digital broadcasting to become a reality, the digital master control had to be built and large scale digital routing solutions had to be developed. For transparency to the operator, the first master control, described here, is the functional equivalent of an analogue version with added keying features. Various options for large scale digital routing are proposed and discussed. A system example of the hub and node router configuration is presented and the concept of virtual suites is introduced.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001150"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "MPEG-2 Out of the Blue! (Or Lets Put an MPEG on a Square Chip)",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Maizels",
                    "Mihailo M Stojancic",
                    "Chuck Ngai"
                  ],
                  "abstract": "The MPEG-2 Standard for digital motion video will be ratified as an international standard in late 1994. This paper describes a recently developed silicon component that efficiently implements real time decompression of an MPEG-2 encoded video data stream. The chip has been developed by IBM Corporation and is fully compliant with the MPEG-2 Draft Standard at MP@ML (Main Profile at Main Level). We include an overview of the MPEG-2 algorithm, and outline the main characteristics of the video decoder chip. Rather than going into details of the internal architecture of particular coprocessors, the descriptions and examples are given in terms of function and specific application environments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001151"
                  }
                }
              },
              {
                "article_local_id": "35",
                "article_title": "A Graded Entropy Test Sequence Series for Subjective Video Quality Assessment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/35/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew McMahon"
                  ],
                  "abstract": "As part of a desire to standardise subjective testing of video systems, the ITU-R (formerly known as the CCIR) has produced a set of testing methodologies (Recommendation 500), and a library of test sequences (detailed in Recommendation 803). One of the test sequences (“Diva with Noise”) has, over the years, been the centre of argument as to whether it is “critical, but not unduly so”, as called for by Recommendation 500. The main objection to the use of the “Diva” sequence is that it is more critical than material which would actually be broadcast. To date, most codecs fail tests using the existing “Diva with Noise” sequence.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001154"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Advanced Digital Camcorder Design",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris Middleton-Williams"
                  ],
                  "abstract": "The challenge in producing a digital camcorder is to implement in the digital domain, all of the features currently available in analog camcorders. Features are continuously being added with each generation whilst miniaturisation increases portability. Once a feature has been added or level of miniaturisation reached, it becomes a standard for the next generation of product. Consumers now expect air-conditioning, automatic transmission and stereo systems in their cars as standard rather than luxury options‥",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001136"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Images from Mould: The Treatment of 26 Million Feet of Wet and Mouldy Film",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mark Nizette",
                    "Michael Newnham"
                  ],
                  "abstract": "The Colour Acetate Restoration Programme (CARP) was established in 1990 to restore and repair film which had been blemished while in storage. The film had been exposed to high humidities for extended periods, and it was discovered that much of the footage was suffering from mould, ferrotyping and blocking.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001122"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Converging Technologies and Newton's Third Law of Motion",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dominic Case"
                  ],
                  "abstract": "This is not a paper about engineering hardware: it's about the way hardware is used. It concerns the massive revolution that has taken place in film production and post production over the past few years as a result of changes in technology. The adoption of new equipment in certain areas has had more far-reaching implications than I suspect the designers of the equipment ever dreamed of; and I think that is an important area to be discussed at a conference such as this one.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001141"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Fluorescent Lighting Systems for Television and Motion Pictures",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Mardick Balli"
                  ],
                  "abstract": "Although many of us present here today may not realize it, we are witnesses to a profound change taking place in the Television and Motion Picture field, one that does not happen often and one that will continue to have its effect over the years to come. This change concerns that of lighting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001128"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Automated Telecine Syncing and Data Base Management for Electronic Film Post",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Bowring"
                  ],
                  "abstract": "At the start of each shot on the rushes of any sound film, is the unique tribal dance of the film maker, that age old tradition of a person waving sticks, making a loud noise and then running away while the camera finds the frame for where the shot will really begin.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001143"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "An On-Line True Random Access Edit System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steve Shaw"
                  ],
                  "abstract": "The dictionary defines editing as ‘making up the final version by selection, rearrangement etc. of recorded material’.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001140"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Digital Sound Manipulation for Film and Television and its Role in Affecting Emotions",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen Joyce"
                  ],
                  "abstract": "In order to explore and incorporate the new possibilities afforded by digital sound manipulation (DSM) in films it is necessary to examine what we know of the nature of auditory, and to a lesser extent, visual perception and cognition. However, in this condensed paper such research shall only be alluded to with the emphasis being placed on the possible outcomes of such research. This inquiry into the emotional affective qualities of sound within film is directed in particular toward the nature of environmental soundscapes and their manipulation. This knowledge may hopefully then be applied to extend the range of affective sonic options in films in an attempt to manipulate the audience's emotional states more precisely and with a wider range of emotional affective possibilities than currently afforded by traditional sound design.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001142"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "An Automated On-Air System",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gerry Brooks"
                  ],
                  "abstract": "This paper describes an Automated On-Air system using a Panasonic M.A.R.C. Type III. This system uses 10 VTRs, 2 Robots, and can store either 400 or 800 cassettes. Using the in-built Library Management Function, the M.A.R.C. Type III can transmit on 3 Channels, Record programme on schedule, Compile commercial breaks ahead of time, Record new commercials or Spots into the Library, and Auto Programme Delay mode to turn around programmes for example for daylight saving.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001147"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "The Advantages and Flexibility of Flying Spot Scanners for Film to Video Transfers",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Vince Crook"
                  ],
                  "abstract": "For nearly half a century flying spot telecines have formed the cornerstone of post production and have provided the means to present feature films and documentaries to the TV viewer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001144"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Digital Courier - Transmitting Rushes for Non Linear Editing",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bruce Williamson"
                  ],
                  "abstract": "Digital courier is an open system for the sending of digitised, compressed images and sound over commonly available telecommunication lines. It was conceived for those productions originating in film and editing on non-linear style editing machines. The intention was to reduce the time in getting the rushes into the editors machine and to allow some freedom in where the editing process was located, ie near to a laboratory or nearer to the production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001139"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Protection Ratios for Digital Terrestrial TV in Australia",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raymond Treloar"
                  ],
                  "abstract": "The Communications Laboratory, of the Australian Department of Communications and the Arts, has commenced a protection ratio measurement programme as a necessary precursor to the possible future introduction of digital terrestrial television (dttv) services into Australia. Protection ratios are used in the planning of terrestrial television and radio services to reduce the likelihood of unacceptable interference to a wanted service from other signals generated in the same area, in neighbouring areas or, under certain circumstances, in quite distant locations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001146"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "16×9 - The Challenge for the Broadcasters",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Cox"
                  ],
                  "abstract": "The challenge can be summarised as the following: (1) That there will be two co-existing home receiver populations to consider, 4 × 3 and 16 × 9. (2) The generation, storage, manipulation and transmission of 16 × 9 images with or alongside 4 × 3. (3) The type of plant a broadcaster will need and the economics of phasing in a 16 × 9 service. (4) The old basic practical problem of “fitting” - or in other words converting one aspect ratio to another for optimum display with a minimum loss of image content.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001148"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Propagation and Demographic Analysis for a Broadcast Environment",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Vander Heyden",
                    "Ken Pearson"
                  ],
                  "abstract": "The prediction of radio propagation is renowned for being an imprecise science. There is a vast array of variables which affect radio propagation most of which must be quantified or at least approximated in the calculation method, if the broadcast system designer is to have confidence in the predicted results.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001145"
                  }
                }
              },
              {
                "article_local_id": "40",
                "article_title": "High Definition Production in Arts and Documentaries",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/40/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul Kafno"
                  ],
                  "abstract": "We deliberately chose a wide range of special lighting to ring the changes, ranging from supplements to natural daylight, to dramatic effects achieved by filming at night. These, combined with the high reflectivity of the musical instruments, gave some wonderful possibilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001159"
                  }
                }
              },
              {
                "article_local_id": "37",
                "article_title": "Introduction to Vision 1250",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/37/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Scott"
                  ],
                  "abstract": "The organisation “Vision 1250” was set up in 1990 to promote the 1250/50 High Definition Television production standard not only in Europe but throughout the world. To set the scene for 1250 HDTV today I wish to give a Little of the history which led to the creation of this Grouping.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001156"
                  }
                }
              },
              {
                "article_local_id": "39",
                "article_title": "The Market Place for HDTV and Wide Screen Product",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/39/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian Scott"
                  ],
                  "abstract": "Programme producers today, in looking towards the future, find that they require a production system which is fast, flexible, economical, of high quality, compatible with 35mm film and which, in particular, has a 16:9 widescreen format. In other words one which will guarantee the life and marketability of their product.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001158"
                  }
                }
              },
              {
                "article_local_id": "34",
                "article_title": "Subjective Viewing Testing of MPEG-2",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/34/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Murray Delahoy"
                  ],
                  "abstract": "During visual acuity and colour vision checking some assessors were found to have deficient colour vision. For non-expert assessors this data was removed from the database. For expert observers the data was retained because visual inspection of the results for colour vision deficient and non colour vision-deficient observers shows no obvious differences.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001153"
                  }
                }
              },
              {
                "article_local_id": "36",
                "article_title": "Effective Nearly Lossless Compression of Digital Video Sequences",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/36/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alan McIlwaine",
                    "B.K. Natarajan",
                    "V. Bhaskaran"
                  ],
                  "abstract": "We present a non-linear filtering technique for digital video to enable improved nearly lossless compression. In contrast to preprocessing techniques, our technique uses the compression algorithm for both filtering and compression in one step, by exploiting the property that random noise is hard to compress.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001155"
                  }
                }
              },
              {
                "article_local_id": "38",
                "article_title": "The Big Picture around the Little Picture",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/38/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Krohn"
                  ],
                  "abstract": "Hello and welcome. I want to thank you all for investing your time to come here for what I expect will be a worthwhile discussion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001157"
                  }
                }
              },
              {
                "article_local_id": "33",
                "article_title": "Recording Image Data Compressed Signals on Magnetic Media",
                "article_url": "https://journal.smpte.org/conferences/SMPTE%20'94%20Conference%20&%20Exhibition,%20Sydney,%20Australia/33/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Fraser Morrison"
                  ],
                  "abstract": "The information content of a television image is highly redundant. Exploiting this redundancy by image data compression allows the recording of these television signals on a digital VTR whose data rate is chosen to provide optimum performance and is less than the input image data rate. Almost transparent results can be achieved when a sophisticated compression scheme and mild compression ratios are used. The recorder data channel differs from the conventional digital VTR channel significantly in order to process the signal in which the image redundancy has been removed without any defects. Powerful forward error correction is employed. The tape media used requires special attention during the manufacturing process to eliminate the causes of surface debris that could produce momentary head clogs that may possibly exceed the error correction range. Automatic systems are used to ensure perfect insert editing under all environmental and interchange conditions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-07"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001152"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "ITU/SMPTE Tutorial on Digital Terrestrial Broadcasting (DTTB)",
            "conference_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "Introduction",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard C. Kirby",
                    "Richard L. Nickelson"
                  ],
                  "abstract": "Digital television offers unprecedented possibilities to deliver television programs and associated stereophonic sound and data channels to the home with quality that is very close to that of the original studio program. As recently as the beginning of this decade it was widely accepted that the emission of such programs would require very high bandwidths, especially in the case of high definition television, and for that reason broadcasting engineers were basing their future plans on delivery media where large bandwidths were more readily available, such as satellite and cable systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001277"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "An Overview of the DTTB Model",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. N. Baron"
                  ],
                  "abstract": "Recent advances in communication technology have brought digital transmission of television services from the realm of a future possibility to a near-term practical reality. The commonly held view is that the application of digital technology to the television sciences will provide higher picture and sound quality than conventional terrestrial television transmission and, at the same time, increase the efficiency of spectrum utilization by allowing multiple program services to be broadcast in current single-program channels. For digital services to be successful, there must be a consensus on standards in areas such as source and channel coding, modulation methods, content identification, and error protection and correction. A model of a digital terrestrial television broadcast (DTTB) system was developed by the International Telecommunications Union (ITU) Radio-communications Task Group 11/3 on Digital Terrestrial Television Broadcasting (DTTB) as a means of analyzing the system requirements. The model developed by the Task Group is described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001278"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Video Compression Techniques and Multilevel Approaches",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marzio Barbero",
                    "Mario Stroppiana"
                  ],
                  "abstract": "Digital compression techniques are applied to video signals to allow their transmission and distribution through a number of media to the viewer. Systems based on transform techniques have been developed for different applications: from videophone to transmission of TV and HDTV with contribution quality. A brief overview of the basic algorithms adopted for the compression is given: transform (DCT) and sub-band coding, entropy coding and motion evaluation and compensation. The importance of adopting suitable test material to evaluate the coding systems is discussed. In addition, the paper mentions the issues presently debated in standardization bodies and international projects: multilevel approaches, to provide various levels of resolution and quality for applications ranging from mobile video to HDTV, and the benefits that the adoption of progressive scanning formats could provide in terms of coding efficiency and picture quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001279"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "MPEG Overview",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stan Baron",
                    "W. Robin Wilson"
                  ],
                  "abstract": "The MPEG standard address the compression and decompression (restoration) of moving pictures (video) and sound (audio) and the formation of a multiplexed common data stream that includes the compressed video and audio data plus any associated ancillary service data. The MPEG standard further addresses the synchronization of the video, audio, and ancillary data during playback of the decompressed signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001280"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Encipherment and Conditional Access",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Louis Claude Guillou",
                    "Jean-Luc Giachetti"
                  ],
                  "abstract": "We aim at modeling conditional access in any television environment (terrestrial broadcasting, cable and satellite). After defining the subject by saying what conditional access is, two models are presented. They correspond to two different systems, wide-spread in Europe: — The first model distributes control words. It is illustrated by “Discret 1”, a proprietary system used by about 3 500 000 subscribers of Canal-Plus in France. — The second model distributes authorizations. It is illustrated by “Eurocrypt”, an open system used by about 800 000 receivers throughout Europe: Filmnet and Kinnevik (600 000), Canal-Plus (60 000), France Telecom (50 000), Polycom, Maxat, KabelKanal,… — The emergence of digital signals technically facilitates the design of open systems. The use of a strong cryptography becomes justified. The encipherment techniques appear at three different levels: — for scrambling the program components, — for controlling the access rights, — for managing the access rights and for updating the authorization keys. — This modelisation emphasizes the impact of standardization and the reserves for further evolution. The knowledge harvested on existing systems allows to determine the axes for additional developments, specifically in relation with digital television.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001282"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Planning Factors and Their Influence on System Aspects",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jorgen Weber"
                  ],
                  "abstract": "Introducing new or enhancing current radio services is dependent on the ability of the service to coexist with other services. Introduction of digital TV must also respect other services and international agreements concerning the use of spectrum. In some countries digital terrestrial TV will be introduced as enhancements of existing services, and new spectrum is not likely to be made available. This may even be true where the digital TV system is used for new services, because TV broadcasting is seen by many regulators as a spectrum inefficient service and because no free spectrum is available. As a consequence we have to face the fact that digital terrestrial TV must be able to coexist with present TV services in shared bands. This paper discusses the questions related to introduction of digital terrestrial TV, and in particular the possible trade-offs which will be necessary to make the service work. Will we accept a slightly reduced quality of the analogue service? What is the noise figure of new receivers? Should it be scalable? Can it be portable? What is the power range? Can it use adjacent channels? Other questions could be whether a worldwide scenario is possible. Are the constraints the same all over the world? Are the trade-offs equally acceptable anywhere? Yet another will be if one modulation scheme is superior to another, and must it carry HDTV from the start or would standard or enhanced definition do? There are questions about coverage, graceful degradation, service availability and so on. This paper deals with such problems as factors affecting the planning process.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001283"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Digital Television Broadcasting: Issues for Successful Implementation",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. D. Windram",
                    "A. G. Mason"
                  ],
                  "abstract": "In considering the issues for successful implementation of Digital Terrestrial Television Broadcasting, we can draw on a foundation of NTL's experience as the provider of the NTL 2000 digital video compression system world-wide, and over five years of study on the SPECTRE project in the United Kingdom. SPECTRE is concerned with all aspects of Digital Television including the low-bit rate video coding, modulation, frequency planning, and perhaps most important, practical field trials. The work was initiated under the Independent Broadcasting Authority, but since the IBA was abolished in 1990, it has been carried out by NTL, under contract from the Independent Television Commission in the UK.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001284"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Digital Television Broadcasting – A Swedish Perspective",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Per Appelquist"
                  ],
                  "abstract": "Digital technology was first picked up as a means to convey HDTV signals when analog technology proved to be insufficient. This was the original reason for us to choose a digital solution for HD-DIVINE, and I guess the same is true for the digital proposals in the U.S. Now that we have our digital systems it turns out that we are facing a completely new media situation. With digital systems we can use a computer to receive and process signals. This allows for interactive services, where several concurrent services can be selected individually by the viewer and merged together to form a completely new and tailor-made experience for each viewer. The capacity to caiq TV signals of the available media will multiply compared with today, while digital technology will bring down distribution and production costs. The individual viewer can choose to receive signals from broadcasters, specialist companies delivering through telecom networks, different kinds of computer software to process and interconnect different services, databases on CD-ROM, other individuals sending information, etc. What we can see is a completely different media landscape; new structures and services will emerge and each player today has to redefine his own role now to be fit for tomorrow.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001285"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "ITU/SMPTE Tutorial Workshop on Digital Terrestrial Television Broadcasting Panel Discussion Opening Remarks",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keith G. Malcolm"
                  ],
                  "abstract": "It might be asked, why am I here and why does Australia, a country of 7,682,300 square kilometers (2,966,138 square miles) that is, about as big as the continental U.S., but with a population of only about 18 million, take such an active part in DTTB studies? The answer is national interest — the same force that is driving European, Japanese, and North American developments in HDTV and Advanced TV systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001286"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth P. Davies"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001276"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The Service Multiplex",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gary Tonge"
                  ],
                  "abstract": "One of the goals in the current European work on digital television broadcasting is to achieve as much commonality as is practicable between system specifications for terrestrial, satellite and cable applications. It is already generally accepted that the MPEG-2 standard should provide the basis for common source coding across these applications. Modulation and channel coding, on the other hand, are likely to be application specific because of the very different properties of terrestrial, satellite and cable channels. Lying somewhere in the middle is the area of multiplexing. The prospect for a common approach to multiplexing across different media, and indeed between different regions of the world, has excited widespread interest. But what exactly is multiplexing, what features would a common system need to deliver to broadcasters and consumers, and is a common approach to multiplexing feasible?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001281"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Channel Coding Approaches and Consequences - Single and Dual Carriers",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glenn A. Reitmeier",
                    "Richard J. Klensch",
                    "Hugh E. White"
                  ],
                  "abstract": "One of the key technical challenges to providing a terrestrial high definition broadcast television service in the United States is to simulcast the new service into the same spectrum space occupied by present day NTSC television. Since both NTSC and high definition television must coexist during a transition period, the optimum utilization of available spectrum for HDTV requires achieving a low level of interference between NTSC and HDTV stations. Both single carrier and dual carrier transmission systems have been proposed for HDTV and the present paper examines some of their fundamental strengths and weaknesses. Based on an overall consideration of the latest computer analysis of HDTV and NTSC service areas, and other factors, it is concluded that a single carrier approach is preferred.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001290"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Digital Television System Scalability and Interoperability",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stanley Baron"
                  ],
                  "abstract": "The United States Federal Communications Commission (FCC) is the governmental body charged with regulating the terrestrial broadcasting industry. In July of 1987, in response to a petition from broadcasters, the FCC issued a Notice of Inquiry (NOI) concerning the adoption of standards that would permit an advanced television service to be established in the United States.1 After studying the response to the NOI, the FCC, in September 1988, issued a Tentative Decision and Further NOI2 defining a plan of action. This plan of action was further defined by FCC Chairman Sikes on 21 March 1990.3 In summary, the tentative decision and plan of action requires that: (1) Existing terrestrial broadcasters must be able to implement an advanced television service; (2) The spectrum for such service will be found within the existing VHF and UHF bands; (3) ATS broadcasting shall be received by the present population of over 160,000,000 NTSC receivers by an ATS signal which is accompanied by a simulcast of an NTSC signal. (4) Channel bandwidth is limited to 6 MHz.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001293"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Error Management in Digital Terrestrial Television Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yuichi Ninomiya"
                  ],
                  "abstract": "A digital transmission broadcasting system must be able 10 control degradation of the received picture due to transmission errors. Error correcting algorithms are one of the most powerful technologies, but the many other technologies for error control should also not be forgotten. A total approach to error management must be applied when designing a digital terrestrial television broadcasting system. Other important technologies include error detection and concealment methods, transmission equalization technologies, modulation systems, including coded modulation, and weighted error protection systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001289"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Receiver Characteristics",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Artigalas",
                    "D. Westerkamp"
                  ],
                  "abstract": "The discussion on future digital TV services puts some requirements on the design of the next generation of TV receivers. For quite some transition period they must be able to receive both (Analogue as well as digital services).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001287"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Digital Terrestrial Television Using the COFDM Technique",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bertrand Sueur",
                    "Damien Castelain",
                    "Gabriel Degoulet",
                    "Marc Riviere",
                    "Bernard Le Floch"
                  ],
                  "abstract": "In the process of defining a new system for digital terrestrial TV broadcasting, operational constraints related to frequency management, as well as service concepts in agreement with current and future trends, constitute the original requirements on which the broadcasters have to base their developments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001291"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Modulation and Channel Coding for ATV Terrestrial Transmission",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yiyan Wu"
                  ],
                  "abstract": "This paper discusses modulation and channel coding issues related to digital television terrestrial broadcasting (DTTB), such as data throughput, spectrum efficiency, single- and multi-carrier modulations, interferences under simulcasting conditions and multi-layer services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001288"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Displays & Colorimetry for Future Television",
                "article_url": "https://journal.smpte.org/conferences/ITU/SMPTE%20Tutorial%20on%20Digital%20Terrestrial%20Broadcasting%20(DTTB)/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "L. DeMarsh"
                  ],
                  "abstract": "Color television systems have always assumed a specific display with the color coding in the camera and transmission system derived from this display using the CIE system of colorimetric specification. However, display phosphors have changed since the beginnings of color television resulting in increased display luminance but at the expense of significantly reduced color gamut that can be displayed. Since camera characteristics have changed to be compatible with current CRT displays, the color gamut that is captured and transmitted is limited to that of current CRT displays. We will likely see new display technologies in the future and these displays may well be capable of displaying a larger color gamut than current CRT's. Also other imaging systems, such as film, have color gamuts larger than current CRT's, so interoperability with other imaging systems demands a larger color gamut. For future television we need to define a source coding colorimetry that satisfies our long term need for a larger color gamut. We than perform color transformations at system interfaces and in some displays to derive the signals appropriate for that specific system or display. Two approaches for capturing a larger color gamut are considered. The second approach, allowing negative and above white RGB signals, seems to be the most readily implemented with current technology and is being evaluated for inclusion into the production standards for future television systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1994-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001292"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1993",
        "conferences": [
          {
            "conference_name": "Advanced Television and Electronic Imaging for Film and Video: SMPTE Advanced Television Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Keynote Address: Brave New Images",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David George"
                  ],
                  "abstract": "Good morning, ladies and gentlemen, SMPTE members, and guests. Welcome to the 1993 Advanced Television and Electronic Imaging Conference of the Society of Motion Picture and Television Engineers. Welcome, also, to visitors to this much celebrated and exciting city. I'm sure you agree with me that it's nice for the SMPTE to be back in New York, even in February.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00667"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Implementation of a Large Digital Routing System",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter F. Warth"
                  ],
                  "abstract": "In the design of a digital television broadcast plant there are many issues to consider such as digital format, tape format, embedded audio and future advanced image formats. The heart of any broadcast plant is the central routing and distribution system. For CBC's new Broadcast Centre in Toronto, a large, multi-matrix digital routing system was designed by a multi-disciplinary team formed from several different companies. The design incorporated a complex, custom designed control and supervisory system and CRT type custom control panels. In the absence of final digital standards, and without established test procedures for digital systems, new approaches were investigated to establish testing criteria and methodologies.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00668"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Digital Signal Distribution in a Combined Digital/Analog Environment",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Connell"
                  ],
                  "abstract": "This paper deals with all aspects of multiple signal distribution and interconnection within Crawford Communications. The signals discussed are audio and video both in the analog and digital domain as well as the associated control system. Because the facility is spread across four buildings all using different video formats many challenges had to be overcome. These challenges include signal distribution over long distances, overcoming different ground potentials in different buildings, the need for a common control system for all routing systems, and signal conversion between different formats. Because many signals must travel large distances between buildings some signals are sent via serial digital connections and some are sent via the analog and EQ distribution amplifier method. The advantages and costs of both methods are discussed. Signal formatting and conversion between different formats using a common control system was a must to complete the project. This signal conversion is done using router control among multiple routing systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00670"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "1,001 Questions to Ask before Buying a Non-Linear Editing System",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert R. Turner"
                  ],
                  "abstract": "Non-linear editing technology is the developing future of movingimage post production. But non-linear editing can mean Quantel's Henry or Diva's Videoshop, depending on the person with whom you discuss the subject. Most who consider such a system can easily see the advantages of the technology but few truly understand the process or options one should consider. An individual movingimage editor's or communicator's needs vary so widely, it is difficult for anyone but that individual to prioritize those needs. In order for those decisions to be made, one must first know what questions to ask. This paper will examine many of those quesitons.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00672"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "PIXAR Image Computer: Specifications, Applications and Uses at the Advanced Television Test Center",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James M. DeFilippis",
                    "Bernard L. Dickens",
                    "Carl W. Cornwell"
                  ],
                  "abstract": "The Advanced Television Test Center is the primary test facility for the evaluation of the Proposed Advanced Television Systems(ATV) under consideration by the Federal Communications Commission(FCC). In order to evaluate the still image quality and video performance of these systems the ATTC selected the PIXAR Image Computing System. Century Computing, Inc of Laurel, MD is the system integrator and software application developer. — This paper will discuss the applications and uses of the PIXAR during ATV testing and the creation of the test images from a set of ultra-high resolution source images. The downsampling of the source images was a challenge and required a novel extension of the native PIXAR filter algorithm. Special test patterns, developed with the PIXAR, used to objectively analyze and quantify ATV system video performance are discussed. — Finally, future improvements and additions to the PIXAR Image Computing system will be discussed",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00676"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Merging Digital Technology into an Analogue World",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas R. Sprague"
                  ],
                  "abstract": "Over the past five years the population of composite digital video tape recorders has grown to over 10,000 machines. Yet, most of these machines are installed in totally analogue environments where many of the benefits of digital recording are lost to both the A to D and D to A conversion process as well as alignment errors in the analog signal path. Much of the “digital” advantage can be restored with the addition of a single composite digital mixer/keyer such as the DYAD2, which has been developed jointly by PALTEX International and Imaging Systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00683"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Numbers, Numbers Everywhere!",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John T. Lim",
                    "Larry C. Thaler"
                  ],
                  "abstract": "For a television networks' News division, a presidential election year provides both opportunities and challenges. The opportunity is to capture the enthusiasm of our audience with a unique, year-long story. The challenges are to inform that audience clearly and accurately about a story which unfolds in many places at differing times. — The election narrative begins with coverage of the primaries, and is capped off by a full night of broadcast on election eve. For all of these productions, the results themselves play a crucial role in defining the story. How to get this “raw data” displayed to the audience accurately, quickly and in an entertaining manner presents a tremendous challenge for the people and technology of the News division. — As network budgets get smaller, the challenge gets even greater. This paper will outline techniques used at NBC News to meet these objectives, and will illustrate the automation and production techniques used to create graphics and animations during the “Decision 92” election coverage.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00684"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Technology for Accurate Color",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Poynton"
                  ],
                  "abstract": "Color monitors are now a ubiquitous among workstations, and desktop scanners and printers are becoming increasingly affordable. However, mismatches in color handling mean that you cannot yet scan a color image, look at it on your screen, print it on a local color printer, and send it off to a prepress system, and expect the colors to remain true at each stage of the process. This situation is about to change: color management will soon be available on desktop workstations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00686"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Technical and Logistical Issues in 3-D Character Animation",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brennan McTernan",
                    "Steven Giangrasso"
                  ],
                  "abstract": "This document describes an effective approach to character animation in 3D. It relates our experience in creating the four minute animation entitled “Rappin' Ribbit.” We look at the logistical issues involved in going from story to finished animation and the technical issues involved in lip-syncing, rotoscoping, compositing, and flexible body animating.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00677"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "A Film Quality Digital Archiving & Editing System",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Winston Hodge",
                    "Bill Harvey",
                    "Robert S. Block"
                  ],
                  "abstract": "Film archiving of commercial theatrical motion picture film has not been as successful as it was believed it was going to be. Continuing degradation of film quality over time has represented serious loss to the major motion picture studios. This article is a proposal to rectify these deficiencies using new digital technology using advanced state of the art image processing and database technology. Furthermore, because of the similarity of a digital archiving and a very high resolution editing system, consolidation of those features is discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00673"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "The Key Element of the PTV Satellite System of the Future",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard Miller"
                  ],
                  "abstract": "Public Television is in the midst of a major re-structing plan whereby it will be expanding its national program distribution capabilities from the current four channels to sixteen channels. In addition, PBS will be providing channel capacity to public television associated educational institutions as well as other non-associated non-profit educational institutions. Thus, the overall distribution capability of the new public television satellite network will expand to approximately 40 channels. In addition, public television is providing a nationally inter-connected 180 site two-way data network in support of its expanded video services. This dramatic expansion is being achieved by employing the latest digital distribution technologies. This presentation will describe the public television plan in more detail and discuss some of the new services which these technologies will make possible.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00679"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Jitter Effects and Measurement in Serial Digital Television Signals",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David K. Fibush"
                  ],
                  "abstract": "Just as the definition and measurement of jitter in baseband NTSC signals was a difficult topic for many years, we are now finding that jitter is of significant interest and some controversy in the implementation of serial digital audio and video systems. Specifications such as 40 ns of jitter in AES/EBU digital audio and 0.5 ns of jitter in serial digital video are important to insure conformance to the proposed standard. It is necessary to define jitter and appropriate measurement methods as well as understand how acceptable jitter in the signal interconnection system may affect resulting analog signals. Test methods can use wideband oscilloscopes or recently available television waveform monitors. Measurement of jitter in serial data systems is a developing subject for television applications. Several methods of measuring jitter and test results for both digital audio and digital video are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00671"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "The Preservation of the Fox Newsreel Library by Digital Means: A Progress Report",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andrew G. Setos",
                    "R. Evans Wetmore"
                  ],
                  "abstract": "The bulk of the Fox Movietone Newsreel Library is camera original 35mm motion picture film on a cellulose nitrate base. — Not only is the film difficult to handle and hard to access but it is inexorably decomposing. — As a practical matter optical or contact printing of 60 million feet of film, given its shrunken condition, is economically unthinkable. — Electronic storage alternatives were investigated which would at once capture as much image information as practical while simultaneously manufacturing NTSC copies. — Not only was the advent of Advanced Television considered, but also the ability to recreate credible 35mm motion picture film from the electronic storage for theatrical use. — To that end Fox is building two purpose built high resolution monochrome telecines.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00674"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Design Considerations for Serial Digital Television Systems",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keith Y. Reynolds"
                  ],
                  "abstract": "With the move to serial digital television systems, different design considerations are necessary. New devices are required that were not necessary in analog systems. They include serializers, deserializers, D to A converters, A to D converters, multiplexers, demultiplexers, frame delays, line delays, audio delays, serial component digital to composite digital converters, serial composite digital to component digital converters, to name a few. — Additional considerations often must be made to allow mixed analog/digital operation, with a gradual transition to full digital. — This paper describes the considerations that need to be made when designing a digital television plant. The serial digital routing switcher plays a key role in determining the optimum system for each facility.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00669"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "“The Integration of Testing & Maintenance Management Techniques for Television”",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joseph Mahedy"
                  ],
                  "abstract": "The role of today's Engineering Manager has drastically changed since the late 1980's. He faces entirely new problems with operating cost reductions, staffing and new technologies. Some new and innovative ways to integrate maintenance testing and diagnostics techniques will be an important part of the overall maintenance management process. Utilization of the PC and new engineering software and its serial interface to equipment will be commonly used by the entire maintenance staff.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00680"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Digital Television Effects and Control",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David E. Acker"
                  ],
                  "abstract": "The bridge between the different and sometimes competing worlds of video effects and computer-generated images is built with logic chips. It's fair to say that everyone on each side of this bridge understands the power of digital image processing and that one thing they all would agree on is that its incredibly fast rate of technical change is overwhelming at times.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00678"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Virtual Studio System for TV Program Production",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kazuo Fukui",
                    "Masaki Hayashi",
                    "Yuko Yamanouchi"
                  ],
                  "abstract": "Computer imaging techniques are playing an important role in TV program production. The authors have been studying a new program production environment called “Virtual studio system”(VSS), which enhances the freedom of image creation, with the tehniques of composing computer generated images and real images taken by video cameras. — General composing method may only be used to create efficiently composed images so far as no practical camera motion is necessary. But VSS is able to keep the relationship among these component objects, through changing camera parameters include zooming, panning, tilting and relocation, so that the composed images would look as if they were all same type of component images in a scene and shot with a single camera. — We have developed two types of VSS. One is “VSS driven by actual camera motion”, and the other is “VSS driven by virtual camera motion” which is further extended the concept of the former system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00675"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Use of the ATTC/Tektronix Format Converter in ATV Testing",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Philip S. Crosby",
                    "Charles W. Rhodes"
                  ],
                  "abstract": "The Format Convertor (FC) was devised by the Advanced Television Test Center (ATTC) as a means of recording source and output video for the Advanced Television (ATV) standards being evaluated by ATTC and the FCC. Tektronix Laboratories was asked by ATTC to design and build the FC. — Used in conjunction with a DVTR intended for the 1125 line system, the FC orthogonally samples the user's signal and sends a stream of samples formatted as a digital 1125 line signal to the DVTR. In actuality, a line of digital video as seen by the DVTR may contain more or less than one line of samples of the user's signal. When the digital video signal is played back from the recorder, the FC reformats the sample stream into the user's standard. Automatic user format detection by the FC permits intermixing of formats on the same tape. — User standards include 525 and 787-788 line progressive and 1050 and 1125 line interlaced standards at either 59.94 or 60 Hz field rates. The architecture is extensible to include operation where the field rate of the user standard differs from that of the recorder in small integer ratios.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00681"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Fiber Optical Interconnection in Television Cameras",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Sturcke",
                    "Johann Safar",
                    "Tetsuro Hanoaka",
                    "Noriaki Wada",
                    "Makoto Shimizu"
                  ],
                  "abstract": "A practical fiber optic link between a television camera head and its remote base station has finally been developed. The real significance of this is that the cable linking the remote controlled camera to its base station no longer limits performance. This technology advances the evolution of higher performance television cameras including the future family of HDTV cameras, all of which will deliver higher quality images than are common today.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00687"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Double Scan Playback - A Novel Technique for Increasing the Error Handling Capability in Digital VTRs",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takeo Eguchi",
                    "Luke Freeman"
                  ],
                  "abstract": "There is a trend in Digital Video Tape Recorders to increase the error correction capability of sucessive formats.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00682"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Smart Color for Digital Imaging",
                "article_url": "https://journal.smpte.org/conferences/Advanced%20Television%20and%20Electronic%20Imaging%20for%20Film%20and%20Video:%20SMPTE%20Advanced%20Television%20Imaging%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rudolph E. Burger"
                  ],
                  "abstract": "One of the key technological challenges facing the desktop imaging industry is achieving automatic color matching between dissimilar imaging devices (scanners, monitors, printers). This has proven to be a more illusive problem than the original WYSIWYG challenge of desktop publishing because of the many complicating factors involved in color reproduction and, worse yet, our perception of color. There is no universally accepted mathematical model that describes what we see when we look at a complicated color image. Since we can't yet accurately describe it, it's hard to encapsulate it into software.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1993-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00685"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1992",
        "conferences": [
          {
            "conference_name": "Proceedings: The 26th Annual SMPTE Advanced Television and Electronic Imaging Conference",
            "conference_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/",
            "articles": [
              {
                "article_local_id": "9",
                "article_title": "Challenges in Full Motion Video/Audio for Personal Computers",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edwin J. Kroeker"
                  ],
                  "abstract": "Video compression and manipulation, audio digitization/signal processing, and fine-pitch manufacturing and component technologies have come together to enable add-in peripheral cards that allow a personal computer user to collect, edit, manipulate, and output video and audio information. — This paper develops a model of what a full motion video/audio peripheral card for a personal computer should be, and discusses some of the implementation design challenges.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00716"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Networked Mixed Media Computing",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Brian C. Knittel"
                  ],
                  "abstract": "Networked Mixed Media Computing is defined as combining various “media” (audio, video, text, graphics, MIDI, and images) together under the control of software applications distributed across a network of computers. This technology will change the way that video, audio, and computer people operate, and we should expect some integration of the now very separate video, audio, and computing industries. — The impact of Networked Mixed Media Computing will be felt when it is easy to use, easy to produce material, and inexpensive enough to be prevalent. This paper discusses these issues.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00717"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Digital Telecommunications for Digital Audio/Visual Production",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom Scott"
                  ],
                  "abstract": "Digital techniques are becoming prevalent in audio and video production. Telephone techniques are similarly evolving. Audio and video professionals are faced with learning new communications terms and techniques. This paper is a beginner's guide to digital telephone terminology with examples drawn from Lucas Arts' use of this type of terrestrial telecommunications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00718"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "The Enhanced Viewing Experience – What Does it Take?",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter D. Symes"
                  ],
                  "abstract": "The planned Advanced Television transmission system for the United States will be in place before many program producers can afford true High Definition equipment. The paper discusses a proposed interim production standard, and relates its capabilities to the requirements for an enhanced viewing experience in the home. The economic advantages of the interim system are discussed, and consideration is given to the role of image processing equipment in optimizing display of the images.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00719"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "The Design Challenges of Full-Motion Video for PC-Computer Systems",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dave Hodgson"
                  ],
                  "abstract": "The author divides full-motion video applications for PC-computer systems into three subdivisions, according to functionality and application. The issues of the decoding and encoding of composite video signals, and of the keying and overlay of video signals originating from natural sources and signals synthesized by computer graphical means, are discussed as they relate to PC-compatible personal computer systems. The problems presented by the combination of interlaced and non-interlaced video signals, and by the requirements for color space conversion, are reviewed. A brief discussion of compression schemes for the computerized handling of motion video is offered, followed by a review of design issues relating to image processing structures and to Image Capture hardware.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00720"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Digital Signal Processing with Separated Lows and Highs for TV Applications",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Martin Botteck"
                  ],
                  "abstract": "The rapid development of microelectronic components and the related technology during the last years has made a lot of applications feasible for digital signal processing in the field of television. Especially the availability of cheap field or frame memories has focused the interest on techniques with temporal processing components as e. g. Standards conversion, improved PAL and NTSC coding and transmission /1/,/2/, compatible or noncompatible HDTV bandwidth reduction coding techniques as MUSE /3/ or HD-MAC /4/ as well as display conversion for flicker-free TV-reproduction. The latter shell be dealt with in more detail in this paper.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00721"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Hammar"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00709"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank J. Haney"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00708"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Opening Address",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank J. Haney"
                  ],
                  "abstract": "Good morning ladies and gentlemen, members and guests. Welcome to the 26th Annual Advanced Television and Electronic Imaging Conference of the Society of Motion Picture and Television Engineers. Welcome also to the ever beautiful “City By The Bay”. The theme of the conference “Collision or Convergence: Digital Video/Audio, Computers and Telecommunications”, and the papers to be presented today and tomorrow should, we hope, generate much interest in the converging technologies of digital picture and sound, compression, and computers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00710"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Design of the A72 Digital Character Generator and its Implications",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Adam J. Wilt"
                  ],
                  "abstract": "This article discusses the design and evolution of the Abekas A72 Digital Character Generator, and discusses how its architecture has affected its evolution. The A72 was intended to offer the highest possible character quality and smooth motion effects. While these goals were achieved, the CG was initially unable to satisfy market needs for density and complexity of text pages. However, the flexibility of the design allowed the system to grow and evolve, not only to remedy its initial shortcomings, but to offer capabilities and effects previously thought impossible to implement. The use of many general-purpose processors, with software used to control even low-level tasks normally “hardwired” on a CG, allowed this growth to occur with few hardware modifications to existing A72s. This approach proved invaluable in keeping the CG up-to-date, and it is suggested that such an approach may be increasingly advantageous for future equipment design.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00713"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "The Ultimate Motion Imaging System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "G. Seth Shostak"
                  ],
                  "abstract": "The imaging systems most popular today, 35mm film and television, deliver images with, at most, a few hundred megabytes of information per second. How close are such systems in terms of visual fidelity to an ultimate system: one that would reproduce moving imagery indistinguishable from reality? By considering the parameters of human vision, we can estimate the data rate for such an ultimate system to be approximately 750 GBytes sec-1. Extrapolation of current technologies suggests that we can build practical versions of such systems within three decades.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00711"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "High Quality Audio Compression for Broadcast and Computer Applications",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John P. Stautner"
                  ],
                  "abstract": "This paper discusses advanced high quality digital audio compression algorithms and techniques. Performance issues are discussed in the context of broadcast and computer applications. The algorithms are classified according to their features, the resulting benefits, and their cost Results from international activities for the standardization of audio compression algorithms are reported. Enhancements and advanced algorithm developments leading to increased performance, flexibility and efficient implementation are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00714"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "The Computerization of the Video World and the Videozation of the Computer World",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steven Mayer",
                    "Charles Clarke"
                  ],
                  "abstract": "Historically the video and computer industries have seen themselves as separate industries because of differences in technology, customer base, and the type of information that is being processed.…pictures versus numbers. Major technical and market trends occurring in both the video and computer industries suggest that these two industries started overlapping in the 80's, and that by the end of the 90's, there will be no separate video and computer industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00712"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Factors that will Shape Future HDTV Technical Plants",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James A. Kutzner"
                  ],
                  "abstract": "Considerable discussion has taken place regarding the HDTV plant of the future. Included in this discussion is the topic of compression and the need for a compression hierarchy. What needs to be discussed is the development of this hierarchy from the point of view of the users, that is the broadcast, cable, and related industries. A Compression Hierarchy is proposed and discussed in a practical setting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00729"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "A Tutorial on Picture and Sound Compression, and an Introduction to JPEG and MPEG: Or, a Little Data can Go a Long Way!",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Poynton"
                  ],
                  "abstract": "This note comprises two parts: a tutorial on the storage and transmission of digital images and sounds in compact forms, and an outline of the JPEG and MPEG-1 standards for image compression. — Image and sound data is generally quite voluminous and taxes the data capacity of computers. Fortunately image and sound data is usually highly redundant, so digital compression techniques may be used to make more tractable the problem of storing and transporting images and sounds using computer techniques. — JPEG is an acronym for Joint Photographic Experts Group, an international standards group within ISO and CCITT that is standardizing a compression algorithm for continuous-tone still color pictures. — MPEG is an acronym for Moving Pictures Experts Group, a standards group within ISO that is standardizing the coding of moving pictures and associated audio information.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00715"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Digital Image Exchange: File Format and Calibration",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "K. Curry",
                    "G. Kennel",
                    "M. McCrackan",
                    "D. Snider"
                  ],
                  "abstract": "Eastman Kodak Company is developing a High Resolution Electronic Intermediate System for the motion picture industry. This system scans and digitizes motion picture film images. The images are interactively manipulated on a computer-based workstation and then recorded back to motion picture film.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00725"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "HDTV and HRI - Avoiding the Collision and Applying Perspective to a Convergence",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurence J. Thorpe"
                  ],
                  "abstract": "That there is a convergence of television, telecommunications, and computing is not in doubt. It is already quite visible, its advance is global - and inexorable. Its inevitability is spurred by the insatiably expanding demands of worldwide complex, sophisticated, and information-based societies. Technologies are bound together not because of any esoteric elegance of their engineering, but rather, because system solutions - of ever-increasing sophistication - are being sought for a vast multiplicity of human and institutional needs. So, this discussion begins squarely based on the intractable reality that a convergence is already well underway. The question is: To what degree should technologists intervene in the “management” of the convergence?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00723"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Weighing the Advantages of Scalable Digital Video",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Craig J. Birkmaier"
                  ],
                  "abstract": "As the theme of this conference suggests, in the past year we have become increasingly aware of the rapid convergence of the computer, video, film, telecommunications and publishing industries. While in the past, each of these industries developed their standards independently from one another, it is becoming increasingly obvious that future systems must be constructed so as to allow data to move freely between all users in all environments. The history of past attempts, and the proliferation of imaging standards in these industries, leads to the obvious conclusion that there are no common denominators upon which we can construct a global digital communications system. However, if one looks beyond the obvious, and examines the nature of a totally digital communications system - one with vastly improved bandwidth as well as point to point and multi-point switching capabilities - a not so obvious conclusion can be reached: The system should operate as much as possible without the need for any standards. From this point of view, backward compatibility to all previous standards becomes a reality. This paper will explore some of the requirements for a scalable digital video system that provides backward compatibility with both analog and digital imaging standards, as well as a solid foundation on which higher resolution imaging systems can be built.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00727"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Digital HDTV Compression Techniques for Terrestrial Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William Y. Zou"
                  ],
                  "abstract": "The latest digital signal processing and VLSI developments have significantly contributed the rapid emergence of digital image compression techniques in HDTV applications. Significant progress has been occurring in the development of advanced television techniques for terrestrial broadcasting. Currently, the most promising advanced television systems in the United States explore the possibility of a digital signal fitting into a 6 MHz terrestrial broadcast channel. One of the challenges of designing a digital system is to compress an HDTV source so as to transmit it in a 6 MHz television channel. The fundamental goal of digital HDTV compression is to reduce the bit rate while maintaining an acceptable image quality. Numerous bandwidth compression techniques have been developed, such as differential pulse code modulation (DPCM), subband coding including transform coding, vector quantization, hybrid coding, entropy coding and adaptive versions of these techniques in response to the growth of image-processing methods. These techniques usually explore the psychophysical as well as statistical redundancies in the image data to reduce the bit rate. This paper will review these compression techniques, such as intraframe coding, interframe coding, motion prediction/compensation, subband/transform coding, quantization, entropy coding and buffer. Also, it will discuss how these techniques are employed in the proposed digital HDTV terrestrial broadcasting systems. To compare the proposed digital systems, a table of attributes, characteristics and processes of digital HDTV terrestrial broadcasting systems is provied.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00722"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Lessons My Mother (Ma Bell) Taught Me about Compatible Variable Bit Rate Video",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Carl Ostrom"
                  ],
                  "abstract": "With three separate industries proceeding with their own agendas, the advent of digital video products and services could produce a new nightmare of multiple incompatible signal formats and connectivity requirements. This paper will examine the possibility of using the variable bit rate concept of the telecommunications standard H.261 to provide a single multi-application signal standard consisting of the integration of 4:2:2 digital component and the JPEG and/or MPEG computer video standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00726"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Improvement of Picture Quality in Nonstandard Speed Play of Digital VTR",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hitoaki Owashi",
                    "Kyoichi Hosokawa",
                    "Kazuhiko Yoshizawa",
                    "Yoshizumi Watatani",
                    "Shoji Ohno",
                    "Toshiaki Kawamura"
                  ],
                  "abstract": "In nonstandard speed play of a composite video tape recorder (VTR), the reproduced video is converted to a standard TV signal, since fields in the reproduced video are skipped or repeated. For the field conversion processing a Y/C separation circuit and a line-interpolation circuit are used. In a conventional processor, the picture quality is deteriorated due to vertical displacement of the image and lower resolution. To remove these deficiencies a motion-adaptive field-conversion circuit, which uses inter-field signals, has been developed. Based on these techniques, three kinds of gate arrays were developed and employed in a D2 VTR for NTSC signals. Consequently above problems were solved and picture quality was remarkably improved.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00730"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "A Novel Image Compression Technique Using Modular Algorithm",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jidong Shen"
                  ],
                  "abstract": "In the practice of predictive image coding, information loss is a problem in the accuracy of representing the prediction residual sequence. This is because the high order of probability distribution requires a huge size of codebook. This paper presents a modular arithmetic based technique for DPCM image compression. By using this algorithm, the length of codewords required by the following entropy coding is necessarily limited to a certain positive integer, the residual sequence is exactly reconstructed from decoder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00728"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Enterprise-Wide (Network) Digital Automation Protocols: What's Happening? What's Needed?",
                "article_url": "https://journal.smpte.org/conferences/Proceedings:%20The%2026th%20Annual%20SMPTE%20Advanced%20Television%20and%20Electronic%20Imaging%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Paulson",
                    "David E. Lewis"
                  ],
                  "abstract": "“Enterprise” defined and differentiated from “network” Enterprises are businesses established and operated by entrepreneurs to make money. (The English word derives from the French “entre-prendre.”) It is used in the computer industry to define business activities which require computer “networking” to make money (interconnection of mainframes, data bases and dumb, smart and intelligent terminals for the interchange of information between and among people)",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1992-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00724"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1991",
        "conferences": [
          {
            "conference_name": "A Television Continuum 1976 to 2017: 25th Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "10",
                "article_title": "Fast Audio Measurements for Television Network and Satellite Service using Digital Techniques",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard C. Cabot"
                  ],
                  "abstract": "The paper will discuss methods to test the amplitude response, phase response and distortion of audio equipment and links. A new approach is described which is considerably faster than existing methods in common use. The signal may be transmitted and acquired in one second, producing minimal disturbance to broadcast programs and allowing quasi-real time measurements. Results may be displayed as obtained or viewed off line if desired. Measurement results on typical equipment are included.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00903"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Opening Address – 25th Television Conference",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank Haney"
                  ],
                  "abstract": "Good morning ladies and gentlemen, members and guests. Welcome to the 25th Annual Television Conference of the Society of Motion Picture and Television Engineers. Welcome also to the “Motor City”. The theme of this conference “A Television Continuum – 1967–2017” and the papers to be presented today and tomorrow should, we hope, generate much interest as to where we have been, where we are now, and where we are going into the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00896"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank J. Haney"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00894"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "The Changing Role of the Television Engineer",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Irving S. Rosner"
                  ],
                  "abstract": "At the time of the first Annual Television Conference, in 1967, the television engineer was working in a rapidly changing technological environment. The environment itself was broadcast based with strong domestic manufacturing, research and development support. In the quarter century that has elapsed since then, the technology has matured, the industry expanded far beyond the broadcast base and its manufacturing, research and development declined domestically. Today's television engineer faces a different set of problems and functions in a different manner from that of the earlier time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00897"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Multi-Channel Applications of Cart Machines",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ray Baldock"
                  ],
                  "abstract": "Increased industry interest in programming multiple output channels from a single location led Odetics engineers to investigate an economical solution to feeding different commercials to each feed. Implementation without duplicating the cart library or dedicating a cart machine to each feed were the basic design criteria. — This paper will describe the design of a Break Tape Manager (BTM) to meet these requirements and its integration with the Cart Machine using a Local Area Network. This approach minimizes the number of VTRs required for each additional channel. The system can manage programming and commercial replay for several independent feeds as well as for split feeds, where the programming is common and only the commercials are regionalized. The BTM also accommodates late changes to the regional schedules. — Such operation is now commonly required for superstation or network operation and is becoming an important issue to local broadcasters as they look for additional revenue streams for their product. — The introduction of the BTM highlights the importance of being able to share database information between several automated systems. An expandable network based system architecture is therefore an important aspect of system design and is vital when multiple cart machines and workstations are in use. This paper also describes the implementation of the LAN for managing multiple cart machines and integrating their operation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00900"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rudolph J. Kryger"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00895"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Fiberoptic Circuit Transportation of Video Signals: A Solution without an Urgently Perceived Need",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Paulson"
                  ],
                  "abstract": "“Lightwave” systems for the transmission of television and computer graphics images over optical glass fibers moved from laboratory experiments to implementation as high-quality, highly useful, cost-effective commercial services in the 1980s decade. First-generation systems used a baseband electrical signal waveforms to intensity-modulate a low-power light source, for transmission of a single video channel over a kilometer or two of multimode fiber. Many are still in use today, because the solid-state terminal electronics are highly reliable and stable, and the fiber is also stable, resistive to physical contamination, and impervious to EMI and RFI. — Third generation systems now in the marketplace can transmit dozens to hundreds of video channels plus ancillary voice and data channels on single mode fiber, for distances up to 50 and more kilometers. However, there is little to no design, function or interface specification commonality among any of these systems, even within generational groups. — Early 1990s establishment of a nested family of fiber transmission system standards is the absolute prerequisite to prevent inevitable transmission systems chaos in the mid 1990s. This chaos will suddenly arrive when innovators in the television and graphics and sound production and postproduction marketplaces suddenly discover that fiber is the only solution to needs for transmitting constantly higher and higher resolution images and mushrooming numbers of ancillary audio, intercom and data channels. — Perhaps, quite by accident, however, standards setters in the telecommunications and television/radio broadcasting/sound recording industries may be on courses which will lead not to chaos but to accommodation. — If the price is right!",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00899"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "New Technology in Still Stores – What are the Implications?",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bob Pank"
                  ],
                  "abstract": "The practice of storing frozen TV images on computer discs for later recall is now some ten years old. Over that period there have been very significant changes in the technologies applied to still stores allowing their use to be expanded well beyond the original concepts of a straight store and recall device. Disc capacity, size and price make on-line stores of a 1,000 or more images an economic reality whilst VLSI circuitry packs more electronics into smaller frames. To reap the benefits of these advances requires not so much a rebuilding of the hardware with new components but re-thinking the part that still stores can play in modern TV production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00904"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Proposal for Error Detection and Handling in Studio Equipment",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bob Elkind",
                    "David Fibush"
                  ],
                  "abstract": "By its nature, video equipment which is digital, rather than analog, has greater potential for “minor” failures which result in signal distortions which are visually obnoxious. Analog equipment is more likely to fail gracefully and subtly when it malfunctions. On the other hand, digital equipment has a potential for self-testing, verification, monitoring, and remote diagnosis that is not possible with analog equipment, by its very nature. — A proposal for exploiting this potential for error detection, self-diagnosis, and complete system monitoring in digital equipment is described. The proposal includes generating CRC words which are inserted into the digital video signal and used for error detection. Additional error information is also inserted into the signal which allows appropriate monitoring equipment to detect the occurrence of any bit errors, and identify and isolate failing video equipment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00909"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "“Plotting a Course to an All Digital Television Facility”",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "P.G. Whittingham",
                    "J. Howells"
                  ],
                  "abstract": "The all-digital television facility will be here before the turn of the century. In transition, what does a planner consider when adding digital audio and video systems today? Faced with a start up operation, how does one deal with the need to integrate large numbers of analogue devices into a new digital plant? How may future Advanced Television affect today's design of a digital facility? — The authors will outline the key elements of SONY's system design of a Serial Digital Router for the new CBC Toronto Broadcast Centre. The many factors examined are common to any facility considering digital systemization.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00908"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Video Compression and Noise Reduction using Transform/Subband Coding and Adaptive Amplitude Modulation",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David M. Baylon",
                    "Jae S. Lim"
                  ],
                  "abstract": "This paper presents in a unifying and tutorial manner, the basic ideas behind transform and sub-band representations of a signal. Although transform and subband representations appear to be different, we discuss how, in fact, they are equivalent. This theoretical relationship gives useful insights into the design of video processing and compression systems. An application of this result to the design of an adaptive amplitude modulation/demodulation (AM/DM) system for noise reduction of images is then described. We discuss the AM noise reduction technique for additive noise, and then present a method to reduce the AM side information by exploiting the transform representation of an image.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00910"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "The Past Quarter Century and the Next Decade of Video Tape Recording (Invited)",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hiroshi Sugaya"
                  ],
                  "abstract": "Since the first commercially successful video tape recorder (VTR) was developed in 1956, many VTRs were developed and put on the commercial market. If the picture quality is almost the same, the tape consumption per hour (TCH) of a commercially successful VTR in its sales year will decrease according to a trend line of one tenth per ten years. If the picture quality is improves, the trend line will move toward a higher position on a parallel line. — We can forecast the future specification of the VTR as a function of TCH from such a trend chart. The miniaturization of the pitch and wavelength is a motivating force of VTR development. In this manner, high utility, high performance, but low cost VTR was developed and continues to improve. The harmonization of hardware and software is the next important problem. — In this paper, a short technical history of VTR, the future of VTR predicted from the trend chart, and the technical motivating force of VTR development are discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00898"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Techniques for High-Accuracy Measurements in HDTV Systems",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ed Wardzala"
                  ],
                  "abstract": "Some techniques for making high-accuracy measurements at baseband HDTV frequencies are described. Measurement artifacts in video systems and test equipment are partitioned into linear and non-linear effects. A method for isolating the measurement network from the video system under test is described to locate the linear sources of measurement uncertainty. A discussion of identifying nonlinear measurement error in a component video environment is presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00902"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "A Study of the Most Suitable Level and Width of DTL-Signals for CCD Camera",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hiroshi Kouchi",
                    "Tohru Mochizuki"
                  ],
                  "abstract": "CCD devices are gradually gaining the popularity in the field of image pickup devices for TV broadcasting video camera. When CCD is used, resolution becomes different from tube camera. This paper describes how to determine the most suitable DTL in case of CCD camera by evaluating the picture qualities. The result shows that the following are desirble. (1) Double DTL method with low and high frequency DTL signals. (2) Level of each DTL signals should be controled according to lens zoom position. (3) Non-linear process for DTL signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00905"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "The All Digital Television Plant: It Seemed Like a Good Idea at the Time",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank Davenport"
                  ],
                  "abstract": "Coverage of the Seoul Olympics resulted in a quantity of television equipment to be dispersed throughout the NBC Network. As a consequence, the equipment which will result from the NBC coverage of the 1992 summer Olympics [Fig. 1] will have few “good homes” to go to. However, at 30 Rockefeller Plaza, the Master Grid is celebrating its 22nd birthday, and since it is comprised of relays and DTL logic it is becoming increasingly difficult to maintain. Hence there seemed to be an ideal linkage between the upcoming Olympics master router acquisition and the planned 1992/93 replacement of the ageing Master Grid. In addition the experience gained in design and operation of a “Digital” Olympic facility would prove very beneficial to the planned refurbishment of 30 Rock.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00912"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Clock Rate Conversion for Digital Video",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. Hamalainen"
                  ],
                  "abstract": "Over the next two or three years we will be debating about the future of US TV standards, deciding whether it will be analog or digital, simulcast or NTSC compatible, how to transmit it to the homes and with which quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00911"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Progress Report from SMPTE Ad Hoc Group for ES-Net",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marc S. Walker"
                  ],
                  "abstract": "For over 12 years, SMPTE and EBU committees have been working in cooperation on machine control standards for television equipment. This work has resulted in the highly successful ES-Bus hardware specification, ANSI – SMPTE 207M. This has been accepted worldwide, resulting in the many devices with 9 pin connectors and RS-422 control. The time has come for a higher performance level in a hierarchy of control systems. The Ad Hoc Group on ES-Net has been looking at various candidate networks, and will soon recommend a network to its parent committee. This paper discuses the issues being examined in selecting a network.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00901"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "The Opportunities of Signal Monitoring in a Large Serial Digital Plant",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robin Wilson"
                  ],
                  "abstract": "When faced with the technical planning of a digital television facility, signal monitoring is a topic that appears at first to be of low priority. This was the case in NBC while structuring the initial plans of operation in a digital plant. Our first assumptions were that we could use waveform, vector and picture monitors similar to that used today. Perhaps a minor modification would be required to convert the serial digital data stream to an analog waveform. The analog waveform can then be displayed on the same type of CRTs that are presently used. As a result of further research we became alarmed at the extra cost the additional circuitry would incur.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00913"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "A 1/2″ High Definition VCR with a Single-Channel Analog Baseband Recording Method",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takashi Furuhata",
                    "Hiroaki Takahashi",
                    "Kichizaemon Okazaki",
                    "Michiyori Miura"
                  ],
                  "abstract": "A high definition video cassette recorder with a single-channel analog baseband recording method has been developed to provide a convenient means for long time recording and reproducing of HD programs not only for semi-professional use but also for home entertainment. By introducing a newly developed high efficiency video signal encoding method to realize single-channel baseband recording, and SN ratio improvement techniques, it features the maximum recording time of 150 minutes with a 1/2″ small size cassette for 1125/60 HD standard signals. This paper describes those techniques to realize a new HD VCR capable of wideband and high-quality picture reproduction.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00907"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Format Choices for the Future",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ken Shaw"
                  ],
                  "abstract": "The success or failure of a new videotape recording format is determined by how well it satisfies three basic criteria. These are: economic criteria (cost to purchase, operate and associated media costs; Performance criteria (editing capabilities, special effects, shuttle speeds, etc.); and market criteria (multiple suppliers, standard interchange format, installed base). In addition, each format must also be evaluated in terms of its intended application(s). The formats explored in this paper will be: D-1, D-2, DX, Type C, and Betacam SP. Through step-by-step analysis of these criteria and applications, each audience member will gain the tools necessary to draw some concrete conclusions regarding their particular format requirements which will best suit their needs today and in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00915"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Development of the Super-HARP Camera, a Rival to the Human Eye, for the Next Generation of Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Junichi Yamazaki",
                    "Kenkichi Tanioka",
                    "Keiichi Shidara"
                  ],
                  "abstract": "NHK has developed a new high-performance camera tube for producing superior pictures and with a sensitivity 100 times that of conventional camera tubes or CCDs. The new tube, called the Super-HARP, uses the phenomenon of avalanche multiplication in a thin target layer, and is capable of producing high picture-quality in a wide-range of conditions from daylight to moonlight. Its sensitivity has made it possible to develop many new kinds of programs and it will certainly bring about changes in the basic techniques of TV program production and studio lighting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00906"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Experimental Digital VCR with New DCT-Based Bit-Rate Reduction and Channel Coding",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Naoki Endoh",
                    "Shigeo Kizu",
                    "Toshinori Odaka",
                    "Keisuke Ogi",
                    "Kenji Shimoda",
                    "Masaaki Tamura"
                  ],
                  "abstract": "The number and the size of recording bits of a VCR should become smaller for it to become more compact and long-playing. The authors have achieved a data rate of 28 Mbits/s for a component coded video which normally requires approximately 200 Mbits/s, maintaining a high picture quality with less noticeable degradation by using a new DCT(discrete cosine transform)-based bit-rate reduction method. The authors have developed a data format based on the triple Reed-Solomon product code and a new 8/14 modulation scheme to make the recording density higher. An experiment has shown the feasibility of the authors' new system concept.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00914"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Open Architecture Television",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "V. Michael Bove",
                    "Andrew B. Lippman"
                  ],
                  "abstract": "We introduce the concept of Open Architecture Television, in which a digital representation of moving images is specifically designed to facilitate interconnection. The fundamental concept behind the Open Architecture approach is that the next generation of television systems should add degrees of freedom in addition to lines of resolution. Rather than defining a single television standard with a fixed number of lines per frame and frames per second, we consider a system in which production, distribution, storage, and viewing of moving images can each freely employ a variety of standards optimized for specific situations. Scanning parameters of the various segments in the system are effectively decoupled one from another through the medium of a digital interconnection standard. — This flexible, extensible video format will accommodate a variety of production frame rates and resolutions, support a broad range of display quality for differing applications, and incrementally upgrade (rather than becoming obsolete) when higher-resolution cameras and displays become available. We demonstrate that a particular hierarchical representation for video (that of three-dimensional subband coding) possesses these desirable properties and additionally offers a common technological basis for digital television channels spanning several orders of magnitude in bandwidth. We outline the technical and psychovisual considerations involved in developing an Open Architecture Television system, and describe our experiments in signal processing and hardware design toward this goal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00916"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Plasma Addressed Liquid Crystal (PALC), a New Flat-Panel Technology for Full-Color Video",
                "article_url": "https://journal.smpte.org/conferences/A%20Television%20Continuum%201976%20to%202017:%2025th%20Annual%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas S. Buzak"
                  ],
                  "abstract": "Current methods that attempt to provide high addressability, flat-panel displays suffer from fabrication difficulties due to the large number of active circuit elements required. A new active matrix technique forgoes the use of transistors and uses an ionized gas to electrically address a variety of electro-optic materials. This plasma active-substrate is functionally similar to a large array of transistors, but with a comparatively simpler structure. In combination with standard liquid crystal materials, plasma addressing has the demonstrated ability to address the large numbers of pixels required for video images. This technique has the potential for providing flat, full-color displays in large sizes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1991-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00917"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1989",
        "conferences": [
          {
            "conference_name": "Better Video Images: 23rd Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "7",
                "article_title": "The Gemini Process: A Theatrical-Quality Video-to-Film Transfer Process",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stewart Dickson",
                    "Bill Villarreal"
                  ],
                  "abstract": "A system is described for transferring video program material to film. The system provides for increased spatial resolution with a subjective improvement in image quality. Image processing hardware and software enable various treatments of source material for optimum visual quality of the final transferred image. Special hardware has been developed for controlled film recording of images. Applications include film finish of motion pictures made for television, special effects produced in the video domain put on film for composition in film post-production, and standards conversion.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00737"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "A Progress Report on Improved NTSC",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yves C. Faroudja",
                    "Joseph Roizen"
                  ],
                  "abstract": "In the past few years, the NTSC system has been subjected to considerable scrutiny by various researchers in an effort to squeeze every bit of potential picture performance from this well entrenched color standard which now serves more than 30 countries, and hundreds of millions of home receivers. — This paper will describe a variety of recent developments that extend the usefulness of the NTSC signal format into the Advanced Television arena that is now of such great interest to television futurists. — The improvements to be described affect all aspects of NTSC operations, including signal origination, videotape recording, professional and consumer displays, and some of the propagation problems associated with program delivery. The areas to be explored and defined include the new high performance consumer VCRs which employ unique processing circuitry to achieve picture quality superior to the best of current terrestrial broadcasting and cable delivery. In addition the authors will look at how the image display can be made to simulate HDTV performance through the use of line doubling and advanced motion interpolation techniques. — The overall attempt of this paper is to give an overview of the various areas of NTSC image generation, processing, distribution and display, which can be improved substantially by the application of a variety of recently developed techniques. The demonstrable result is that a fully expanded NTSC system can indeed be used for many years to come as a fully compatible Advanced Television System, while the ultimate all-digital television broadcast system is under study and development.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00744"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Opening Address—23rd Television Conference",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank J. Haney"
                  ],
                  "abstract": "Good Morning ladies and gentlemen, members and guests. Welcome to the 23rd Annual Television Conference of the Society of Motion Picture and Television Engineers. Welcome also to the ever beautiful “City by the Bay”. The theme of this conference “Better Video Images” and the papers to be presented today and tomorrow should, we hope, generate much interest as to where we are now and where we are going into the future. A change you have no doubt noticed is that there are no equipment exhibits at this Conference. This came about as a result of a request from the equipment exhibitors who cited both escalating costs and drain of resources in the proliferation of exhibits at shows. We believe that the full plate of papers to be presented here will keep you fully occupied.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00733"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank J. Haney"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00731"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "System-Wide Integration of Analog and Digital Component Video in a Post-Production Environment",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Farney",
                    "Bob Frey"
                  ],
                  "abstract": "Since 1985 Pacific Video Resources has been creating “Better Video Images” by applying a total component approach to production and post production. This facility-wide approach applies component technology to an otherwise traditional post production architecture. All video signals are processed, distributed, and recorded in their component forms resulting in better quality images, avoidance of NTSC artifacts and repeated encode/decode cycles, and greater operational flexibility. The facility includes a central equipment room/technical center supporting two on-line edit suites, a graphics suite, an insert stage, and component duplication. Within the facility are two composite islands for off-line editing and composite duplication. This unique mix of Y, R-Y, B-Y and RGB component analog signals, RP-125 (D1) component digital signals, and alpha/composite signals has created numerous engineering challenges requiring innovative solutions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00734"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Naturalistic Camera Moves in Image Compositing",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Patterson"
                  ],
                  "abstract": "The absence of any camera movement in composited images often undermines the credibility of the composite or gives the images an awkward quality. To overcome this limitation a portable, computerized pan/tilt head capable of repeating pans, tilts, zooms and focus pulls with the accuracy required for image compositing has been developed. It can be operated in the same way as a conventional fluid head tripod, or it can be remotely controlled by a variety of means.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00736"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Hammar"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00732"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Surviving in Broadcasting's Standards “Ménage à Trois”",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Paulson"
                  ],
                  "abstract": "NTSC's 27-year exclusive reign as the sole US standard for video image creation, transmission, processing, switching, mixing, keying, recording, editing, distribution and broadcasting, started to end at the beginning of what SMPTE named as “The Digital (1980s) Decade at the Toronto Television Conference. Ten years later, NTSC's monarchical reign is being threatened by not one but three digital and a pair of newcomer analog contenders, all vigorously championed by technopolitically astute legions of television and communications industry technologists. — Broadcasters and program producers didn't nurture the television industry technologists that have led the recording format evolution parade from NTSC to CAV to D-1, D-2 and beyond, using recording media ranging from magnetic tape through magnetic and optical disks and on to optical paper tape. Neither did they sire or nurture the communications industry technologists who have shut down NTSC full bandwidth, long haul, terrestrial microwave transmission in favor of bandwidth-compressed DS-3 (44.7 Mbps) and even DS-1 (1.544 Mbps) tariffed terrestrial fiber optic transmission services. — This paper is purposefully organized and challengingly written, to encourage vigorous debate about the merits of the menage a trois rule which now confronts us. It concludes with some conjecture about the possibility of moving SMPTE onto a course “back to the future” — arriving finally at a single US standard for video image creation, transmission, processing, switching, mixing, keying, recording, editing, distribution and broadcasting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00746"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "601 in Use",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. J. Mitchell"
                  ],
                  "abstract": "The Moving Picture Company is based in London's Soho district and specializes in Commercials post-production, and video effects. This specialism dates back to the mid-70's, still 2" days, when we experimented with hand drawn mattes, and obtained the first Quantel 5001.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00739"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Objective Measurement Methods of Motion Artifacts for 45 Mbit, NTSC, DPCM, Bit-Reduction Video CODECS, Part 2",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard Meiseles"
                  ],
                  "abstract": "This paper discusses measurement methods for objectively testing the effects of the Motion Prediction Algorithms used in bit-reduction Video CODECs for NTSC signals. — The objective testing method described in this paper utilizes a series of new test signals for measuring the video distortions of dynamic signals resulting from the bit reduction process. — These proposed test methods may be used to measure the effects the coding algorithm has on dynamic resolution and temporal response.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00741"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "International Transmission of HDTV Signals",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keiichi Kubota",
                    "Yuichi Iwadate",
                    "Kenzo Seo",
                    "Mutsuo Matsumoto"
                  ],
                  "abstract": "To confirm the feasibility of the international and domestic program transmission via satellites, international transmission experiments from Japan to Australia and from Korea to Japan using the MUSE signal were successfully carried out in 1988. The first transmission was conducted on three-hop basis using CS-2,- INTELSAT, and AUSSAT. The second transmission was the live-broadcasting of the Olympic Games in combination with INTELSAT and BS-2. In both transmissions, the CN ratio of about 17.5 dB, which corresponds to the limit of perception of the noise impairment was obtained. Excellent waveform transmission characteristics were also obtained by employing IF and baseband equalizers. Through these experiments, it was concluded that international and domestic transmission of HDTV can be done by existing satellites and earth stations without modifications as long as modulators and earth stations are connected by an IF signal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00742"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Component Digital Switching",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Andy Sheldon"
                  ],
                  "abstract": "The Abekas A84 Digital Post Production switcher is designed to be integrated into a CCIR 601 Component Digital editing environment. — The A84 has 8 compositing layers each capable of performing two separate keys. Utilizing ASPIK™ Adaptive Sub-Pixel Intelligent Keying the A84 will ensure that the key edges are free from stair stepping.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00738"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "EBU Activities in the Worldwide Search for HDTV Studio Standards",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles P. Sandbank",
                    "David Wood"
                  ],
                  "abstract": "The paper addresses the current EBU position with respect to the dilemma between the desire for a single world-wide standard for HDTV programme exchange and the recognition of the need for programme sources compatible with emission strategies for 50 Hz as well as 60 Hz environments. Some possibilities for a dual mode approach along the lines of Rec.601 are examined and the advantages of 50 Hz as a basis for an eventual programme exchange standard are explained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00747"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Reducing Financial Aliasing in HDTV Production",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles A. Pantuso"
                  ],
                  "abstract": "The acceptance of High Definition technology by program producers and broadcasters will depend on financial viability as much as on specific technical parameters. This paper proposes a method of operating HDTV equipment which reduces the cost, complexity, and image degradation inherent in conversion to PAL, NTSC, and 35mm film. The operating modes proposed are frame-rate friendly to the local television standard, and High Definition tapes created using the system can be interchanged between countries with no temporal interpolation required. This offers the possibility of international hardware standardization now, and enhanced-capability HDTV-only distribution in the future. Specific details of the process are discussed in relation to the SMPTE-240M standard, but the underlying principles are applicable to any of the proposed HDTV production systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00748"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Compatible Hierarchy of Studio Standards",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jean Chatel"
                  ],
                  "abstract": "The concept of a compatible hierarchy of studio standards has been formely introduced. This paper, after reminding parameters of the different members discusses extensions of this hierarchical family. It emphasizes the complementarity of the different levels when the hierarchy of standards is associated with a hierarchy of studio equipment. — Members of the hierarchy are mainly described by the signal representation of their luminance component. Other levels can be derived from the different options for the colour difference signal representation. Practical considerations on performance and interface aspects allow selection of the most appropriate options. Further analysis of practical implementation of digital interfaces show that some interlace and progressive signal representations can make use of the same pieces of equipment. — The hierarchy of equipment offers a great flexibility with respect to cost or technical constraints in that the most appropriate standard can be used for the application. — These considerations emphasize the attractiveness of compatible evolution in the introduction of new television systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00752"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Second-Generation HDTV Camera",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurence J. Thorpe"
                  ],
                  "abstract": "A considerable experience was gained by a widespread international deployment of the first generation HDC-100 cameras within a diverse spectrum of HDTV program origination. Throughout, a close dialogue was maintained between these many end users and our HDTV camera design engineering group. A working alliance of the video and film communities were also developing the parameters for a very complete rendering of an HDTV studio origination standard - which was finally completed by SMPTE in 1988 in the form of the now well known SMPTE 240M. This emerging standard was to shape many of the technical decisions in the design of the new HDC-300 camera. — The HDC-300 design sought to realize a camera system more compact, lightweight, and having a lower power consumption - than its predecessor. Major investments in new technologies were made. A totally new pickup tube design - the result of a collaborative effort of Sony, Hitachi and NHK - produced a 25mm tube smaller than that of the HDC-100. The utilization of the latest in contemporary microcircuit packaging techniques constituted a central aspect of the overall design program.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00749"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "8-City DS3 Digital Video Trial—Progress and Networking Features",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert J. Blackburn"
                  ],
                  "abstract": "Momentum continues to build toward a U.S. field trial of a land-based digital network for broadcast television distribution and collection. There are two primary challenges to the trial: first, to be sure that the picture quality including the effects of real transmission impairments, such as errors and protection switching hits, will be acceptable to the television broadcasters; and second, to be sure that the networking controls are at least as good as today's satellite networks for collecting from and distributing to fixed locations. Both of these challenges are being faced and, with the continued good will of the numerous trial participants, the trial is moving forward. This paper reviews the trial status and the extremely flexible networking arrangements that are being pursued.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00740"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Engineering and Program Production Experience with High-Definition Television",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Norman W. Green",
                    "Derek P. Allsop",
                    "Mike A. Elgey"
                  ],
                  "abstract": "In 1990 a decision will be made regarding a worldwide High Definition Television standard. The ITV Association together with other European organisations and companies are working towards a new standard which is compatible with those existing in Europe. This paper reviews the effort made by the ITV Association in both the engineering and programme production fields, and outlines its goals for future participation in the development of an acceptable European HDTV standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00750"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Better Video through Digital Post-Production Techniques",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas Kennedy",
                    "Bert Swackhamer"
                  ],
                  "abstract": "We have seen the introduction over the last few years of digital cel recorders for use in postproduction. More recently, digital VTRs have been introduced which are compatible with these formats. With the CCIR 601 format VTRs, this has opened up a new vista of postproduction techniques for special effects and graphics. With composite digital VTRs there is the prospect of better video generally through these VTRs becoming the dominant format in postproduction and broadcasting. This paper describes some of One Pass Film & Video's experiences with these developments from September, 1987 through January, 1989.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00735"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Reduction of Multipath Effects and Channel Distortion in Broadcast Television",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Melih Pazarci"
                  ],
                  "abstract": "A new technique for the adaptive recursive removal of “ghosts” is described. The system is based on look-up and decision-based adaptive assignment of the parameters of the recursive algorithm. A coarse channel estimation is used to select the initial parameter set. The algorithm requires a training signal in the vertical blanking interval. A master control algorithm keeps track of the echo-channel and system parameters, and makes the necessary control decisions and echo assignments. Two-axis synchronous detection is used and the echo reduction operation is performed in the baseband. The system is targeted for digital NTSC and IDTV/EDTV/HDTV receivers. It is primarily intended for use in the reception of terrestrial VHF/UHF distribution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00745"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Future HD Video Production",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kotaro Wakui",
                    "Noboru Yura"
                  ],
                  "abstract": "HDTV has two aspects. One aspect is HDTV as the tool for production. The other aspect is HDTV as media. We will discuss about the existing state and future of HDTV as a production tool. — Possibly half inch HD VCR will come out in 1989, then HDTV business expansion will be boosted. Higher sensitivity and higher resolution tube and CCD camera and digital VTR (1.188 Gbit/sec) will be in practical use, then HDTV production power will increase greatly. Telecine(Laser) and Laser Film Recorder will be improved enough to make the media mixture of film and video widely. — We expect that the production/post production will be active. Further around mid1990s, we will get the total digital production/post production system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00754"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "High-Definition Transmission, Signal Processing, and Display",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Glenn",
                    "Karen G. Glenn"
                  ],
                  "abstract": "The transmission, signal processing and display of high definition television (HDTV), can benefit from a complete understanding of visual perception. This information is used in the design of a reduced-bandwidth compatible transmission system, and a progressively scanned camera and display for improved vertical resolution without interline flicker. Its application to the development of a solid-state light-valve HDTV projector for theater and consumer use will also be discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00756"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "NTSC Compatible Advanced Television System and Implications for Studio Standards",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. Merrill Weiss",
                    "Kerns H. Powers"
                  ],
                  "abstract": "In the broadcasting industry, the transition from today's NTSC to the inevitable HDTV is perceived to be the outlaying of major investments accompanied by the risk of low to nonexistent rates of return. An NTSC-compatible system approach can alleviate the initial economic shock, and with careful planning, can be designed to permit a phase-in period of several years. The migration concept discussed in this paper increments the degree of participation, especially by local broadcasters and smaller production companies, with corresponding incremental improvements in the picture quality delivered to the viewer at each step in the migration. — This paper describes a family of studio scanning standards that are appropriate to each of these levels of quality at the home display. Emphasis is placed on the use of progressive scanning rather than interlace in the first major upgrade to gain as early as possible the advantages that progressive scan offers in production and post-production operations. An exciting new progressive scan concept is described that holds promise of achieving for archiving purposes the full high-definition static and dynamic resolution within the same recording bandwidth required of today's interlaced HDTV equipment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00753"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "A Very High Resolution, 16.7 Million-Color HDTV Graphic System",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "T. Fujimori",
                    "H. Gaggioni",
                    "M. Imai",
                    "N. Ichikawa",
                    "H. Hirase",
                    "M. Terada",
                    "K. Hata"
                  ],
                  "abstract": "This paper describes the architecture and design considerations of a very high resolution HDTV Color Graphics System for operation with the Sony NEWS family of workstations. This graphics system uses the SMPTE-240M HDTV standard and supports also all the high resolution display formats commonly available (HDTV 1920 times 1035 interlaced, 2048 times 2048, 2048 times 1536, etc.) with a 16.7 million color architecture. It uses six graphics accelerators (100,000 short-vectors/sec), very high speed circuitry as well as a VME interface for communication with host computer. — The introduction of this graphics system, along with the software environment provided by the NEWS Workstations will facilitate the use of the unique capabilities embedded in the SMPTE 240M HDTV standard in its applications to electronic printing and publishing, industrial design and the motion picture industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00751"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "How to Use 4:2:2 in the 16/9 Aspect Ratio",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Max Artigalas",
                    "Jean-Luc Grimaldi"
                  ],
                  "abstract": "In the 1960s and 1970s television technology remained in line with existing broadcasting standards. That technology relied on coded processing of the video signal (became no other technical solution was really feasible at that time) and formed the basis of the development of the three standards that are now in use throughout the world : NTSC, PAL and SECAM. The only point these three standards had in common -an aspect ratio of 4/3- was the result of contemporary tube geometry and was a direct spin-off from the medium that was then in wide use in production-16 mm film. These standards still form the technical basis of most production equipment and of all broadcast, transmission and reception equipment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00743"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "The European Perspectives on HDTV",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John R. Forrest",
                    "Gary Tonge"
                  ],
                  "abstract": "The introduction of HDTV in Europe is being considered primarily for new services which are using, the MAC transmission standard. The MAC system offers significant advantages over present composite systems for compatible HDTV, especially in its inherent dual aspect ratio specification. The Eureka HDTV project is developing an HDTV production and transmission system based on a 50 Hz field rate and on MAC. A European HDTV launch is planned for 1992. However, widescreen services may be available to the public before that date by using an Enhanced Television (ETV) approach.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00755"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Spectrum Compatible High-Definition Television Transmission System",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wayne Bretl",
                    "Richard Citta",
                    "Ronald Lee",
                    "Pieter Fockens"
                  ],
                  "abstract": "The Spectrum Compatible HDTV (SC-HDTV) system achieves the encoding of a 28.9 MHz source signal for transmission over a conventional 6 MHz channel. The new signal format reduces mutual interference between existing NTSC broadcasts and the new high-definition broadcasts to such a degree that significant amounts of currently “taboo”-ed spectrum space become available. As a result, every existing NTSC station can be assigned a second 6 MHz high definition channel. — The HD encoding drastically reduces the required transmitter power which reduces the interference into NTSC broadcasts while at the same time providing immunity against interference by NTSC signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00757"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Evolutionary Approaches to Advanced Television—Making the Migration Possible",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. Merrill Weiss"
                  ],
                  "abstract": "The introduction of Advanced Television (ATV) in the United States is such a complex, difficult, and expensive undertaking that the means for bringing it into being must follow a carefully considered migration path. Important elements of the change which must be provided are the attraction of a large audience, the participation of the largest possible number of program sources and distributors to attract that audience, and the minimization of the costs of introduction to make that participation practical. An approach to meet these goals using Advanced Compatible Television (ACTV) is described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00759"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "A Compatible High-Definition Television System using the Noise-Margin Method of Hiding Enhancement Information",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "W.F. Schreiber",
                    "E.H. Adelson",
                    "A.B. Lippman",
                    "B. Girod",
                    "P. Monta",
                    "A. Popat",
                    "H. Sallic",
                    "P. Shen",
                    "A. Tom",
                    "K. Zangi"
                  ],
                  "abstract": "This paper discloses a novel method of hiding enhancement information in a normal television signal. A receiver-compatible EDTV system is described based on this method, as well as on a method of conforming the 16:9 aspect ratio of the EDTV system to the 4:3 aspect ratio of NTSC without using side panels. Finally, a scheme for hiding digital audio in chrominance is discussed. The three techniques are independent. — It is found that when video signals are transmitted in the usual over-the-air channels, if the SNR is satisfactory at the receiver, it is actually higher than required in some spatial-frequency bands. This ‘noise margin’ provides a place to add a large amount of extra information. The additional video information is hidden in such a way that the added signal appears on NTSC receivers as low-level additive random noise, processed and distributed so as to minimize its visibility, while at the same time achieving the maximum possible SNR of the hidden information. On a special EDTV receiver, the second signal is detected independently, combined with the first signal, and displayed at high resolution. The method does require a channel SNR high enough to make good NTSC pictures; however, an adequate SNR is required for any method of transmitting high-quality NTSC-compatible EDTV/HDTV images through analog channels. — As an alternative to transmitting side panels, a wide aspect ratio on the EDTV display is achieved by discarding a portion of the height of the transmitted image as displayed on a normal receiver, having previously ensured that the areas so discarded are free of significant content. Thus, both screens can be completely filled, but the appearance on the EDTV display is favored, since the image is originally composed for the wide screen, in the same manner as in 1.85:1 film, and possibly visible seams are avoided. — It is shown that the NTSC chrominance channel has excess temporal and vertical resolution. At the cost of a very small decrease in luminance resolution on today's most expensive receivers, a scheme is introduced for transmitting digital audio in the excess temporal bandwidth. The excess vertical chrominance resolution is used to increase chrominance horizontal resolution, which is very low in NTSC. These methods are useable independently of the noise-margin method for increasing luminance resolution and aspect ratio, and could be added to today's system, although not to existing receivers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00760"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "HDTV and Today's Broadcasting World",
                "article_url": "https://journal.smpte.org/conferences/Better%20Video%20Images:%2023rd%20Annual%20SMPTE%20Television%20Conference/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yozo Ono"
                  ],
                  "abstract": "Video image quality is changing dramatically and true High Definition Television produces the highest quality picture possible. — There are two aspect to the commercial application of HDTV: (1) The production system–how to create the original HDTV picture, and (2) The transmission system–how to distribute that picture intact. — NHK has developed both a production system and several transmission systems, MUSE and MUSE family, to meet various needs. — A tremendous number of related facilities and hardware products need to be developed concurrently to make HDTV practical in the existing broadcasting world: Cameras, VTRs, Telecines, Microwave Transmitters, Swithers, RF transmitters and others are included in such a support system. — DBS, Cablecasting, VCRs and Discs are other distribution options for the HDTV picture. What is necessary to integrate HDTV technology into the available distribution systems will also be ducussed in this paper.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1989-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00758"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1988",
        "conferences": [
          {
            "conference_name": "Television Technology in Transition: 22nd Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. Wayne Caluger"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00517"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Communications between Analogue Component Production Centers",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris J. Dalton",
                    "Andrew T. Malcher"
                  ],
                  "abstract": "The introduction of Component Analogue and Digital equipments has created a demand for the transfer of component signals between production areas and centres. Existing plants usually offer a single wire composite link for transfer. A Time Division Multiplex, or MAC format, offers an alternative mode of component transfer without composite decoding errors. The ITV Association Technical Laboratories have developed a wideband system based on the SMPTE SMAC proposals but using a standard sync waveform as carrier, also an ENG development offering best utilisation of existing narrow band, 5 MHz, links. The paper will describe the systems, report on operational experience gained with an ENG equipment within the UK, and on progress towards standardisation in the EBU.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00527"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Video Recording Formats in Transition",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Koichi Sadashige"
                  ],
                  "abstract": "Digital recording formats, including D-1, D-2, and component HDTV format, will dominate the high end of video recorder application fields in 1990's. — Technique for mass replication of digital tape nearly-perfected, logical direction for consumer VCR is to go didital. A high degree of data compression with no decernible quality degradation will be employed. Consumer HDTV digital VCR will also be developed. — For the large segment of video recorder applications between the high end and consumer areas, component analog video recording, and extended definition color under recording will be the mainstay through the foreseeable future. — First application of the magneto-optical disc recording technique will probably be for the cart machine. — Technical and commercial success of efforts to develop a digital recording format of D-2 quality in a smaller package depends largely upon the availability of advanced magnetic tape of unprecedent electrical and physical characteristics.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00521"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Opening Address—22nd Television Conference",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard T. La Zare"
                  ],
                  "abstract": "Good morning Ladies and Gentleman; members and quests. Welcome to the 22nd Annual SMPTE Television Conference. The theme of our conference “Technology in Transition” conjures up visions of new ways, new methods and new things. Indeed this very month, January through the years boasts a legion of technological innovations. Including the first successful heart transplant operation performed by Dr. Christiaan Barnard, January 2nd, 1968. He captured the imagination of the world and dramatized a whole new frontier for science. New frontiers, indeed are all around us. Some much closer than we think.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00519"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "A New Approach to the D-1 Digital Tape Recorder",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rolf Hedtke"
                  ],
                  "abstract": "The worldwide introduction of the digital video and audio interface standards of CCIR and AES will allow new operational practices within television studios. The most important device is the digital component television tape recorder according to the SMPTE D-1 standard. For the DCR 100, which was introduced by BTS as a high-end VTR for production and postproduction new system architectures and operating strategies have been developed. Based on latest technology these improved features will change the mode of operation as well as the maintenance and repair procedures. Therefore the users can derive great benefit from new operating methods, higher reliability, less maintenance cost and improved availability of the DCR 100.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00523"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "The Application of High Hc Cobalt-Iron Oxide Tape for Digital Video Recording",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "K. Isesaka",
                    "Y. Fujimaki",
                    "T. Nakamura",
                    "S. Takahashi",
                    "K. Kobyashi",
                    "S. Leader"
                  ],
                  "abstract": "The 4:2:2 component recording system (Type D-1) records signals at a rate of over 200 Mb/sec with a shortest recording wavelength of only 0.9 um. — Low error rates (in the order of 10–6 to 10–7) can be obtained if a tape formulation can be developed with a high output and low noise characteristics optimized to record at these wavelengths. As the D–1 DVTR can only use ferrite video heads, a high coercivity cobalt oxide tape was developed to meet the needs of the format. — The paper discusses why such a formulation was chosen and contrasts how the D–1 tape performs against other media when evaluated for the 4:2:2 standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00524"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Luncheon Address: Isn't this where We Came In?",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joseph A. Flaherty"
                  ],
                  "abstract": "One of the problems in speaking at such a luncheon as this is that you never know what the audience expects. It is not unlike the occasion when Isaac Stern was scheduled to give a mid-winter recital in Ithaca, New York. Unfortunately on the appointed day, an immense blizzard dropped 20 inches of snow on Ithaca, and when Mr. Stern came on the stage that evening, only six people had made it to the auditorium, and two of them were ushers. Isaac looked at this audience, laughed, and said, “This is ridiculous. Let's just go to the bar, have a drink, and warm up.” One man in the audience jumped up and said, “Oh, Mr. Stern, I have driven for six hours through this snow just to get here tonight. Sing something.”",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00520"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Control-Room Design and Monitoring Considerations for Accurate Stereo Imaging",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert L. Todrank"
                  ],
                  "abstract": "This paper will first define the concepts of auditory stereo imaging and discuss the reasons why imaging is so important to the final listener's perceptions. I then outline the important factors within the listening environment and their impact on stereo imaging. The paper also describes various monitoring systems and how the selection of the monitor system works in conjunction with the room's acoustical treatments. Lastly the paper discusses specific construction details and offers design concepts for broadcast control rooms. Practical solutions to existing problems are discussed and well as ideas for new construction.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00539"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Channel-Compatible 6-MHz HDTV Distribution Systems",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "W. F. Schreiber",
                    "A. B. Lippman",
                    "A. N. Netravali",
                    "E. H. Adelson",
                    "D. H. Staelin"
                  ],
                  "abstract": "A TV distribution system is described whose purpose is to achieve the highest possible image quality within a prescribed analog channel bandwidth, assumed here to be 6 MHz, using receiver technology deemed to be practical in the near future. This system is designed to be used immediately for controlled-access systems such as cable. It is also suitable for eventual broadcasting use in a two-stage strategy in which an intermediate backward-compatible system is the first stage. Applications to fm, recording, and digital transmission are described. — The efficiency of analog channel utilization is improved over NTSC by using double sideband quadrature modulation of two 3-MHz signals on a single carrier in the center of the band, and by elimination of the retrace intervals and sound carrier. Higher perceived quality for a given transmission rate is achieved by dividing the signal into components according to both spatial and temporal frequency, and transmitting the appropriate combination of components according to the degree of motion in each scene. A “smart,” programmable, open-architecture receiver is proposed capable of decoding a wide variety of signal formats and displaying the image at higher line and frame rates than transmitted. Such a receiver can also display the backward-compatible EDTV system described in a companion paper, and can be upgraded over time by virtue of its programmability and by adding hardware and software modules.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00532"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Flickerless 3-D Laser Video Disc System",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "T. Hioki",
                    "T. Toyama",
                    "Y. Morita",
                    "H. Watanabe",
                    "H. Isono",
                    "M. Yasuda",
                    "H. Kusaka",
                    "M. Yamada"
                  ],
                  "abstract": "SANYO and NHK have developed the first flickerless 3–D laser video disc system. This system consists of 3-D laser video disc player, 120 Hz vertical frequency monitor and liquid crystal glasses. The 3-D video signal, left and right eye's video fields being time multiplexed alternatively, is time compressed to double fields of NTSC to 120/sec, 60 for right eye and 60 for left eye, above threshold of flicker. On the other hand, the video signal uses 4:1 interface to gain higher resolution, so that each frame has 524.5 scanning lines for each eye. Both sides of CLV disc play 60 minutes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00526"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Television Signal Transmission: Another Technology in Transition",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Paulson"
                  ],
                  "abstract": "“NTSC” became the preeminent initialism in the broadcasting industry in 1953, when the FCC decreed that the analog composite video wave form documented in the EIA RS170 drawing would become the only acceptable standard for broadcasting color television signals from VHF and UHF television stations under its regulatory control.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00530"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Experience with an Experimental Digital Component Video Production Facility",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Chris J. Dalton",
                    "Norman W. Green"
                  ],
                  "abstract": "An experimental digital component video production facility has been installed at the studios of Thames Television, London. This project has been managed by the ITV Association and is the culmination of several years co-operation between the ITV Technical Development Laboratories and specialist UK manufacturers of broadcast equipments. The facility has been designed to CCIR Recommendations and is currently in use for assessing engineering operations and also studio and post-production programmes. The paper reviews the equipment and facilities offered, highlights some of the difficulties encountered during design and installation, and discusses the potential role of a digital production facility within a Broadcasting organisation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00529"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "HDTV - A Perspective for the Broadcaster",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Laurence Thorpe"
                  ],
                  "abstract": "A vigorous five year activity within the SMPTE and ATSC has culminated with the endorsement of both organizations to proceed with the refined version of the 1125/60 HDTV signal format as a North American voluntary standard for studio origination. SMPTE examined HDTV in the broadest sense of program production and subsequently proposed a well defined, total approach to system colorimetry and transfer characteristic.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00533"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Digital Interface Devices",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gerhard R. Wischermann"
                  ],
                  "abstract": "After the definition of CCIR-Rec. 601 for the 4:2:2 sampling parameters and the CCIR-Rec. 656 covering electrical and mechanical parameters for the interface, the industry started to design and manufacture various devices. That became apparent at Montreux last year.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00528"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "G.G. Israel Studios-Jerusalem, Ltd.: Concept and Design Stages",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William C. Spencer"
                  ],
                  "abstract": "After the initial meetings at the 1986 NAB, Tele-Systems personnel traveled to Israel to meet with the Architects and additional G.G. Studios personnel to fully outline their requirements for the facility and prepare a technical approach to enable them to realize their goals. From these meetings, and many meetings with potential vendors at the IBC 86, SMPTE 86 and NAB 87, it was decided that the most practical way to accomplish these goals was through a hybrid analog/digital component plant with sufficient bandwidth in the signal handling equipment to accommodate all present and proposed HDTV standards as well as the basic 625/50 Y,U,V signals that would be the mainstay of the plant initially.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00536"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Diagnostics for a Composite Digital Video Tape Recorder",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William S. Herz"
                  ],
                  "abstract": "It is generally accepted that complex digital equipment should include some form of diagnostics to assist in the location of fault conditions. Signature analysis techniques, when integrated into the hardware and software of a digital video tape recorder can efficiently test and greatly facilitate troubleshooting digital circuitry with minimal circuit overhead. In addition, other techniques may be incorporated to improve the testability and reliability of the system, such as the inclusion of special test signals in the video and audio paths. The most effective systems are those that are completely self-contained and do not require the use of any external equipment. The above mentioned diagnostic techniques have been successfully integrated in a digital composite DVTR.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00525"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Computer-Aided Design in Facilities and System Integration",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ed Webster",
                    "Ron Jones"
                  ],
                  "abstract": "This article will examine how computer assisted drafting (CAD) and computer assisted engineering (CAE) programs are used to streamline television system and facility design. Hardware considerations will be discussed; basic system components will be identified. Typical CAD workstation software will be detailed. System design applications will be shown. An overview of facility architectural design and television system design with and without the use of CAD/CAE software will be presented. Finally a brief case study of the overall design of a mobile teleproduction vehicle will be examined. The use of CAD/CAE in this specialized design area will be discussed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00535"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Single-Channel Backward-Compatible EDTV Systems",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. B. Lippmanny",
                    "A. N. Netravali",
                    "E. H. Adelson",
                    "W. R. Neuman",
                    "W. F. Schreiber"
                  ],
                  "abstract": "In this paper, we describe some methods for adding additional information to a compatible NTSC broadcast signal so that an advanced receiver can decode that information to provide improved picture quality (Extended Definition Television, EDTV), while a standard NTSC receiver will display an image with minimally visible impairments. In particular, we transmit chrominance information at one half the frame rate and use alternate frames to encode high definition luminance information in the chrominance signal. This is useful for any EDTV system. We also suggest a particular design where we usurp some active lines from the top and bottom of the picture and encode augmentation information into this region so that both the EDTV and the NTSC receiver receive similar looking wide screen pictures, the EDTV one containing greater resolution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00531"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Real-Time Multi-Level Digital Compositing—Quality Issues",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter D. Symes"
                  ],
                  "abstract": "A previous paper1 discussed the advantages of multi-level compositing when compared with “one layer at a time” techniques, and described the architecture of a system designed to provide multi-layer capabilities in the digital domain. — This paper examines a number of issues which affect the quality of composited images in the digital domain, and solutions implemented in the Grass Valley Group Kaleidoscope and Kadenza systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00544"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Audio for Video: The Integration of Digital",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Oliver F. Morgan"
                  ],
                  "abstract": "This paper begins with a review of the wide range of digital audio origination, storage and processing devices coming into use in editing suites. It points out the need for a centralized workstation to manage the control and interconnection of these devices, and the need for unified and simplified control of audio similar to the universal control employed in video editing. A system is presented which makes use of recent advances in digital signal processing and interface standardization to provide a compact and comprehensive audio “paint” station.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00541"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Fault Diagnosis in the Digital Studio",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David J. Bradshaw"
                  ],
                  "abstract": "The increasing use of digital equipment in television studios brings with it potential problems for the maintenance engineer when diagnosing faults. The paper considers the reasons for this, the levels at which diagnosis is required and some of the techniques that can be used.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00537"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Controlling Audio Mixers in Video Post Production",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael D. Patten"
                  ],
                  "abstract": "The concept of the Edit Suite Audio Mixer, or ESAM, was first introduced in 1983. Its purpose was to allow audio to be edited simultaneously with, and in the same way as, video. Although fulfilling its desired role, at the Olympic Games in the winter of 1984, the controlling protocol was a hasty adaptation of the editor's existing video switcher control protocol. — Since then, Graham-Patten Systems has, with cooperation from editing system and audio console manufacturers, developed the ESAM SERIAL II protocol, designed specifically for controlling audio mixers in the video post production environment. Because of its eminent suitability for editing, and its ease of implementation, the protocol has become widely established.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00543"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "System Considerations for Off-Line Disc Editing",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stanley D. Becker"
                  ],
                  "abstract": "The optical video disc is a natural device for editing applications. The disc players are fast (worst case access time about 1.5 seconds), have a reasonable capacity (30 minutes), and are inexpensive and reliable. There are, however, certain requirements and restrictions that must be adhered to for successful disc based editing. Because the disc editor is an “off line” device, the requirements depend in part on the originating and release media. Several common combinations are possible: (1) Material originated on video tape to be released on video tape. (2) Material originated on 24 fps film to be released on video tape. (3) Material originated on 24 fps film to be released on film and video tape. (4) Material originated on 24 fps film to be released on film.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00545"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "VITC and Perfs",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bob Nollner"
                  ],
                  "abstract": "The B.H.P. Inc. Touchvision Editing System is an editor designed to edit film on video. Design was based on ease of editing and accurate relationship of the video medium to the actual film frames. Other design features considered were: freedom from keyboard manipulation, familiarity with “flat bed” style editing. The basic editor system and support systems allows for a complete video editing environment, which is faster and more economical than traditional film editing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00546"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Challenges to the Development of a Standardized Professional Studio Color Picture Monitor",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roland J. Zavada"
                  ],
                  "abstract": "The NTSC/FCC color specifications for the US (North American) television system are display dependent with a defined color gamut. Within a decade after the introduction of color, the industry found phosphor sets approximating the NTSC primaries inadequate for brightness and lag. A decision by the EBU to base their colorimetry on an average of modern phosphors was made and proposed as an international standard. It became necessary for the US to choose to develop corrective matrices to shift the modern phosphors used in studio color picture monitors to approximate NTSC or to change the colorimetry of the system. This paper documents the two decade background and justification leading to a choice of a standard set of non-NTSC chromaticaties commonly referred to as the SMPTE “C” set. It also introduces pending supporting documentation designed to improve color consistency and to develop methods for the critical review of program material.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00538"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Digital Audio in the Sirius-100",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David E. Acker"
                  ],
                  "abstract": "Advancements in digital signal processing, driven primarily by computer technology, and the demands of the entertainment industry for higher technical performance and extended system capabilities, have had a major impact on the world of audio. As a result, digital audio products represent one of the fastest growing segments of the entertainment industry today.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00542"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Advanced Television Standards",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E. B. Crutchfield"
                  ],
                  "abstract": "Work has begun on developing standards for delivering advanced or high definition television to the consumer. The Advanced Television Systems Committee (ATSC), of which SMPTE is a member, has established the technical specialists group, designated T3S4 to conduct studies and tests leading to the recommendation of standards. The Federal Communications Commission has established an advisory committee to study the prospects for and approaches to advanced television systems. This paper describes the status of ATSC work and plans as well as the structure of the FCC committee, subcommittees and working parties.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00534"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Technical Challenges of a New Small-Format DVTR",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Watney"
                  ],
                  "abstract": "Starting with today's television tape recording requirements this paper goes on to examine the requirements for a single general application small digital format which might serve both ENG and most post production applications. The technical challenges involved in both reducing the required data rate and increasing the volumetric packing density are discussed. Considering tape thickness, track pitch, wavelength and data compression, it is concluded that it would be at least three years before a viable half inch standardization effort for television applications could commence. A more desirable 8mm format would take longer. Considering the standardization cycle, the long lead time for the significant VLSI production and the development of a full range of products that would be required, the implication is that it will be 5 to 7 years or more before a viable, standard, general purpose small format television DVTR could be available in product form. Military reconnaissance applications which are less demanding than television applications in the areas of play time and multigeneration capability could be met with the best of existing technology.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00522"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Graphics for Engineering",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Cathy Galvin"
                  ],
                  "abstract": "In a television station, we hear a lot about maintaining the consistency and quality of the on-air look. What makes up an on-air look. Is it just having 10 good news graphics a night? Or is it a $100,000 metallic station logo that flies over the city skyline every time the promotion department has an avail? Is it having a nice open for your 6pm newscast? None of those examples by themselves make up the on-air look. The on-air look is the station's recognizable image or identity throughout a days worth of programming, from sign-on to sign-off. Elements that make up the on-air look include Station Image Graphics, News Graphics and Programming and Promotional Graphics.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00540"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20Transition:%2022nd%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard T. La Zare"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1988-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00518"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1987",
        "conferences": [
          {
            "conference_name": "Television Technology: A look Toward The 21st Century: 21st Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joe Roizen"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00871"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard T. La Zare"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00872"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Opening Address—21st Television Conference",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard T. La Zare"
                  ],
                  "abstract": "Good morning Ladies and Gentlemen, Members and Guests. It is indeed a pleasure to welcome you to the Society of Motion Picture and Television Engineers 21st Annual Television Conference.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00873"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Variable-Resolution Rendering System Extends Television Animation Graphics to Film and Print Media",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Philip Lucht"
                  ],
                  "abstract": "Problems encountered in transferring computer-generated television-resolution images to film and print media are briefly reviewed, including the effects of anti-aliasing. It is argued that, in order to fully utilize the spatial resolution these media provide, pictures must be completely re-rendered directly at high resolution. This introduces a new set of problems which are briefly summarized. When previewing requirements are considered, as well as the final product, rendering systems allowing completely variable resolution seem most appropriate. Features of such a system currently under development at BTS Broadcast Television Systems, Inc. are described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00876"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "R-DAT Format Overview",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "P. A. Dare",
                    "R. Katsumi"
                  ],
                  "abstract": "It is now some 35 years since ${1\over 4}$ inch analog audio tape recording was introduced to the broadcasting and television industry. The ${1\over 4}$ inch analog type format, whether it be in its full track or ${1\over 2}$ track modes, has served the industry well, in fact; there are very few standards that have survived 35 years in the audio recording industry. That standard is now challenged by the R-DAT proposal; R-DAT being an acronym for Rotating Digital Audio Tape. In addition to potentially changing the industry's attitude to the inch analog tape format, the R-DAT format potentially challenges the tried and trusted NAB cassette. I would like to describe to you the current status of the R-DAT standard. While the 1983 worldwide DAT conference did not discuss the professional R-DAT standard there is little doubt that the professional standard will track very closely the consumer format that has been proposed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00877"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Operational Experiences and Future Expectations from the M-II Format",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Steven Bonica"
                  ],
                  "abstract": "The choice of the MII format for use at NBC and the reasons which led up to the choice are discussed. The format and the initial specifications are reviewed. The product line is described, and recent installations for network delay and News operations are detailed. Planned installations for VT Operations and future applications, including automation, are also addressed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00878"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Improved Television Systems: NTSC and Beyond",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William F. Schreiber"
                  ],
                  "abstract": "After a discussion of the limits to received image quality in NTSC and a review of various proposals for improvement, it is concluded that the current system is capable of significant increase in spatial and temporal resolution, and that most of these improvements can be made in a compatible manner. Newly designed systems, for the sake of maximum utilization of channel capacity, should use many of the techniques proposed for improving NTSC, such as high-rate cameras and displays, but should use the component, rather than composite, technique for color multiplexing. A preference is expressed for noncompatible new systems, both for increased design flexibility and on the basis of likely consumer behavior. Some sample systems are described that achieve very high quality in the present channels, full “HDTV” at the CCIR rate of 216 Mb/s, or “better-than-35-mm” at about 500 Mb/s. Possibilities for even higher efficiency using motion compensation are described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00888"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Evolution during Revolution",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Guy Gougeon"
                  ],
                  "abstract": "The future of the TV broadcaster is today very unclear as the effects of new technologies such as the digitalization of current operations, the introduction of HDTV, and explosive growth in the number and kind of distribution channels are considered. The broadcaster is pulled forward inexorably by the seemingly insatiable requirements of viewers for more programs, better programs and higher technical quality, fuelled by new developments in consumer electronics. Innovation is needed to contain his production costs, to meet the viewers' demands for the quality and quantity and to retain a reasonable share of viewing time and of slots on the channel selector. The competition from other media such as cable, quasi-DBS, pre-recorded discs and tapes is strong. The broadcaster of today is faced with the dilemna of planning this future in the face of a plethora of competing but incomplete systems, many with confusing economic and political complications. At the same time, new uses for the large investment in plant and equipment owned by himself, his communications partners and his viewers must be evolved. There is no doubt that the need for innovation and major change is certain – the questions are concerned only with when and how. In this paper, the critical technical questions facing the broadcasting industry will be summarized and some possible future directions will be outlined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00889"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "New Frontiers, the Next 15 Years",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael J. Sherlock"
                  ],
                  "abstract": "The paper looks at progress in the past 15 years, examines the likely changes in the next 15 years, explores the processes of making television, in the industry and at NBC. Quality improvements and cost reduction as prime motivators are discussed. New camera and recording techniques, software tools and automation are included. New facilities of the future at NBC are discussed, as is the contribution of standards to the industry. A standard for a 1/2" digital component recorder is proposed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00893"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Development of Component Digital VTRs and the Future Potential of the D-1 Format",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jurgen K. R. Heitmann"
                  ],
                  "abstract": "Since 1979 discussions about digital component recording are under way. For one year now the appropriate equipment has been on the market and further equipment is about to follow. The introduction of the 19 mm component DVTR represents significant steps in terms of technology and operational practice. The first of these is of course the transition from analog video to digital video. Linked to this, however, is a further transition from composite video to component video. The digital component video recorder can be considered as the key for the digital studio of the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00881"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "CBS Experience with Small Format Videotape and the Implications for the Future",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bernard L. Dickens"
                  ],
                  "abstract": "From the introduction of videotape in 1956, through the beginning of this decade, the broadcast industry has seen relative order in videotape technology. In 1958, two inch quadruplex recording characteristics were quickly standardized to allow tape interchange. Later, the U–Matic tape format became a de facto standard for newsgathering because it was the only small cassette format available. Similarly, the one inch type C system rapidly became a de facto standard by providing important new features, improved performance and lower costs to broadcasters. Today, however, videotape technology sees increasing disorder – bordering on chaos. — As the broadcast industry has grown, and broadcast technology has become more sophisticated, requirements for videotape formats have diversified. Production, post production, field production and newsgathering all demand unique characteristics and features of a recording system. As these demands increase, improved signal quality and lower costs remain of paramount importance. In an effort to meet the needs of broadcasters, manufacturers have introduced numerous new and incompatible videotape formats during the past five years. Most recently, improved versions of existing formats have been introduced with varying degrees of compatibility with their predecessors. As a result, during the 1980's, broadcasters have been forced to evaluate and choose from among ten different recording systems. — In 1985 CBS introduced a one half inch videotape system in its new Hard News Center. More recently, CBS has evaluated combination camera/recorders for network newsgathering. In this paper the author will report on the CBS experience with small format videotape systems and examine the implications of this experience for the ability of present videotape technology to meet current and anticipated broadcast requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00879"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "The Video Computer: Image Computing in the Studio",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alvy Ray Smith"
                  ],
                  "abstract": "A general-purpose video computer is proposed which combines many studio or post-production functions, now available only in separate pieces of equipment, and extends their functionality. The ideal machine is described and the current state of the idea is given. The restrictions of realtime and broadcast day are compared. The conclusion is that video computers are already a viable idea within the broadcast-day-turnaround criterion and that the hardware exists as so-called image computers, general-purpose digital computers for the class of computations on images. Consequently software houses could immediately begin preparing applications on video computers for the broadcast video market.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00875"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "The Composite Digital Format and its Applications",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edwin Engberg",
                    "Richard Brush",
                    "Maurice Lemoine",
                    "Steve Magnusson",
                    "Fraser Morrison",
                    "Dave Rodal",
                    "Dennis Ryan",
                    "John Watney"
                  ],
                  "abstract": "With the introduction of professional digital video tape recorder hardware, much discussion has arisen in the video community over the issues surrounding component and composite digital recording methods. Some believe the two recording methods will battle in the marketplace with one becoming the eventual winner. We at Ampex believe both formats will be in use over the next decade with the specific features and benefits of each format matching different applications. — This paper describes the composite digital format and highlights its major features. To technically understand the format a description is presented which contains information about: (1) Encoding parameters (2) Mechanical parameters (3) Record content (4) Longitudinal tracks (5) Media — The important differences between the composite digital and D-1 formats are compared. Emphasis is placed upon how the composite digital format meets the needs of the user who records and distributes video in composite form.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00882"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Television Engineering Research in the BBC, Today and Tomorrow",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bruce Moffat"
                  ],
                  "abstract": "Television engineering research in the BBC is intended to ensure that the future engineering needs of the BBC can be met economically and effectively. To that end new broadcasting systems and techniques are innovated and assessed. It is important to strike a balance in this work between current and future requirements, mainly through internal projects, but partly in cooperation with other enterprises. Major examples of relevant work include High Definition Television in conjunction with Digitally Assisted Television, bandwidth compression, subscription systems, digital techniques for studios and transmission, and digital stereophony for television.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00885"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Today's Videographic Environment—An Overview",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter C. Lowten"
                  ],
                  "abstract": "The utilization of images to enhance information transfer, to entertain and motivate, has created an environment based on two separate approaches to image manipulation, those being via dedicated hardware or general purpose computers. — The interaction of broadcast and business video requirements are modifying manufacturers product directions, as is the groundswell of new creativity being stimulated by the flexible artistic tools that videographic technology has itself created. — These environmental stimuli are encouraging the development of “spinoff” technology which it would otherwise be uneconomic to pursue, and are providing a marketplace for diverse solutions to the manipulation of visal images.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00874"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Video Research for the Human Viewer",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. K. Clemens"
                  ],
                  "abstract": "Video research for the human viewer begins with research on how a human being perceives a moving image. The research includes studies on how the eye processes images with different parameters such as brightness, contrast, distance from the eye and resolution. Coupled with these studies is research on how the human brain processes more complex stimuli. For example some questions that can be asked are: What is the effect of the visual persistence?; How is motion treated?; And what is the effect of size and brightness on how the the brain treats the information about the image. — The results of this research are crucially important to questions such as: What is the best picture that can be displayed through a channel of a given restricted bandwidth?; What is the best display for a given cost?; What is the optimum frame rate? And how is motion best treated?. — Research at the RCA Laboratories includes the total system which brings the video image to the human viewer. The goal is to develop metrics which can be used to compare system tradeoffs. The research includes hardware and software system simulation as well as study of the human viewer. The research programs and some of the pertinent results will be presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00883"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "The Big Screen is Closer than you Think",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John R. Forrest"
                  ],
                  "abstract": "Plans for domestic satellite broadcasting (DBS) in the 12 GHz band in Europe are well advanced. Services using the MAC-packet transmission standard adopted in Europe will commence this year. Over the next three years, a number of national satellites will be launched and there is the likelihood of additional pan-European services. Though it had been thought that implementation of high definition television was some way in the future, this highly competitive programme environment will spur the introduction of a higher definition television service suitable for large, wide aspect-ratio screens with stereo sound. An important feature of this evolution is the capability of the MAC-packet system to deliver this new form of television, while providing conventional pictures to existing receivers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00886"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Cultivating the Wasteland with Technology",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard R. Green"
                  ],
                  "abstract": "Let me begin by asking if you have ever heard of the seersucker theory. It was first published in 1980 by an associate professor at Wharton. It deals with the ability of experts to make accurate forecasts.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00890"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "New Technology and the Broadcaster",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Max Berry",
                    "Robert Thomas"
                  ],
                  "abstract": "In the formative years of television broadcasting, new developments in technology were immediately and enthusiastically embraced by engineers and management alike in their drive to improve picture quality, extend services and add new production values to television programs. Emphasis is now increasingly being directed toward the impact of technology upon spectrum conservation, viewer perceptions and the vital matter of the profitability of broadcast companies themselves. New developments must be analyzed in these terms and realistic priorities established to identify those projects which should be implemented immediately, relative to those that might be postponed or abandoned entirely. Equipment designers and manufacturers are challenged to produce hardware that translates the promise of new technology into products that will justify capital investment by a return in increased reliability and reduced operating and maintenance costs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00892"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "High Performance Half-Inch Metal Tape for M-II Videocassettes",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Masaaki Fujiyama",
                    "Shigeo Komine",
                    "Koshu Kurokawa"
                  ],
                  "abstract": "The world's first metal tape for the M-II system was introduced by Fuji Photo Film in 1985. The main concepts for the breakthroughs were, 1) the use of a polymer binder possessing high affinity with the pigment to prevent its aerial oxidation which would lead to demagnetization, and 2) the optimization of the molecular structure of the binder to minimize the transfer of organic matters to the head, and to control the solubility of the lubricants in the binder. The binder polymer also enabled the uniform dispersion of the fine pigment grains to give highly smooth surface of the magnetic layer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00880"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Television: The Challenge of the Future",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joseph A. Flaherty"
                  ],
                  "abstract": "Television is a technology in its youth – only 50 years have passed since the introduction of a regular broadcast service by the BBC. Today, many improvements in broadcast television services are technically possible. As the 21st century approaches, implementation of these improvements is essential if broadcasters are to remain competitive. — The first step toward the future is to begin the orderly changeover of production facilities to allow the production of programs of a higher technical quality. To a large degree, this changeover has begun. No modern television plant today uses strictly analog composite signals for its operations. Digital signals and component formats are increasingly being used to provide new capabilities and improved performance. — As improvements in production systems continue to be implemented – including the use of high definition television – superior delivery system must also be developed. VCRs and cable systems have fewer technical restrictions than broadcast services in taking advantage of such developments. — This paper examines the current trends in improved production systems and their implications for the furture; and discusses the need to provide higher technical quality throughout the various delivery channels.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00891"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Technical Research and Development for the Growth of Tomorrow's Broadcasting Business",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Masahiko Ohkawa"
                  ],
                  "abstract": "Television broadcasting has rapidly developed and now, technically it is progressed nearly as far as it can go, and it is groping for further development toward the establishment of an advanced television system. This paper describes the author's views on trends in broadcast technology which need to be studied and researched for the further growth of broadcasting in the 21st century. Television broadcasting can provide a great amount of information quickly, and over a wide area. It is indispensable for our everyday lives as a medium which gives us at very little cost, thought-provoking and entertainment programs with high-quality pictures and sound. In the second half of the 20th century, the rapid spread of television has transformed man's life and culture, and it has grown into a telecommunications media which has a great influence on society. This outstanding growth of television has had, as its basis, farsighted technical research. For further growth in broadcasting, it should meet viewers' needs and expectations in the high-level information society of the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00884"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "TV Research in CCETT: To and through the 90s",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology:%20A%20look%20Toward%20The%2021st%20Century:%2021st%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jacques Sabatier",
                    "Jacques Poncin"
                  ],
                  "abstract": "This paper intends to give a view on the major tracks presently considered in France on the way to the future of broadcastinq systems. The main research laboratory active in this field, CCETT, will first be presented. Then, some general considerations will be introduced on the way the broadcastinq system is evolving, on the present situation in Europe and on the directions which, in our view, have to be explored prioritarily. Some of the research programs undertaken at CCETT on these main axes will finally be outlined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1987-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00887"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1986",
        "conferences": [
          {
            "conference_name": "Digital Television Tape Recording and Other New Developments: 20th Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "Introduction to the Papers on the Type D-1 Digital Video Recorder",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frederick M. Remley"
                  ],
                  "abstract": "In these introductory comments I wish briefly to outline the role of SMPTE engineering committees in the preparation of the standards for the Type D-1 broadcast quality, component digital video recorder. Other papers will describe parallel efforts by EBU technical groups in Europe; I will focus principally on the SMPTE organization of work. Hopefully this will make it easier to explain some of the factors in the standardization process that have led to a D-1 standard and to this series of papers.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00762"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Digital Television Recording — History and Background",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John L. E. Baldwin"
                  ],
                  "abstract": "In Europe, interest in the choice of digital video standards had become significant by about 1970 but it did not seem that a standard could be seriously considered until that standard could be shown to be recordable, in digital form, using an amount of tape comparable with that used for analogue recording.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00763"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Type D-1 Digital Television Tape Recorder: An Overview",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bernard L. Dickens"
                  ],
                  "abstract": "The recent approval of the Component Digital Television Tape Recorder (DTTR) format by the International Radio Consultative Committee (CCIR) Study Groups 10 and 11 was a significant achievement in world television standards. When the recommendation of CCIR Study Groups 10 & 11 is ratified by the CCIR Plenary Assembly in May 1986, for the first time there will be worldwide agreement on a recording format that was designed for use with both 525160 and 625150 TV standards. All current TV recording formats were designed for one TV standard and adapted for the others, resulting in two formats with a high degree of commonality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00765"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "SMPTE Type D-1 Cassette Design Considerations",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "P. A. Dare",
                    "K. Ike"
                  ],
                  "abstract": "The story of the D-1 cassette begins more than a century ago in the steaming jungles of South Asia where the secretions of millions of lac insects were harvested to meet the industrial world's need for shellac. Used in finishing varnishes, shellac in its molded form was made into electrical insulation fittings. However, as demand grew there was intense pressure put on the supply of lac and with a sense of urgency matched only with our desire to get to the moon, there was launched a frantic search for a synthetic shellac. Forty years later we were presented with the gift, plastic, a material par excellence of the twentieth century. The first form of plastic was Bakelite, invented in 1907 by a Belgian born chemist named Leo Hendrick. Bakelite was an instant success seized upon by the industry for uses ranging from pot handles to billiard balls. The age of plastic was born and the first decision was made on the SMPTE D-1 cassette. Certainly the plastic developed by Leo Hendrick is not the same plastic that we know today. The plastic used in the SMPTE D-1 cassette is an ABS high impact type plastic that has a high resistancy to shattering and has a high dimensional stability when subjected to the rigors of our environment. Now to describe perhaps some of the more salient features of the D-1 cassette as it exists in 1986.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00767"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Digital Audio Recording in M II Format VTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shiro Tsuji",
                    "Masamitsu Ohtsu",
                    "Nobuyoshi Kihara"
                  ],
                  "abstract": "The recent digital technologies have greatly improved the performance of industrial and home-use audio equipment. And there exists a similar tendency in the field of broadcast VTR as well. An experimental digital audio recording section has been developed for MII Format VTR that is a new generation broadcast VTR using 1/2 inch tape cassette. The outline of digital signal processing by the time axis compressed extended tape wrap recording system and the element technologies such as coding and error correction are described in this report.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00777"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "A New Small Format VTR Using an 8mm Cassette",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Toshiaki Kawamura",
                    "Susumu Kasai",
                    "Tamotsu Tominaga",
                    "Hideo Sato",
                    "Minoru Inatsu"
                  ],
                  "abstract": "In 1982, Hitachi Denshi developed a highly compact portable combined camera/VTR system utilizing the 1/4ʺ format that was well suited for ENG applications. Shortly thereafter, an effort to standardize the 1/4ʺ small format VTR was made by the SMPTE.2,3 However, the effort ended without success due to user anxiety about metal tape, etc.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00778"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Considerations for Improvement of HDTV Digital VTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yoshizumi Eto",
                    "Masuo Umemoto",
                    "Toshiaki Kawamura"
                  ],
                  "abstract": "Many efforts have been made to form a world studio standard for high definition television(HDTV). In addition, HDTV equipment has been developed that shows the high picture quality of HDTV systems. Consequently, HDTV equipment is now expected to find markets in several new application areas and be used in the broadcastiong services in the future.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00779"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "The BTSC Multichannel Television Sound System",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Carl G. Eilers"
                  ],
                  "abstract": "The quest for a method of broadcasting stereophonic sound and second language with television goes back many decades. There was a flurry of activity, worldwide, in the late 1950's and early 1960's. In the mid 1960's, the question was raised again in the U.S., but was dropped because of the lack of interest. In the 1970's, both Japan and West Germany adopted standards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00780"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "“Harry” and the SMPTE Digital Standard in the Edit Suite",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard Shephard"
                  ],
                  "abstract": "Harry is a real-time digital video recorder which can replay frames in random order in real time. Harry can therefore edit material on a frame by frame basis without the delays normally associated with the mechanics of editing, i.e. tape shuttling, recueing and synchronizing. All the prerequisites for editing short segments exist within Harry. Clips may be cut, keyed or mixed together without using any external equipment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00782"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Standards and Recommended Practices",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "The fundamental parameters for the first standardized broadcast-quality digital videotape recording format were approved by the Society's Working Group on Digital Television Tape Recording, the Video Recording and Reproduction Technology Committee, and the Standards Committee.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00783"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "The User Requirements for the 4:2:2 Component Digital VTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William C. Nicholls"
                  ],
                  "abstract": "When the SMPTE Digital Ad Hoc Users' Group first met, they realized they had a unique opportunity. For the first time, they were gathered to supply requirements for a recorder which didn't exist. Not one manufacturer had begun production of a 4:2:2 component digital VTR. It was a unique opportunity, but also a challenge, and a big responsibility. Who were these users? They were all technical personnel from broadcasting and production organizations. They were called into existence by the SMPTE Digital Television Tape Recorder Working Group.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00764"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Magnetic Media for DTTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. R. Moore",
                    "M. P. Sharrock"
                  ],
                  "abstract": "The SMPTE Digital Television Tape Recorder (MTR) Committee has been in the process of developing an industry consensus for the tape format standard since mid-1983, with the formal work assignment of working group MTR (V16.64). It is informative to look at the trends in the magnetic video tape industry relative to the requirements of the SMPTE proposed American National Working Standard V16.74 for the MTR, Type D-1. This standard covers the principal tape properties and will become the proposed SMPTE 225 standard.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00766"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "The SMPTE D-1 Format and Possible Scanner Configurations",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takeo Eguchi"
                  ],
                  "abstract": "The major part of this paper describes some historical background to the D-1 format, the basic concepts employed and supporting technical information. The remaining part describes possible scanner configurations proposed by different manufacturers as practical implementions of the D-1 recording format.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00768"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Formatting and Coding the Audio in the DTTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth P. Davies"
                  ],
                  "abstract": "Recording of the audio and time-code information in the Digital Television Tape Recorder (DTTR) takes place in an environment that is optimised largely for the digital video information, as the audio information from the four audio channels together represents only 2 percent of that of the video channel and even with the necessary overhead added is about 6 percent of the recorded data. In tape area usage the digital audio is 5 percent of the total with cue audio 4 percent and time-code 3 percent. Within these constraints an impressive level of performance can be achieved however in technical quality, operational flexibility and ruggedness by the use of suitable coding, shuffling and error protection.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00771"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Optimization of the D-1 DTTR Standard by Simulation Techniques",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roland Mester"
                  ],
                  "abstract": "The D-1 DTTR standard marks the launch of a world-wide non-manufacturer-specific standard for digital video recording. The standard is based on the experience gained by several manufacturers with experimental digital recorders. The measurements and experience obtained with these devices made it possible to develop mathematical models corresponding to reality. These mathematical models permitted the standard to be optimized by simulation techniques above and beyond the limits of the experimental recorders.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00774"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Measurement Methods and Diagnostic Techniques for DTTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rolf Hedtke"
                  ],
                  "abstract": "An important criterion in the procurement of new equipment is availability (A). In approximate terms, the following applies: ${\rm A}=1-({\rm MTTR}/{\rm MTBF})$ MTBF stands for Mean Time Between Failure, while MTTR stands for Mean Time to Repair.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00775"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Picture Quality Criteria, Error Statistics and Error Correction for the D-1 Format DVTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John P. Watney"
                  ],
                  "abstract": "The generally accepted picture quality requirement of the D-1 format (4:2:2) DVTR was that it should provide a quality of 4.5 on the CCIR 5 point scale, after 20 generations. It was also understood that there should be margin to allow for tape degeneration in the field, and also for “difficult” pictures. If and when the quality degraded below this level it should be gradual and graceful. From several preliminary experiments and demonstrations it was clear that there was a gap between the raw error rate that could be achieved from a DVTR, at an acceptable tape consumption, and that which was required to meet the picture quality expected. Some form of error management would be required. This would take the form of error correction to handle the regularly expected errors and error concealment to handle burst errors which overloaded the error correction system. The latter would also provide graceful degradation when conditions fell outside of the normally specified range, such as damaged tape or a clogged head.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00770"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "The D-1 DTTR: The Design for the Electrical Part of the Standard",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jurgen K. R. Heitmann"
                  ],
                  "abstract": "The mechanical part of the D-1 standard defines the magnetic pattern on tape. The basic mechanical work was done prior to the electrical work, but not without consideration of the electrical problems. The helical tracks of the D-1 track pattern allow the recording of 227 Mbit/sec of data. The mechanical standard describes which part of the tracks is used for video according to CCIR 601 and which for each of the 4 digital audio signals according to AES/48 kHz standardization.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00769"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Development of Small High-performance Studio VTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Iwao Obata"
                  ],
                  "abstract": "Japan Broadcasting Corporation (NHK) has fourty local stations. In the local stations, many programs, such as infomation, sports, amusement etc., are made with VTRs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00776"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard T. La Zare"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00761"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Video Data Shuffling for the 4:2:2 DVTR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Brush"
                  ],
                  "abstract": "Digital recording offers the promise of exact reproduction of recorded signals. In practice, this ideal is not quite achievable due to errors during the read process. Error correction coding (ECC) is one approach to overcoming the problem. Nevertheless, even a powerful ECC method will fail for some error conditions. A second approach for uncorrectable errors is concealment. For good concealment of video data, each erroneous or unknown pixel to be concealed should be surrounded by a sufficient number of good neighboring pixels.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00773"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "SMPTE Type D-1 Digital Television Recorder — Error Control",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "James H. Wilkinson"
                  ],
                  "abstract": "The D-1 cassette digital television recorder uses one of the highest recording densities found in magnetic recording formats; compare for example the 5 inch single density disc recording approximately 270Kb/inch2 with the D1 format of nearly 30Mb/inch2. This 100:1 increase in density is essential to keep the cassette size to a practical level but, in exchange, each recorded bit is potentially more prone to errors on replay. Fortunately for those working in the field of information engineering there are a number of techniques and rules which, properly applied, can rectify these difficult situations. In the field of digital video recording, we can usefully apply three basic techniques; (1) source encoding, (2) channel encoding, and (3) error control, to optimise the recording strategy.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00772"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Proposed: SMPTE Engineering Guideline: Tape Transport Geometry Parameters for 19-mm Type D-1 Cassette for Component Digital Video Recording",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "This guideline describes three feasible examples of mechanical designs and test conditions for achieving the record dimensions specified in SMPTE 224M. The parameters are for reference purposes only.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00785"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Proposed American National Standard for Component Digital Video Recording–19-mm type D-1 Cassette–Tape Record",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "This standard specifies the dimensions and locations of the audio, video, and ancillary data, analog audio cue track, time code, and control track records for 19-mm type D-1 helical-scan component digital cassette video tape recorders operating on the 525/60 television system encoded according to CCIR Recommendation 601.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00784"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "Bases of the EBU Standard on Magnetic Recording of Digital Component Video Signals",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. Todorovic"
                  ],
                  "abstract": "The author begins by outlining the design imperatives which had to be taken into account in defining the standard for magnetic recording of digital component video signals, and goes on to outline the main features of the Standard. He sets out the factors underlying the choice of tape width and leader characteristics, and explains the track structure and the subdivision of tracks into sectors. More particularly, he develops the possible solutions examined before a decision was taken on the location of audio and video signal segments and the grouping of data words for error-protection purposes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00789"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Production Facilities for MTS",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Douglas F. Dickey"
                  ],
                  "abstract": "Stereo audio is a more critical, less forgiving form than mono. The effective marriage of stereo and multichannel sound with television pictures is a still more difficult art. Both the producers and the consumers of stereo television are demanding greater creative sophistication and greater sonic quality. If the transition to regular nationwide stereo television service is to be completed, ways must be found to meet these demands in roughly the same timeframe as is presently allowed for mono production. Otherwise, production costs will rise and programme output will slow — a wholly unacceptable situation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00781"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Recording of Digital Television",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frederick M. Remley"
                  ],
                  "abstract": "The three papers that follow present important summaries of steps, taken in Europe and elsewhere, that led finally to standards for digital television tape recording.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00786"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Standardization of the Digital Television Tape Recorder within the Framework of the CCIR",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "P. Zaccarian"
                  ],
                  "abstract": "The article outlines the work the CCIR has been doing in the area of digital television tape recording, putting the emphasis not on actual decisions, but on the decision-making process itself. The introduction reviews various aspects of the problem at hand and is followed by four paragraphs describing the activities of the Joint Interim Working Party set up by CCIR Study Groups 10 and 11 to deal with the question. The author then gives an overview of the work still to be done, and concludes with thanks and acknowledgements to the companies and individuals that have contributed to the success of the work.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00790"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Journeying Forth with the MAGNUM Group…: A Few Milestones along the Way to Digital Television Tape Recording",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J.J. Peters"
                  ],
                  "abstract": "The recently established EBU standard on digital television tape recording is an excellent example of successful international cooperation, which began by bringing together users at a regional level and was later extended to take on wider geographical and industrial dimensions. The article that follows outlines how the research which culminated in the finalization of this standard was conducted, and discusses factors underlying some of the technical options finally adopted.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00788"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Recording of Digital Television",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Television%20Tape%20Recording%20and%20Other%20New%20Developments:%2020th%20Annual%20SMPTE%20Television%20Conference/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "A happy circumstance brings our Review to open its columns today to a presentation of the EBU's work on digital television tape recording. In effect, during this month of October 1985 we are celebrating “Standards Day”, promoted by the ISO to make users of modern technologies more aware of the advantages of standardization. No better way could have been found for the EBU to celebrate this event, and to highlight its keen willingness to engage in this sort of activity, than to give an account of a successful feat of international standardization launched and overseen by the potential users themselves.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1986-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00787"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1985",
        "conferences": [
          {
            "conference_name": "Components of the Future: 19th Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "4",
                "article_title": "Digital Production Switchers",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jacques Vallee",
                    "Max Artigalas",
                    "Michel Favreau"
                  ],
                  "abstract": "Following the 601 CCIR recommendation on a world-wide digital standard, the THOMSON-CSF Company and particularly its subsidiary THOMSON VIDEO EQUIPEMENT has developed a great range of equipment for the French Television experimental digital studio at Rennes. This studio is described in a companion paper Ref. 1 and will be operationnel in mid-85.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00794"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Digital Television Tape Recording: A Report of Progress toward a Standard",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "F. M. Remley"
                  ],
                  "abstract": "The digital television tape recorder (DTTR) is near to becoming a reality. This paper describes some of the main features of the new video recording system. In contrast to the Type C and Type B recorders presently used, the DTTR has not evolved from earlier designs. The new format derives instead from an analysis of the present and future needs of broadcasters and production organizations. It makes a new synthesis of past experience in digital audio and data recording and it capitalizes on experience gained from nearly 30 years of analog video recording equipment design and manufacture.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00795"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The All-Digital Studio is Here",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "D. Nasse",
                    "J. L. Grimaldi",
                    "A. Cayet"
                  ],
                  "abstract": "One of the most important effects of the introduction of digital processing in video systems was probably to challenge the “composite” representation of colour pictures (to which there was no practical alternative) and to establish “components” as a valuable tool to improve the performance of most systems dealing with baseband signals when components were not already made mandatory by some kind of picture processing not achievable on composite signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00796"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Digital Component TV Made Simple for Everyone",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E. S. Busby"
                  ],
                  "abstract": "There are two things to remember about digital television and digital audio. One is that the signal is measured with an exact lack of precision, and the other is that it is measured frequently, at a uniform rate. I will not even mention names like Nyquist and Shannon, but I stress this point…if you measure too slowly, something really important will happen while you aren't looking.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00793"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Streets"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00791"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard T. La Zare"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00792"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Technical History of Home VTR Development",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yuma Shiraishi"
                  ],
                  "abstract": "Home video recorders which came on the scene in the late 1970s are now in widespread use not only for their original application, the recording of TV programs for time-shift viewing but, more recently, for the playback of prerecorded cassettes. With the most current evolvement in video, a video recorder and camera in a single-piece configuration, it has now become possible to make personalized live video recordings as simple as ever.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00805"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Editing with the D.R.A.W. Videodisc",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William F. Justus",
                    "Gary Matz"
                  ],
                  "abstract": "The video disc is a new tool for improving editing systems. It proposes to make editing easier, faster and more thorough. The first shows have now been edited using DRAW video discs. The principal advantage of the video disc is the dense storage available and the ability to produce replicas using masters. (See figure 1 for a comparison of picture media area).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00806"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Resolution Considerations in Using CCD Imagers in Broadcast-Quality Cameras",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas M. Gurley",
                    "Carl J. Haslett"
                  ],
                  "abstract": "The evolution of a totally solid-state camera, with performance suitable for broadcast applications, has been underway for many years. The first all-transistorized cameras were introduced some two decades ago.1 The manufacturer called this product line “The New Look.” But, the imaging device remained a pickup tube, with its inherent instability, fragility, and limited life.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00807"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Super Motion System",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "L. J. Thorpe",
                    "T. Nakamura",
                    "K. Ninomiya"
                  ],
                  "abstract": "Since the introduction of the Type “C” format 1 inch VTR, slow motion video replay has gained wide popularity by permitting close examination of movement in sports, science, drama, and increasingly – even as a special effect in commercials. The dynamic tracking technology (essential to this facility) has become an indispensable element of this format. Indeed, the slow motion ability is eagerly sought within smaller format systems, such as 3/4 inch and the new 1/2 inch.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00808"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Enhanced Television — A Progressive Experience",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J.L.E. Baldwin"
                  ],
                  "abstract": "In a paper (Ref 1) presented in San Francisco at the SMPTE Conference in February 1983, my doubts were expressed about the use of the term ‘Kell Factor’. It also made the point that for MAC signals (Multiplexed Analogue Components) the most significant cause of impairments was the use of an interlaced display and that a progressively scanned display, derived from an interlaced transmission system, should eliminate these impairments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00809"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Optical Video Disc for High Definition Television by the MUSE",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "T. Toyama",
                    "Y. Morita",
                    "T. Hioki",
                    "O. Ohta",
                    "Y. Ishii",
                    "Y. Ninomiya",
                    "Y. Ohtsuka",
                    "Y. Izumi",
                    "S. Goushii"
                  ],
                  "abstract": "Since 1970, NHK (Japan Broadcasting Corporation) and other organizations have been continuously researching high definition television (HDTV). As a result of this research NHK has proposed an HDTV provisional standards featuring 1,125 scanning lines, 60 Hz field frequency and 5:3 aspect ratio. Items based on these standards, such as HDTV camera, display, telecine, VTR, etc., are currently under development. HDTV, which is capable of storing at least 5 times more information than a conventional TV and displaying a highly detailed wide screen image, is drawing public attention as the TV system of the next generation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00810"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "A Possible Digital VTR for HDTV",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Y. Eto",
                    "M. Umemoto",
                    "S. Mita",
                    "S. Nagahara"
                  ],
                  "abstract": "More than 30 years have elapsed since TV broadcasting service began in major countries under the current TV standard format. An HOTV is expected to form the new TV system of the next generation. System concepts and basic equipment are being developed for HDTV by many organizations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00811"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "High Definition Production Standards—Interlace or Progressive?",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kerns H. Powers"
                  ],
                  "abstract": "In the days of the simpler life, feature films were produced for theatrical release, and television programs were produced for broadcast to the home. Today, virtually all productions, whether produced in video or on film, address the revenue from worldwide distribution through multiple media. These include theatrical films, made-for-TV movies, drama series, sitcoms, soaps, game shows, sports, and even news. The video distribution media, especially, continue to proliferate as we have seen with cable, MDS, prerecorded tape and disc, SMATV and DBS. The importance of the worldwide market has placed high priority on the need for a single worldwide high definition electronic production (HDEP) standard1–4 to augment the current high definition standard, which is 35 mm film at 24 frames per second.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00813"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Digital Video Standards: A Progress Report",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stanley Baron"
                  ],
                  "abstract": "This paper provides a snap-shot of the current status of S.M.P.T.E. efforts in the area of digital video component interface standards-for use in studio applications. Electrical and mechanical interface requirements and considerations are given. The technical bases and performance level requirements of CCIR 601, S.M.P.T.E. RP-125, and the current efforts towards a serial digital standard (T14.18-X1) are provided. The relationship between the three documents is also described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00797"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Component Color Production Switchers Analog and Digital Trade-Offs",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Birney D. Dayton"
                  ],
                  "abstract": "As the interest level rises in the use of component color television production equipment, a review of the pros and cons of various approachs to the implementation of a component color production switcher may be of value. Analog and digital solutions have been proposed. This paper will look at the trade-offs between the various possible approaches and attempt to offer a reasonable path to the future. To this end, the basic functions of a production switcher will be reviewed, and the benefits and problems associated with different design approaches will be reviewed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00798"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "SMAC Codec Multiplexers and Demultiplexers",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Virgil L. Lowe"
                  ],
                  "abstract": "The purpose of this paper is to describe the codecs used to convert parallel components into SMAC, and SMAC back into parallel components.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00800"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "B-MAC — A Transmission Standard for PAY DBS",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Keith Lucas"
                  ],
                  "abstract": "The signals in use today for the transmission of broadcast TV services are direct descendents of the original monochrome transmissions of the 1940s. The method adopted for the addition of colour (namely the colour subcarrier) was dictated by the requirement to be compatible with the early monochrome receivers, and by the technology then available. Since that time, there have been significant advances in technology, due in particular to the advent of large scale integration of electronic components. Moreover, the economic environment in which television services must operate has been transformed through the introduction of Cable TV, VCRs, video games, home computers, etc. which compete for the screen. (It is forseeable that the home TV receiver may degenerate into a monitor, fed by a series of stand-alone input devices, each providing a separate service).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00803"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Component Processing in Time Base Correctors and Post-Production Switchers",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David E. Acker"
                  ],
                  "abstract": "It has been known for some time now that component video processing offers several technical and performance advantages over composite video processing Numerous technical papers support this point with analyses and have presented the reasons why higher performance can be achieved in processing television pictures in this way. Current signal processing literature on this subject is almost overwhelming.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00799"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "New and Unique Method for Measuring Video Analogue Component Signal Parameters",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dan Baker"
                  ],
                  "abstract": "Based on the growing need to distribute and process the video signal in analogue component form, a means of simultaneously monitoring at least three component signals is needed. A traditional voltage versus time display of the signals in sequence (parade) is quite useful for monitoring and measuring a number of signal parameters. In the case of RGB components, the parade display is typically used and illustrates amplitude, transient response (group delay), and frequency response errors in any or all of the components. Relative errors in amplitude and timing are more difficult to measure with the parade display unless the waveform monitor can be adjusted to overlay the component signals on top of one another. The display can then be expanded vertically and horizontally to provide the resolution needed for precise timing and amplitude comparisons.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00801"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Improved PAL by a Combination of NTSC-SECAM-PAL",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "G. Holoch",
                    "N. Mayer"
                  ],
                  "abstract": "In the existing TV standards NTSC, SECAM and PAL the luminance and chrominance components are transmitted in a frequency multiplex format with a full compatibility to monochrome characteristics. As the spectrum of the modulated subcarrier is shared with the high frequency components of the luminance signal, cross effects normally arise after demodulation which impair the picture quality. Moreover the bandwidth of the luminance signal is restricted by notch filters in the coder and in the decoder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00802"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "The D2-MAC Packet System for All Transmission Channels",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. Sabatier",
                    "D. Pommier",
                    "M. Mathieu"
                  ],
                  "abstract": "After almost five years of research carried out within the European Broadcasting Union (EBU), the CCETT laboratories were led to study and realize the so-called D2-MAC-packet system, as a member of the MAC-packet family promoted by the EBU.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00804"
                  }
                }
              },
              {
                "article_local_id": "32",
                "article_title": "Component Video Panel Discussion Feb. 15, 1985, San Francisco",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/32/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. Merrill Weiss",
                    "Stanley Baron",
                    "Birney D. Dayton",
                    "David A. Griffin",
                    "Geoffrey Leighton",
                    "Dominique Nasse",
                    "Charles A. Poynton",
                    "Laurence J. Thorpe"
                  ],
                  "abstract": "WEISS: I will open the floor to questions, but in order to get things started, I will pose one to the panel and let everybody have a crack at it. I hope this will get us off to a good, thorough discussion. Given all of the development in the technology that's taking place in both analog and digital components, will we really see a change in industry practices from the current composite systems to components? Are people going to adopt what we are doing, and if they are, when will that happen? Why don't we go left to right and start with Dominique.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00822"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Stereo Audio in Television",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas B. Keller"
                  ],
                  "abstract": "The industry began work on TV Multichannel Sound Standards in January 1979 in response to the strong interest by many sectors of the broadcast and consumer electronics industry. Television receiver manufacturers expressed interest in multichannel sound development because high fidelity sound for television can only be sold in stereophonic form which would be incorporated in to a new generation of television receivers. Broadcasters desiring to take advantage of new technology and the potential for improved television service to the public supported the request of a National Association of Broadcasters (NAB) Committee evaluating future uses of television ancillary broadcast services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00814"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "The Digital Television Tape Recorder — Audio and Data Recording Aspects",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth P. Davies"
                  ],
                  "abstract": "For some users, the digital television tape recorder (DTTR) is most attractive for reasons of its video performance, particularly in regard to numbers of generations without significant impairment addition. Others, however, recognize that the largest improvement in performance when going to these new machines from current analog-based, C-format machines will be in the quality, flexibility and quantity of the audio recording tracks. The recording format proposed offers the potential of: * 120 dB dynamic range. * 20 kHz bandwidth. * Very low distortion. * Negligible timing errors such as flutter, wow and dispersion. * Four channels individually editable in sample, track, field or frame increments. * Twenty or more generations without impairment build-up if digital processing is employed. * Graceful reduction of performance, at worst, in the event of catastrophic failures such as heads clogging, tape scratches etc.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00816"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Stereo/Multichannel Audio in Production and Broadcasting: Expectations, Experiments and Future Trends",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Paulson"
                  ],
                  "abstract": "On March 29, 1984, the FCC backed into an endorsement of multichannel television sound (MTS) broadcasting with a ruling worthy of comparison to the judgmental wisdom of Solomon. It “authorized Stereo TV by establishing technical guidelines to protect from frequency interference a multichannel sound system designed by Zenith Audio Corp. and dbx Inc.” (See Bibliography Reference 8). “The Commission's position, therefore, did not rule out other systems for TV stereo sound transmission. “However, in reality the action tacitly gives a vote of confidence to the work of the Electronic Industries Association, which recommended the Zenith/dbx systems over several others.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00815"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Implementing the BTSC Companding System for Multichannel TV Sound",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Leslie B. Tyler",
                    "David E. Bates"
                  ],
                  "abstract": "Early in 1984, the Electronic Industries Association (EIA) and the National Association of Broadcasters (NAB) recommended that the FCC adopt the Broadcast Television Systems Committee (BTSC) system for multichannel TV sound (MTS) as a standard for US TV broadcasting. In March of 1984, the FCC ruled that the BTSC system (along with others) may be used by US television stations wishing to transmit MTS. Significantly, the BTSC system was granted protection from interference with its pilot tone, transmitted at the horizontal scanning rate, 15,734 Hz. This protection, along with the strong industry consensus, has encouraged the television industry to adopt BTSC generally for commercial-television production1 and increasingly for broadcasting.2",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00818"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "An Audio Broadcast System Using Delta Modulation",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth Gundry"
                  ],
                  "abstract": "Digital systems are technically attractive for the delivery of high quality audio to the home because they can be substantially transparent even under conditions of impaired reception, and permit scrambling without degradation in quality. Conventional multilevel pulse code modulation (pcm), with its precise D-A converters (at least 13-bit), elaborate output filters and complex error correction, can perform very well, but its cost is much higher than that normally associated with consumer audio circuitry. This paper describes a digital transmission technique based on delta modulation, whose decoder cost is a small fraction of that of a pcm system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00819"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Digital Stereo Sound with Terrestrial Television",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. H. Jones"
                  ],
                  "abstract": "The possibility of stereophonic or two-channel sound with television has excited increasing interest in recent years; stereo capable video tapes and discs have appeared, television receivers are being equipped to reproduce stereophonic sound, and in several countries there have been experimental broadcasts or scheduled transmissions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00817"
                  }
                }
              },
              {
                "article_local_id": "31",
                "article_title": "Forging a HDTV System for Production and Post Production — A Working Group Report",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/31/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard J. Stumpf"
                  ],
                  "abstract": "Studies on HDTV are being carried out by many organizations and groups around the world, including NHK, EBU, ATSC, and the CCIR. For over 10 years, SMPTE has been active in these studies, has maintained liaison with the EBU, and has directly supported the efforts of the CCIR. As a founding member of the Advanced Television Systems Committee (ATSC), SMPTE pledged support of its Television Technology Committees to the work of this new organization.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00821"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Major Parameters of HDTV",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tetsuo Mitsuhashi"
                  ],
                  "abstract": "The HDTV must satisfy the visual and psychological requirement of the viewers. Electro-cinematography, printing, application to other imaging systems, ease of manufacturing the equipment and cost are also important factors.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00812"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "A Digital Audio Time Base Corrector for Linear Magnetic Recording",
                "article_url": "https://journal.smpte.org/conferences/Components%20of%20the%20Future:%2019th%20Annual%20SMPTE%20Television%20Conference/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas J. Rosback"
                  ],
                  "abstract": "The marketplace acceptance of component television and high-fidelity video cassette recorders signals a significant consumer interest in high quality audio for television. Unfortunately, many of the video tape recorders in present use are incapable of providing satisfactory audio reproduction due to a variety of inherent mechanical limitations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1985-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00820"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1983",
        "conferences": [
          {
            "conference_name": "Video Pictures of the Future: 17th Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "11",
                "article_title": "Arithmetic Control Algorithms for Digital Video Effects",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jim Blecksmith"
                  ],
                  "abstract": "The modern Digital Video Effects unit (DVE) has become a part of a larger system. To understand the DVE control algorithms, the overall system must briefly be described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00596"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "The Computer Controlled Frame Buffer as a Production Tool",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas F. Klimek",
                    "Herman E. Towles"
                  ],
                  "abstract": "The digital frame buffer under computer control is a production tool of wide capabilities. Some of these are generally available in the television production field as “Digital Video Effects” CDVE) systems. However, an even greater spectrum of effects is possible if the buffer is tied to a general purpose computer and directed by user software.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00599"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "The Type “C” Format … a Moving Target",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William F. Carpenter"
                  ],
                  "abstract": "When the SMPTE “C” format was agreed upon in 1978 there were doubts in the minds of many as to whether it would ever replace the quadraplex VTR's which were in use worldwide. Most VTR users could understand the projected economies of this new format specifically in reduced tape cost and the resulting reduced space required for archival storage of the tape. Also, the performance features of picture in shuttle and still frame provided by the one field per scan format held a future of increased productivity in the editing area. In addition to these basic comparisons to quad in both performance and economy there was intrinsic value to the mobile production user of reduced size, weight and power, all basic concerns in the growing field production environment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00600"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "New Chrominance and Luminance Components for Multiplexed Component Video Signals in HDTV Systems",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles W. Rhodes"
                  ],
                  "abstract": "In the design of any new color television system, the choice of the luminance signal equation and of the two color difference components to be used is important. It would be worthwhile to carefully consider alternatives to the classic NTSC equations as the new system is almost certain to be based upon time division multiplexed chrominance and luminance components and not on a composite signal. It is important also to note that the NTSC system was developed before the invention of the video tape recorder or the concept of satellite transmission, both of which use, and will continue to use, FM with its triangular noise spectrum. It will be wise to take into consideration the effects of transmission noise in choosing both the luminance equation and the color difference components.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00588"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "L. Merle Thomas"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00586"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Preface",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Maurice L. French"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00587"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Compatible Systems for High Quality Television",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M.J.J.C. Annegarn",
                    "R.H. Jackson"
                  ],
                  "abstract": "The feasibility of introducing a picture memory into domestic receivers at an acceptable cost opens new ways to approach the improvement of television picture quality. Until very recently straightforward improvement of the system was the only way to produce a better picture. The advent of a picture memory opens up at least two alternative approaches which have been described in outline in a previous paper by Jackson and Tan (Ref 1). The options suggested were, first to assume that the normal transmission would be left unchanged and to use a combination of memory plus picture processing to achieve a greatly improved picture. Secondly, to assume the alternative starting point of achieving a large screen picture of very high quality whilst using processing to retain as much compatibility as possible. This paper gives more detail about work already done on these approaches and also suggests some new possibilities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00592"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Diagnostics for a Microprocessor Based Video Tape Recorder",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Glen Rose",
                    "Gary Warren"
                  ],
                  "abstract": "The recent practical availability of moderate cost microprocessor chips and memory IC's has resulted in a revolutionary change in the design of VTR machine control and servo systems. In the past VTR machine control consisted of arrangements of discrete IC devices operating as both combinational and sequential logic circuits. Now machine control is dictated by software instructions contained in IC memory chips interconnected with a microprocessor IC to form a computer control structure. The result is a control system with logic density orders of magnitude greater than previously available.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00610"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Tools for Interactive Picture Processing Systems",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Alan L. Bridges"
                  ],
                  "abstract": "Innovations in raster graphics technology have led to the development of tunrkey computer graphics systems that combine interactive graphics and digital image processing. These interactive picture processing systems provide hardware and software necessary for input, creation, manipulation, storage and output of visual images. Interactive picture processing systems have evolved from traditional visual communications media, such as painting, paper, pencils, printing, photography, mechanical typesetting, film, and video. This revolution has changed the emphasis of computer graphics from numbers-intensive to art-intensive devices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00595"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "A Second Generation “Type C” One-Inch VTR",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "H. Tanimura",
                    "Y. Fujiwara",
                    "T. Mehrens"
                  ],
                  "abstract": "The sponsorship of standards by the SMPTE and EBU in 1978 for the “Type C” format triggered a remarkable world-wide acceptance by professional television organizations of the one-inch helical scan VTR. During the very short period of 4 years the number of machines produced on the Type C format is comparable to that of 2-inch quadruplex. Some of the reasons for this rapid growth are: • Excellent quality, high reliability and ease of maintenance. • Easy operation, flexibility in editing applications and portability. • Drastic reduction in operating costs and in capital costs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00601"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "The HDTV Camera - Fighting the Resolution/Noise Battle",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ulrich H. Reimers"
                  ],
                  "abstract": "During the development of any component for a future-oriented HOTV system the question arises: to what extent can this type of apparatus be implemented using components currently available on the market, and in which areas is technological progress a prerequisite for a successful future-oriented development. The most vital components in the construction of a colour camera for HDTV systems are - under this aspect - without doubt the camera lens and the pick-up tube. This article describes the resolution performance which can be achieved today using these components. A very important characteristic of the HOTV - as indeed of any other camera - is its sensitivity and its light requirement on location; these parameters are both directly related to the signal-to-noise ratio in the camera signal. The signal-to-noise ratio in a HOTV image and its subjective evaluation by the viewer are two of the numerous parameters in HDTV systems which so far remain largely unresearched. This article will therefore attempt to demonstrate which signal-to-noise ratios are feasible in a HDTV camera at the present time, and to which extent these values can be regarded as satisfactory. Tests of noise visibility in HOTV images, which include practical experiments, support these theses.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00589"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Menu-Driven User Interfaces for Videographics",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard G. Shoup"
                  ],
                  "abstract": "Many applications of digital computers in video production require smooth, flexible interactions between the user and the computer. Computer-assisted editing of videotape and the creation of videographics are cases in point. Although a keyboard or control panel is commonly employed as a user interface, interactive menus are frequently a more effective way to couple the operator to his task.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00598"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Extended Definition Television with High Picture Quality",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Broder Wendland"
                  ],
                  "abstract": "Present day TV-Systems do not offer a picture quality which would meet the requirements of future systems and applications. This is true at least for picture reproduction on large screens or in connection with new services as e.g. teletex or computer graphics. Therefore about 12 years ago the Japanese (NHK) were starting experiments with high line number TV-systems and they created a 1125 line system with a luminance bandwidth of about 20 MHz /1/.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00591"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Progress Report on EBU-SMPTE Serial Data Control of TV Equipment",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "R. McAll",
                    "M. Stickler"
                  ],
                  "abstract": "During the past few years broadcasting organizations and manufacturers of broadcasting equipment have become increasingly aware of the potential advantages of establishing a standard system for the remote control of television and radio production equipment based on the use of digital techniques.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00607"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "A High Definition Still Frame Television System",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Glen R. Southworth"
                  ],
                  "abstract": "Television systems with 1000 line or greater resolution have been available for several decades, but the relatively wide transmission bandwidths required have limited useage to short distances. The availability of satellite transponders, particularly DBS services, and the resulting greater amount of available spectrum space has stimulated renewed activity in this field, especially in high quality color video for the entertainment field.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00590"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "8-9 Block Code: A DC-Free Channel Code for Digital Magnetic Recording",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "H. Yoshida",
                    "Y. Hashimoto",
                    "T. Shimada"
                  ],
                  "abstract": "Channel coding is generally employed in digital magnetic recording to match certain properties of the coded sequence to the channel characteristics of the recorder. Since magnetic recorders are incapable of reproducing very low frequencies or dc content, dc-free channel codings have been primarily employed in the digital VTR's, for example 8–10 block code [1], M2 [2], interleaved NRZI* [3,4], tri-level code [5] and so on. This paper describes the dc-free 8–9 block coding. The coding strategy is discussed in detail with examples of three practical methods. The properties of the 8–9 block code have been investigated both by hardware experiments and by computer simulation. The performance of this channel code is found to be better than that of the 8–10 block code when it is applied to an experimental digital VTR without any major modification to the recording and playback circuits.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00605"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Broadcast Quality Video/Audio Recording System with VHS Cassette and Head Scanning System",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Koichi Sadashige",
                    "Ichiro Arimura"
                  ],
                  "abstract": "Significant advances in the art of magnetic recording technology in the 1970's made the development of a Broadcast Quality Video Recording System based upon the VHS (Video Home System) tape transport and cassette possible.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00606"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "The Technical Director's Interface to Digital Video Effects",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Dienhart"
                  ],
                  "abstract": "Since 1977, broadcasters in North America have been introduced to a series of digital video special effect systems that have given the video producer a vast range of manipulative capabilities. Initially, principal attention was paid to the appearance of the effects themselves and less work was done in the area of how, operationally, those effects were put together. Today the range of creative potential housed in these digital tools has expanded significantly. Like all tools. their effectiveness is determined by the operator's ability to understand and utilize them fully. In today's modern broadcast environment p that operator is very likely to be the technical director (TD). Namely, the person with the ultimate responsibility to see that the right buttons get pushed at the right time, and whose knowledge of the capabilities of the equipment, frequently, significantly contributes to the creative realization of the production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00597"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "How Not to be Frightened by Microprocessors",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E. Stanley Busby"
                  ],
                  "abstract": "It might help to explain the title if I told you that I once debated against the premise that “all fear stems from ignorance”. I lost, convinced that at least we are much more comfortable about things we know about. This paper is not very technical, and is intended to be of help to those who know what an oscilloscope is, but don't know where to stick the probe on a microprocessor. Relax, this won't hurt.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00608"
                  }
                }
              },
              {
                "article_local_id": "29",
                "article_title": "The Evolution of a Comprehensive Computer Support System for the Television Operation",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/29/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael S. Tooms",
                    "John W. Anderson"
                  ],
                  "abstract": "During the period 1978/79, an in depth study was undertaken into the television operation to determine amongst other objectives the likely effect of the rapidly developing computer and particularly microprocessor technology on television production and management techniques.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00614"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Product Evolution through Software: The RCA TK-47 Studio Camera - a Case History",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Bernard Hurley"
                  ],
                  "abstract": "The RCA TK-47 Studio Camera has experienced considerable growth since its introduction. Much of this change has been possible because of the programmable microprocessor-based control system. I would like to explain to you, now, exactly what those changes were, the impact of software on those changes, and some general observations for implementing microprocessor-based products.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00611"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "An Introduction to Analog Component Recording",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Koichi Sadashige"
                  ],
                  "abstract": "Relentless push to raise the FM carrier frequency, i.e., from Low Band to High Band, then to the Super High Band, was the outcome of the efforts by the equipment designers to meet the ever increasing performance requirements imposed upon the analog composite video recording system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00603"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Analogue Components, Multiplexed Components and Digital Components - Friends or Foes?",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J.L.E. Baldwin"
                  ],
                  "abstract": "The colour broadcasting standards now in use, NTSC, PAL and SECAM, are conventionally referred to as being composite systems. This word is used to differentiate between such systems, which only use one signal path for transmitting a colour picture, and the alternative of the three paths required for the separate transmission of red, green and blue primary signals. The use of a single path for conveying a colour signal made the system compatible with monochrome for operations in studio centres.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00602"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Switching and Distribution of High Resolution RGB Video Signals",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Patric L. Lewis",
                    "Lee V. Good"
                  ],
                  "abstract": "This videotape visually describes a High Resolution Switching and Distribution System installed at Ames Research Center, Moffett Field, California. The equipment is located in the “FLIGHT AND GUIDANCE SIMULATOR” building. The original motion simulator was first operational in 1969.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00593"
                  }
                }
              },
              {
                "article_local_id": "28",
                "article_title": "Microprocessor Control Achieves Design Flexibility for Video Production Switchers",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/28/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Howard P. Butler",
                    "David C. White"
                  ],
                  "abstract": "The design and manufacture of a sophisticated studio television system such as the GVG 300 production switcher can extend over many years. During that time, it can be expected that a number of design changes will occur, as a result of improving technology, added features. and. of course. the discovery that original design concepts may need modification.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00613"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "A Microprocessor Based Camera Remote Control Unit",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John A. Gray"
                  ],
                  "abstract": "The introduction of the TK-47 automatic color camera at NAB 1978 added a new impetus to the evolution of TV camera technology. This represented the world's first color camera chain which decisively embraced the now firmly established digital semi-conductor memory. The multiplicity of remote control potentiometers traditionally found on color camera CCU's are now totally eradicated and replaced instead by a couple of chips of semi-conductor RAM. The latter, in turn, are supervised by a microprocessor and the loading or updating is from a remote digital terminal. Because this new memory is now resident within each individual camera chain and not, as formerly, within the CCU potentiometers the digital remote terminal no longer constitutes an integral component of the camera chain. Rather, it now assumes the role of technical supervisor and electrically it can now be delegated to any of a large number of cameras within a TV complex. The terminal affords microprocessor assisted manual alignment of the total camera chain, as well as at the touch of a button, a sophisticated automatic system that will completely and automatically align the camera chain. All control interconnections within the camera system are via a serial digital data bus.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00612"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "An Intelligent Time Code Peripheral for Computer Based Video Tape Editing Systems",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Racelo"
                  ],
                  "abstract": "In 1969 SMPTE proposed a standard time code, now familiarly known as Longitudinal Time Code (LTC), which laid the foundation for computer based video tape editing systems. In the following year, the semiconductor industry introduced the first microprocessor chip. Eleven years later in 1981, SMPTE proposed a new time code standard called Vertical Interval Time Code (VITC) for high performance video tape editing systems, and this standard was adapted to PAL and SECAM systems by the European Broadcasting Union (EBU). At the same time, the semiconductor industry introduced a new generation of high performance microcomputer chips which far exceeded the capabilities of the earlier microprocessors. This paper reviews the differences between VITC and LTC, and discusses an intelligent time code peripheral, packaged in a single 1–3/4 inch rack-mounted chassis, which employs modern microcomputer technology to simultaneously generate and read both time codes for use in NTSC, PAL, and SECAM systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00609"
                  }
                }
              },
              {
                "article_local_id": "30",
                "article_title": "Digital Diagnostics: How Much should the Patient Tell?",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/30/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roy H. Trumbull"
                  ],
                  "abstract": "The first logic circuits I ever worked on used relays. In distinction to TTL, these circuits were PBL (pin ball logic). One characteristic all logic circuits seem to share whether constructed of relays, transistors, ICs, or the latest VLSI devices is that, past a certain complexity, the function of a circuit is not readily apparent to a person who was not a party to its design. This is not to say that the function can't be determined. But there will be a price to pay in man-hours for an individual to get inside of the designer's head and obtain an intimate knowlege of the circuit. This may be desirable when working on the same circuitry day in and day out, but when many pieces of equipment are worked on infrequently, such an approach is not cost effective.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00615"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Digital Video Recording: New Results in Channel Coding and Error Protection",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jurgen K. R. Heitmann"
                  ],
                  "abstract": "The worldwide standardization of digital video recording necessitates in addition to standard mechanical parameters a standardized magnetic track pattern on the tape. It is necessary to specify the location of each picture element within the track, the channel code and the type of error protection. These parameters should all be discussed with the aim of finding an economic solution to the problems of digital video tape recording.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00604"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Computer Graphics Animation Methods",
                "article_url": "https://journal.smpte.org/conferences/Video%20Pictures%20of%20the%20Future:%2017th%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Black"
                  ],
                  "abstract": "The rapid proliferation of computer graphics systems, designed to aid the short-turnaround production of both static and animated short-burst graphics for video has taken place with a simultaneous burst of impossibly high expectations, confusion and general bewilderment at what these systems really do.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1983-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00594"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1982",
        "conferences": [
          {
            "conference_name": "Tomorrow's Television: 16th Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "4",
                "article_title": "Code Utilization for Component-Coded Digital Video",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "D. Izraelevitz",
                    "J. L. Koslov"
                  ],
                  "abstract": "Component coding with luminance and two color-difference components (Y, C1,C2) has recently received much attention for its use as a uniform representation of programs generated using 525-line (NTSC) and 625-1ine (PAL SECAM) standards, [1], and also as a road to reduced encoding bit rates, [2].",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00619"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Digital Television Tape Recording: Forming a Format",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. L. E. Baldwin"
                  ],
                  "abstract": "Now that we have a strong probability of achieving a single worldwide television studio standard for the sampling of the luminance and chrominance components within each line of the television signal it is time to try to achieve a worldwide format for recording such signals on magnetic tape. Obviously there must be two versions of this format, one for 525 lines, and the other for 625, but these two different versions should have such similarity that one machine could easily be switched to operate on either of the two standards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00620"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Development and Applications of Measuring Equipment for Precise Registration of Levels of Television Signals",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "T. Sueoka",
                    "K. Wakui",
                    "K. Murakami",
                    "H. Nakamura"
                  ],
                  "abstract": "The performance abilities of the recently-developed 3-tube color camera are advancing year by year. Its development requires new methods of evaluation. For example, warm-up time is a very important parameter for the recent battery supplied ENG camera. This time evaluation requires much precise data concerning color balance and registration error from various points in the picture within short time intervals. The conventional methods of using osciloscopes and photographs is now inadequate for meeting these requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00622"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Optimization of a High-Quality Color Camera for ENG/EFP Purposes",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ad Franken",
                    "Vasanth Rao"
                  ],
                  "abstract": "In 1975 Philips and Amperex introduced a 2/3-in Plumbicon tube that was specially designed to fulfil the requirements which then applied to portable ENG cameras. The concept of this tube was largely based on that of the existing 1 1/4-in and 1-in Plumbicon tubes which had already proved their worth in studio cameras throughout the entire world for many years. The technology which formed the basis for the diode tubes introduced a few years later was in fact not very different from that employed in the types already in common use.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00623"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Optimum Use of One-Inch Type C Audio Channels",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Martin A. Lilley"
                  ],
                  "abstract": "Although the audio tracks on the SMPTE and EBU Type C formats are only .031 inches wide compared with .070 inches wide on the 2-inch quadruplex format the audio performance of Type C format video tape recorders exceeds that of quadruplex machines. At first it would appear that the narrower track width used on the Type C format would result in an audio signal-to-noise ratio inferior to that obtained on quadruplex recorders, but this is not the case. Because the video tracks are slanted at an acute angle along the tape, the magnetic particle orientation of one-inch videotape is made longitudinal to favor the video performance. This proves of considerable benefit as far as the audio performance is concerned. The use of narrow audio tracks allows three or four (EBU format C option III) high quality audio channels to be recorded on one- inch wide videotape. This permits greater flexibility of operation and cuts down on capital equipment costs for such items as separate open reel audio recorders and machine synchronizers which would otherwise be required.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00625"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "A Review of Issues Related to the Choice of Sample Rates for Digital Audio",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. J. Gibson"
                  ],
                  "abstract": "During 1981 significant progress has been made towards the adoption of 48 kHz as a standard sample rate for digital audio to be used in professional audio equipment as well as in television and motion picture systems. This progress is the result of substantial work done by a number of technical committees sponsored by the SMPTE, the Audio Engineering Society (AES), the European Broadcast Union (EBU), the International Radio Consultative Committee (CCIR), and the International Electrotechnical Commission (IEC). This paper reviews the issues which have been debated in these committees and the background for the choice of 48 kHz among several candidates, some of which have been in use for some time. — In the spirit of reaching an agreement on the sample rate, compromises and sacrifices have been made. Of particular concern for the 525/60-color television system is that 8008 audio samples must be distributed, on the average, on 5 frames, i.e. not all frames will contain the same number of samples. It will be shown that this five-frame periodicity will not constrain editing and switching, but that it will require added hardware. The 625/50 television system as well as the 48 frames per second motion picture system will not suffer from this problem, i.e. each frame will contain the same number of samples as the preceding frame. — Finally the paper will discuss the implications of the fact that certain consumer products now in existence or about to be marketed may operate with a different sample rate than 48 kHz.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00626"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Management of Audio Samples in Digital Television Recording",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E. S. Busby"
                  ],
                  "abstract": "In a previous paper, Mr. Gibson points out potential problems arising from the choice of various audio sampling rates in digital television recording. In this paper I will speak of potential solutions to them. Most are not tried and proven solutions, but are the kind of thing I would try if given the task. I will mention some new problems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00627"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Digitally—What's Up? A Report on Progress and Directions from the Working Group on Digital Video Standards",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth P. Davies"
                  ],
                  "abstract": "This Society has been a leader in the standardization process for many years and in digital video recognized the urgent need for action leading towards standards as early as 1975 in the establishment of a Study Group and, more recently, a Working Group to recommend standards. In 1980, a Study Group on Digital Television Tape Recording was also set up. This activity has involved a great deal of effort in the various committees as the work progressed from concepts and investigations to experiments, demonstrations and an eventual recommendation to USSG-11 for CCIR for a framework for a componentbased standard acceptable for worldwide use.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00617"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "F. M. Remley"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00616"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "A Rationalized Approach to Broadcast Automation",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter D. Symes"
                  ],
                  "abstract": "For many years Television Broadcasters have recognized the potential benefits of some degree of automated operation within the TV station, and in particular automation of the Master Control operation which assembles the final output of the station to be sent to the transmitter.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00634"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Television Station Automation: The Station's Viewpoint",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John T. Davis"
                  ],
                  "abstract": "Automation of various facets of television operations has existed for several years. However, a totally integrated system of television automation has been developed only recently.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00635"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "High-Definition Television and Compatibility with Existing Standards",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. P. Sandbank",
                    "M. E. B. Moffat"
                  ],
                  "abstract": "The current interest in High Definition Television (HDTV) is perhaps somewhat surprising since during the last 20 years there have been no significant changes in display technology which herald the availability of consumer products giving a large area hiqh-resolution bright display, and which are capable of doing justice to a picture scanned with more than 625 lines. However, the interest in new TV standards must be seen in the light of the fact that, displays apart, durinq this same 20 years there have been fundamental changes in most other aspects of television technology. Solid state devices have led to the introduction of digital techniques in the studio as well as for recording and distribution. The use of satellites and optical fibre cable have both been established as a means of transmitting video directly to the home viewer. New technology for storing video on tape or disc has appeared in the consumer area.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00636"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "An Evolutionary Approach to High Definition Television",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles W. Rhodes"
                  ],
                  "abstract": "The number of lines per picture is generally accepted as an indicator of the performance of a television system. Fiqure 1 shows the number of lines per picture, with the approximate date at which each broadcast service was initiated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00637"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Color Picture Display System for High-Definition Television",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eiichi Taira",
                    "Minoru Takeda"
                  ],
                  "abstract": "The wide screen, high-definition television aims to present a more attractive and improved impression of “realism” to the viewers and to satisfy the demands of the coming video generation for a crisper picture with higher resolution.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00638"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "High-Resolution Optical Systems for High-Definition Television",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jack Dawson"
                  ],
                  "abstract": "HDTV camera lenses and prism systems must be capable of twice the resolution of conventional lenses and optics used for today's TV standards, and produce 35mm film color quality on a large screen with a minimum aspect ratio of 5:3. — The large picture size and aspect ratio require a much higher degree of sharpness to attain the color fidelity. Resolution, brightness and contrast all contribute to the sharpness of the picture. — The discussion presents the most important design considerations for a zoom lens and prism system that produce consistently high quality pictures regardless of F stop and focal length.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00639"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "A Compatible High Fidelity TV Standard for Satellite Broadcasting",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Tom S. Robson"
                  ],
                  "abstract": "Direct broadcasting of television to the home from the satellite will be a reality by the middle of this decade in Europe. In the United States of America, satellite plans are not yet fixed and a number of proposals have been made including the use of High Definition Television, with higher numbers of lines and requiring a much wider bandwidth than that for existing television systems. In the USA therefore, the options for Satellite Broadcasting are still wide open. But what is the position in Europe, and are ideas now developing in Europe applicable to the USA?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00640"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Development of a VTR for High-Definition Television",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hiromichi Shibaya",
                    "Hironobu Katayama",
                    "Kazumasa Enami",
                    "Kouji Kamijou",
                    "Takeshi Yoshida",
                    "Hikoyata Abe",
                    "Hideo Kasahara",
                    "Keiichi Yaguchi",
                    "Kazuo Abe",
                    "Jun-ichi Ishida",
                    "Yuichi Ninomiya",
                    "Yoshimichi Ohtsuka"
                  ],
                  "abstract": "An experimental VTR to record the wide band video signal of the High-Definition TV System has recently developed. In this paper, the design policy, the construction and performances of the VTR will be presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00641"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "A Serial Communications Architecture for Real-Time Digital Control",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Steele",
                    "Graeme Little",
                    "William Russell"
                  ],
                  "abstract": "Modern serial communications design techniques have grown to be an important consideration in the planning and implementation of new video products. The real-time requirements of frame rate control demand a high rate of response, while user needs demand a design which can be both flexible in its configuration and sophisticated in its control over the equipment. Many of today's technologies allow for these design constraints to be incorporated in concept, but at the potential price of extremely sophisticated electronics. The correct choice of technologies requires the system architecture of the equipment to be well thought out and organized very early in the product planning cycle in order to minimize unnecessary cost and complexity. Unless the manufacturer has thoroughly planned out a product or series of products, the end result will be less than ideal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00629"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "TV Stereo and Bilingual Service of NHK",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yoshiaki Inamoto"
                  ],
                  "abstract": "When we started our tentative TV audio-multiplex service in 1978, our object was to offer it in Tokyo and Osaka. Today, however, it is growing into a nation-wide service using NHK's TV networks.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00624"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "A General Purpose Machine Control System",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas R. Meyer"
                  ],
                  "abstract": "The high costs of modern equipment dictate that individual units must be used by more than one activity within television facilities to maximize return on investment. This shared use requires flexible control systems which can accomodate present and future equipment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00632"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Network of 60 Microcomputers Automates PBS Multichannel Satellite Program Distribution",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "George E. Lemaster",
                    "Robert W. Schmidt"
                  ],
                  "abstract": "Program distribution at Public Broadcast1ng Service (PBS) evolved from a single channel terrestrial interconnection with regional delay centers to a multi-channel operation with satellite distribution. To facilitate the program switching operation a multi-channel automation system was specified by PBS and custom built by the Grass Valley Group. A manual machine control and routing switcher control system was developed and built by PBS. Several unique features were incorporated into these systems. The system architecture is described and the progress and pitfalls of several features are assessed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00631"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Serial Data Machine Control System",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Marc S. Walker"
                  ],
                  "abstract": "The need to remote control equipment has existed for many years. The old methods of parallel multiple wire remote control are becoming unsatisfactory for the modern television plant. The use of standard serial data communications systems allows for improved operation with reduced complexity in wiring and operation.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00630"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "New Integrated Circuits for Video Digital Filters",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Willard K. Bucklen"
                  ],
                  "abstract": "Digital processing of video signals has become commonplace in television studios. The required electronic components that were state-of-the-art in 1973 are now commodity items. However, the demands placed on the hardware by the processing algorithms have not remained static; the special effects, comb filtering, and bandwidth reduction techniques employed today impose a tremendous computational burden. The real time video signal path needs dedicated, highly pipelined digital circuits. To that end, two integrated circuits have been developed that address the practical problems faced by the video system designer. One, a high speed parallel multiplier, is opitmized for televisions's speed, resolution, accuracy, power, and size constraints. The other, an FIR filter chip, offers an even more efficient solution to the majority of signal filtering applications.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00618"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "VIMACS—A Vertical Interval Machine Control System",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "B. Greenberg",
                    "A. Molinari",
                    "S. Ripley"
                  ],
                  "abstract": "The American Television Industry is a unique blend of show business and advertising tied together with Engineering and Technology. As such the broadcaster is constantly striving to improve his “On Air Look”, reduce presentation errors and consequent loss of income. Modern day Telecasting has come to rely upon pre-recorded material for much of its broadcast day. The key to a smooth “On Air Look” is accurately timed Machine starts. This is achieved either by local operation at the source, or preferably, by Remote Control at the point of use. Depending upon the size of the operation, there can be many such control points. The system which allows this control is one of the hearts of a modern T.V. Broadcasting plant.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00633"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The Art of Digital Techniques in the Broadcast Studio",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard J. Taylor"
                  ],
                  "abstract": "The application of digital techniques in the broadcast studio has changed dramatically the on-air look of television in recent years. The creative possibilities realized by the digital approach seem endless as directors and producers discover almost un-imagined freedom.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00621"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Status Report—SMPTE Working Group T14.10 Standardization of Digital Control for Television Equipment",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William E. Bauer",
                    "Graeme M. Little"
                  ],
                  "abstract": "Committee T14.10 was formed as a working group of the Committee on Television Video Technology. The first meeting was held in September 1978, under the Chairmanship of R. W. McAll. The specific purpose of the group is to define a data communication link standard to be used for digital remote control of TV studio equipment. The proposed standard will be defined by three separate documents as follows: 1) the electrical and mechanical characteristics of the signal and interconnect circuits; 2) a supervisory protocol for traffic control, to be recognized and followed by an interface device associated with each equipment connected to the link; 3) a structure and language vocabulary to be used for the text of the messages to be carried by the link. — It is intended that the electrical and mechanical specification (document 1) will be issued as an ANSI Standard; and documents 2 and 3 will become SMPTE Recommended Practices.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00628"
                  }
                }
              },
              {
                "article_local_id": "27",
                "article_title": "Panel Discussion on Multichannel Television Audio: Participants in Panel Discussion",
                "article_url": "https://journal.smpte.org/conferences/Tomorrow's%20Television:%2016th%20Annual%20SMPTE%20Television%20Conference/27/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "S. Lee Whitehurst"
                  ],
                  "abstract": "Thomas B. Keller (Panel Moderator) is Senior Vice-President for Science and Technology for the National Association of Broadcasters, Washington, D.C.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1982-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00642"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1981",
        "conferences": [
          {
            "conference_name": "Television Technology in the 80s: 15th Annual SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "2",
                "article_title": "A New Channel Code for Magnetic Digital Recording",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Max Artigalas"
                  ],
                  "abstract": "The problems met in digital video tape recording are very similar to those met in digital data transmission but with a specific complexity due to the physical characteristics of tape (especially its elasticity).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00644"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "D.V.T.R. Editing Considerations for Multiplexed Audio vs. Separate Audio Edge Tracks",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth Clunis"
                  ],
                  "abstract": "In a conventional helical scan video tape recorder, the video and audio signals are recorded and reproduced entirely independent of each other so that it is possible to picture-lock two video recorders and edit either picture or audio as desired. This statement may not be true of an all digital recorder wherein both the video and audio signals depend upon clocks in order to convey information. The T. V. signal, as we know it today, is a time structured system which needs an identifiable starting point and periodic updating in order to work. The digital representation of a T.V. signal while different in many respects will still be time structured. The audio signal, on the other hand has not been considered a time structured signal until the advent of the digital audio recorder. In the past a slight slippage of speed between two recorders might possibly be noticed as a change in pitch but in a digital world that same slippage of time base would cause a loss of clock synchronization with the intendent disastrous sound effects. To a degree it is possible to reclock two signals not running synchronously by using a process known as asynchronous buffering. The degree of slippage and the interval of time over which it occurs determine the amount of digital storage needed. The cost of such buffering and the problems created by the offset times usually preclude any buffering beyond that required for small instantaneous time variations like clock jitter or machine flutter.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00651"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Digital Television Error Correction without Overhead Bits",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. A. Goldberg",
                    "J. P. Rossi"
                  ],
                  "abstract": "Transmission, storage and processing of PCM digital television signals in noisy channels subjects the digital signal to uncertainties, and causes bit errors. These appear as random bright and dark noise specks in the picture. The usual way of dealing with errors is by adding parity bits to identify and correct the errors. Many error correcting codes utilizing interlinked parity bits have been developed for this purpose and require overhead bits to carry redundant information. Whenever there is a statistical probability of excessive errors being generated, the television system has had to carry the burden of these overhead bits in order to insure satisfactory picture quality. The penalty is a higher total bit rate. There may be situations where bit errors have occurred in a prior section of the television chain outside our control. If the signal lacks parity coding, then there will be no way to reduce the bit error rate using parity techniques.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00652"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Reflections of a Camera Designer",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "L. W. Germany",
                    "H. Breimer",
                    "H. Blom",
                    "E. Tienkamp"
                  ],
                  "abstract": "Many user specifications start by defining the ideal camera with such phrases as, the ideal camera would have no camera cable, however in practice the studio camera requires power for a camera headlight, and possibly three phase for the camera dolly. It should be of the lightest practical weight consistent with cost and strength, but must be equipped with entensive operational facilities and communications, and in remote pickup applications must be capable of operation with thick gloves.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00653"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "A Super Camera Using Saticon and Built-in Computer Control System",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takashi Sueoka",
                    "Kotaro Wakui",
                    "Keinsuke Murakami",
                    "Tohru Mochizuki",
                    "Teruo Kawai",
                    "Kenzi Ohzeki"
                  ],
                  "abstract": "A TV-color camera, as the input apparatus to TV broadcasting system, has affected not only overall picture quality but also total production cost such as man power and time demand for studio-work and news-gathering. The various technologies surrounding camera engineering has been developed in recent years, and new technology like digital techniques are being applied in this field.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00654"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Advances in EFP Camera Design",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John O. Ryan"
                  ],
                  "abstract": "Mindful of the capabilities and limitations of current technology, most broadcasters would agree that the desirable features of an ideal Electronic Field Production (EFP) camera include most, if not all, of the following: (1) Picture quality comparable to the best studio cameras. (2) A fully portable self-contained configuration with size, weight and power consumption comparable to modern ENG cameras. (3) Full remote set-up and operating capabilities. (4) Full automatic set-up capability from a central unit common to a number of cameras. (5) On-board auto-iris, auto-color-balance, auto-beam-control and perhaps auto-centering. (6) Adaptability for long distance operation via lightweight cable (triax, fiberoptic, etc.). — Crucial to the success of any camera, particularly one intended for the harsh environments of EFP, are these additional requirements: (7) Stability. (8) Reliability and ease of maintenance. (9) Freedom from complex non-operational adjustments. (10) Avoidance of costly specialized components (hybrid and custom IC's, etc.).",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00655"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "A New High Resolution Plumbicon Tube",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. Franken"
                  ],
                  "abstract": "In the last few years, there has been an increasing interest in high resolution television systems that have a high number of lines and/or “slow scan.” The interest seems to be associated with closed circuit television. In this context one might think, for example, of electronic cinematography where the image is recorded directly on to magnetic tape instead of film. The advantage is that electronic signal processing techniques can be used, and the image is available for playback almost immediately after having been recorded.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00656"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Lag Reduction and Lag Characteristics of Television Camera Tube Signals",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert G. Neuhauser"
                  ],
                  "abstract": "Lag in a television camera tube is the measure of the rate of decay of the video signal when the illumination is changed or cut-off. The lag is usually measured as a percent of the original signal level after an interval of time from the removal of the light. Build-up lag is the term applied to the rate of build-up of signal when light is applied to a camera tube.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00657"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Questions on the Orientation of Research in HDTV in the 80's",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joseph Polonsky"
                  ],
                  "abstract": "It is only during the last two or three years that high definition television has become an international topic and this can probably be attributed to the following points; people have only recently become aware that: (1) Picture quality of domestic reception is far from satisfactory, due to a more critical judgement (2) picture quality could be greatly improved by modern techniques and technology, even within the scope of present-day standards (3) Domestic television will, in the future, have a wider application: no longer a broadcasting corporation monopoly, but tied in to various local and remote video sources (4) These future TV services will not be subject to the present technical restrictions and can envisage much higher resolution (more than 1000 lines) to identify detail in unfamiliar pictures, graphics or data (5) HDTV is already of interest in several professional fields, such as cinema production.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00659"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "The NHK High-Resolution Wide-Screen Television System",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Takashi Fujio"
                  ],
                  "abstract": "In Japan, NHK(the Japan Broadcasting Corporation) started research into a high-definition wide-screen television system about ten years ago, and is now taking the initiative in developing such a system. Wide-ranging studies(1) of picture-quality, picture aspect, signal standards and broadcasting systems are now being carried out.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00661"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "A Format for Digital Television Tape Recording",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. L. E. Baldwin"
                  ],
                  "abstract": "It has often been the case in the past, when people talk about digital video tape recorders, that they concentrate their attention on the problems of high bit rates and packing densities, on the niceties of idfferent channel coding and have completely forgotten probably the most important carrier of infomation, the sound channel.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00646"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Louis L. Pourciau"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00643"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Digital Video Tape Recording with Increased Packing Density—Progress Report",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Morizono",
                    "H. Yoshida",
                    "Y. Hasimoto",
                    "T. Eguchi"
                  ],
                  "abstract": "The advantages of high packing density in a digital VTR are expected to be a low tape consumption, reduced size and weight of the equipment and easier cassettability. We can also expect that higher packing density will make possible the perfection of the digital recording capability of high definition TV systems. For these reasons, the present authors have recently been concerned with the feasibility of digital video tape recording attaching great importance to higher packing density [1–3]. We now have a much clearer idea of the potential of digital video tape recording than previously, although much work remains to be done.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00647"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Aspects and Considerations about the Mechanical Format of Digital VTRs",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dieter K. E. Pohl"
                  ],
                  "abstract": "In the magnetic recording of conventional television signals in a studio, a bandwidth of about 5 MHz must be recorded. The physical characteristics of familiar recording systems and the requirements in regard to signal-to-noise ratio are taken into account by using narrow-band frequency modulation. A typical frequency spectrum of this type of recording is shown in Figure 1.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00648"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Recent Developments in Error Concealment Techniques",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M-J. Colaitis",
                    "D. Nasse"
                  ],
                  "abstract": "Digital magnetic recording has always been considered as one of the most promising techniques to be applied to television. The high bit rates involved used to be by far the most difficult problem, but many experiments have now demonstrated the feasibility of sufficiently high bit rates together with reasonable medium consumption. Such high packing densities, implying narrow tracks, seem to have solved the bit rate problem but others still remain. Attention is now focussed on the operational requirements that a digital VTR must satisfy, emphasizing variable speed playback and picture in shuttle capabilities in particular.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00645"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Mechanical Tape Format Considerations for Digital Television Recording",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Thompson"
                  ],
                  "abstract": "During the past several years, there has been a great deal of discussion in the Broadcast and Teleproduction industry about digital television – – especially digital video recording, and the selection process for an eventual recording standard. Mechanical tape format is a key ingredient in this selection process. The technology issues surrounding mechanical tape format parameters are indeed complex – – there are a great many variables and tradeoff alternatives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00649"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "High Definition Television Studies on Compatible Basis with Present Standards",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Broder Wendland"
                  ],
                  "abstract": "Present day television systems do not offer the optimum picture quality which is possible within the given standards. Compatible improvements are proposed which use digital preprocessing at the transmitter and signal postprocessing at the receiver. It is the author's opinion that, before any new standards for HDTV-Systems will be defined, the possible improvements within the given standards should be examined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00660"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Multiplex Sound Television Broadcasting in Japan",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kiyomi Iizuka"
                  ],
                  "abstract": "Sound Inn S is a television program on Tokyo Broadcasting System, Inc. and its affiliated stations throughout the country from 11:00 to 11:30 p.m. every Sunday evening. This show is so popular that it was featured in Japan Tonight, a gala television event telecast in April, 1980 by station WOR in New York City, introducing hundreds of thousands of Americans to what TV is like in Japan.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00658"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Formats for Digital Video Tape Recorders",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "D. Dolby",
                    "M. Lemoine",
                    "M. Felix"
                  ],
                  "abstract": "In the twenty-four years of professional videotape history, only three mechanical formats have been widely used: the quadruplex that dominated the first twenty years and the helical Band C formats that are now expanding rapidly.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00650"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Test Signals in the Digital Domain",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John L. Judge"
                  ],
                  "abstract": "In September of 1974, a paper titled “The Use of Digital Techniques in Television Waveform Generation”(1) was given by J.P. Chambers at the IBC Conference in London. Following the presentation of Chamber's paper, a research effort was initiated at Tektronix, Inc. into the feasibility of developing an all-digital test-signal generator for commercial use. In April of 1980, this effort culminated in the introduction of the TEKTRONIX 1900 Digital Test Signal Generator. This paper will discuss some of the observations and potential applications of digital test-signal generation that were noted during that research and design effort.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00664"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Systems Engineering Considerations in the All Digital Television Production and Transmission Center",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Michael Tooms"
                  ],
                  "abstract": "In television terms systems engineering embraces the design and implementation of the electronics system which supports the production processes. However, in order to discuss systems engineering in a meaningful manner in a field which is as yet virtually undefined, it is first necessary to outline in general terms an operational specification for the electronic system and also define the features of the digital techniques to be used in designing the system. It is desirable that the operational specification should be sufficiently extensive to enable any shortcomings in the proposed digital parameters to be fully explored.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00662"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Digital Decoding of PAL and NTSC Signals Using Field Delay Comb Filters and Line-Locked Sampling",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. K. P. Clarke"
                  ],
                  "abstract": "Although there is widespread interest in digital television techniques, most studio equipment currently operates with analogue signals. In addition, most signals are distributed and processed in composite form. This avoids the problem of distributing separate analogue YUV components, even though many studio processes would benefit from component signal operation. Exceptionally, where direct processing of the composite signal is too difficult, such as for special effects and standards conversion, the signals are first decoded to component form, but this usually results in a loss of quality.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00663"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Worldwide Standardization — Now or Never",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas S. Robson"
                  ],
                  "abstract": "In the UK we have lived with a 405-line television system since the first public high definition television service, as it was then called, was inaugurated in 1936. This, like those that were adopted in other countries, such as the 525-line standard originated in the United States and the 625-line standard in Europe, is an analogue system throughout from the signal origination through the studios, links, transmitters and receivers to the display device in the homes.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00665"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Panel Discussion on Digital Video Component Tests",
                "article_url": "https://journal.smpte.org/conferences/Television%20Technology%20in%20the%2080s:%2015th%20Annual%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "This panel discussion is a review of the Digital Video Component Tests that were held in San Francisco during the week of the 15th Annual SMPTE Television Conference. The presentation was fully recorded, including the questions that arose from the audience. The recording was then especially transcribed for this edition of Television Technology in the 80's. The panel discussion which follows is intended to give an “exchange of ideas” concerning the Digital Video Component Tests to all those attending the conference. The panelists in the discussion were as follows: Stephen D. Kerman Session Chairman Tektronix, Inc. Frank Davidoff Chairman. Task Force on Component Digital Coding Frank Davidoff, Inc. William G. Connolly Chairman. Study Group on Digital Television Tape Recording CBS Television Kenneth B. Davies Chairman. Working Group on Digital Video Standards Canadian Broadcasting Corp. Charles A. Ginsburg Chairman. Study Group on Digital Television Ampex Corp. Roland J. Zavada SMPTE Engineering Vice-President Eastman Kodak Co.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1981-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00666"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1980",
        "conferences": [
          {
            "conference_name": "Digital Video Volume 3: 14th SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "3",
                "article_title": "The All-Digital Television Studio",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank Davidoff"
                  ],
                  "abstract": "Digital technology is having a profound influence on many aspects of human activity. It certainly has affected all areas of television broadcasting. Some of its more important applications in this area include digital logic circuits, digital control of equipment, microprocessor control of equipment, computer-controlled program switching and editing, computer graphics, teletext and other ancillary signals, digital audio, and digital video.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00430"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Report of the Committee on New Technology",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Hopkins"
                  ],
                  "abstract": "Given the theme of the 14th Television Conference as “The Digital Decade” it is appropriate to present here a report from the Committee on New Technology. The Committee on New Technology has been intimately involved in digital television throughout its life. The committee came into being in July 1976, when the SMPTE Board of Governors approved a new engineering committee organization. Eight new committees were formed at that time with a general scope which applied to every committee.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00431"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "When are Digits Going to Meet the Action?",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. R. Sanders"
                  ],
                  "abstract": "Interest in the digital coding of broadcast television signals may be said to have started in about 1966. At that time several organisations, including Bell Laboratories in the USA and the BBC, had built suitable high speed analogue-to-digital converters. A BBC Research Department Review of Progress contained the following statements which are of interest in the light of subsequent events:- “It is intended to use the digital equipment to do subjective tests in order to establish the correct number of levels for digital signal processing.” It also said, “Within two years it may well be possible to develop a competitively priced standards converter using digital techniques.” Both highly prophetic statements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00432"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "An Overview of Progress toward the Digital TV Plant",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anthony H. Lind"
                  ],
                  "abstract": "The 1970s were indeed a digital decade. In fact, this is the fourth consecutive Winter TV Conference which has focused on digital developments. The developments in the solid-state industry of high-speed solid-state memories, including RAMS, ROMS, PROMS and EPROMS – plus the evolution of small computer technology which led to the introduction of, first, mini-computers and then microprocessors, micro-computers, and related devices – paved the way for us. These very small and relatively economical devices led to revolutionary developments in the fields of digital video, digital audio, and digital control.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00434"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Digital Video Processing—1980",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Lowry"
                  ],
                  "abstract": "The end objective of the engineering portion of the motion picture and television industries is to provide the tools for effective visual communication. Advances in engineering technology have brought the film and videotape media progressively closer together during the past decade. The digital technology of the 80s will make further and significant strides toward the eventual creation of one highly versatile electronic motion picture communications tool.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00435"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Component versus Composite Coding for Television Signal Processing",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. L. E. Baldwin"
                  ],
                  "abstract": "Up to about a year ago the digital coding schemes for signals in PAL countries were normally based on digitally coding the composite PAL signal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00436"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Three Dimensional Spectrum and Processing of Digital NTSC Color Signals",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E. Dubois",
                    "M.S. Sabri",
                    "J.-Y. Ouellet"
                  ],
                  "abstract": "The sampling of NTSC color signals is studied with the aid of the three-dimensional spectrum. The effect of various spatio-temporal sampling patterns on the spectrum is derived and some experimental measurements are given. A number of sampling structures which allow a 2fsc horizontal sampling rate are identified, and possible reconstruction filters are described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00437"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Editor's Foreword",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00428"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Architecture of the French LSI Set for Antiope Teletext Decoders",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yves Noirel",
                    "Bernard Marti",
                    "Alain Poignet"
                  ],
                  "abstract": "The Antiope Videotex System is composed of two completely separate parts. The Data Transmission System (DIDON) and the Display System (Antiope). The Data Transmission System derives from a CCETT standardized protocol which can be used for teletext as well as for any other kind of data services such as facsimile or remote control. The future availability of a discontinued 819 line television system within France and the possibility of using that network for data broadcast has pushed the development of DIDON and the LSI's required for its use.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00444"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "The Users View of Teletext Systems",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Walter Ciciora"
                  ],
                  "abstract": "This paper attempts to analyze the North American consumer's reaction to Teletext. A forecast is required since a consumer teletext system has not yet been implemented in North America. While Teletext has many potential categories of users and can be implemented in many different ways, this paper will concentrate on broadcast teletext as an ancillary service for consumers. The analysis is based on considerations of technical feasibility and the constraints imposed by consumer behavior. The results of this analysis have important implications on system design.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00445"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Digital Recording: What is to be Done?",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dominique Nasse"
                  ],
                  "abstract": "Digital magnetic recording is probably as old as the earth itself. The earth's magnetic field was indeed retained by lava becoming solid a hundred million years ago, and the hundreds of flux reversals that have been occurring since that time are now stored in the Atlantic ocean deeps within a natural “tape” of lava flow running at a few inches per year. More recently, the first experimental achievement of alternate magnetization of a steel wire was reported by Arago to the French Academy of Sciences in 1820.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00446"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Digital Audio Recording for Television: Some Choices",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E. Stanley Busby"
                  ],
                  "abstract": "In concise form, some aspects of digital audio recording on videotape are discussed. It may be important for the specialist to know, in the next few years, answers to some related questions. Digital audio recording is briefly compared with bias (analog) audio recording. The essential elements of a digital recording system are mentioned; its accuracy is proportional to the number of bits available to measure a signal; its dynamic range is given by a multiple of this number plus a constant. Four methods for the digitization of an audio signal are described: linear digitization, nonlinear companding, floating point, and near-instantaneous companding. Sampling rates and their influence on bandwidth and interfacing are discussed. Alias components must be avoided, and the dc components of the signal must be suppressed or accommodated. In designing digital audio recording equipment, not only must there be given careful consideration to the physical arrangement of the recording heads and the corresponding track placement on the tape, but also to the concealment and correction of errors within the bit stream. General agreement on design practices will make recorders of various manufacturers freely interchangeable.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00447"
                  }
                }
              },
              {
                "article_local_id": "21",
                "article_title": "Digital Video Recording in the 625-Line System",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/21/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hubert Foerster",
                    "Josef Sochor"
                  ],
                  "abstract": "Multiple generation copies of video tape recordings are, even today, still subject to considerable reductions in quality. At the present time, it is difficult to forsee any progress being made in the tape, head and amplifier fields which will bring about any noticable improvement, as long as the analogue, FM recording method is retained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00448"
                  }
                }
              },
              {
                "article_local_id": "22",
                "article_title": "Experimental Digital VTR with Tri-Level Recording and Fire Code Error Correction",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/22/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yoshizumi Eto",
                    "Seiichi Mita",
                    "Yasuhiro Hirano"
                  ],
                  "abstract": "A few experimental digital VTR devices have recently demonstrated the technical feasibility of digitalization. However, standardization is vital for digital VTR proliferation. Consequently, more detailed work should be continued focusing on the optimum tape format, channel coding and picture coding. Introduced here will be some basic results on our experimental digital VTR, especially concerning the magnetic recording and error correcting techniques.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00449"
                  }
                }
              },
              {
                "article_local_id": "23",
                "article_title": "Digital Video Recording—Some Experiments and Future Considerations",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/23/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Masahiko Morizono",
                    "Hirorumi Yoshida",
                    "Yoshitake Hashimoto"
                  ],
                  "abstract": "A digital VTR is expected to have a very high picture quality, which would enable multiple generation dubbing with virtually no picture impairment, and possibly at lower capital and running cost. Adjustment free circuits and a self-diagnosis system should also enable easier maintenance and higher reliability.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00450"
                  }
                }
              },
              {
                "article_local_id": "25",
                "article_title": "Progress Report of the “SMPTE Study Group on Digital Television Tape Recording”",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/25/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William G. Connolly"
                  ],
                  "abstract": "In a paper presented earlier in this conference, the Chairman of the New Technology Committee, Bob Hopkins, reported on the formation of the SMPTE Study Group on Digital Television Tape Recording as directed by the Steering Committee in March, 1979.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00452"
                  }
                }
              },
              {
                "article_local_id": "26",
                "article_title": "Glossary of Digital Television Terms",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/26/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00454"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Current and Future Developments in Digital Switching and Effects",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "R. Dennis Fraser"
                  ],
                  "abstract": "The advent of video digitization advanced and simultaneously threatened the broadcast business in 1973 with the introduction of a digital time base corrector and in 1974 with the full-frame synchronizer. Limited digital techniques such as character generators had been with the industry prior to this but were not in themselves manipulative of the video signal. The actual a-to-d, memory, d-to-a concept of timing a video signal has been with us just six short years in which time we've witnessed more progress in application than in practically any broadcast equipment area in the previous six decades. Both consumer and scientific demands on memory mediums have advanced us through 1K to 4K to 16K chips with a promise around the corner for 64K and 128K single chip capacities. The broadcaster has found himself in the position of either grasping quickly the concepts of digital or hiring young, bright engineers with an emphasis in that domain.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00438"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Integrated Circuits for TV in the Digital Decade",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William M. Webster"
                  ],
                  "abstract": "Forecasting the events of the Digital Decade to come is a risky business but very worthwhile to attempt. It's risky because there can be quantum jumps in technology at any time. For example, at the time the transistor was invented everyone expected the continued evolution of vacuum tubes and few, if any, foresaw solidstate circuitry. The best that a forecaster can do is acknowledge that such surprises are possible and then use existing facts and trands to build up a surprise-free forecast that is not too conservative.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00429"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Multifunction Digital Video Processor",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stephen Kreinik",
                    "Renville H. McMann"
                  ],
                  "abstract": "The application of digital techniques has made possible several classes of devices that process a video signal in the digital domain. The first such commercial product was the Digital Time Base Corrector. It allowed compact, inexpensive video tape recorders to be used by the broadcaster.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00440"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Network Distribution of Digital Television Signals",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Denis J. Connor"
                  ],
                  "abstract": "The distribution system for network television signals involves the tandem connection of many different transmission systems, all of which presently operate using analog techniques. During the 1980's, the common carriers will install many digital transmission systems so as to realize the maximum economic benefit from digital switching machines. As a consequence it is virtually certain that by 1990 some, if not most, of the distribution system for network television signals will involve the use of digital transmission techniques. — The present situation regarding digital transmission of television signals in North America is reviewed and some areas of concern are noted. There is an obvious need for close liaison between the broadcaster, the common carriers, the manufacturers and the regulatory authorities if the present quality of the distribution system is to be maintained.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00441"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Overview of Broadcast Teletext Systems for NTSC Television Standards",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. R. Storey",
                    "H. G. Bown",
                    "C. D. O'Brien",
                    "W. Sawchuk"
                  ],
                  "abstract": "The development of the British teletext and viewdata systems has sparked a new interest in information services for the general public. In this paper, the term broadcast teletext is used to refer to one-way broadcast information services whereas the generic term, videotex, is used to refer to interactive services carried over public telephone networks. Broadcast teletext refers to the transmission of digital data for direct reception by the public. It is intended to provide a limited one-way information service through the cyclic repetition of pages of information transmitted as ancillary signals on normal television programs. The information contained in both videotex and broadcast teletext signals is received by suitably supplemented television receivers and displayed on the television screen as textual messages or graphic images. Two spare lines in the Vertical Blanking Interval (VBI) of each field of the television signal are used in the United Kingdom to transmit teletext signals, but more lines could be dedicated to this use if they became available. The use of only two lines in the VBI provides a strictly limited service with the public only having access to a few hundred pages of information. However, as it is a broadcast service, all members of the public with teletext decoders and within range of the television station can access the information at the same time. Of course, a much improved one-way broadcast service could be provided by using the full bandwidth of a television channel to provide public access to a few thousand pages of information. This could easily be provided on cable television networks in North America which often have sufficient bandwidth for up to 35 television channels. On the other hand, people with videotex decoders can have access to data bases containing over 100,000 pages by communicating interactively over the public telephone network: but in this case, the service may be limited to only a few hundred users at a time. Cable television operators with two-way networks could also provide an interactive service of this kind. Other configurations are feasible and include hybrid configurations in which page requests are transmitted over the telephone network to an information supplier who then inserts data in the broadcast teletext cycle of the local television station.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00442"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Progress Report of the Subcommittee on Teletext of the EIA Broadcast Television Systems Committee",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert A. O'Connor"
                  ],
                  "abstract": "The Subcommittee on Teletext of the “Broadcast Television Systems Committee”, sponsored by the EIA, was established just about one year ago to develop a set of technical standards for a System M teletext service. The Subcommitte is composed of representatives of the major industries involved, five task forces, and observers. The Subcommittee and its task forces have been very active during this period having held a total of 27 meetings to date.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00443"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Digital Audio Formats for Recording and Digital Communications",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Toshi Doi",
                    "Heitaro Nakajima"
                  ],
                  "abstract": "The digitization of signal has started in voice communication and space communication to obtain good efficiency in multiplexing and to get information under terrible condition of signal to noise ratio. Recently, it is observed that even high quality signal processing will go into digital. Digital audio era has started several years ago in the field of HI-FI, and digital video era is expected to dawn within 5 years, from professional field.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00433"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Software-Based Digital Signal Processing",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Kupnicki"
                  ],
                  "abstract": "The advent of high speed and density of the mass storage medium has opened new possibilities and flexibility to digital signal processing. Although it is practical to store a complete frame of video, a designer is now faced with the problem of controlling its access to fully realize its potential. With the use of ROM Sequence Generators, Microcontrollers and Microprocessors in both the data stream and control path, it is possible to implement a system where increase in sophistication does not automatically mean lack of flexibility, or increase in cost.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00439"
                  }
                }
              },
              {
                "article_local_id": "24",
                "article_title": "Recent Advances in Digital Video Recording",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%203:%2014th%20SMPTE%20Television%20Conference/24/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Robert Thompson"
                  ],
                  "abstract": "During the last year or so, there has been a great deal of discussion in the Broadcast and Teleproduction industry about digital television –– especially digital video recording. A number of companies have been doing some very important work in the digital recording area. But much work remains to be done. For instance, the proper choice of certain key recording parameters is very important to the long term effectiveness and user value of digital recorders. Also, the matter of recording format standardization is a very important area that requires careful consideration and intensive technical effort. The technological issues of digital recording are complex and sophisticated –– there are a great many variables and trade-off alternatives.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00451"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "Digital 1980 SMPTE Workshop NAB Convention",
            "conference_url": "https://journal.smpte.org/conferences/Digital%201980%20SMPTE%20Workshop%20NAB%20Convention/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Transcript of the Digital 1980 SMPTE Workshop NAB Convention — Las Vegas — 14 April 1980",
                "article_url": "https://journal.smpte.org/conferences/Digital%201980%20SMPTE%20Workshop%20NAB%20Convention/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Digital television technology remains a matter of overriding concern and interest for all who are involved with the television industry. To respond to the need for reliable, up-to-date information on this subject, the SMPTE — at the 1980 National Association of Broadcasters Convention in Las Vegas — conducted a workshop entitled “Digital 1980 — SMPTE Workshop.” The Moderator was K. Blair Benson of Video Corporation of America. Panelists included: William G. Connolly of CBS, Michael T. Fisher of American Broadcasting Companies, Inc., Robert S. Hopkins of RCA Corp., Miguel E. Negri of National Broadcasting Co., Roland J. Zavada of Eastman Kodak (who is also SMPTE Engineering Vice President), and Hank Thedick of Public Broadcasting Service.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1980-04"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00453"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1979",
        "conferences": [
          {
            "conference_name": "Digital Video Volume 2: 13th SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "3",
                "article_title": "The Use of the Computer in Animation Production",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edwin Catmull",
                    "Alexander Schure"
                  ],
                  "abstract": "NYIT has assembled a team of computer scientists, video technicians and animation artists for the express purpose of generating images and animation of professional broadcast quality. — The facilities include many computers, framebuffers, 2-inch videotape machines, sophisticated computer graphics equipment and a post-production video studio. The central piece of equipment is the “frame-buffer,” a memory which stores an entire rgb picture, has a video output port and a port for random access by computer. — NYIT has undertaken a considerable software effort to make that hardware useable in a production environment. The programs developed thus far give us the capability to “paint” backgrounds, to color animated figures, create special effects, combine images, change scanned-in images, and digitally synthesize or modify a broad class of images. Our focus has been on 2-d animation. Having made substantial gains in solving problems in that area we are currently adapting the programs for production. — The researchers have paid considerable attention to the technical problems of aliasing, color control and image quality. In addition they are now focusing on 3-d animation. — The work has not been without difficulties. Digitally synthesized pictures can take from 15 seconds to 2 minutes to create using a general purpose computer. In addition, once a program is developed, it must be moved out of a research environment and into a production one. — The NYIT system of hardware and software has been successfully used to make an animated film, some test commercials and animated sequences to demonstrate the power and versatility of the system. We have been able to produce some astonishing results.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00419"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Some Experiments in Television Graphics and Animation Using a Digital Image Memory",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard G. Shoup"
                  ],
                  "abstract": "This paper describes an experimental digital video system which can be used for interactive creation and manipulation of simple, cartoon-like graphics and animated imagery. The videographics system (known informally as “SuperPaint”) was designed and built at Xerox in 1973 as an experiment in computer imaging and digital picture composition. Since then, it has been further developed as a computer graphics research tool and used for a variety of experiments in television graphics and imaging.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00420"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The Mosaic Keyer",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Shigeru Jumonji"
                  ],
                  "abstract": "The use of microcomputers is becoming widespread in recent times, so much so that we are said to be in the age of microcomputers now. It is small wonder, then, that the microcomputer is finding its way into broadcasting equipment also. The mosaic keyer to be described here is a compact TV pattern generator unit for video special effects using a microcomputer (MC6800) (Fig. 1). This unit divides the TV raster into 64 elements each in the vertical and in the horizontal directions (in all, 4096 elements) and controls the writing in each of these elements by means of a microcomputer.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00422"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Low Bit-Rate System for Digital Coding of the Television Signal",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "P. Rainger",
                    "P.A. Ratliff"
                  ],
                  "abstract": "It is generally accepted that a bit-rate of about 100 Mbit/s is required for digital coding of high-quality television signals, using conventional linear p.c.m. Although such simple coding has many advantages in the television studio, it is grossly inefficient in terms of information-carrying capacity, and once the digital video signal leaves the studio, for distribution to local-area transmitters for example, it will have to compete with all manner of other digital signals in tomorrow's world of all-digital communications. The concept of universal, digital communication highways is fine, but the video signal is a greedy companion in comparison with the major occupant of these highways, the telephone signal. Similarly such video signals are greedy of digital storage media which will soon play a major role in studio-signal processing, and thus it is important to look at methods of coding them more efficiently. Of course, the final solution involves striking a balance between the cost of hardware required to effect a bit-rate economy and the cost of transmission or storage of the digital signal.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00423"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Editor's Foreword",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Carlos Kennedy"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00412"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Digital Video Recording — A Progress Report",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Lemoine",
                    "J. Diermann"
                  ],
                  "abstract": "One year ago at the SMPTE Winter Conference in Atlanta, we presented a paper dealing with an analysis of choices in digital video recording. The design objectives for this new recording technology were established against the reference point of the present one-inch analog technology, which is finding wide acceptance in the broadcast industry. The advantages and disadvantages of various digitizing methods and sampling rates, and their significance for the existing television standards of the world, were weighed against one another. Digital recording of sounds and its specific problems were related to digital recording of video. Finally, the three major methods of scanning magnetic tape were analyzed with respect to their usefulness as a vehicle for digital video signals.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00425"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "The Expanding World of Digital Video Effects",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard John Taylor"
                  ],
                  "abstract": "The accelerating pace of the development of digital techniques for television has presented the Broadcaster with an interesting dilemma. On the one hand he sees the power of the techniques to provide solutions to engineering problems, extend existing capabilities and create new effects and thus applies pressure to the industry to speed up development. On the other hand, he sees that very pressure bringing with it the high probability of equipment purchased this year being obsolescent next year.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00418"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Digital Video Recording — A Panel Discussion from the 13th SMPTE Television Conference",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Edit. Note: A mark of the importance of digital technology to the television industry is seen in the fact that the SMPTE has arranged two panel discussions on the subject only three months apart. The first, dealing with the near-term future of digital television, was held during the 120th Conference in New York. The present panel discussion on digital video recording was held on Saturday afternoon, 3 February, following five papers on the same subject. The panel was comprised of the authors of those five papers along with four additional people with digital television expertise. Panelists (and their affiliations) included.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00427"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Separate Components Digital Video Recording is Needed and Possible",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dominique J. Nasse"
                  ],
                  "abstract": "The interest and the feasibility of a digital videotape recorder (DVTR) have already been widely discussed and even demonstrated [1,2]. It is generally agreed that the availability of a practical DVTR is the key point that would make fully digital processing of television pictures a reality. This means that a DVTR should not only satisfy the quality, cost, and operational requirements but also operate with a satisfactory digital standard. The first list of requirements is more or less common to all potential users, although some differences appear in the relative weighting of quality vs. investment and operatioanl costs, for example, between the European and U.S. points of view. But the question of the adequate digitizing standards, which for the 525 NTSC system is mainly a matter of choosing a sampling frequency, happens to be more complicated and should be considered in more detail for 625 systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00424"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Digital Video Recording — What will it Do for the Broadcaster?",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward H. Herlihy"
                  ],
                  "abstract": "The purpose of this dissertation is to explore what and how broadcasters in the United States think about digital video recording. The paper will examine requirements that broadcasters envision, including features, operating costs, maintainability, interfacing and finally, general observations and views of format and timing of introduction of a viable, digital video recorder.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00426"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Color Graphics and Animation by Mini-Computer",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%2013th%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Noboru Asamizuya",
                    "Tatuo Futai"
                  ],
                  "abstract": "Currently, color graphics display units are used to communicate certain kinds of information, such as computer data and broadcast election results. In such cases animation outputs are more suitable for correct, immediate and effective information communication than still pictures. If a device for easy production of animations is available, it can be useful in broadcasting and education.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1979-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00421"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1978",
        "conferences": [
          {
            "conference_name": "One-Inch Helical Video Recording: 12th SMPTE Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Editor's Foreword",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frederick M. Remley"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00572"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "An Overview of One-Inch Helical Video Recording",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frederick M. Remley"
                  ],
                  "abstract": "In this paper I want to summarize the present situation of the various newly introduced broadcast quality video recording systems using tapes of one-inch width. Further announcements and introductions of new recording equipment will certainly take place in the months ahead, and no attempt at prophesy is intended. It does not require a prophet, however, to see that changes are in store for most of us who use video recorders. The familiar, sometimes loved, sometimes hated quadruplex recorder is facing competition from a variety of systems now available to the television broadcaster. We can expect that quadruplex recordings will be with us for some time to come, though, and such recordings remain the standard for the national and international exchange of television programs.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00573"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Proposed SMPTE Type C Helical-Scan Recording Format: A Subcommittee Report",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David K. Fibush"
                  ],
                  "abstract": "In an amazingly short period of time, SMPTE committees have reached agreement on a proposed tape recording format for high quality one-inch helical-scan video tape recorders. Starting with a “white paper” submitted to the SMPTE by ABC and CBS and ending with approval of the SMPTE Standards Committee, the basic format documents for 525 line NTSC systems have been completed in less than one calendar year.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00574"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "The Development of National Standardization of the One-Inch Helical Video Tape Recording Systems",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. E. Alden"
                  ],
                  "abstract": "On 24 January 1977 the SMPTE Engineering Vice-President received a letter, submitted by ABC and CBS following their joint study, requesting the Society to set up a special ad hoc committee to assist in resolving a potentially serious problem arising with the rapid development of one-inch helical tape recording systems. The letter reflected the broadcast industry's concern over the proliferation of systems with non-interchangeable formats and offered a proposed format for a continuous field (nonsegmented) one-inch helical system for professional broadcast quality applications. The letter stressed the need for prompt action and urged the Society to move expeditiously on the matter.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00575"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "BCN Digital Store: An Economical Accessory for Production and Post Production",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hans-Peter Maly"
                  ],
                  "abstract": "The segmented field recording method of BCN appears initially to block the path to still pictures and to picture reproduction at variable tape speeds. The search for a solution to these problems led to a concept which, in addition to mastering these tasks, opened up a variety of new possibilities with reference to production, postproduction and electronic editing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00576"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Technical Description of Sony's Portable One-Inch Machine, the BVH 500: First Discussion of its Technical Parameters",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Masahiko Morizono"
                  ],
                  "abstract": "As the current program production system begins to show the trend towards EFP (Electronic Field Production), the demand for portable VTR broadcast quality has grown considerably. In particulars the SMPTE one-inch type-C format has gained wide recognition with its advantages of compactness, high performance and low operating cost. Naturally, the development of one-inch portable VTR's employing this format has begun to attract attention.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00577"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Mechanical Design Considerations for Helical-Scan Videotape Recorders",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dennis M. Ryan"
                  ],
                  "abstract": "The primary purpose of any tape transport is to move the tape past the magnetic heads under precise position, tension, and velocity control. Helical scan VTR's, perhaps more than any other type, demand careful attention to each of these requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00578"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Post-Production Experience with the Ampex VPR-1 High-Band Video Tape Recorder",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Denny K. Fussell"
                  ],
                  "abstract": "TRI·COMM PRODUCTIONS, INC. is based on Hilton Head Island, South Carolina. The following discussion highlights TRI·COMM, our capabilities, why we selected the Ampex VPR-1, and how we interface our equipment with our client's needs to provide top quality while still maintaining a respect for the creative, intimate side of television that our production co-workers cherish.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00583"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Post Production and Production Using One-Inch Helical Videotape and VTRs",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E. Grey Hodges",
                    "Emerson F. Lawson",
                    "Robert W. Dycus"
                  ],
                  "abstract": "As far as I know, Jefferson Productions is the only company in the country other than CBS Television that is using one of the new helical-scan I-inch formats for production and post-production of nationally broadcast material. Thus far, we have used nearly 300 hours of videotape in the recording and editing of shows and commercials with the system, and feel that we have “debugged” it to the point that the problems have been solved, or are on the way toward a solution, and that the system will soon be profitable for us.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00584"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Transcript of the Panel Discussion on One-Inch Helical Video Recording",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Joe Roizen (Telegen) Moderator: Good afternoon, ladies and gentlemen. I must say that I am amazed at some of the statements that have been made today with regard to the various 1-in helical recorders. And I'm also surprised at some of the unique difficulties that have been described. They sound like the usual transitional problems that people have with new technology.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00585"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "User's Experience with Type B “BCN Helical” Portable and Studio Editing VTR",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William D. Kelly"
                  ],
                  "abstract": "We first became acquainted with the Bosch Fernseh BCN line after a demonstration in our New York Studios in mid-February 1977. We did everything we could to put them out of action, but failed. They were obviously rugged and simple to operate, and we were assured that they were reliable. At that time there were about 200 units in use around the world, but only a few in the U.S.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00580"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "A New Edit Room Using One-Inch Non-Segmented Helical VTRs",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William C. Nicholls"
                  ],
                  "abstract": "The editing facility described in this paper is located at CBS Television City in Hollywood. This facility is the first editing room to utilize the new 1" broadcast quality helical scan video tape machines which offer so many advantages over quadruplex machines for post-production eaiting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00582"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Videotape Program Production at CBS Studio Center",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William G. Connolly"
                  ],
                  "abstract": "In February of 1975, CBS issued target specifications for the design of a videotape recorder with improved editing capabilities. The thrust of these specifications was for a recorder with vastly improved transport characteristics, coupled with a tape format which would permit the display of viewable pictures at a variety of speeds in both forward and reverse. The intended application was for off-line editing systems from which a work copy would be produced. The camera originals would later be conformed through automatic assembly in an on-line editing system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00581"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Outdoor Program Production Utilizing Compact Equipment",
                "article_url": "https://journal.smpte.org/conferences/One-Inch%20Helical%20Video%20Recording:%2012th%20SMPTE%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Ichihiko Hishida"
                  ],
                  "abstract": "The program I am going to show you is a part of a two-hour television program which has been produced with a hand-held color camera and one 1" portable VTR. This program, titled “Waves Surging Like Hopping Rabbits,” was produced for participation in the Japan Art Festival in the autumn of last year.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-02"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00579"
                  }
                }
              }
            ]
          },
          {
            "conference_name": "Digital Video Volume 2: 120th SMPTE Technical Conference",
            "conference_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%20120th%20SMPTE%20Technical%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Editor's Foreword",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%20120th%20SMPTE%20Technical%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "M. Carlos Kennedy"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M001118"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "The ANTIOPE Broadcast Teletext System",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%20120th%20SMPTE%20Technical%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Yves Guinet"
                  ],
                  "abstract": "The ANTIOPE system was conceived in 1973 and studied at the CCETT public telecommunications and broadcasting communications research center in Rennes since that time. Its first public demonstration in France was conducted by TDF in September of 1976. Since this time regular experimental transmissions have been made.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00413"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Optical Television Link Employing a Digitally Modulated Laser",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%20120th%20SMPTE%20Technical%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "A. A. Goldberg",
                    "S. Juchnowycz",
                    "J. Rossi"
                  ],
                  "abstract": "Producers of news, sports and on-location drama television programs strive to make their shows more interesting and immediate. A technique that is becoming increasingly popular is to use a mobile television camera and microwave links to convey the picture and sound back to the control point. The limited number of microwave channels available for this purpose can be supplemented with optical links over unobstructed paths of a kilometer or less. FCC authorization is not required but the light beams must be safe in the environment.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00414"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "A Monolithic Video A/D Converter",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%20120th%20SMPTE%20Technical%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Willard K. Bucklen"
                  ],
                  "abstract": "For several years, digital processing functions have been finding their way into the television studio. The first large-scale application was in time base correction of video tape recorder outputs. permitting the use of smaller, lower cost recorders in broadcast applications. Since the introduction of the digital TBC in 1973, there have been fascinating new digital developments: special effects generation. noise reduction, video feed synchronization, standards conversion, and even transmission over digital networks and optical communication links.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00415"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Digital Processing in the DPS-1",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%20120th%20SMPTE%20Technical%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John D. Lowry",
                    "Richard Kupnicki"
                  ],
                  "abstract": "The DPS-1 is truly a DIGITAL Processing System designed to perform a wide variety of processing and storage operations on the television signal. These include basic functions such as time base correction, frame synchronization, and effects. Its design is based to a great extent on the use of high speed computer technology rather than on the mixture of analog and digital techniques found in a great many of the digital television systems in use today, which have evolved from an analog television design philosophy.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00416"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "The Near-Term Future for Digital Television—A Panel Discussion from the 120th SMPTE Conference",
                "article_url": "https://journal.smpte.org/conferences/Digital%20Video%20Volume%202:%20120th%20SMPTE%20Technical%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Edit. Note: During the Society's Technical Conference in New York, 29 October to 3 November 1978, a panel discussion was arranged to conclude the Digital Television Session on Wednesday morning, 1 November. The panel was comprised of authors of participating papers in that session and representatives of the SMPTE Study Group on Digital Television and of the Working Group on Digital Video Standards. Panelists and their affiliations are listed below.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1978-11"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00417"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1976",
        "conferences": [
          {
            "conference_name": "Television Newsgathering: 10th Annual SMPTE Winter Television Conference",
            "conference_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Introduction",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "K. Blair Benson"
                  ],
                  "abstract": "One of the foremost concerns of broadcasters today is the impact of recent advances in equipment design and performance on television newsgathering. In fact, it is seldom that technological developments have so significantly influenced the future of an entire segment of the broadcasting industry. Recognizing the importance of this aspect of television news reporting, the SMPTE devoted a full day and evening at the 10th Annual Winter Television Conference this year in Detroit to an intensive coverage of the subject.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00547"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "WAGA and ENG",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hugo A. Bondy"
                  ],
                  "abstract": "WAGA-TV wasn't the first station to become active in the Electronic Newsgathering field. However, with six months or so of varied experience under our belts this report may be of interest, especially to those who may be in a position similar to ours; that is - a combined transmitter/studio operation with a tall tower located five to seven miles from the points which generate maximum day-to-day news activities.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00549"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Electronic Journalism Editing at NBC",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Mausler"
                  ],
                  "abstract": "A small lightweight, battery powered, portable tape recorder is the heart of Electronic Journalism at NBC. The Video Tape Recorder (VTR), Sony type V03800, uses 20 minute 3/4ʺ cassettes. The helical scan format is commonly known as U-Matic, under the SONY trade name. The cassette feature of this equipment has proved to be particularly suitable for the highly mobile fast moving use that Electronic Journalism demands. The Edit Rooms at the studios are equipped with Sony V02850 Video Tape Recorders which are used both for direct playback to air and for editing.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00560"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "ENG Editing on Helical Video Cassettes: An Inexpensive New Non-Timecode System that is Fast, Flexible and Accurate",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Dennis G. Christensen",
                    "Gary H. Beeson"
                  ],
                  "abstract": "Examining television news gathering trends in the United States over the past year it becomes apparent that in many areas video tape is beginning to replace film as the preferred storage medium for news gathering applications. As a result of this trend, direct comparisons of size, weight, cost, shooting ratios, editing capability, etc., are a topic of serious discussion throughout the broadcast television industry.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00561"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Transcript of the Panel Discussion on Electronic Newgathering",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "I'd like the opportunity now to introduce the panel and then I have a couple of instructions as to the way we'd like to conduct the session in order to get the most value out of it. Starting on my left is Hugo Bondy whom you're familiar with from an earlier paper today. Hugo is a Chief Engineer of WAGA, Atlanta. Next to Hugo is Jim Kitchell, Manager of NBC News Services Division. Next to Jim is Torn Battista, Executive Vice President of the Columbia Television Stations Division. Adjacent to Torn, we have Ray Schneider, Director of Special projects Engineering & Development, Columbia Television Network. On my right is John Tallerico, WLIX, Lansing and Jackson, Michigan, Director of News. Next to John is Charles Kotcher, Chief Engineer at WXYZ, Detroit, ABC owned and operated. Ray Smith, next to Charlie, is Manager of Engineering, WKYZ, Cleveland; and at the end of the line we have Charles Meyer, Supervisor of ENG at WBBM-TV, Chicago, CBS owned and operated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00562"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "A Single Package Portable Color Camera for ENG",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "L. J. Bazin",
                    "J. J. Clarke",
                    "A. H. Lind"
                  ],
                  "abstract": "The TK-76 Television News Gathering Camera as described at the ll7th SMPTE Technical Conference in Los Angeles in September 1975 is shown in Figure 1. It is a small, lightweight 0 single package camera requiring only the application of a nominal 12 volt battery to generate fully encoded color signals. Shown around the cameraman's waist is a battery belt which is considered the normal source of power for the portable, man-carried, application. Since September, the product design has been completed and the camera is now in its first production cycle.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00552"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Assembling an Electronic News Gathering System",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Raymond J. Smith"
                  ],
                  "abstract": "At this session, we want to discuss some of the aspects the process of getting into electronic news gathering. As you know, this process is being referred to in various different ways: E.J.; ENG; Mini-Cam; etc. If I may, I would like to call it E.J. since that is the name I find easiest to remember.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00548"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Mini-Cameras",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Nick H. Nishi"
                  ],
                  "abstract": "The Ikegami HL series of hand-held color cameras is the most widely used camera of this type in the world today. More than 300 sets of these have been sold and they are being used by US broadcasters, including all three (3) networks.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00551"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Spectra-TAC Systems for Electronic Newsgathering",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Robert Fleissner"
                  ],
                  "abstract": "Over the years, two-way communications systems have continued to grow in their operating flexibility and mobility. The vehicle mounted radio has given way to the smaller, lower power radios. With communications associated with the person rather than the vehicle, entry into an apartment building, basement, garage or shopping center never leaves the user without communications to his base station. This increased mobility has placed additional demands on the coverage requirements.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00557"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Micro-Power LSI'd Hand Held Color Camera for ENG System",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "T. Imai",
                    "M. Kawasaki",
                    "Y. Ushiyama",
                    "K. Nagai",
                    "K. Yuasa",
                    "K. Wakui",
                    "T. Mochizuki"
                  ],
                  "abstract": "NEC placed emphasis on increased reliability and stability as the basic design concept for developing completely self-contained color camera for ENG. The result of examinations led us to think that power consumption reduced to the minimum and reduced heating are the prime requirements to realize the above aims. For without attaining those requirements, miniaturization of camera and driving over long period through battery those are essential for ENG camera are impossible. NEC owes it to NHK that NEC introduced the technical direction of “μ-POWER” as the fundamental design philosophy. Under the joint effort with NHK, NEC started development of μ-Power LSI of Process Amplifier in the summer of 1974 and the test product was developed in the spring of 1975. This product clearly indicated the possibility of LSI'd video circuit. with this knowledge, NEC expanded the scope of development of LSI including encoder, preamplifier, synchronizing system and deflection system to develop next generation color camera and the prototype of μ-Power LSI'd color camera was developed in October 1975. Commercialized first lot will be completed in the spring of 1976. The prototype camera is 3-tube color camera employing 2/3ʺ Plumbicon* that power consumption is approximately 25 W.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00553"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "New Developments in Electronic News Gathering Equipment",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "David K. MacDonald"
                  ],
                  "abstract": "Industrial and educational users associated with helical scan recording techniques are familiar with the extremely rapid rate manufacturers have been able to develop new products to meet non-broadcast applications. In fact, the technology in the helical scan market has moved so fast in the last ten years that some criticism has been voiced by users that technological obsolescence is assured within a year or two for industrial buyers. As an ex-product manager, I can empathize with the industrial user who has recently made a large cash outlay for video equipment only to find that newer and better equipment is in the offing a short time later. On the other hand, there is no doubt that the free enterprise pursuit of customers has benefited the industrial user tremendously through the development of a high quality, more reliable, and less expensive bevy of video products.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00554"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Experimental Production Use of the Canadian Domestic Satellite",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Peter Burgess"
                  ],
                  "abstract": "The Canadian Domestic communication satellite ANIK has now been in broadcasting distribution service for three years and, during that period, there has been a large expansion from the initial utilization. The main thrust to date has been providing a program distribution service, but some experimentation has been done in what can be better termed program production, utilizing unique capabilities offered by satellite.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00555"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Television News Gathering — A Balanced Approach",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edmund M. DiGiulio"
                  ],
                  "abstract": "I'm certainly delighted and pleased, and flattered, to be invited here this year again, as last year, at this marvelous love-feast of electronic camera manufacturers and performers of ENG. I'm really a little puzzled at why I have been invited. Is there some peculiar FCC rule that requires you to have a token minority film man in your midst?",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00556"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Microcam I: A New Concept in the Design of a Portable Color Camera for Broadcast Applications",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Renville H. McMann",
                    "Clyde W. Smith"
                  ],
                  "abstract": "During the eight years since the original Minicam, a proliferation of small color cameras has shown the tremendous utility of a broadcast quality camera that can be carried on the back and shoulders of a strong cameraman. The recent upsurge in electronic news gathering ENG has generated the need for a camera with the weight and operating simplicity of a movie camera, so that the cameraperson can be chosen for his or her journalistic ability rather than for sheer strength and technical competence. The Microcam described in this paper was developed by the same CBS Laboratories–now Thomson-CSF Laboratories–CBS Television Network team that developed the Minicam and the project benefited greatly from that experience. The project originated under the CBS Corporate Research Program and later was jointly sponsored by Thomson-CSF S. A. and the CBS Television Network.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00550"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Review of Electronic News Gathering Antennas with Multiple Polarization",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas J. Vaughan"
                  ],
                  "abstract": "Electronic News Gathering (ENG) has produced a requirement for Microwave Antennas that are Adaptable, Reliable and Reasonable in price.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00558"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Microwave Concepts for Electronic News Gathering",
                "article_url": "https://journal.smpte.org/conferences/Television%20Newsgathering:%2010th%20Annual%20SMPTE%20Winter%20Television%20Conference/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John Fielek"
                  ],
                  "abstract": "The Electronic News Gathering (ENG) concept has become an accepted method for television broadcasters to provide better and faster presentations of significant events to their viewers. ENG allows remote live events transmission to the studio for immediate taping or broadcasting.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1976-01"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00559"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1971",
        "conferences": [
          {
            "conference_name": "Video Cartridge, Cassette and Disc Player Systems: Proceedings of the Symposium",
            "conference_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/",
            "articles": [
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Stanley F. Quinn"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00176"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Socio-Economic Aspects of Videoplayer Systems — A Perspective",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wilton R. Holm"
                  ],
                  "abstract": "What we are going to discuss here today, has been called a new technology. Basically it involves a video-player, which may also be a video recorder, and which, when connected to the antenna terminals of a television monitor, or receiver, will reproduce, with sound, a prerecorded video program. The TV set is common to all systems which have been proposed. But the video-players of the various prospective systems involve not one, but several technologies. It would seem prudent then, that right at the beginning of our symposium we define “technology” and make some basic observations about technologies in a socio-economic context.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00177"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Video Cassettes — The New Medium",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Daniel I. Cooper"
                  ],
                  "abstract": "I wanted to start by speaking in French because we are in Montreal, and because I owe a debt to the program, as it is printed in French. Bi-lingualism fascinates me, and so I read the French as well as the English versions of my talk as it's given in this short form brochure that not all of you have. And I was struck by the difference, because in the English version, they speak of video cassettes as new medium; and in the French version it says video cassettes, 5 new medium.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00178"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "High-Speed Contact Duplication of Video Magnetic Tapes",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles E. Anderson"
                  ],
                  "abstract": "The first part of this paper reviews briefly the principles of contact duplication which were reported in several previous papers.1,2,3 These principles are applicable to all types of recordings regardless of tape format, quadruplex or helical. The second part discusses those problems which are particularly important when duplicating helical recordings.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00182"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Videoplayer Compatibility with Television Receivers",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Rolf Spies",
                    "Norman Parker",
                    "Albert W. Massman"
                  ],
                  "abstract": "In the past it has become common practice in commercial application of video playback systems to utilize video monitors that were especially designed to accept the video signals of a particular playback system. This enabled the designer to optimize both the video player and monitor for most practical and economical results. The necessary interconnections usually consisted of video and audio cables which made it very convenient to operate and set up the video playback system. However, when one considers the use of home television receivers as a means for monitoring the output signals of video players, the compatability of the signal with those receivers has to be kept in mind.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00183"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "Compatibility and Standardization of Various Systems of Video Cassettes",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Jose Bernhart"
                  ],
                  "abstract": "At the recent EBU colloquium at London, Dr. Zaccarian concluded his report on video recorders and players, intended for the general public's use, with these words: “The only characteristic common to all these systems is that there is none.”",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00184"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Cable Television Prospects for Cassette Systems",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "I. Switzer"
                  ],
                  "abstract": "Current cable television functions are centered on the “community antenna” concept. Cable systems receive television broadcast stations at either remote or local antenna sites and feed these broadcast television channels to paying subscribers. Some cable systems are originating some programs and program origination on cable systems is receiving increasing attention from the cable television industry and regulatory agencies. Some consideration is being given to the use of cable system facilities for generalized communications functions, some of which include the transmission of visual information.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00187"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Industrial Applications of Videoplayer Systems",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas R. Shepherd"
                  ],
                  "abstract": "For several years the subject of video player systems and their applications has been receiving a rising crescendo of attention from all quarters. Their potential as a new industry, their threat to existing industries, and the societal changes with which their introduction coincide give this new medium a special fascination. Our discussion focuses on industrial applications of video player systems, and includes observations on the questions of the potential in industry of these systems, their threat to existing products such as 16 millimeter films, and some of the ways in which their use relates to changes currently occurring in industry as well as the rest of society.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00188"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Another Chance for the Individual (Home Utilization of Video Cassettes)",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Paul J. Caravatt"
                  ],
                  "abstract": "When I was asked to talk about Home Utilization of Cassettes, I told However, we also have in the home several tests of cassette your Chairman that we had cassettes in use in the home today. We do – exactly six! However, we also have in the home several tests of cassette programing on videotape recorders and other technical devices that will be transferred to cassettes – some next week and more every week thereafter – until we are in several hundred homes by the end of next year.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00189"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "The Design Concept of the Sony Color Video Cassette Total System",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kazuo Iwama"
                  ],
                  "abstract": "It has been almost ten years since the video tape recorders were brought into use widely in the non-broadcasting industry. There are many types of applications of VTR's and as manufacturers of such VTR's, we have spent much time in considering a cassette type of video tape recorder as opposed to a reel-to-reel type. There is no doubt that a cassette is much easier to handle than an open reel. However, we have reached the conclusion that we must research and develop the VIDEOCASSETTE as a new total system of audio-visual communications, rather than a mere modification of existing VTR's. The reason being the following. Considering the operation of current slant-track VTR's, handling of the tape is the most burdensome area, not only regarding its threading on the recorders, but also touching the tape by finger contact is the cause of many problems. By eliminating tape handling, the cassette is most effective in playback operations. In the recording operation, the operator must provide a signal to be recorded, either from live cameras or other sources. The operator must be aware of technical factors of the program to be recorded. Even in recording an off-the-air signal, adjustment of the tuner is critical for good results. On the other hand, a VIDEOCASSETTE has a possibility of being capably handled by anyone with average knowledge, if the operation is limited to the reproduction of previously recorded information. Exploring the state-of-the-art of slant-track low-cost VTR's. we find that there is a large market of such application where a program has been recorded, dubbed to a number of cassettes, distributed ad then reproduced by those who want to view the program at a convenient time. In such cases where recording and reproduction can be separated, more complex recording techniques can be introduced in the recording operation if it is effective to simplify the operation of playback. The SONY Color VIDEOCASSETTE Total System has been based on these considerations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00190"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Super-8 Film: A Universal Input to Video Cassette and Television Systems, Part I: Application Concepts",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Eric A. Yavitz"
                  ],
                  "abstract": "No subject in recent memory has had as much discussion or aroused as much interest as the much-ballyhooed arrival of the video cassette. If it has done nothing else, the fanfare and publicity have served as a stimulus for many people to consider their visual communications requirements, and to examine what applications they might have for the video cassette when it arrives. The result has been a beneficial one, in that many potential applications have been uncovered, and some long-dormant ones have been dusted off and re-examined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00191"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Super-8 Film: A Universal Input to Video Cassette and Television Systems, Part II: Technical Consideration",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Joseph L. Boon"
                  ],
                  "abstract": "In a separate paper published above Eric Yavitz of Kodak's Motion Picture and Education Markets Division presented a story (Fig. 1) of the value of motion pictures in scanning systems which generate sound and picture information in a form ready to be fed into a standard home television receiver or into a telecasting system for reception by standard TV monitors. Mr. Yavitz also pointed out that film generated for this purpose is completely compatible for use in optical projection onto conventional reflection screens or onto rear projection screens, such as those found in education, etc.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00192"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Color Recording on the Video Disc",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Walter Bruch"
                  ],
                  "abstract": "In June 1970, the three companies AEG-TELEFUNKEN, DECCA and TELDEC, a subsidiary of AEG-TELEFUNKEN and DECCA, presented the world's first Video Disc for monochrome recording in Berlin. About one year later in August 1971, a color version of the Video Disc was demonstrated in Germany. The recording and play back process of the Video Disc requires the combination of luminance, color and audio information into a single signal which has been achieved by a new color video recording technique. Before describing this process the specifications and features of the disc and the player for the 625-line television standard should be summarized [1].",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00193"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Panel Discussions: Perspective and Utilization",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Gilles Bergeron, Sous-Ministre, Dept. of the Minister of Communications 930 Chemin Ste-Foy, Quebec 6, P.Q., Canada",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00194"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Some Reflections on Cassettes and Video Cassettes",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Claude Soule"
                  ],
                  "abstract": "Hardly a day goes by that we don't see press releases announcing the emergence – for 1971, 1972 or 1973 – of the “X-record” or “Y-vision” with a statement of the price or of the location of program supply, or of news of agreements reached with certain groups on certain processes outlining the rights on certain full-length films.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00180"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Techniques for Storage and Reproduction of Audio-Visual and Television Programs",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard Theile"
                  ],
                  "abstract": "Although we have had television for many years now, it is interesting to note that video cassettes for home use were developed only recently. There is good reason for this: the technical process for the storage of the visual image is much more complicated compared to that of sound. Therefore, more time was required for the development of the video storage means, i.e., the equivalent systems to the audio disc and tape. To be fair, there was one reasonably cheap system of picture storage in existence in the early days of television; that was the 8mm amateur film. Furthermore, this known medium also has gained considerable importance in the last few years by the introduction of television to the audio-visual business. So, one could generally say that the introduction of television techniques is the novel feature which caused the recent boom in the discussions about audio-visual developments.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00181"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Quebec 1971 and Information by Images",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gilles Bergeron"
                  ],
                  "abstract": "With your permission, I shall begin by extending to you the greetings and best wishes of Jean-Paul L'Allier, Minister of Communications, who is most happy to see you holding your annual meeting in Quçbec just when you have decided to study so vital a topic as new video equipment. Quçbec is keenly interested in these instruments of technical progress and this will be the subject of my talk. Indeed, Mr. L'Allier and the entire Department of Communications are eagerly looking forward to the results of your symposium discussions.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00185"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Audio-Visual Methods of Self-Education in the Health Sciences or “What You Want, when You Want it, where You Want it, and as Often as You Need it”",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "J. Norrie Swanson"
                  ],
                  "abstract": "In the Middle Ages, a young man who wished to become a doctor of medicine, was able to select his own teachers. Having heard for instance, of the reputation of a famous surgeon, say in Padua, he went there and served an apprenticeship until he had learned all that doctor could teach him. Then he travelled on to the next authority, making his selection according to what he felt was necessary to make him a good practitioner. (Fig. 1)",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00186"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Video Cassettes — Boom or Bust?",
                "article_url": "https://journal.smpte.org/conferences/Video%20Cartridge,%20Cassette%20and%20Disc%20Player%20Systems:%20Proceedings%20of%20the%20Symposium/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Gordon B. Thompson"
                  ],
                  "abstract": "In order to set the analysis that follows in perspective, let us divide the field of video cassettes, etc., into three classes: the prerecorded sort of thing that emulates today's phonograph and audio cassette business, the “do-it-yourself” kind of business that is typified by the Port-a-Pac video-tape recorder and resembles the present day audio tape recorder, and finally an electronic delivery system.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1971-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00179"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1970",
        "conferences": [
          {
            "conference_name": "Proceedings of the Symposium on Cable Television",
            "conference_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/",
            "articles": [
              {
                "article_local_id": "9",
                "article_title": "Suggested Technical Standards for CATV Program Origination",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lyle O. Keys"
                  ],
                  "abstract": "The National Cable Television Assoc. has recognized the need for establishing technical standards for CATV program origination. A Standards Committee has been formed to arrive at audio and video engineering standards to protect the interests of the viewing public while avoiding needless economic burdens on the CATV operator. Performance parameters considered for video standards are time-base stability, signal-to-noise ratio, resolution capabilities, synchronizing waveforms, transients, switching techniques and color-encoding methods. Tape format will not be of concern. Some of the recommendations will call for improvements of equipment by the manufacturers. Of major importance is the provision of a means of setting up cameras and encoders to ensure overall color accuracy and camera match without necessitating instrumentation and staffing comparable to that of broadcast stations.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00696"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Remarks before the SMPTE, October 8, 1970",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sol Schildhause"
                  ],
                  "abstract": "We're all here because of our common interest in CATV and I'd like to view with you some of what's going on in this very complicated process of evolving assemblance of a broadband cable system. I won't take you by the hand and mince through any romantic telling of how cable TV early got started. I'll also stay away from using “revolutionary technology”, “wave of the future”, “explosive new medium of communications”, and some of those other overworked and unbearably trite references. And I'll do my best not to drown you in a bath of statistics.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00689"
                  }
                }
              },
              {
                "article_local_id": "3",
                "article_title": "Broadband Communications: A View from the CAT-bird Seat",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Irving B. Kahn"
                  ],
                  "abstract": "“Catbird seat” is an expression meaning a place of advantage or privilege. Community Antenna Television operators may well consider themselves to be occupying a sort of special CAT-bird seat as their industry evolves rapidly into a new medium of broadband communications. History teaches that change is inevitable, that resistance to it is usually fatal. Broadband communications promises diversity of programing, pinpoint delivery to specific audiences, retention and recall of information and entertainment programs, and a wealth of non-entertainment services that, nevertheless, may employ entertainment techniques of presentation. In short, the motion-picture and television industries face not a threat but a rare opportunity to join the broadband evolution and become a part of a new and exiting era.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00690"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "Panel Discussion: The Coming Software Explosion for Cable Television",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Mr. Taylor: It has been said that engineers can do almost anything, provided that they have sufficient motivation and sufficient funding. The new age in communications is not awaiting technological development. With only a few exceptions, we know how to do what is to be done and how much time in which to do it. However, there is a certain lack of motivation in some places – a sort of hesitation, perhaps, to confront the conununication giants in the market places. This kind of foot dragging is understandable in the face of the unknown and with fear of the legal dragons which may have to be fought; but in a more important sense it arises from a misunderstanding of the essential characteristics of coaxial cable distribution systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00691"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "G. Norman Penwell"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00688"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "Automatic Programing for Cable Television",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Kenneth D. Lawson"
                  ],
                  "abstract": "There is limited economic incentive for major investments in research and development for automatic cablecasting. The size of the market is relatively small; the demand/supply curve is so steep that the price at which one half of the systems would buy is below that which suppliers will supply. Channel space is still lacking for multiple channel automatic services; the rate of cable system construction will remain depressed until copyright and other regulatory issues are settled. Local live studio operation will absorb the lion's share of available revenues for cablecasting. Many present equipment concepts should be converted to digital printout displays and color added; this will increase revenues for automatic equipment purchases. Better organized advertising programs will be developed for the expanding CATV market to help finance automatic program services.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00695"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Cable Television Needs a Complete Super-8 Film System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "G. Norman Penwell"
                  ],
                  "abstract": "A challenge is made to the film industry to develop a complete super-8 film chain for cable television. There are several equipment elements that remain to be developed before super 8 can become a viable and competitive medium for use in local origination and news coverage in cable-television operation. The unique attractions of super 8 for the cable-television industry are assessed and compared to the alternatives of 16mm film and videotape recording. The cable-television industry needs are outlined and projections of system growth throughout the next decade are made. The potential market for such a super-8 system is explored and a typical local origination studio using the super-8 format is proposed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00694"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "Simplified Color Slide TV Camera System for Cable Television",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "C. Bailey Neal"
                  ],
                  "abstract": "Experience with a broadcast-type four vidicon color film chain has indicated that to maintain good performance, frequent and skilled maintenance is required. A simplified color slide TV camera system has been developed using the flying-spot scanner principle. A recently-developed phosphor for color flying-spot tubes contributed substantially to the picture quality and signal-to-noise ratio improvement over previous color flying-spot cameras. A minimum number of operating adjustments is needed because of the inherent simplicity of a flying-spot camera and because the camera, encoder/matrix and sync generator incorporate circuits which inherently require minimum adjustment. Animation can be provided with polarized slides, if desired. The polarization system, which provides animation, has been designed to minimize unwanted color modulation. Automatic cuing of the slide projector advance mechanism, and an audio channel, can be incorporated.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00699"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "Operation and Control of the Professional-Type Color Camera through CATV Cable",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Anthony C. Cuomo"
                  ],
                  "abstract": "Digitally controlled color cameras and a two-way CATV cable make it possible to completely change the operating procedure in the origination of on-the-spot television pickups. Simply, the two-way CATV cable makes it possible to use this link as the “camera cable” between the digitally controlled color camera and its control unit. In the operation of the multiplexed type color camera, signals are sent to and from the CCU on RF carriers. These signals are compatible with those normally transmitted on CATV cable and include video, audio and control signals. The new two-way CATV cable can replace the coaxial-type camera cable, thereby requiring only the camera head to be transported to the field. All other remaining peripheral equipment can then remain in the broadcast center in its controlled environment. This system of operation offers potentially large savings in equipment and manpower. Some of the details of normal color camera control requirements, how the digitally controlled color camera operates, the signals on the coax camera cable and the capability of the two-way CATV cable to handle these signals are reviewed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00700"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Coaxial Cable for Municipal Services",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "E. A. Rollor",
                    "August F. Bruns"
                  ],
                  "abstract": "Communications is becoming more and more important as a means to increase efficiency of municipal operations. The availability of a frequency band of a megahertz or so on a passive coaxial cable system can offer a city a sufficient number of communications channels to serve its foreseeable needs for many years in the future. A relatively small size cable without repeater amplifiers can provide an extremely reliable transmission system. The cost is not great considering the capacity and versatility provided. If the cable television operator installs this cable system to be used primarily for commercial purposes, he can allocate a portion of the spectrum to the city as a token of good will. A proposal to provide such a communication medium is a very attractive feature in any package offered to a city in solicitation of a cable television franchise. The applications of this transmission system from the viewpoint of a city government may be classified generally as emergency alarm signalling, voice communications, data communications and slow-scan television.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00701"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "Utility Meter Reading and the Realization of Two-Way Communications",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "H. J. Moeller"
                  ],
                  "abstract": "Cable TV now serves about 7% of the TV sets in the nation. To increase this to more than 10%, something must be offered urban-subscribers which is not on individual antennas. Distant signals certainly will boost the penetration, but there are reasons to doubt that this alone could put CATV into the 20 million subscriber category. Closed-circuit programing by tape, film, microwave or satellite interconnection seems to be necessary but undeveloped. Feasibility is determined by what added capital costs are needed to be amortized annually to acquire the meter reading revenue and what is realistic to expect the utility industries to pay for a CATV operator. Revenue from specialized communication services could be great enough to lower CATV rates, with consequent increased penetration and an improved position for offering closed-circuit material at compensating extra charges.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00702"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Applications for a Bidirectional Broadband Coaxial Cable Communications System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Donald G. Chandler"
                  ],
                  "abstract": "Applications of bidirectional equipment for broadband coaxial cable communications are described. Emphasis is placed on a time-multiplexed, as contrasted with a frequency-multiplexed, system; particular emphasis is placed on actual test situations, including video surveillance, remote origination, educational applications, remote TV channel monitoring, utility-meter reading and burglar and fire alarm monitoring.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00703"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Interactive Television—What it Means to Cable Television",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edward J. Callahan"
                  ],
                  "abstract": "The promise that cable TV holds for the future of communications is multifaceted. Along with the high-quality television signals delivered to the homes many new services will be available. The functions required for these services can be categorized as follows: monitoring, control, keyboard data entry, hard and soft copy output and high-resolution display. The applications offered can be classified as user interactive or noninteractive. To accommodate these new functions, systems will have bidirectional capability and, in many cases, extended bandwidth approaching 300 MHz. Home terminals will have keyboards ranging in size from three or four buttons up to the size of a standard typewriter. Various system considerations are discussed relative to the addition of these new services to cable TV systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00704"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "How Receiver Design Affects Cable Television Performance Specifications",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "W. M. Harrold",
                    "J. D. Lovely"
                  ],
                  "abstract": "Performance specifications for Canadian cable systems applicable at the time of their license renewals are due for issue by the federal Department of Communications. The authors participated on the Canadian Radio Technical Planning Board in the preparation of the final draft version of this regulation, Broadcast Procedure 23, as the Electronic Industries Association representative presenting the receiver manufacturers' viewpoint. The pertinent performance specifications arrived at are reviewed. The rationale leading to the choice of limit values is discussed, along with the effect these may have on subjective receiver operation. Receiver design trends and their effect on CAN operation are discussed. CAN performance characteristics remaining as problems to receiver makers are noted and suggestions made on ways of alleviating the problems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00705"
                  }
                }
              },
              {
                "article_local_id": "19",
                "article_title": "Receiver/Cable Television Problems and Case Histories",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/19/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "I. Switzer"
                  ],
                  "abstract": "The cable TV system serves as a link between the broadcast transmitter and the home receiver. The broadcast transmitter, while not flawless, is usually built and maintained to professional standards. The household television receiver which serves as the final terminal in the television chain is often not maintained with the special technical requirements of cable television in mind. Some of the technical characteristics of CATV systems which affect receiver operation and maintenance are reviewed, with case histories of receiver/cable TV problems presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00706"
                  }
                }
              },
              {
                "article_local_id": "20",
                "article_title": "Panel Discussion: Receiver/Cable Television Interface",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/20/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Archer Taylor (Session Chairman), Malarkey, Taylor & Assoc., Inc., 1225 Connecticut Ave., N.W., Washington, DC 20036",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00707"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "Chrominance/Luminance Crosstalk in Cable Television Demodulators",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Charles W. Rhodes"
                  ],
                  "abstract": "Cable television systems frequently employ demodulators as part of their head-end equipment which convert the UHF or VHF-TV signal to video. Distortions of this (video) signal cannot generally be corrected. In the case of color TV signals, distortion changes the luminance level; it always is decreased in the case of the negative modulation. Quadrature distortion also is a systematic and fundamental source of differential gain, chrominance gain being reduced as the luminance level increases. When the cable television demodulator and the home receiver both contribute to the distortion, they are additive. The interrelationships of luminance errors and differential gain in terms of both luminance level and chrominance level are outlined for several different IF response characteristics. A new test signal to measure the luminance distortion and its application is discussed. Other methods are reviewed.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00697"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Ground Stations, the CATV Satellite Interface",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Hubert J. Schlafly"
                  ],
                  "abstract": "The opportunity for distribution of multichannel programing to all areas of the country is becoming a reality via the satellite/ground station technology. The economic viability of such a system, to a large measure, depends on the cost, performance and complexity of the many ground stations that would be required and by the local facilities for distributing those signals to the ultimate user. The Cable Television industry is well suited to provide this latter requirement and to provide the motivation for a favorable solution of the first requirement. The question of two-way transmission, via satellite at these multiple “head-end” locations, becomes a matter of great interest as a long-term consideration. The World Administrative Radio Conference now scheduled to convene in June 1971 in Geneva, Switzerland, may greatly influence this long-term consideration.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00692"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "A Color Camera Designed for Cable Television",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Wolter J. Wolthers"
                  ],
                  "abstract": "The design of a modular compact three-tube color camera particularly suited for use in cable television includes only the operational features required for CATV origination. The design is based on the prism beam-splitting system and three camera tubes. Either 1-in vidicon or 1-in Plumbicon tubes can be used. Two basic versions can be obtained because of the flexible modular design. The operation of the camera is automatic to a high degree; it is equipped with a 7-in electronic viewfinder and a video switching/audio unit. This unit contains the switches for the viewfinder video and input connectors for an external video signal, intercom headset and program microphone. The standard lens for the camera is a f/1.7, 25–125 mm zoom lens.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00698"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "Local Programing on Film for Cable Television",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Cable%20Television/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John A. Pistor",
                    "Earl W. Kage"
                  ],
                  "abstract": "There is an immediate requirement for some CATV systems to originate local programs and other material by April 1, 1971. The various means of preparing material to be used for local program or advertising origination is discussed. Production equipment which has already proven itself and which requires little maintenance is used. In this case it is 16mm. Some of the requirements for a CATV system are described, such as mobility, preplanning, the quality of the system and inter-changeability of the system with other systems.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1970-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00693"
                  }
                }
              }
            ]
          }
        ]
      },
      {
        "year": "1969",
        "conferences": [
          {
            "conference_name": "Proceedings of the Symposium on Super 8 Film Production Techniques",
            "conference_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/",
            "articles": [
              {
                "article_local_id": "3",
                "article_title": "The Evolution of Quality in 8mm Prints",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/3/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "John M. McDonough",
                    "Richard K. Schafer"
                  ],
                  "abstract": "Until ten years ago no extensive professional use was made of 8mm as a release-print material. Although some progress was made during the early sixties, it was not until the introduction of the super 8 format that 8mm received consideration as a prime medium for education and instructional technology. Expanding the use of films to many new areas of information transmittal now becomes a definite possibility. To realize this potential, however, it was recognized not only that better hardware was needed but that the entire film system needed upgrading. In improving the films in the system, it was the aim to produce a screen image from super 8 that was comparable in quality to the then existing 16mm systems. The step-by-step progress that has been made over the last few years toward achieving this goal is traced and predictions are made. The presentation is accompanied by a series of films.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00920"
                  }
                }
              },
              {
                "article_local_id": "10",
                "article_title": "The Future of Super 8 in the Department of Defense",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/10/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William F. Gallogly"
                  ],
                  "abstract": "The introduction of super 8 motion pictures into the Department of Defense (DOD) is an event of major proportions in the audio-visual field. Within the DOD the applications of this relatively new media are endless and will be used to serve a common purpose in indoctrination, education, training and orientation. The lightweight, simplified equipment with its accompanying lower cost has made it possible to use motion pictures in more places and in more ways. The key to the future use of super 8 is to be found in acceptance and agreement by industry that a universal standard for the compatible cartridge is an absolute necessity. The economy in laboratory and print processing will open the gates to unlimited demand and large-scale inventories of super 8 film and equipment. The basic problem confronting the DOD as it affects the future of super 8 is the desire to introduce proprietary cartridges and projectors into the system, thereby possibly permitting a reduction in the role of the Armed Forces as a producer and supplier of training films. Prior to any standardization or commitment by the DOD, all available products under development on the market will be examined.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00927"
                  }
                }
              },
              {
                "article_local_id": "5",
                "article_title": "Parameters for Super 8 Optical Sound",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/5/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Edgar A. Schuller",
                    "John Arvonio"
                  ],
                  "abstract": "Commercially acceptable optical sound quality on Super 8 composite prints can be realized in film laboratories on a routine production basis with the present state of technology. In order to insure a high state of consistency in sound quality it is necessary to specify and control the parameters which circumscribe this extremely small format. The parameters which must be defined are in the three general areas of recording, duplication and reproduction; these are described in detail. The various formats now used to produce super 8 optical sound prints are described. Characteristics of the formats which effect production capability and quality are detailed. These films, useful for maintaining consistency of the system are described. A wide range of program material is demonstrated on various reproducers and compared to the original tape master.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00922"
                  }
                }
              },
              {
                "article_local_id": "11",
                "article_title": "Super 8: A Producer's Viewpoint",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/11/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "George A. Howard"
                  ],
                  "abstract": "The introduction and acceptance of super 8 has created completely new problems for the motion-picture industry, lying in all areas of production and in laboratories. In addition, completely new procedures have had to be established for handling and control of material being produced for release in 8mm and in the release prints themselves. All aspects of this film format are discussed from the viewpoint of a producer-distributor, considering the laboratory area from a customer's standpoint.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00928"
                  }
                }
              },
              {
                "article_local_id": "6",
                "article_title": "16mm and Super 8: Noncompetitive Media",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/6/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Sidney P. Solow"
                  ],
                  "abstract": "The present large-scale utilization of 16mm in the field of educational, business and religious films seems to be undisturbed by the growth of super 8. The smaller film has made feasible audio-visual techniques which have created new and expanding markets. Samples of technical subjects are shown to illustrate some of the areas in which motion pictures, because of super 8, are being used widely for the first time.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00923"
                  }
                }
              },
              {
                "article_local_id": "4",
                "article_title": "8mm Cartridge/Cassette/Film Standardization",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/4/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Lee H. Schank"
                  ],
                  "abstract": "A brief review of 8mm sound cartridge/cassette systems is presented as a basis for views on the future directions of product development in the field and what is being done to spur further growth of the market. Technical aspects of optical versus magnetic sound is covered.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00921"
                  }
                }
              },
              {
                "article_local_id": "7",
                "article_title": "Lack of Standardization on Hardware in Super 8",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/7/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "G. Carleton Hunt"
                  ],
                  "abstract": "A brief review of the 8mm format is given. There was an increased interest in professional 8mm in the early sixties. The potential of the 8mm-width print film was retarded by the lack of existing standards. Standardization is essential to provide a base for widespread use and worldwide distribution. The possibility of 8mm print footage surpasses both 35mm and 16mm if the industry adopts the necessary standards.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00924"
                  }
                }
              },
              {
                "article_local_id": "12",
                "article_title": "The Standardization of the Super 8 System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/12/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Roland J. Zavada"
                  ],
                  "abstract": "The super 8 system was commercially introduced in 1965. Coincident with this introduction, proposals to standardize film and equipment were made to the Society of Motion Picture and Television Engineers, followed by proposals for international recommendations. Commercial acceptance has traditionally been a guideline for national standardization to insure that through practical experience the dimensions and specifications are reasonably valid. To obtain equivalent reliability, the early standardization of the super 8 system required the prerequisite of an informed industry. National standards have been approved on more than half of the 29 subjects of the super 8 system originally considered as standard proposals. Most of the remaining subjects have received engineering committee consideration and are in the final stages of approval. There is considerable feeling in the industry that there is insufficient standardization, principally in the use of super 8 sound film in cassette or cartridge projection systems. The SMPTE is expected to guide the establishment of standards; however, the Society cannot become involved in the comparative rating of competitive items.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00929"
                  }
                }
              },
              {
                "article_local_id": "1",
                "article_title": "Foreword",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/1/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Richard J. Goldberg"
                  ],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00918"
                  }
                }
              },
              {
                "article_local_id": "2",
                "article_title": "Super 8: Whither Bound?",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/2/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Norwood L. Simmons"
                  ],
                  "abstract": "A significant benefit of the super 8 system is that it now makes the motion picture medium accessible for small-group and individual viewing. Implications of this breakthrough are discussed in terms of 8mm statistics and potential markets. Six key attributes of super 8 are flexibility, accessibility, repeatability, controllability, compatibility and profitability. Compatibility and performance factors influencing the choice of a super 8 sound system and a cartridge design are discussed in terms of the eventual potentialities of this new format in screen communication.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00919"
                  }
                }
              },
              {
                "article_local_id": "13",
                "article_title": "The Possibilities and Advantages of 8mm Film in the Educational Field",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/13/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Walter Cappel"
                  ],
                  "abstract": "The merits of 8mm film in education are pointed out. Three factors necessary for creating a new aptitude are motivation, understanding and knowhow. Informative films show new methods (readiness). Educational films, which are usually short and silent, demonstrate events which cannot be observed directly, e.g., high-speed photography, time-lapse photography, microphotography and special effects. They give insight. Instructional films give knowhow for building a skill, especially when the student can practice what he learns from the film.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00930"
                  }
                }
              },
              {
                "article_local_id": "16",
                "article_title": "Panel Discussion: Super 8 Production Techniques",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/16/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "Dr. Goldberg called upon the authors of the Symposium papers to assemble as a panel. Roland Connor took the place of Norwood L. Simmons; Col. William F. Gallogly and Walter Cappel were absent.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00933"
                  }
                }
              },
              {
                "article_local_id": "9",
                "article_title": "A Super 8 Projection Cartridge System for Automatic Loading and Operation",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/9/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "R. C. Gearhart",
                    "M. E. Brown"
                  ],
                  "abstract": "Super 8 films, cameras, projectors and auxilliary equipment may properly be described as comprising a system in which the common super 8 film format is intended to serve the widest possible variety of photographic display applications. Subsystem needs include a projection cartridge offering film loading, cleaning and editing simplicity in addition to operating reliability and handling convenience. A super 8 projector design utilizing a new film cartridge system is described. A number of unique features involved in the cartridge and projection system are covered in some detail. These features include the cartridge mounting, automatic film take-up assembly and automatic rewind and review.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00926"
                  }
                }
              },
              {
                "article_local_id": "17",
                "article_title": "Standards on the Super 8 System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/17/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00934"
                  }
                }
              },
              {
                "article_local_id": "18",
                "article_title": "Bibliography",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/18/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [],
                  "abstract": "",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00935"
                  }
                }
              },
              {
                "article_local_id": "14",
                "article_title": "Loop Projectors and Optical Sound",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/14/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Frank P. Brackett",
                    "Paul Galanis",
                    "Armand Paul",
                    "William Newbern",
                    "Douglas Fletcher"
                  ],
                  "abstract": "The technical processing specifications for super 8 optical sound along with the characteristics of the sound system in the Technicolor loop cartridge projector is described. The channels available for preparing super 8 from various types of negatives (65mm, 35mm, 16mm sizes and 133, 185 and other aspect ratios) are discussed in detail. The use of super 8 in education, the capability film has to increase visual literacy and reduce the signal-to-noise ratio in the process of transmission of learning sequences are outlined. The situation regarding optical or magnetic, sound film standards by markets and equipment trends are reviewed. A live on-screen super 8 comparison to 16mm is presented.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00931"
                  }
                }
              },
              {
                "article_local_id": "15",
                "article_title": "The Bell & Howell 8mm Cartridge Projection System",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/15/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "Thomas J. Rappel",
                    "Frank L. Windsor"
                  ],
                  "abstract": "Standardization of cartridge systems is very desirable for the industry assuming certain criteria are met. Such a standard system should be: easy to use; reliable; of minimum cost; versatile, so as not to restrict the use of other projector features such as multiple play, rewind, and high or low speed projection; and adaptable, both to different markets and to various projector design. The Bell & Howell open loop or reel type rim drive cartridge system is described as a system to meet all the criteria given.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00932"
                  }
                }
              },
              {
                "article_local_id": "8",
                "article_title": "8mm Printing Systems",
                "article_url": "https://journal.smpte.org/conferences/Proceedings%20of%20the%20Symposium%20on%20Super%208%20Film%20Production%20Techniques/8/",
                "article_tags": [
                  "Original Research"
                ],
                "metadata": {
                  "authors": [
                    "William D. Hedden"
                  ],
                  "abstract": "Most 8mm release prints are derived from productions originally photographed on either 16mm or 35mm materials. Several methods of printing involving reduction steps have been used commercially. Some of the printing systems used and some of the printing equipment that has been or is being used by different laboratories for the making of large quantities of 8mm release prints are described.",
                  "pub-date": {
                    "readable_descriptor": "Published",
                    "essence": "1969-10"
                  },
                  "content-type": {
                    "readable_descriptor": "Content type",
                    "essence": "Original Research"
                  },
                  "doi": {
                    "readable_descriptor": "DOI",
                    "essence": "10.5594/M00925"
                  }
                }
              }
            ]
          }
        ]
      }
    ]
  }
]